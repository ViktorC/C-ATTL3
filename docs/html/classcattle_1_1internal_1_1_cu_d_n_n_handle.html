<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: cattle::internal::CuDNNHandle&lt; Scalar &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecattle.html">cattle</a></li><li class="navelem"><a class="el" href="namespacecattle_1_1internal.html">internal</a></li><li class="navelem"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">CuDNNHandle</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="classcattle_1_1internal_1_1_cu_d_n_n_handle-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">cattle::internal::CuDNNHandle&lt; Scalar &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>A singleton utility class providing methods for GPU accelerated deep neural network operations on rank 4 data.  
 <a href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_cu_d_n_n_handle_8hpp_source.html">CuDNNHandle.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a7407f99110a39d1029cf017322a87d9b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a7407f99110a39d1029cf017322a87d9b">op</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;a, Scalar alpha, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;b, Scalar beta, cudnnOpTensorOp_t op_type, Scalar gamma, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;c) const</td></tr>
<tr class="memdesc:a7407f99110a39d1029cf017322a87d9b"><td class="mdescLeft">&#160;</td><td class="mdescRight">It performs the specified operation on tensors a and b and saves the result in c.  <a href="#a7407f99110a39d1029cf017322a87d9b">More...</a><br /></td></tr>
<tr class="separator:a7407f99110a39d1029cf017322a87d9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a029824a2ec8a03cc177ff99e39b8d3af"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a029824a2ec8a03cc177ff99e39b8d3af">add_bias</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;bias, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;tensor) const</td></tr>
<tr class="memdesc:a029824a2ec8a03cc177ff99e39b8d3af"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adds a bias tensor to another tensor.  <a href="#a029824a2ec8a03cc177ff99e39b8d3af">More...</a><br /></td></tr>
<tr class="separator:a029824a2ec8a03cc177ff99e39b8d3af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e86661f3b3efc544dd34a801b1e851e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a5e86661f3b3efc544dd34a801b1e851e">conv2d_output_dims</a> (std::size_t input_height, std::size_t input_width, std::size_t input_channels, std::size_t filters, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation, std::size_t &amp;output_height, std::size_t &amp;output_width, std::size_t &amp;output_channels) const</td></tr>
<tr class="memdesc:a5e86661f3b3efc544dd34a801b1e851e"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the dimensions of the output tensor of the convolution.  <a href="#a5e86661f3b3efc544dd34a801b1e851e">More...</a><br /></td></tr>
<tr class="separator:a5e86661f3b3efc544dd34a801b1e851e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa70ea0feb72e78b1d0f209692acf67bd"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#aa70ea0feb72e78b1d0f209692acf67bd">convolution2d_fwd</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar, true &gt; &amp;filter, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;bias, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:aa70ea0feb72e78b1d0f209692acf67bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs a GPU accelerated 2D convolution on a rank 4 tensor.  <a href="#aa70ea0feb72e78b1d0f209692acf67bd">More...</a><br /></td></tr>
<tr class="separator:aa70ea0feb72e78b1d0f209692acf67bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79ac548344b6f983d444686a8d98b4e9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a79ac548344b6f983d444686a8d98b4e9">convolution2d_bwd</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;out_grad, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar, true &gt; &amp;filter, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;bias, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;prev_out_grad, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar, true &gt; &amp;filter_grad, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;bias_grad) const</td></tr>
<tr class="memdesc:a79ac548344b6f983d444686a8d98b4e9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs a backward 2D convolution on a rank 4 tensor to compute the gradients of the output of the previous layer, the convolution filter, and the bias.  <a href="#a79ac548344b6f983d444686a8d98b4e9">More...</a><br /></td></tr>
<tr class="separator:a79ac548344b6f983d444686a8d98b4e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55b831a2eb7cbc840f5cae8ee89a5570"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a55b831a2eb7cbc840f5cae8ee89a5570">activation_fwd</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, cudnnActivationMode_t act_mode, Scalar coeff, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:a55b831a2eb7cbc840f5cae8ee89a5570"><td class="mdescLeft">&#160;</td><td class="mdescRight">It applies the specified activation function the the input tensor.  <a href="#a55b831a2eb7cbc840f5cae8ee89a5570">More...</a><br /></td></tr>
<tr class="separator:a55b831a2eb7cbc840f5cae8ee89a5570"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d6df977da77c67928f92b474dc1a285"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a2d6df977da77c67928f92b474dc1a285">activation_bwd</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output, cudnnActivationMode_t act_mode, Scalar coeff, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;in_out_grad) const</td></tr>
<tr class="memdesc:a2d6df977da77c67928f92b474dc1a285"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the gradient of the input of the activation function.  <a href="#a2d6df977da77c67928f92b474dc1a285">More...</a><br /></td></tr>
<tr class="separator:a2d6df977da77c67928f92b474dc1a285"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a992cae7a1c58ef7bb4e8460072632530"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a992cae7a1c58ef7bb4e8460072632530">softmax_fwd</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:a992cae7a1c58ef7bb4e8460072632530"><td class="mdescLeft">&#160;</td><td class="mdescRight">It applies the softmax activation function the the input tensor.  <a href="#a992cae7a1c58ef7bb4e8460072632530">More...</a><br /></td></tr>
<tr class="separator:a992cae7a1c58ef7bb4e8460072632530"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa593cec63c9a1f53fa222a667462fe8c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#aa593cec63c9a1f53fa222a667462fe8c">softmax_bwd</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;in_out_grad) const</td></tr>
<tr class="memdesc:aa593cec63c9a1f53fa222a667462fe8c"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the gradient of the input of the softmax activation function.  <a href="#aa593cec63c9a1f53fa222a667462fe8c">More...</a><br /></td></tr>
<tr class="separator:aa593cec63c9a1f53fa222a667462fe8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63f47c31ba65badd22da7ce3c0aa07d0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a63f47c31ba65badd22da7ce3c0aa07d0">pool2d_output_dims</a> (std::size_t input_height, std::size_t input_width, std::size_t input_channels, cudnnPoolingMode_t pool_mode, std::size_t window_height, std::size_t window_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t &amp;output_height, std::size_t &amp;output_width, std::size_t &amp;output_channels) const</td></tr>
<tr class="memdesc:a63f47c31ba65badd22da7ce3c0aa07d0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the dimensions of the output of the 2D pooling operation.  <a href="#a63f47c31ba65badd22da7ce3c0aa07d0">More...</a><br /></td></tr>
<tr class="separator:a63f47c31ba65badd22da7ce3c0aa07d0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9dc3603f13b1f318e228691c32bafe13"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a9dc3603f13b1f318e228691c32bafe13">pool2d_fwd</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, cudnnPoolingMode_t pool_mode, std::size_t window_height, std::size_t window_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:a9dc3603f13b1f318e228691c32bafe13"><td class="mdescLeft">&#160;</td><td class="mdescRight">It performs a 2D pooling operation on the input tensor.  <a href="#a9dc3603f13b1f318e228691c32bafe13">More...</a><br /></td></tr>
<tr class="separator:a9dc3603f13b1f318e228691c32bafe13"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae950696a0abb68c382586d99ffc99711"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#ae950696a0abb68c382586d99ffc99711">pool2d_bwd</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;out_grad, cudnnPoolingMode_t pool_mode, std::size_t window_height, std::size_t window_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;prev_out_grad) const</td></tr>
<tr class="memdesc:ae950696a0abb68c382586d99ffc99711"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the gradient of the input of the pooling layer.  <a href="#ae950696a0abb68c382586d99ffc99711">More...</a><br /></td></tr>
<tr class="separator:ae950696a0abb68c382586d99ffc99711"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afde3ec8e42cf81996320995d1b037cff"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#afde3ec8e42cf81996320995d1b037cff">batch_norm_fwd_training</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;gamma, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;beta, bool spatial, Scalar exp_avg_factor, Scalar epsilon, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;means, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;vars, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;mean_cache, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;inv_var_cache) const</td></tr>
<tr class="memdesc:afde3ec8e42cf81996320995d1b037cff"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies the batch normalization function to the input data and updates the running mean and variance averages.  <a href="#afde3ec8e42cf81996320995d1b037cff">More...</a><br /></td></tr>
<tr class="separator:afde3ec8e42cf81996320995d1b037cff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3094b231c417426b06f0e84dc8832994"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a3094b231c417426b06f0e84dc8832994">batch_norm_fwd_inference</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;gamma, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;beta, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;means, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;vars, bool spatial, Scalar epsilon, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:a3094b231c417426b06f0e84dc8832994"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies the batch normalization function to the input data for inference using the running mean and variance averages.  <a href="#a3094b231c417426b06f0e84dc8832994">More...</a><br /></td></tr>
<tr class="separator:a3094b231c417426b06f0e84dc8832994"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2f42cc9e92ed9c8255f3790af4d0e4b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#af2f42cc9e92ed9c8255f3790af4d0e4b">batch_norm_bwd</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;out_grad, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;gamma, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;mean_cache, const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;inv_var_cache, bool spatial, Scalar epsilon, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;prev_out_grad, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;gamma_grad, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;beta_grad) const</td></tr>
<tr class="memdesc:af2f42cc9e92ed9c8255f3790af4d0e4b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the backward pass of the batch normalization function and computes the gradients of the function's input, the gamma scaling tensor, and the beta bias tensor.  <a href="#af2f42cc9e92ed9c8255f3790af4d0e4b">More...</a><br /></td></tr>
<tr class="separator:af2f42cc9e92ed9c8255f3790af4d0e4b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa832a112b2c4f51291749a4de7116f54"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#aa832a112b2c4f51291749a4de7116f54">dropout_state_size</a> (std::size_t &amp;state_size) const</td></tr>
<tr class="memdesc:aa832a112b2c4f51291749a4de7116f54"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the necessary state size required for the RNG used by the dropout function.  <a href="#aa832a112b2c4f51291749a4de7116f54">More...</a><br /></td></tr>
<tr class="separator:aa832a112b2c4f51291749a4de7116f54"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e55aa4c437ddcbe0fe32c81cf511555"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a7e55aa4c437ddcbe0fe32c81cf511555">dropout_reserve_size</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, std::size_t &amp;reserve_size) const</td></tr>
<tr class="memdesc:a7e55aa4c437ddcbe0fe32c81cf511555"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the necessary reserve size for the dropout.  <a href="#a7e55aa4c437ddcbe0fe32c81cf511555">More...</a><br /></td></tr>
<tr class="separator:a7e55aa4c437ddcbe0fe32c81cf511555"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02d1da9583070b2b02db099b1e5f2ab3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a02d1da9583070b2b02db099b1e5f2ab3">dropout_fwd</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, Scalar dropout, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;state, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;reserve, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:a02d1da9583070b2b02db099b1e5f2ab3"><td class="mdescLeft">&#160;</td><td class="mdescRight">It applies the dropout function to the input tensor.  <a href="#a02d1da9583070b2b02db099b1e5f2ab3">More...</a><br /></td></tr>
<tr class="separator:a02d1da9583070b2b02db099b1e5f2ab3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3dcf87e328ad64c5604767ee25ca192"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#ab3dcf87e328ad64c5604767ee25ca192">dropout_bwd</a> (const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;out_grad, Scalar dropout, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;state, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;reserve, <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;prev_out_grad) const</td></tr>
<tr class="memdesc:ab3dcf87e328ad64c5604767ee25ca192"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the gradient of the input of the dropout function.  <a href="#ab3dcf87e328ad64c5604767ee25ca192">More...</a><br /></td></tr>
<tr class="separator:ab3dcf87e328ad64c5604767ee25ca192"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a9b27fe08963ff261ffb0e1b3ba288b40"><td class="memItemLeft" align="right" valign="top">static const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">Self</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a9b27fe08963ff261ffb0e1b3ba288b40">get_instance</a> ()</td></tr>
<tr class="separator:a9b27fe08963ff261ffb0e1b3ba288b40"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Scalar&gt;<br />
class cattle::internal::CuDNNHandle&lt; Scalar &gt;</h3>

<p>A singleton utility class providing methods for GPU accelerated deep neural network operations on rank 4 data. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a2d6df977da77c67928f92b474dc1a285"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d6df977da77c67928f92b474dc1a285">&#9670;&nbsp;</a></span>activation_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::activation_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnActivationMode_t&#160;</td>
          <td class="paramname"><em>act_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>in_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the gradient of the input of the activation function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">act_mode</td><td>The type of activation function used. </td></tr>
    <tr><td class="paramname">coeff</td><td>The activation function coefficient used by certain activation functions (e.g. ELU). </td></tr>
    <tr><td class="paramname">in_out_grad</td><td>The gradient of the output of the activation function and after the method finishes execution, the gradient of the input of the activation function. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a55b831a2eb7cbc840f5cae8ee89a5570"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a55b831a2eb7cbc840f5cae8ee89a5570">&#9670;&nbsp;</a></span>activation_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::activation_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnActivationMode_t&#160;</td>
          <td class="paramname"><em>act_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It applies the specified activation function the the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">act_mode</td><td>The type of activation function to use. </td></tr>
    <tr><td class="paramname">coeff</td><td>The activation function coefficient used by certain activation functions (e.g. ELU). </td></tr>
    <tr><td class="paramname">output</td><td>The activated output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a029824a2ec8a03cc177ff99e39b8d3af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a029824a2ec8a03cc177ff99e39b8d3af">&#9670;&nbsp;</a></span>add_bias()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::add_bias </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>tensor</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Adds a bias tensor to another tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bias</td><td>The bias tensor. </td></tr>
    <tr><td class="paramname">tensor</td><td>The tensor to which the bias is to be added. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="af2f42cc9e92ed9c8255f3790af4d0e4b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af2f42cc9e92ed9c8255f3790af4d0e4b">&#9670;&nbsp;</a></span>batch_norm_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::batch_norm_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>mean_cache</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>inv_var_cache</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>spatial</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>gamma_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>beta_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the backward pass of the batch normalization function and computes the gradients of the function's input, the gamma scaling tensor, and the beta bias tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor used. </td></tr>
    <tr><td class="paramname">out_grad</td><td>The gradient of the output of the function. </td></tr>
    <tr><td class="paramname">gamma</td><td>The gamma scaling tensor. </td></tr>
    <tr><td class="paramname">mean_cache</td><td>The mean cached during the forward pass. </td></tr>
    <tr><td class="paramname">inv_var_cache</td><td>The inverse variance cached during the forward pass. </td></tr>
    <tr><td class="paramname">spatial</td><td>Whether the batch normalization should be performed in spatial or per-activation mode. </td></tr>
    <tr><td class="paramname">epsilon</td><td>A small constant for numerical stability. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the batch normalization function's input. </td></tr>
    <tr><td class="paramname">gamma_grad</td><td>The gradient of gamma. </td></tr>
    <tr><td class="paramname">beta_grad</td><td>The gradient of beta. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a3094b231c417426b06f0e84dc8832994"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3094b231c417426b06f0e84dc8832994">&#9670;&nbsp;</a></span>batch_norm_fwd_inference()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::batch_norm_fwd_inference </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>means</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>vars</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>spatial</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies the batch normalization function to the input data for inference using the running mean and variance averages. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">gamma</td><td>The gamma scaling tensor. </td></tr>
    <tr><td class="paramname">beta</td><td>The beta bias. </td></tr>
    <tr><td class="paramname">means</td><td>The running mean average. </td></tr>
    <tr><td class="paramname">vars</td><td>The running variance average. </td></tr>
    <tr><td class="paramname">spatial</td><td>Whether the batch normalization should be performed in spatial or per-activation mode. </td></tr>
    <tr><td class="paramname">epsilon</td><td>A small constant for numerical stability. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="afde3ec8e42cf81996320995d1b037cff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afde3ec8e42cf81996320995d1b037cff">&#9670;&nbsp;</a></span>batch_norm_fwd_training()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::batch_norm_fwd_training </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>spatial</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>exp_avg_factor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>means</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>vars</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>mean_cache</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>inv_var_cache</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies the batch normalization function to the input data and updates the running mean and variance averages. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">gamma</td><td>The gamma scaling tensor. </td></tr>
    <tr><td class="paramname">beta</td><td>The beta bias. </td></tr>
    <tr><td class="paramname">spatial</td><td>Whether the batch normalization should be performed in spatial or per-activation mode. </td></tr>
    <tr><td class="paramname">exp_avg_factor</td><td>The exponential average factor for the running mean and variance averages. </td></tr>
    <tr><td class="paramname">epsilon</td><td>A small constant for numerical stability. </td></tr>
    <tr><td class="paramname">means</td><td>The running mean average (it gets updated by the method). </td></tr>
    <tr><td class="paramname">vars</td><td>The running variance average (it gets updated by the method). </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">mean_cache</td><td>The cached mean for back-propagation. </td></tr>
    <tr><td class="paramname">inv_var_cache</td><td>The cached inverse variance for back-propagation. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a5e86661f3b3efc544dd34a801b1e851e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5e86661f3b3efc544dd34a801b1e851e">&#9670;&nbsp;</a></span>conv2d_output_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::conv2d_output_dims </td>
          <td>(</td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>filters</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>receptor_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>receptor_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_channels</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the dimensions of the output tensor of the convolution. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_height</td><td>The input height. </td></tr>
    <tr><td class="paramname">input_width</td><td>The input width. </td></tr>
    <tr><td class="paramname">input_channels</td><td>The number of input channels. </td></tr>
    <tr><td class="paramname">filters</td><td>The number of convolution filters. </td></tr>
    <tr><td class="paramname">receptor_height</td><td>The height of the receptor. </td></tr>
    <tr><td class="paramname">receptor_width</td><td>The width of the receptor. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the convolution. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the convolution. </td></tr>
    <tr><td class="paramname">vertical_dilation</td><td>The vertical dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">horizontal_dilation</td><td>The horizontal dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">output_height</td><td>The output height. </td></tr>
    <tr><td class="paramname">output_width</td><td>The output width. </td></tr>
    <tr><td class="paramname">output_channels</td><td>The number of output channels. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a79ac548344b6f983d444686a8d98b4e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a79ac548344b6f983d444686a8d98b4e9">&#9670;&nbsp;</a></span>convolution2d_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::convolution2d_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar, true &gt; &amp;&#160;</td>
          <td class="paramname"><em>filter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar, true &gt; &amp;&#160;</td>
          <td class="paramname"><em>filter_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>bias_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs a backward 2D convolution on a rank 4 tensor to compute the gradients of the output of the previous layer, the convolution filter, and the bias. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">out_grad</td><td>The gradient of the output tensor. </td></tr>
    <tr><td class="paramname">filter</td><td>The convolution filter. </td></tr>
    <tr><td class="paramname">bias</td><td>The bias tensor applied to the output of the convolution. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the convolution. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the convolution. </td></tr>
    <tr><td class="paramname">vertical_dilation</td><td>The vertical dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">horizontal_dilation</td><td>The horizontal dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the previous layer's output tensor. </td></tr>
    <tr><td class="paramname">filter_grad</td><td>The gradient of the convolution filter. </td></tr>
    <tr><td class="paramname">bias_grad</td><td>The gradient of the bias tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aa70ea0feb72e78b1d0f209692acf67bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa70ea0feb72e78b1d0f209692acf67bd">&#9670;&nbsp;</a></span>convolution2d_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::convolution2d_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar, true &gt; &amp;&#160;</td>
          <td class="paramname"><em>filter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs a GPU accelerated 2D convolution on a rank 4 tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">filter</td><td>The convolution filter. </td></tr>
    <tr><td class="paramname">bias</td><td>The bias tensor to apply to the output of the convolution. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the convolution. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the convolution. </td></tr>
    <tr><td class="paramname">vertical_dilation</td><td>The vertical dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">horizontal_dilation</td><td>The horizontal dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">output</td><td>The convolution output tensor with the bias applied to it. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ab3dcf87e328ad64c5604767ee25ca192"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3dcf87e328ad64c5604767ee25ca192">&#9670;&nbsp;</a></span>dropout_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::dropout_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>dropout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>reserve</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the gradient of the input of the dropout function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out_grad</td><td>The gradient of the output of the dropout function. </td></tr>
    <tr><td class="paramname">state</td><td>The memory used by the RNG. </td></tr>
    <tr><td class="paramname">reserve</td><td>The reserve filled during the forward pass. </td></tr>
    <tr><td class="paramname">dropout</td><td>The average factor of elements set to 0 in the input tensor. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the input of the dropout function. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a02d1da9583070b2b02db099b1e5f2ab3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a02d1da9583070b2b02db099b1e5f2ab3">&#9670;&nbsp;</a></span>dropout_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::dropout_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>dropout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>reserve</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It applies the dropout function to the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">dropout</td><td>The average factor of elements to set to 0 in the input tensor. </td></tr>
    <tr><td class="paramname">state</td><td>The memory used by the RNG. </td></tr>
    <tr><td class="paramname">reserve</td><td>The reserve used for backpropagation. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a7e55aa4c437ddcbe0fe32c81cf511555"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7e55aa4c437ddcbe0fe32c81cf511555">&#9670;&nbsp;</a></span>dropout_reserve_size()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::dropout_reserve_size </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>reserve_size</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the necessary reserve size for the dropout. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">reserve_size</td><td>The reserve size. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aa832a112b2c4f51291749a4de7116f54"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa832a112b2c4f51291749a4de7116f54">&#9670;&nbsp;</a></span>dropout_state_size()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::dropout_state_size </td>
          <td>(</td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>state_size</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the necessary state size required for the RNG used by the dropout function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">state_size</td><td>The state size. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a9b27fe08963ff261ffb0e1b3ba288b40"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9b27fe08963ff261ffb0e1b3ba288b40">&#9670;&nbsp;</a></span>get_instance()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">Self</a>&amp; <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::get_instance </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>A reference to the only instance of the class. </dd></dl>

</div>
</div>
<a id="a7407f99110a39d1029cf017322a87d9b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7407f99110a39d1029cf017322a87d9b">&#9670;&nbsp;</a></span>op()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::op </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>b</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnOpTensorOp_t&#160;</td>
          <td class="paramname"><em>op_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>c</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It performs the specified operation on tensors a and b and saves the result in c. </p>
<p>\(C = op(\alpha * A, \beta * B) + \gamma * C\)</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">a</td><td>The first operand. </td></tr>
    <tr><td class="paramname">alpha</td><td>The scaling factor of the first operand. </td></tr>
    <tr><td class="paramname">b</td><td>The second operand. </td></tr>
    <tr><td class="paramname">beta</td><td>The scaling factor of the second operand. </td></tr>
    <tr><td class="paramname">op_type</td><td>The operation type. </td></tr>
    <tr><td class="paramname">gamma</td><td>The scaling factor of the result tensor. </td></tr>
    <tr><td class="paramname">c</td><td>The resutl tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae950696a0abb68c382586d99ffc99711"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae950696a0abb68c382586d99ffc99711">&#9670;&nbsp;</a></span>pool2d_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::pool2d_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnPoolingMode_t&#160;</td>
          <td class="paramname"><em>pool_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the gradient of the input of the pooling layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">out_grad</td><td>The gradient of the output. </td></tr>
    <tr><td class="paramname">pool_mode</td><td>The pooling mode. </td></tr>
    <tr><td class="paramname">window_height</td><td>The height of the pooling window. </td></tr>
    <tr><td class="paramname">window_width</td><td>The width of the pooling window. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the pooling. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the pooling. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the input of the pooling layer. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a9dc3603f13b1f318e228691c32bafe13"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9dc3603f13b1f318e228691c32bafe13">&#9670;&nbsp;</a></span>pool2d_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::pool2d_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnPoolingMode_t&#160;</td>
          <td class="paramname"><em>pool_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It performs a 2D pooling operation on the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">pool_mode</td><td>The pooling mode. </td></tr>
    <tr><td class="paramname">window_height</td><td>The height of the pooling window. </td></tr>
    <tr><td class="paramname">window_width</td><td>The width of the pooling window. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the pooling. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the pooling. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor of the pooling operation. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a63f47c31ba65badd22da7ce3c0aa07d0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a63f47c31ba65badd22da7ce3c0aa07d0">&#9670;&nbsp;</a></span>pool2d_output_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::pool2d_output_dims </td>
          <td>(</td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnPoolingMode_t&#160;</td>
          <td class="paramname"><em>pool_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_channels</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the dimensions of the output of the 2D pooling operation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_height</td><td>The input height. </td></tr>
    <tr><td class="paramname">input_width</td><td>The input width. </td></tr>
    <tr><td class="paramname">input_channels</td><td>The number of input channels. </td></tr>
    <tr><td class="paramname">pool_mode</td><td>The pooling mode. </td></tr>
    <tr><td class="paramname">window_height</td><td>The height of the pooling window. </td></tr>
    <tr><td class="paramname">window_width</td><td>The width of the pooling window. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the pooling. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the pooling. </td></tr>
    <tr><td class="paramname">output_height</td><td>The output height. </td></tr>
    <tr><td class="paramname">output_width</td><td>The output width. </td></tr>
    <tr><td class="paramname">output_channels</td><td>The number of output channels. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aa593cec63c9a1f53fa222a667462fe8c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa593cec63c9a1f53fa222a667462fe8c">&#9670;&nbsp;</a></span>softmax_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::softmax_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>in_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the gradient of the input of the softmax activation function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">in_out_grad</td><td>The gradient of the output of the activation function and after the method finishes execution, the gradient of the softmax activation function's input. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a992cae7a1c58ef7bb4e8460072632530"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a992cae7a1c58ef7bb4e8460072632530">&#9670;&nbsp;</a></span>softmax_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::softmax_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It applies the softmax activation function the the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">output</td><td>The softmax activated output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>C:/Users/Viktor/git/C-ATTL3/C-ATTL3/gpu/<a class="el" href="_cu_d_n_n_handle_8hpp_source.html">CuDNNHandle.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
