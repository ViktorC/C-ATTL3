<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: cattle::internal::CuDNNHandle&lt; Scalar &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecattle.html">cattle</a></li><li class="navelem"><a class="el" href="namespacecattle_1_1internal.html">internal</a></li><li class="navelem"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">CuDNNHandle</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="classcattle_1_1internal_1_1_cu_d_n_n_handle-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">cattle::internal::CuDNNHandle&lt; Scalar &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>A singleton utility class providing methods for GPU accelerated deep neural network operations on rank 4 data of [N,H,W,C] orientation.  
 <a href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_cu_d_n_n_handle_8hpp_source.html">CuDNNHandle.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:acd5781e6e3acdcb1a6d888cddf616843"><td class="memItemLeft" align="right" valign="top">Array4&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#acd5781e6e3acdcb1a6d888cddf616843">conv2d_output_dims</a> (const Array4 &amp;input_dims, std::size_t filters, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation) const</td></tr>
<tr class="memdesc:acd5781e6e3acdcb1a6d888cddf616843"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the dimensions of the output of the convolution.  <a href="#acd5781e6e3acdcb1a6d888cddf616843">More...</a><br /></td></tr>
<tr class="separator:acd5781e6e3acdcb1a6d888cddf616843"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11d9ff0d2bf96e04b13e142fd57fb99e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a11d9ff0d2bf96e04b13e142fd57fb99e">convolution2d_fwd</a> (Scalar *input, Scalar *filter, Scalar *bias, const Array4 &amp;input_dims, const Array4 &amp;output_dims, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation, Scalar *output) const</td></tr>
<tr class="memdesc:a11d9ff0d2bf96e04b13e142fd57fb99e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs a GPU accelerated 2D convolution on a rank 4 tensor of [N,H,W,C] orientation.  <a href="#a11d9ff0d2bf96e04b13e142fd57fb99e">More...</a><br /></td></tr>
<tr class="separator:a11d9ff0d2bf96e04b13e142fd57fb99e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39f10a0e8df9b93dd041d23100d49c57"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a39f10a0e8df9b93dd041d23100d49c57">convolution2d_bwd</a> (Scalar *input, Scalar *out_grad, Scalar *filter, Scalar *bias, const Array4 &amp;input_dims, const Array4 &amp;output_dims, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation, Scalar *prev_out_grad, Scalar *filter_grad, Scalar *bias_grad) const</td></tr>
<tr class="memdesc:a39f10a0e8df9b93dd041d23100d49c57"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs a backward 2D convolution on a rank 4 tensor to compute the gradients of the output of the previous layer, the convolution filter, and the bias.  <a href="#a39f10a0e8df9b93dd041d23100d49c57">More...</a><br /></td></tr>
<tr class="separator:a39f10a0e8df9b93dd041d23100d49c57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46b5ef9ed5403f8e934dc35038c377c9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a46b5ef9ed5403f8e934dc35038c377c9">activation_fwd</a> (Scalar *input, const Array4 &amp;dims, cudnnActivationMode_t act_mode, Scalar coeff, Scalar *output) const</td></tr>
<tr class="memdesc:a46b5ef9ed5403f8e934dc35038c377c9"><td class="mdescLeft">&#160;</td><td class="mdescRight">It applies the specified activation function the the input tensor.  <a href="#a46b5ef9ed5403f8e934dc35038c377c9">More...</a><br /></td></tr>
<tr class="separator:a46b5ef9ed5403f8e934dc35038c377c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae958103fd306a6ad9c1e0d50d9e13d57"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#ae958103fd306a6ad9c1e0d50d9e13d57">activation_bwd</a> (Scalar *input, Scalar *output, Scalar *out_grad, const Array4 &amp;dims, cudnnActivationMode_t act_mode, Scalar coeff, Scalar *prev_out_grad) const</td></tr>
<tr class="memdesc:ae958103fd306a6ad9c1e0d50d9e13d57"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the gradient of the input of the activation function.  <a href="#ae958103fd306a6ad9c1e0d50d9e13d57">More...</a><br /></td></tr>
<tr class="separator:ae958103fd306a6ad9c1e0d50d9e13d57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6ca224fc2b1b651fa8076e95b477cad"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#ae6ca224fc2b1b651fa8076e95b477cad">softmax_fwd</a> (Scalar *input, const Array4 &amp;dims, Scalar *output) const</td></tr>
<tr class="memdesc:ae6ca224fc2b1b651fa8076e95b477cad"><td class="mdescLeft">&#160;</td><td class="mdescRight">It applies the softmax activation function the the input tensor.  <a href="#ae6ca224fc2b1b651fa8076e95b477cad">More...</a><br /></td></tr>
<tr class="separator:ae6ca224fc2b1b651fa8076e95b477cad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2da9235cdf411aa8c37c6a5554bc415d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a2da9235cdf411aa8c37c6a5554bc415d">softmax_bwd</a> (Scalar *output, Scalar *out_grad, const Array4 &amp;dims, Scalar *prev_out_grad) const</td></tr>
<tr class="memdesc:a2da9235cdf411aa8c37c6a5554bc415d"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the gradient of the input of the softmax activation function.  <a href="#a2da9235cdf411aa8c37c6a5554bc415d">More...</a><br /></td></tr>
<tr class="separator:a2da9235cdf411aa8c37c6a5554bc415d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96fab0b5d093978af1813c12f597192f"><td class="memItemLeft" align="right" valign="top">Array4&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a96fab0b5d093978af1813c12f597192f">pooling2d_output_dims</a> (const Array4 &amp;input_dims, cudnnPoolingMode_t pool_mode, std::size_t window_height, std::size_t window_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride) const</td></tr>
<tr class="memdesc:a96fab0b5d093978af1813c12f597192f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the dimensions of the output of the 2D pooling operation.  <a href="#a96fab0b5d093978af1813c12f597192f">More...</a><br /></td></tr>
<tr class="separator:a96fab0b5d093978af1813c12f597192f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82c4dac7a96422dd4372e3f6e936d40e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a82c4dac7a96422dd4372e3f6e936d40e">pooling2d_fwd</a> (Scalar *input, const Array4 &amp;input_dims, const Array4 &amp;output_dims, cudnnPoolingMode_t pool_mode, std::size_t window_height, std::size_t window_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, Scalar *output) const</td></tr>
<tr class="memdesc:a82c4dac7a96422dd4372e3f6e936d40e"><td class="mdescLeft">&#160;</td><td class="mdescRight">It performs a 2D pooling operation on the input tensor.  <a href="#a82c4dac7a96422dd4372e3f6e936d40e">More...</a><br /></td></tr>
<tr class="separator:a82c4dac7a96422dd4372e3f6e936d40e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9f83600e06cd769e65776e38e025656"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#aa9f83600e06cd769e65776e38e025656">pooling2d_bwd</a> (Scalar *input, Scalar *output, Scalar *out_grad, const Array4 &amp;input_dims, const Array4 &amp;output_dims, cudnnPoolingMode_t pool_mode, std::size_t window_height, std::size_t window_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, Scalar *prev_out_grad) const</td></tr>
<tr class="memdesc:aa9f83600e06cd769e65776e38e025656"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the gradient of the input of the pooling layer.  <a href="#aa9f83600e06cd769e65776e38e025656">More...</a><br /></td></tr>
<tr class="separator:aa9f83600e06cd769e65776e38e025656"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e3bc20f4a0d4ecc849cb4c2c326508e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a5e3bc20f4a0d4ecc849cb4c2c326508e">batch_norm_fwd_training</a> (Scalar *input, Scalar *gamma, Scalar *beta, const Array4 &amp;dims, bool spatial, Scalar exp_avg_factor, Scalar epsilon, Scalar *means, Scalar *vars, Scalar *output, Scalar *mean_cache, Scalar *inv_var_cache) const</td></tr>
<tr class="memdesc:a5e3bc20f4a0d4ecc849cb4c2c326508e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies the batch normalization function to the input data and updates the running mean and variance averages.  <a href="#a5e3bc20f4a0d4ecc849cb4c2c326508e">More...</a><br /></td></tr>
<tr class="separator:a5e3bc20f4a0d4ecc849cb4c2c326508e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a387e53b8328502dd284ef8a1083e4545"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a387e53b8328502dd284ef8a1083e4545">batch_norm_fwd_inference</a> (Scalar *input, Scalar *gamma, Scalar *beta, Scalar *means, Scalar *vars, const Array4 &amp;dims, bool spatial, Scalar epsilon, Scalar *output) const</td></tr>
<tr class="memdesc:a387e53b8328502dd284ef8a1083e4545"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies the batch normalization function to the input data for inference using the running mean and variance averages.  <a href="#a387e53b8328502dd284ef8a1083e4545">More...</a><br /></td></tr>
<tr class="separator:a387e53b8328502dd284ef8a1083e4545"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef678ece1cd9918512de16cf74ac492c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#aef678ece1cd9918512de16cf74ac492c">batch_norm_bwd</a> (Scalar *input, Scalar *out_grad, Scalar *gamma, Scalar *mean_cache, Scalar *inv_var_cache, const Array4 &amp;dims, bool spatial, Scalar epsilon, Scalar *prev_out_grad, Scalar *gamma_grad, Scalar *beta_grad) const</td></tr>
<tr class="memdesc:aef678ece1cd9918512de16cf74ac492c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the backward pass of the batch normalization function and computes the gradients of the function's input, the gamma scaling tensor, and the beta bias tensor.  <a href="#aef678ece1cd9918512de16cf74ac492c">More...</a><br /></td></tr>
<tr class="separator:aef678ece1cd9918512de16cf74ac492c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2f4fba55c7a5b17a66bd44912fe388a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#aa2f4fba55c7a5b17a66bd44912fe388a">dropout_fwd</a> (Scalar *input, const Array4 &amp;dims, Scalar dropout, Scalar *output, std::vector&lt; Scalar &gt; &amp;reserve) const</td></tr>
<tr class="memdesc:aa2f4fba55c7a5b17a66bd44912fe388a"><td class="mdescLeft">&#160;</td><td class="mdescRight">It applies the dropout function to the input tensor.  <a href="#aa2f4fba55c7a5b17a66bd44912fe388a">More...</a><br /></td></tr>
<tr class="separator:aa2f4fba55c7a5b17a66bd44912fe388a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ea4fda313544c9078f44e06a2c94402"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a6ea4fda313544c9078f44e06a2c94402">dropout_bwd</a> (Scalar *out_grad, std::vector&lt; Scalar &gt; &amp;reserve, const Array4 &amp;dims, Scalar dropout, Scalar *prev_out_grad) const</td></tr>
<tr class="memdesc:a6ea4fda313544c9078f44e06a2c94402"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the gradient of the input of the dropout function.  <a href="#a6ea4fda313544c9078f44e06a2c94402">More...</a><br /></td></tr>
<tr class="separator:a6ea4fda313544c9078f44e06a2c94402"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a66ff49f3b34f05a1043f22d5d0275575"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">CuDNNHandle</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">get_instance</a> ()</td></tr>
<tr class="separator:a66ff49f3b34f05a1043f22d5d0275575"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Scalar&gt;<br />
class cattle::internal::CuDNNHandle&lt; Scalar &gt;</h3>

<p>A singleton utility class providing methods for GPU accelerated deep neural network operations on rank 4 data of [N,H,W,C] orientation. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="ae958103fd306a6ad9c1e0d50d9e13d57"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae958103fd306a6ad9c1e0d50d9e13d57">&#9670;&nbsp;</a></span>activation_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::activation_bwd </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnActivationMode_t&#160;</td>
          <td class="paramname"><em>act_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the gradient of the input of the activation function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">out_grad</td><td>The gradient of the output of the activation function. </td></tr>
    <tr><td class="paramname">dims</td><td>The dimensions of the input/output tensor (extended by 1s for data of rank lower than 4). </td></tr>
    <tr><td class="paramname">act_mode</td><td>The type of activation function used. </td></tr>
    <tr><td class="paramname">coeff</td><td>The activation function coefficient used by certain activation functions (e.g. ELU). </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the activation function's input. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a46b5ef9ed5403f8e934dc35038c377c9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46b5ef9ed5403f8e934dc35038c377c9">&#9670;&nbsp;</a></span>activation_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::activation_fwd </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnActivationMode_t&#160;</td>
          <td class="paramname"><em>act_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It applies the specified activation function the the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">dims</td><td>The dimensions of the input/output tensor (extended by 1s for data of rank lower than 4). </td></tr>
    <tr><td class="paramname">act_mode</td><td>The type of activation function to use. </td></tr>
    <tr><td class="paramname">coeff</td><td>The activation function coefficient used by certain activation functions (e.g. ELU). </td></tr>
    <tr><td class="paramname">output</td><td>The activated output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aef678ece1cd9918512de16cf74ac492c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef678ece1cd9918512de16cf74ac492c">&#9670;&nbsp;</a></span>batch_norm_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::batch_norm_bwd </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>mean_cache</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>inv_var_cache</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>spatial</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>gamma_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>beta_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the backward pass of the batch normalization function and computes the gradients of the function's input, the gamma scaling tensor, and the beta bias tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor used. </td></tr>
    <tr><td class="paramname">out_grad</td><td>The gradient of the output of the function. </td></tr>
    <tr><td class="paramname">gamma</td><td>The gamma scaling tensor. </td></tr>
    <tr><td class="paramname">mean_cache</td><td>The mean cached during the forward pass. </td></tr>
    <tr><td class="paramname">inv_var_cache</td><td>The inverse variance cached during the forward pass. </td></tr>
    <tr><td class="paramname">dims</td><td>The dimensions of the input/output tensor (extended by 1s for data of rank lower than 4). </td></tr>
    <tr><td class="paramname">spatial</td><td>Whether the batch normalization should be performed in spatial or per-activation mode. </td></tr>
    <tr><td class="paramname">epsilon</td><td>A small constant for numerical stability. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the batch normalization function's input. </td></tr>
    <tr><td class="paramname">gamma_grad</td><td>The gradient of gamma. </td></tr>
    <tr><td class="paramname">beta_grad</td><td>The gradient of beta. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a387e53b8328502dd284ef8a1083e4545"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a387e53b8328502dd284ef8a1083e4545">&#9670;&nbsp;</a></span>batch_norm_fwd_inference()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::batch_norm_fwd_inference </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>means</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>vars</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>spatial</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies the batch normalization function to the input data for inference using the running mean and variance averages. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">gamma</td><td>The gamma scaling tensor. </td></tr>
    <tr><td class="paramname">beta</td><td>The beta bias. </td></tr>
    <tr><td class="paramname">means</td><td>The running mean average. </td></tr>
    <tr><td class="paramname">vars</td><td>The running variance average. </td></tr>
    <tr><td class="paramname">dims</td><td>The dimensions of the input/output tensor (extended by 1s for data of rank lower than 4). </td></tr>
    <tr><td class="paramname">spatial</td><td>Whether the batch normalization should be performed in spatial or per-activation mode. </td></tr>
    <tr><td class="paramname">epsilon</td><td>A small constant for numerical stability. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a5e3bc20f4a0d4ecc849cb4c2c326508e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5e3bc20f4a0d4ecc849cb4c2c326508e">&#9670;&nbsp;</a></span>batch_norm_fwd_training()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::batch_norm_fwd_training </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>spatial</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>exp_avg_factor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>means</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>vars</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>mean_cache</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>inv_var_cache</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies the batch normalization function to the input data and updates the running mean and variance averages. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">gamma</td><td>The gamma scaling tensor. </td></tr>
    <tr><td class="paramname">beta</td><td>The beta bias. </td></tr>
    <tr><td class="paramname">dims</td><td>The dimensions of the input/output tensor (extended by 1s for data of rank lower than 4). </td></tr>
    <tr><td class="paramname">spatial</td><td>Whether the batch normalization should be performed in spatial or per-activation mode. </td></tr>
    <tr><td class="paramname">exp_avg_factor</td><td>The exponential average factor for the running mean and variance averages. </td></tr>
    <tr><td class="paramname">epsilon</td><td>A small constant for numerical stability. </td></tr>
    <tr><td class="paramname">means</td><td>The running mean average (it gets updated by the method). </td></tr>
    <tr><td class="paramname">vars</td><td>The running variance average (it gets updated by the method). </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">mean_cache</td><td>The cached mean for back-propagation. </td></tr>
    <tr><td class="paramname">inv_var_cache</td><td>The cached inverse variance for back-propagation. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="acd5781e6e3acdcb1a6d888cddf616843"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acd5781e6e3acdcb1a6d888cddf616843">&#9670;&nbsp;</a></span>conv2d_output_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Array4 <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::conv2d_output_dims </td>
          <td>(</td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>filters</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>receptor_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>receptor_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_dilation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the dimensions of the output of the convolution. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_dims</td><td>The dimensions of the input tensor. </td></tr>
    <tr><td class="paramname">filters</td><td>The number of convolution filters. </td></tr>
    <tr><td class="paramname">receptor_height</td><td>The height of the receptor. </td></tr>
    <tr><td class="paramname">receptor_width</td><td>The width of the receptor. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the convolution. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the convolution. </td></tr>
    <tr><td class="paramname">vertical_dilation</td><td>The vertical dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">horizontal_dilation</td><td>The horizontal dilation to apply to the receptor. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output dimensions. </dd></dl>

</div>
</div>
<a id="a39f10a0e8df9b93dd041d23100d49c57"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a39f10a0e8df9b93dd041d23100d49c57">&#9670;&nbsp;</a></span>convolution2d_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::convolution2d_bwd </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>filter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>output_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>receptor_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>receptor_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>filter_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>bias_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs a backward 2D convolution on a rank 4 tensor to compute the gradients of the output of the previous layer, the convolution filter, and the bias. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">out_grad</td><td>The gradient of the output. </td></tr>
    <tr><td class="paramname">filter</td><td>The convolution filter. </td></tr>
    <tr><td class="paramname">bias</td><td>The bias applied to the output of the convolution. </td></tr>
    <tr><td class="paramname">input_dims</td><td>The dimensions of the input tensor. </td></tr>
    <tr><td class="paramname">output_dims</td><td>The dimensions of the output tensor of the convolution. </td></tr>
    <tr><td class="paramname">receptor_height</td><td>The height of the receptor. </td></tr>
    <tr><td class="paramname">receptor_width</td><td>The width of the receptor. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the convolution. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the convolution. </td></tr>
    <tr><td class="paramname">vertical_dilation</td><td>The vertical dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">horizontal_dilation</td><td>The horizontal dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the previous layer's output. </td></tr>
    <tr><td class="paramname">filter_grad</td><td>The gradient of the convolution filter. </td></tr>
    <tr><td class="paramname">bias_grad</td><td>The gradient of the bias. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a11d9ff0d2bf96e04b13e142fd57fb99e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a11d9ff0d2bf96e04b13e142fd57fb99e">&#9670;&nbsp;</a></span>convolution2d_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::convolution2d_fwd </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>filter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>output_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>receptor_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>receptor_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs a GPU accelerated 2D convolution on a rank 4 tensor of [N,H,W,C] orientation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">filter</td><td>The convolution filter. </td></tr>
    <tr><td class="paramname">bias</td><td>The bias to apply to the output of the convolution. </td></tr>
    <tr><td class="paramname">input_dims</td><td>The dimensions of the input tensor. </td></tr>
    <tr><td class="paramname">output_dims</td><td>The dimensions of the output tensor of the convolution. </td></tr>
    <tr><td class="paramname">receptor_height</td><td>The height of the receptor. </td></tr>
    <tr><td class="paramname">receptor_width</td><td>The width of the receptor. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the convolution. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the convolution. </td></tr>
    <tr><td class="paramname">vertical_dilation</td><td>The vertical dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">horizontal_dilation</td><td>The horizontal dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">output</td><td>The convolution output tensor with the bias applied to it. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a6ea4fda313544c9078f44e06a2c94402"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6ea4fda313544c9078f44e06a2c94402">&#9670;&nbsp;</a></span>dropout_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::dropout_bwd </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>reserve</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>dropout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the gradient of the input of the dropout function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out_grad</td><td>The gradient of the output of the dropout function. </td></tr>
    <tr><td class="paramname">reserve</td><td>The reserve filled during the forward pass. </td></tr>
    <tr><td class="paramname">dims</td><td>The dimensions of the input/output tensor (extended by 1s for data of rank lower than 4). </td></tr>
    <tr><td class="paramname">dropout</td><td>The average factor of elements set to 0 in the input tensor. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the input of the dropout function. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aa2f4fba55c7a5b17a66bd44912fe388a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa2f4fba55c7a5b17a66bd44912fe388a">&#9670;&nbsp;</a></span>dropout_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::dropout_fwd </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>dropout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>reserve</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It applies the dropout function to the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor </td></tr>
    <tr><td class="paramname">dims</td><td>The dimensions of the input/output tensor (extended by 1s for data of rank lower than 4). </td></tr>
    <tr><td class="paramname">dropout</td><td>The average factor of elements to set to 0 in the input tensor. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">reserve</td><td>The reserve used for backpropagation. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a66ff49f3b34f05a1043f22d5d0275575"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a66ff49f3b34f05a1043f22d5d0275575">&#9670;&nbsp;</a></span>get_instance()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">CuDNNHandle</a>&amp; <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::get_instance </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>A reference to the only instance of the class. </dd></dl>

</div>
</div>
<a id="aa9f83600e06cd769e65776e38e025656"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa9f83600e06cd769e65776e38e025656">&#9670;&nbsp;</a></span>pooling2d_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::pooling2d_bwd </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>output_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnPoolingMode_t&#160;</td>
          <td class="paramname"><em>pool_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the gradient of the input of the pooling layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">out_grad</td><td>The gradient of the output. </td></tr>
    <tr><td class="paramname">input_dims</td><td>The input dimensions. </td></tr>
    <tr><td class="paramname">output_dims</td><td>The output dimensions. </td></tr>
    <tr><td class="paramname">pool_mode</td><td>The pooling mode. </td></tr>
    <tr><td class="paramname">window_height</td><td>The height of the pooling window. </td></tr>
    <tr><td class="paramname">window_width</td><td>The width of the pooling window. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the pooling. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the pooling. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the input of the pooling layer. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a82c4dac7a96422dd4372e3f6e936d40e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a82c4dac7a96422dd4372e3f6e936d40e">&#9670;&nbsp;</a></span>pooling2d_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::pooling2d_fwd </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>output_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnPoolingMode_t&#160;</td>
          <td class="paramname"><em>pool_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It performs a 2D pooling operation on the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">input_dims</td><td>The input dimensions. </td></tr>
    <tr><td class="paramname">output_dims</td><td>The output dimensions. </td></tr>
    <tr><td class="paramname">pool_mode</td><td>The pooling mode. </td></tr>
    <tr><td class="paramname">window_height</td><td>The height of the pooling window. </td></tr>
    <tr><td class="paramname">window_width</td><td>The width of the pooling window. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the pooling. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the pooling. </td></tr>
    <tr><td class="paramname">output</td><td>The output of the pooling operation. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a96fab0b5d093978af1813c12f597192f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a96fab0b5d093978af1813c12f597192f">&#9670;&nbsp;</a></span>pooling2d_output_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Array4 <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::pooling2d_output_dims </td>
          <td>(</td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnPoolingMode_t&#160;</td>
          <td class="paramname"><em>pool_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the dimensions of the output of the 2D pooling operation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_dims</td><td>The input dimensions. </td></tr>
    <tr><td class="paramname">pool_mode</td><td>The pooling mode. </td></tr>
    <tr><td class="paramname">window_height</td><td>The height of the pooling window. </td></tr>
    <tr><td class="paramname">window_width</td><td>The width of the pooling window. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the pooling. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the pooling. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output dimensions. </dd></dl>

</div>
</div>
<a id="a2da9235cdf411aa8c37c6a5554bc415d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2da9235cdf411aa8c37c6a5554bc415d">&#9670;&nbsp;</a></span>softmax_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::softmax_bwd </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the gradient of the input of the softmax activation function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">out_grad</td><td>The gradient of the output of the activation function. </td></tr>
    <tr><td class="paramname">dims</td><td>The dimensions of the input/output tensor (extended by 1s for data of rank lower than 4). </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the softmax activation function's input. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae6ca224fc2b1b651fa8076e95b477cad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae6ca224fc2b1b651fa8076e95b477cad">&#9670;&nbsp;</a></span>softmax_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html">cattle::internal::CuDNNHandle</a>&lt; Scalar &gt;::softmax_fwd </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Array4 &amp;&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It applies the softmax activation function the the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">dims</td><td>The dimensions of the input/output tensor (extended by 1s for data of rank lower than 4). </td></tr>
    <tr><td class="paramname">output</td><td>The softmax activated output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>C:/Users/A6714/git/C-ATTL3/C-ATTL3/gpu/<a class="el" href="_cu_d_n_n_handle_8hpp_source.html">CuDNNHandle.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
