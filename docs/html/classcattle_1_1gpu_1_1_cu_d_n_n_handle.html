<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: cattle::gpu::CuDNNHandle&lt; Scalar &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecattle.html">cattle</a></li><li class="navelem"><b>gpu</b></li><li class="navelem"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">CuDNNHandle</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="classcattle_1_1gpu_1_1_cu_d_n_n_handle-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">cattle::gpu::CuDNNHandle&lt; Scalar &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>A singleton utility class providing methods for GPU accelerated deep neural network operations on rank 4 data.  
 <a href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_cu_d_n_n_handle_8hpp_source.html">CuDNNHandle.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a4029d3474070ab568666b937d3cb2845"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a4029d3474070ab568666b937d3cb2845">op</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;a, Scalar alpha, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;b, Scalar beta, cudnnOpTensorOp_t op_type, Scalar gamma, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;c) const</td></tr>
<tr class="memdesc:a4029d3474070ab568666b937d3cb2845"><td class="mdescLeft">&#160;</td><td class="mdescRight">It performs the specified operation on tensors a and b and saves the result in c.  <a href="#a4029d3474070ab568666b937d3cb2845">More...</a><br /></td></tr>
<tr class="separator:a4029d3474070ab568666b937d3cb2845"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b5b4d3a530697923dd1b806be0bd60a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a9b5b4d3a530697923dd1b806be0bd60a">add_bias</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;bias, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;tensor) const</td></tr>
<tr class="memdesc:a9b5b4d3a530697923dd1b806be0bd60a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adds a bias tensor to another tensor.  <a href="#a9b5b4d3a530697923dd1b806be0bd60a">More...</a><br /></td></tr>
<tr class="separator:a9b5b4d3a530697923dd1b806be0bd60a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5235c1df2f08ca95f3d32003e611a267"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a5235c1df2f08ca95f3d32003e611a267">conv2d_output_dims</a> (std::size_t input_height, std::size_t input_width, std::size_t input_channels, std::size_t filters, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation, std::size_t &amp;output_height, std::size_t &amp;output_width, std::size_t &amp;output_channels) const</td></tr>
<tr class="memdesc:a5235c1df2f08ca95f3d32003e611a267"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the dimensions of the output tensor of the convolution.  <a href="#a5235c1df2f08ca95f3d32003e611a267">More...</a><br /></td></tr>
<tr class="separator:a5235c1df2f08ca95f3d32003e611a267"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae20e54711de984e3c4669065cede0c1d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#ae20e54711de984e3c4669065cede0c1d">convolution2d_fwd</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_filter.html">CuDNNFilter</a>&lt; Scalar &gt; &amp;filter, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;bias, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:ae20e54711de984e3c4669065cede0c1d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs a GPU accelerated 2D convolution on a rank 4 tensor.  <a href="#ae20e54711de984e3c4669065cede0c1d">More...</a><br /></td></tr>
<tr class="separator:ae20e54711de984e3c4669065cede0c1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abcccacd4760726a246ef1fc12f2d8dc3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#abcccacd4760726a246ef1fc12f2d8dc3">convolution2d_bwd</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;out_grad, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_filter.html">CuDNNFilter</a>&lt; Scalar &gt; &amp;filter, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;bias, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;prev_out_grad, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_filter.html">CuDNNFilter</a>&lt; Scalar &gt; &amp;filter_grad, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;bias_grad) const</td></tr>
<tr class="memdesc:abcccacd4760726a246ef1fc12f2d8dc3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs a backward 2D convolution on a rank 4 tensor to compute the gradients of the output of the previous layer, the convolution filter, and the bias.  <a href="#abcccacd4760726a246ef1fc12f2d8dc3">More...</a><br /></td></tr>
<tr class="separator:abcccacd4760726a246ef1fc12f2d8dc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a432fd7129bbf5f6b5f1ca3ca14d51e67"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a432fd7129bbf5f6b5f1ca3ca14d51e67">activation_fwd</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, cudnnActivationMode_t act_mode, Scalar coeff, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:a432fd7129bbf5f6b5f1ca3ca14d51e67"><td class="mdescLeft">&#160;</td><td class="mdescRight">It applies the specified activation function the the input tensor.  <a href="#a432fd7129bbf5f6b5f1ca3ca14d51e67">More...</a><br /></td></tr>
<tr class="separator:a432fd7129bbf5f6b5f1ca3ca14d51e67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f41f0d504fe3ce6953a564f6900d487"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a6f41f0d504fe3ce6953a564f6900d487">activation_bwd</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output, cudnnActivationMode_t act_mode, Scalar coeff, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;in_out_grad) const</td></tr>
<tr class="memdesc:a6f41f0d504fe3ce6953a564f6900d487"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the gradient of the input of the activation function.  <a href="#a6f41f0d504fe3ce6953a564f6900d487">More...</a><br /></td></tr>
<tr class="separator:a6f41f0d504fe3ce6953a564f6900d487"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee3f305b96db4978a1bac172ceeb7a41"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#aee3f305b96db4978a1bac172ceeb7a41">softmax_fwd</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:aee3f305b96db4978a1bac172ceeb7a41"><td class="mdescLeft">&#160;</td><td class="mdescRight">It applies the softmax activation function the the input tensor.  <a href="#aee3f305b96db4978a1bac172ceeb7a41">More...</a><br /></td></tr>
<tr class="separator:aee3f305b96db4978a1bac172ceeb7a41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acae1ee8f18b6b4ae55b1b522194bd064"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#acae1ee8f18b6b4ae55b1b522194bd064">softmax_bwd</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;in_out_grad) const</td></tr>
<tr class="memdesc:acae1ee8f18b6b4ae55b1b522194bd064"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the gradient of the input of the softmax activation function.  <a href="#acae1ee8f18b6b4ae55b1b522194bd064">More...</a><br /></td></tr>
<tr class="separator:acae1ee8f18b6b4ae55b1b522194bd064"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59e3724b27ff80653c7fd48afed6cff0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a59e3724b27ff80653c7fd48afed6cff0">pool2d_output_dims</a> (std::size_t input_height, std::size_t input_width, std::size_t input_channels, cudnnPoolingMode_t pool_mode, std::size_t window_height, std::size_t window_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t &amp;output_height, std::size_t &amp;output_width, std::size_t &amp;output_channels) const</td></tr>
<tr class="memdesc:a59e3724b27ff80653c7fd48afed6cff0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the dimensions of the output of the 2D pooling operation.  <a href="#a59e3724b27ff80653c7fd48afed6cff0">More...</a><br /></td></tr>
<tr class="separator:a59e3724b27ff80653c7fd48afed6cff0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa51029984f059c00f1a50439c0517418"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#aa51029984f059c00f1a50439c0517418">pool2d_fwd</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, cudnnPoolingMode_t pool_mode, std::size_t window_height, std::size_t window_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:aa51029984f059c00f1a50439c0517418"><td class="mdescLeft">&#160;</td><td class="mdescRight">It performs a 2D pooling operation on the input tensor.  <a href="#aa51029984f059c00f1a50439c0517418">More...</a><br /></td></tr>
<tr class="separator:aa51029984f059c00f1a50439c0517418"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a288c41a514d70e017130d713ac6c859d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a288c41a514d70e017130d713ac6c859d">pool2d_bwd</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;out_grad, cudnnPoolingMode_t pool_mode, std::size_t window_height, std::size_t window_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;prev_out_grad) const</td></tr>
<tr class="memdesc:a288c41a514d70e017130d713ac6c859d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes the gradient of the input of the pooling layer.  <a href="#a288c41a514d70e017130d713ac6c859d">More...</a><br /></td></tr>
<tr class="separator:a288c41a514d70e017130d713ac6c859d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4404a2496a25d8a25c7d77bb3ae8021"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#af4404a2496a25d8a25c7d77bb3ae8021">batch_norm_fwd_training</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;gamma, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;beta, bool spatial, Scalar exp_avg_factor, Scalar epsilon, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;means, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;vars, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;mean_cache, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;inv_var_cache) const</td></tr>
<tr class="memdesc:af4404a2496a25d8a25c7d77bb3ae8021"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies the batch normalization function to the input data and updates the running mean and variance averages.  <a href="#af4404a2496a25d8a25c7d77bb3ae8021">More...</a><br /></td></tr>
<tr class="separator:af4404a2496a25d8a25c7d77bb3ae8021"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9af9fd7fb9f40f7e2c3ae98c34bb30d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#ab9af9fd7fb9f40f7e2c3ae98c34bb30d">batch_norm_fwd_inference</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;gamma, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;beta, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;means, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;vars, bool spatial, Scalar epsilon, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:ab9af9fd7fb9f40f7e2c3ae98c34bb30d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies the batch normalization function to the input data for inference using the running mean and variance averages.  <a href="#ab9af9fd7fb9f40f7e2c3ae98c34bb30d">More...</a><br /></td></tr>
<tr class="separator:ab9af9fd7fb9f40f7e2c3ae98c34bb30d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad59c579703ca5be2980e47a6efcf75c1"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#ad59c579703ca5be2980e47a6efcf75c1">batch_norm_bwd</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;out_grad, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;gamma, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;mean_cache, const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;inv_var_cache, bool spatial, Scalar epsilon, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;prev_out_grad, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;gamma_grad, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;beta_grad) const</td></tr>
<tr class="memdesc:ad59c579703ca5be2980e47a6efcf75c1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs the backward pass of the batch normalization function and computes the gradients of the function's input, the gamma scaling tensor, and the beta bias tensor.  <a href="#ad59c579703ca5be2980e47a6efcf75c1">More...</a><br /></td></tr>
<tr class="separator:ad59c579703ca5be2980e47a6efcf75c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a998d83500dc32fc4eccbc620d888a8e4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a998d83500dc32fc4eccbc620d888a8e4">dropout_state_size</a> (std::size_t &amp;state_size) const</td></tr>
<tr class="memdesc:a998d83500dc32fc4eccbc620d888a8e4"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the necessary state size required for the RNG used by the dropout function.  <a href="#a998d83500dc32fc4eccbc620d888a8e4">More...</a><br /></td></tr>
<tr class="separator:a998d83500dc32fc4eccbc620d888a8e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42e76b2f949cdee02b78d78332b54391"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a42e76b2f949cdee02b78d78332b54391">dropout_reserve_size</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, std::size_t &amp;reserve_size) const</td></tr>
<tr class="memdesc:a42e76b2f949cdee02b78d78332b54391"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the necessary reserve size for the dropout.  <a href="#a42e76b2f949cdee02b78d78332b54391">More...</a><br /></td></tr>
<tr class="separator:a42e76b2f949cdee02b78d78332b54391"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada21ae436615ef9f57f0196c626878d8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#ada21ae436615ef9f57f0196c626878d8">dropout_fwd</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;input, Scalar dropout, <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray</a>&lt; Scalar &gt; &amp;state, <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray</a>&lt; Scalar &gt; &amp;reserve, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;output) const</td></tr>
<tr class="memdesc:ada21ae436615ef9f57f0196c626878d8"><td class="mdescLeft">&#160;</td><td class="mdescRight">It applies the dropout function to the input tensor.  <a href="#ada21ae436615ef9f57f0196c626878d8">More...</a><br /></td></tr>
<tr class="separator:ada21ae436615ef9f57f0196c626878d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add52a4fba7477ecec00e00dc963edf9c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#add52a4fba7477ecec00e00dc963edf9c">dropout_bwd</a> (const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;out_grad, Scalar dropout, <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;state, <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray</a>&lt; Scalar &gt; &amp;reserve, <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray</a>&lt; Scalar &gt; &amp;prev_out_grad) const</td></tr>
<tr class="memdesc:add52a4fba7477ecec00e00dc963edf9c"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the gradient of the input of the dropout function.  <a href="#add52a4fba7477ecec00e00dc963edf9c">More...</a><br /></td></tr>
<tr class="separator:add52a4fba7477ecec00e00dc963edf9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a2d1f4116ed51c7f98e7a21df410c4bf1"><td class="memItemLeft" align="right" valign="top">static const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">Self</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a2d1f4116ed51c7f98e7a21df410c4bf1">get_instance</a> ()</td></tr>
<tr class="separator:a2d1f4116ed51c7f98e7a21df410c4bf1"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Scalar&gt;<br />
class cattle::gpu::CuDNNHandle&lt; Scalar &gt;</h3>

<p>A singleton utility class providing methods for GPU accelerated deep neural network operations on rank 4 data. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a6f41f0d504fe3ce6953a564f6900d487"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6f41f0d504fe3ce6953a564f6900d487">&#9670;&nbsp;</a></span>activation_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::activation_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnActivationMode_t&#160;</td>
          <td class="paramname"><em>act_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>in_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the gradient of the input of the activation function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">act_mode</td><td>The type of activation function used. </td></tr>
    <tr><td class="paramname">coeff</td><td>The activation function coefficient used by certain activation functions (e.g. ELU). </td></tr>
    <tr><td class="paramname">in_out_grad</td><td>The gradient of the output of the activation function and after the method finishes execution, the gradient of the input of the activation function. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a432fd7129bbf5f6b5f1ca3ca14d51e67"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a432fd7129bbf5f6b5f1ca3ca14d51e67">&#9670;&nbsp;</a></span>activation_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::activation_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnActivationMode_t&#160;</td>
          <td class="paramname"><em>act_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>coeff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It applies the specified activation function the the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">act_mode</td><td>The type of activation function to use. </td></tr>
    <tr><td class="paramname">coeff</td><td>The activation function coefficient used by certain activation functions (e.g. ELU). </td></tr>
    <tr><td class="paramname">output</td><td>The activated output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a9b5b4d3a530697923dd1b806be0bd60a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9b5b4d3a530697923dd1b806be0bd60a">&#9670;&nbsp;</a></span>add_bias()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::add_bias </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>tensor</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Adds a bias tensor to another tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bias</td><td>The bias tensor. </td></tr>
    <tr><td class="paramname">tensor</td><td>The tensor to which the bias is to be added. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ad59c579703ca5be2980e47a6efcf75c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad59c579703ca5be2980e47a6efcf75c1">&#9670;&nbsp;</a></span>batch_norm_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::batch_norm_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>mean_cache</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>inv_var_cache</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>spatial</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>gamma_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>beta_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs the backward pass of the batch normalization function and computes the gradients of the function's input, the gamma scaling tensor, and the beta bias tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor used. </td></tr>
    <tr><td class="paramname">out_grad</td><td>The gradient of the output of the function. </td></tr>
    <tr><td class="paramname">gamma</td><td>The gamma scaling tensor. </td></tr>
    <tr><td class="paramname">mean_cache</td><td>The mean cached during the forward pass. </td></tr>
    <tr><td class="paramname">inv_var_cache</td><td>The inverse variance cached during the forward pass. </td></tr>
    <tr><td class="paramname">spatial</td><td>Whether the batch normalization should be performed in spatial or per-activation mode. </td></tr>
    <tr><td class="paramname">epsilon</td><td>A small constant for numerical stability. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the batch normalization function's input. </td></tr>
    <tr><td class="paramname">gamma_grad</td><td>The gradient of gamma. </td></tr>
    <tr><td class="paramname">beta_grad</td><td>The gradient of beta. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ab9af9fd7fb9f40f7e2c3ae98c34bb30d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab9af9fd7fb9f40f7e2c3ae98c34bb30d">&#9670;&nbsp;</a></span>batch_norm_fwd_inference()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::batch_norm_fwd_inference </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>means</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>vars</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>spatial</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies the batch normalization function to the input data for inference using the running mean and variance averages. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">gamma</td><td>The gamma scaling tensor. </td></tr>
    <tr><td class="paramname">beta</td><td>The beta bias. </td></tr>
    <tr><td class="paramname">means</td><td>The running mean average. </td></tr>
    <tr><td class="paramname">vars</td><td>The running variance average. </td></tr>
    <tr><td class="paramname">spatial</td><td>Whether the batch normalization should be performed in spatial or per-activation mode. </td></tr>
    <tr><td class="paramname">epsilon</td><td>A small constant for numerical stability. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="af4404a2496a25d8a25c7d77bb3ae8021"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4404a2496a25d8a25c7d77bb3ae8021">&#9670;&nbsp;</a></span>batch_norm_fwd_training()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::batch_norm_fwd_training </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>spatial</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>exp_avg_factor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>epsilon</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>means</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>vars</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>mean_cache</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>inv_var_cache</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies the batch normalization function to the input data and updates the running mean and variance averages. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">gamma</td><td>The gamma scaling tensor. </td></tr>
    <tr><td class="paramname">beta</td><td>The beta bias. </td></tr>
    <tr><td class="paramname">spatial</td><td>Whether the batch normalization should be performed in spatial or per-activation mode. </td></tr>
    <tr><td class="paramname">exp_avg_factor</td><td>The exponential average factor for the running mean and variance averages. </td></tr>
    <tr><td class="paramname">epsilon</td><td>A small constant for numerical stability. </td></tr>
    <tr><td class="paramname">means</td><td>The running mean average (it gets updated by the method). </td></tr>
    <tr><td class="paramname">vars</td><td>The running variance average (it gets updated by the method). </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">mean_cache</td><td>The cached mean for back-propagation. </td></tr>
    <tr><td class="paramname">inv_var_cache</td><td>The cached inverse variance for back-propagation. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a5235c1df2f08ca95f3d32003e611a267"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5235c1df2f08ca95f3d32003e611a267">&#9670;&nbsp;</a></span>conv2d_output_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::conv2d_output_dims </td>
          <td>(</td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>filters</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>receptor_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>receptor_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_channels</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the dimensions of the output tensor of the convolution. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_height</td><td>The input height. </td></tr>
    <tr><td class="paramname">input_width</td><td>The input width. </td></tr>
    <tr><td class="paramname">input_channels</td><td>The number of input channels. </td></tr>
    <tr><td class="paramname">filters</td><td>The number of convolution filters. </td></tr>
    <tr><td class="paramname">receptor_height</td><td>The height of the receptor. </td></tr>
    <tr><td class="paramname">receptor_width</td><td>The width of the receptor. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the convolution. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the convolution. </td></tr>
    <tr><td class="paramname">vertical_dilation</td><td>The vertical dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">horizontal_dilation</td><td>The horizontal dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">output_height</td><td>The output height. </td></tr>
    <tr><td class="paramname">output_width</td><td>The output width. </td></tr>
    <tr><td class="paramname">output_channels</td><td>The number of output channels. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="abcccacd4760726a246ef1fc12f2d8dc3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abcccacd4760726a246ef1fc12f2d8dc3">&#9670;&nbsp;</a></span>convolution2d_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::convolution2d_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_filter.html">CuDNNFilter</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>filter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_filter.html">CuDNNFilter</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>filter_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>bias_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs a backward 2D convolution on a rank 4 tensor to compute the gradients of the output of the previous layer, the convolution filter, and the bias. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">out_grad</td><td>The gradient of the output tensor. </td></tr>
    <tr><td class="paramname">filter</td><td>The convolution filter. </td></tr>
    <tr><td class="paramname">bias</td><td>The bias tensor applied to the output of the convolution. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the convolution. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the convolution. </td></tr>
    <tr><td class="paramname">vertical_dilation</td><td>The vertical dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">horizontal_dilation</td><td>The horizontal dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the previous layer's output tensor. </td></tr>
    <tr><td class="paramname">filter_grad</td><td>The gradient of the convolution filter. </td></tr>
    <tr><td class="paramname">bias_grad</td><td>The gradient of the bias tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae20e54711de984e3c4669065cede0c1d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae20e54711de984e3c4669065cede0c1d">&#9670;&nbsp;</a></span>convolution2d_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::convolution2d_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_filter.html">CuDNNFilter</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>filter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_dilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs a GPU accelerated 2D convolution on a rank 4 tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">filter</td><td>The convolution filter. </td></tr>
    <tr><td class="paramname">bias</td><td>The bias tensor to apply to the output of the convolution. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the convolution. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the convolution. </td></tr>
    <tr><td class="paramname">vertical_dilation</td><td>The vertical dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">horizontal_dilation</td><td>The horizontal dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">output</td><td>The convolution output tensor with the bias applied to it. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="add52a4fba7477ecec00e00dc963edf9c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add52a4fba7477ecec00e00dc963edf9c">&#9670;&nbsp;</a></span>dropout_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::dropout_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>dropout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>reserve</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the gradient of the input of the dropout function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out_grad</td><td>The gradient of the output of the dropout function. </td></tr>
    <tr><td class="paramname">state</td><td>The memory used by the RNG. </td></tr>
    <tr><td class="paramname">reserve</td><td>The reserve filled during the forward pass. </td></tr>
    <tr><td class="paramname">dropout</td><td>The average factor of elements set to 0 in the input tensor. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the input of the dropout function. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ada21ae436615ef9f57f0196c626878d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ada21ae436615ef9f57f0196c626878d8">&#9670;&nbsp;</a></span>dropout_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::dropout_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>dropout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>reserve</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It applies the dropout function to the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">dropout</td><td>The average factor of elements to set to 0 in the input tensor. </td></tr>
    <tr><td class="paramname">state</td><td>The memory used by the RNG. </td></tr>
    <tr><td class="paramname">reserve</td><td>The reserve used for backpropagation. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a42e76b2f949cdee02b78d78332b54391"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a42e76b2f949cdee02b78d78332b54391">&#9670;&nbsp;</a></span>dropout_reserve_size()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::dropout_reserve_size </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>reserve_size</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the necessary reserve size for the dropout. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">reserve_size</td><td>The reserve size. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a998d83500dc32fc4eccbc620d888a8e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a998d83500dc32fc4eccbc620d888a8e4">&#9670;&nbsp;</a></span>dropout_state_size()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::dropout_state_size </td>
          <td>(</td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>state_size</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the necessary state size required for the RNG used by the dropout function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">state_size</td><td>The state size. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a2d1f4116ed51c7f98e7a21df410c4bf1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d1f4116ed51c7f98e7a21df410c4bf1">&#9670;&nbsp;</a></span>get_instance()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">Self</a>&amp; <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::get_instance </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>A reference to the only instance of the class. </dd></dl>

</div>
</div>
<a id="a4029d3474070ab568666b937d3cb2845"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4029d3474070ab568666b937d3cb2845">&#9670;&nbsp;</a></span>op()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::op </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>b</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnOpTensorOp_t&#160;</td>
          <td class="paramname"><em>op_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>c</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It performs the specified operation on tensors a and b and saves the result in c. </p>
<p>\(C = op(\alpha * A, \beta * B) + \gamma * C\)</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">a</td><td>The first operand. </td></tr>
    <tr><td class="paramname">alpha</td><td>The scaling factor of the first operand. </td></tr>
    <tr><td class="paramname">b</td><td>The second operand. </td></tr>
    <tr><td class="paramname">beta</td><td>The scaling factor of the second operand. </td></tr>
    <tr><td class="paramname">op_type</td><td>The operation type. </td></tr>
    <tr><td class="paramname">gamma</td><td>The scaling factor of the result tensor. </td></tr>
    <tr><td class="paramname">c</td><td>The resutl tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a288c41a514d70e017130d713ac6c859d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a288c41a514d70e017130d713ac6c859d">&#9670;&nbsp;</a></span>pool2d_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::pool2d_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>out_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnPoolingMode_t&#160;</td>
          <td class="paramname"><em>pool_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>prev_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the gradient of the input of the pooling layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">out_grad</td><td>The gradient of the output. </td></tr>
    <tr><td class="paramname">pool_mode</td><td>The pooling mode. </td></tr>
    <tr><td class="paramname">window_height</td><td>The height of the pooling window. </td></tr>
    <tr><td class="paramname">window_width</td><td>The width of the pooling window. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the pooling. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the pooling. </td></tr>
    <tr><td class="paramname">prev_out_grad</td><td>The gradient of the input of the pooling layer. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aa51029984f059c00f1a50439c0517418"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa51029984f059c00f1a50439c0517418">&#9670;&nbsp;</a></span>pool2d_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::pool2d_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnPoolingMode_t&#160;</td>
          <td class="paramname"><em>pool_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It performs a 2D pooling operation on the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">pool_mode</td><td>The pooling mode. </td></tr>
    <tr><td class="paramname">window_height</td><td>The height of the pooling window. </td></tr>
    <tr><td class="paramname">window_width</td><td>The width of the pooling window. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the pooling. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the pooling. </td></tr>
    <tr><td class="paramname">output</td><td>The output tensor of the pooling operation. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a59e3724b27ff80653c7fd48afed6cff0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a59e3724b27ff80653c7fd48afed6cff0">&#9670;&nbsp;</a></span>pool2d_output_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::pool2d_output_dims </td>
          <td>(</td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>input_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnPoolingMode_t&#160;</td>
          <td class="paramname"><em>pool_mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>window_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>vertical_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>horizontal_stride</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t &amp;&#160;</td>
          <td class="paramname"><em>output_channels</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes the dimensions of the output of the 2D pooling operation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_height</td><td>The input height. </td></tr>
    <tr><td class="paramname">input_width</td><td>The input width. </td></tr>
    <tr><td class="paramname">input_channels</td><td>The number of input channels. </td></tr>
    <tr><td class="paramname">pool_mode</td><td>The pooling mode. </td></tr>
    <tr><td class="paramname">window_height</td><td>The height of the pooling window. </td></tr>
    <tr><td class="paramname">window_width</td><td>The width of the pooling window. </td></tr>
    <tr><td class="paramname">vertical_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the height rank. </td></tr>
    <tr><td class="paramname">horizontal_padding</td><td>The padding to apply to both the top and the bottom of the input tensor along the width rank. </td></tr>
    <tr><td class="paramname">vertical_stride</td><td>The vertical stride of the pooling. </td></tr>
    <tr><td class="paramname">horizontal_stride</td><td>The horizontal stride of the pooling. </td></tr>
    <tr><td class="paramname">output_height</td><td>The output height. </td></tr>
    <tr><td class="paramname">output_width</td><td>The output width. </td></tr>
    <tr><td class="paramname">output_channels</td><td>The number of output channels. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="acae1ee8f18b6b4ae55b1b522194bd064"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acae1ee8f18b6b4ae55b1b522194bd064">&#9670;&nbsp;</a></span>softmax_bwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::softmax_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>in_out_grad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the gradient of the input of the softmax activation function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">output</td><td>The output tensor. </td></tr>
    <tr><td class="paramname">in_out_grad</td><td>The gradient of the output of the activation function and after the method finishes execution, the gradient of the softmax activation function's input. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aee3f305b96db4978a1bac172ceeb7a41"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee3f305b96db4978a1bac172ceeb7a41">&#9670;&nbsp;</a></span>softmax_fwd()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html">cattle::gpu::CuDNNHandle</a>&lt; Scalar &gt;::softmax_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>&lt; Scalar &gt; &amp;&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It applies the softmax activation function the the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor. </td></tr>
    <tr><td class="paramname">output</td><td>The softmax activated output tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>C:/Users/Viktor/git/C-ATTL3/C-ATTL3/core/gpu/cudnn/<a class="el" href="_cu_d_n_n_handle_8hpp_source.html">CuDNNHandle.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
