<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: cattle::TransConvKernelLayer&lt; Scalar, 1 &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecattle.html">cattle</a></li><li class="navelem"><a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.html">TransConvKernelLayer&lt; Scalar, 1 &gt;</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">cattle::TransConvKernelLayer&lt; Scalar, 1 &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>A class template for a transposed 2D convolutional layer operating on rank-1 data batches (rank-2 tensors).  
 <a href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_trans_conv_kernel_layer_8hpp_source.html">TransConvKernelLayer.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for cattle::TransConvKernelLayer&lt; Scalar, 1 &gt;:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.png" usemap="#cattle::TransConvKernelLayer_3C_20Scalar_2C_201_20_3E_map" alt=""/>
  <map id="cattle::TransConvKernelLayer_3C_20Scalar_2C_201_20_3E_map" name="cattle::TransConvKernelLayer_3C_20Scalar_2C_201_20_3E_map">
<area href="classcattle_1_1_trans_conv_kernel_layer_base.html" alt="cattle::TransConvKernelLayerBase&lt; Scalar, 1 &gt;" shape="rect" coords="0,112,285,136"/>
<area href="classcattle_1_1_kernel_layer.html" title="An abstract class template that represents a kernel-based linear transformation function layer..." alt="cattle::KernelLayer&lt; Scalar, Rank &gt;" shape="rect" coords="0,56,285,80"/>
<area href="classcattle_1_1_layer.html" title="An abstract class template representing layers in a neural network. " alt="cattle::Layer&lt; Scalar, Rank &gt;" shape="rect" coords="0,0,285,24"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a9090769d354995f00340d493f036b284"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a9090769d354995f00340d493f036b284">TransConvKernelLayer</a> (const typename <a class="el" href="classcattle_1_1_dimensions.html">Root::Dims</a> &amp;input_dims, std::size_t filters, <a class="el" href="namespacecattle.html#a5fcb73b3d81bbbcc27f816c46b13735d">ParamInitSharedPtr</a>&lt; Scalar &gt; weight_init, std::size_t receptor_length=3, std::size_t padding=1, std::size_t stride=1, std::size_t dilation=0, <a class="el" href="namespacecattle.html#a8ea9ee634a3a9e87dbc4635d9f14320a">ParamRegSharedPtr</a>&lt; Scalar &gt; weight_reg=nullptr, Scalar weight_clip=0, Scalar weight_max_l1_norm=0, Scalar weight_max_l2_norm=0, Scalar weight_grad_clip=0, Scalar weight_grad_max_l1_norm=0, Scalar weight_grad_max_l2_norm=0, <a class="el" href="namespacecattle.html#a8ea9ee634a3a9e87dbc4635d9f14320a">ParamRegSharedPtr</a>&lt; Scalar &gt; bias_reg=nullptr, Scalar bias_clip=0, Scalar bias_max_l1_norm=0, Scalar bias_max_l2_norm=0, Scalar bias_grad_clip=0, Scalar bias_grad_max_l1_norm=0, Scalar bias_grad_max_l2_norm=0)</td></tr>
<tr class="separator:a9090769d354995f00340d493f036b284"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6080ccef67824a4886b42982186e51aa"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1_layer.html">Root</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a6080ccef67824a4886b42982186e51aa">clone</a> () const</td></tr>
<tr class="memdesc:a6080ccef67824a4886b42982186e51aa"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a clone of the layer instance.  <a href="#a6080ccef67824a4886b42982186e51aa">More...</a><br /></td></tr>
<tr class="separator:a6080ccef67824a4886b42982186e51aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90e9d65ea84f1c74a74147c71976b318"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1_layer.html">Root</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a90e9d65ea84f1c74a74147c71976b318">clone_with_shared_params</a> ()</td></tr>
<tr class="memdesc:a90e9d65ea84f1c74a74147c71976b318"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a clone of the layer instance using a reference to the original's parameters.  <a href="#a90e9d65ea84f1c74a74147c71976b318">More...</a><br /></td></tr>
<tr class="separator:a90e9d65ea84f1c74a74147c71976b318"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03735bb0f5601752db5c420a6bece3ff"><td class="memItemLeft" align="right" valign="top">Root::Data&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a03735bb0f5601752db5c420a6bece3ff">pass_forward</a> (typename Root::Data in, bool training)</td></tr>
<tr class="memdesc:a03735bb0f5601752db5c420a6bece3ff"><td class="mdescLeft">&#160;</td><td class="mdescRight">It has the function represented by the layer applied to the input tensor.  <a href="#a03735bb0f5601752db5c420a6bece3ff">More...</a><br /></td></tr>
<tr class="separator:a03735bb0f5601752db5c420a6bece3ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aedee9c48d1aae1c3294d3a597283d011"><td class="memItemLeft" align="right" valign="top">Root::Data&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aedee9c48d1aae1c3294d3a597283d011">pass_back</a> (typename Root::Data out_grad)</td></tr>
<tr class="memdesc:aedee9c48d1aae1c3294d3a597283d011"><td class="mdescLeft">&#160;</td><td class="mdescRight">It back-propagates the derivative of the error function w.r.t.  <a href="#aedee9c48d1aae1c3294d3a597283d011">More...</a><br /></td></tr>
<tr class="separator:aedee9c48d1aae1c3294d3a597283d011"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classcattle_1_1_kernel_layer"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classcattle_1_1_kernel_layer')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classcattle_1_1_kernel_layer.html">cattle::KernelLayer&lt; Scalar, Rank &gt;</a></td></tr>
<tr class="memitem:a08d25e205022e91c9d13db75fe1babe1 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classcattle_1_1_layer.html">Base</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_kernel_layer.html#a08d25e205022e91c9d13db75fe1babe1">get_params_owner</a> () const</td></tr>
<tr class="memdesc:a08d25e205022e91c9d13db75fe1babe1 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a reference to the layer owning the parameters used.  <a href="classcattle_1_1_kernel_layer.html#a08d25e205022e91c9d13db75fe1babe1">More...</a><br /></td></tr>
<tr class="separator:a08d25e205022e91c9d13db75fe1babe1 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adeda7a9df35daf9f0b75b4241f280591 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classcattle_1_1_dimensions.html">Base::Dims</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_kernel_layer.html#adeda7a9df35daf9f0b75b4241f280591">get_input_dims</a> () const</td></tr>
<tr class="memdesc:adeda7a9df35daf9f0b75b4241f280591 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">A simple constant getter method for the input dimensionality of the layer.  <a href="classcattle_1_1_kernel_layer.html#adeda7a9df35daf9f0b75b4241f280591">More...</a><br /></td></tr>
<tr class="separator:adeda7a9df35daf9f0b75b4241f280591 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af1dd40a0c82ece82e605140cb3e4b3c1 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classcattle_1_1_dimensions.html">Base::Dims</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_kernel_layer.html#af1dd40a0c82ece82e605140cb3e4b3c1">get_output_dims</a> () const</td></tr>
<tr class="memdesc:af1dd40a0c82ece82e605140cb3e4b3c1 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">A simple constant getter method for the output dimensionality of the layer.  <a href="classcattle_1_1_kernel_layer.html#af1dd40a0c82ece82e605140cb3e4b3c1">More...</a><br /></td></tr>
<tr class="separator:af1dd40a0c82ece82e605140cb3e4b3c1 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93f48e39e3e9af884acc8ddd518c45e4 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">is_input_layer</a> () const</td></tr>
<tr class="memdesc:a93f48e39e3e9af884acc8ddd518c45e4 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">A constant method that returns whether this layer functions as an input layer.  <a href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">More...</a><br /></td></tr>
<tr class="separator:a93f48e39e3e9af884acc8ddd518c45e4 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2cfd231e456e1f828dc3638b3a5eb0c7 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_kernel_layer.html#a2cfd231e456e1f828dc3638b3a5eb0c7">set_input_layer</a> (bool input_layer)</td></tr>
<tr class="memdesc:a2cfd231e456e1f828dc3638b3a5eb0c7 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets this instance's input layer status to the given value.  <a href="classcattle_1_1_kernel_layer.html#a2cfd231e456e1f828dc3638b3a5eb0c7">More...</a><br /></td></tr>
<tr class="separator:a2cfd231e456e1f828dc3638b3a5eb0c7 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43964c527f383c2b94555b662bd5ee23 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memItemLeft" align="right" valign="top">std::vector&lt; const Parameters&lt; Scalar &gt; * &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_kernel_layer.html#a43964c527f383c2b94555b662bd5ee23">get_params</a> () const</td></tr>
<tr class="memdesc:a43964c527f383c2b94555b662bd5ee23 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a vector of constant non-owning pointers to the parameters of the layer.  <a href="classcattle_1_1_kernel_layer.html#a43964c527f383c2b94555b662bd5ee23">More...</a><br /></td></tr>
<tr class="separator:a43964c527f383c2b94555b662bd5ee23 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13f89d64108eb11ba7de73a5fa037636 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memItemLeft" align="right" valign="top">std::vector&lt; Parameters&lt; Scalar &gt; * &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_kernel_layer.html#a13f89d64108eb11ba7de73a5fa037636">get_params</a> ()</td></tr>
<tr class="memdesc:a13f89d64108eb11ba7de73a5fa037636 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a vector of non-owning pointers to the parameters of the layer.  <a href="classcattle_1_1_kernel_layer.html#a13f89d64108eb11ba7de73a5fa037636">More...</a><br /></td></tr>
<tr class="separator:a13f89d64108eb11ba7de73a5fa037636 inherit pub_methods_classcattle_1_1_kernel_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classcattle_1_1_layer"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classcattle_1_1_layer')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classcattle_1_1_layer.html">cattle::Layer&lt; Scalar, Rank &gt;</a></td></tr>
<tr class="memitem:ac92d606818b5a240d0ce898e35afe63d inherit pub_methods_classcattle_1_1_layer"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">is_shared_params_clone</a> () const</td></tr>
<tr class="memdesc:ac92d606818b5a240d0ce898e35afe63d inherit pub_methods_classcattle_1_1_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">It determines whether the layer instance is a clone using the shared parameters of another instance.  <a href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">More...</a><br /></td></tr>
<tr class="separator:ac92d606818b5a240d0ce898e35afe63d inherit pub_methods_classcattle_1_1_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ba02f76506a7f8a72f44be78693209e inherit pub_methods_classcattle_1_1_layer"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a3ba02f76506a7f8a72f44be78693209e">is_parametric</a> () const</td></tr>
<tr class="memdesc:a3ba02f76506a7f8a72f44be78693209e inherit pub_methods_classcattle_1_1_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">A method that returns whether the layer has parameters.  <a href="classcattle_1_1_layer.html#a3ba02f76506a7f8a72f44be78693209e">More...</a><br /></td></tr>
<tr class="separator:a3ba02f76506a7f8a72f44be78693209e inherit pub_methods_classcattle_1_1_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pro_methods_classcattle_1_1_kernel_layer"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classcattle_1_1_kernel_layer')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classcattle_1_1_kernel_layer.html">cattle::KernelLayer&lt; Scalar, Rank &gt;</a></td></tr>
<tr class="memitem:a2b3f86fc91f94b904c686f4f7690079a inherit pro_methods_classcattle_1_1_kernel_layer"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_kernel_layer.html#a2b3f86fc91f94b904c686f4f7690079a">KernelLayer</a> (const typename <a class="el" href="classcattle_1_1_dimensions.html">Base::Dims</a> &amp;input_dims, const typename <a class="el" href="classcattle_1_1_dimensions.html">Base::Dims</a> &amp;output_dims, <a class="el" href="namespacecattle.html#a461348c48d2e7c3a187a77e663a72d8b">ParamsSharedPtr</a>&lt; Scalar &gt; weights, <a class="el" href="namespacecattle.html#a461348c48d2e7c3a187a77e663a72d8b">ParamsSharedPtr</a>&lt; Scalar &gt; bias)</td></tr>
<tr class="separator:a2b3f86fc91f94b904c686f4f7690079a inherit pro_methods_classcattle_1_1_kernel_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Scalar&gt;<br />
class cattle::TransConvKernelLayer&lt; Scalar, 1 &gt;</h3>

<p>A class template for a transposed 2D convolutional layer operating on rank-1 data batches (rank-2 tensors). </p>
<p>The results of the convolutions of the filters and the input tensor are concatenated along the highest (2nd) rank of the output tensor.</p>
<dl class="section see"><dt>See also</dt><dd><a href="https://arxiv.org/abs/1603.07285v1">https://arxiv.org/abs/1603.07285v1</a> </dd></dl>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a9090769d354995f00340d493f036b284"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9090769d354995f00340d493f036b284">&#9670;&nbsp;</a></span>TransConvKernelLayer()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1_trans_conv_kernel_layer.html">cattle::TransConvKernelLayer</a>&lt; Scalar, 1 &gt;::<a class="el" href="classcattle_1_1_trans_conv_kernel_layer.html">TransConvKernelLayer</a> </td>
          <td>(</td>
          <td class="paramtype">const typename <a class="el" href="classcattle_1_1_dimensions.html">Root::Dims</a> &amp;&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>filters</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacecattle.html#a5fcb73b3d81bbbcc27f816c46b13735d">ParamInitSharedPtr</a>&lt; Scalar &gt;&#160;</td>
          <td class="paramname"><em>weight_init</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>receptor_length</em> = <code>3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>padding</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>stride</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>dilation</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacecattle.html#a8ea9ee634a3a9e87dbc4635d9f14320a">ParamRegSharedPtr</a>&lt; Scalar &gt;&#160;</td>
          <td class="paramname"><em>weight_reg</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>weight_clip</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>weight_max_l1_norm</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>weight_max_l2_norm</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>weight_grad_clip</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>weight_grad_max_l1_norm</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>weight_grad_max_l2_norm</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacecattle.html#a8ea9ee634a3a9e87dbc4635d9f14320a">ParamRegSharedPtr</a>&lt; Scalar &gt;&#160;</td>
          <td class="paramname"><em>bias_reg</em> = <code>nullptr</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>bias_clip</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>bias_max_l1_norm</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>bias_max_l2_norm</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>bias_grad_clip</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>bias_grad_max_l1_norm</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>bias_grad_max_l2_norm</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_dims</td><td>The dimensionality of the observations to be processed by the layer. </td></tr>
    <tr><td class="paramname">filters</td><td>The number of filters to use. </td></tr>
    <tr><td class="paramname">weight_init</td><td>A shared pointer to a weight initialization used to initialize the weights of the layer. </td></tr>
    <tr><td class="paramname">receptor_length</td><td>The length of the receptor. </td></tr>
    <tr><td class="paramname">padding</td><td>The extent of padding to apply to the input tensor along its length on both ends. </td></tr>
    <tr><td class="paramname">stride</td><td>The convolution stride i.e. the number of elements by which the receptor is to be shifted along the length of the input tensor. </td></tr>
    <tr><td class="paramname">dilation</td><td>The extent of dilation to apply to the receptor. </td></tr>
    <tr><td class="paramname">weight_reg</td><td>An optional regularization function to apply to the weights. </td></tr>
    <tr><td class="paramname">weight_clip</td><td>The maximum allowed absolute weight value. If it is 0 or less, no value clipping is performed. </td></tr>
    <tr><td class="paramname">weight_max_l1_norm</td><td>The maximum allowed L1 weight value norm. If it is 0 or less, no L1 max norm constraint is enforced. </td></tr>
    <tr><td class="paramname">weight_max_l2_norm</td><td>The maximum allowed L2 weight value norm. If it is 0 or less, no L2 max norm constraint is enforced. </td></tr>
    <tr><td class="paramname">weight_grad_clip</td><td>The maximum allowed absolute weight gradient. If it is 0 or less, no gradient clipping is performed. </td></tr>
    <tr><td class="paramname">weight_grad_max_l1_norm</td><td>The maximum allowed L1 weight gradient norm. If it is 0 or less, no L1 gradient max norm constraint is enforced. </td></tr>
    <tr><td class="paramname">weight_grad_max_l2_norm</td><td>The maximum allowed L2 weight gradient norm. If it is 0 or less, no L2 gradient max norm constraint is enforced. </td></tr>
    <tr><td class="paramname">bias_reg</td><td>An optional regularization function to apply to the bias. </td></tr>
    <tr><td class="paramname">bias_clip</td><td>The maximum allowed absolute bias value. If it is 0 or less, no value clipping is performed. </td></tr>
    <tr><td class="paramname">bias_max_l1_norm</td><td>The maximum allowed L1 bias value norm. If it is 0 or less, no bias L1 max norm constraint is enforced. </td></tr>
    <tr><td class="paramname">bias_max_l2_norm</td><td>The maximum allowed L2 bias value norm. If it is 0 or less, no bias L2 max norm constraint is enforced. </td></tr>
    <tr><td class="paramname">bias_grad_clip</td><td>The maximum allowed absolute bias gradient. If it is 0 or less, no gradient clipping is performed. </td></tr>
    <tr><td class="paramname">bias_grad_max_l1_norm</td><td>The maximum allowed L1 bias gradient norm. If it is 0 or less, no bias L1 gradient max norm constraint is enforced. </td></tr>
    <tr><td class="paramname">bias_grad_max_l2_norm</td><td>The maximum allowed L2 bias gradient norm. If it is 0 or less, no bias L2 gradient max norm constraint is enforced. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a6080ccef67824a4886b42982186e51aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6080ccef67824a4886b42982186e51aa">&#9670;&nbsp;</a></span>clone()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1_layer.html">Root</a>* <a class="el" href="classcattle_1_1_trans_conv_kernel_layer.html">cattle::TransConvKernelLayer</a>&lt; Scalar, 1 &gt;::clone </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a clone of the layer instance. </p>
<dl class="section return"><dt>Returns</dt><dd>A pointer to a copy of the instance. The instance does not take ownership of the returned pointer (i.e. the caller is responsible for deleting it). </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a46db46c62f3d46c6bbef5a482d7fcb00">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a90e9d65ea84f1c74a74147c71976b318"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a90e9d65ea84f1c74a74147c71976b318">&#9670;&nbsp;</a></span>clone_with_shared_params()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1_layer.html">Root</a>* <a class="el" href="classcattle_1_1_trans_conv_kernel_layer.html">cattle::TransConvKernelLayer</a>&lt; Scalar, 1 &gt;::clone_with_shared_params </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a clone of the layer instance using a reference to the original's parameters. </p>
<p>Non-parametric layers do not need to support parameter sharing and thus are just expected to return a normal clone.</p>
<dl class="section return"><dt>Returns</dt><dd>A clone of the original layer instance sharing the same parameters with the original. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a074a197df04250449a059d97a4e6e120">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="aedee9c48d1aae1c3294d3a597283d011"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aedee9c48d1aae1c3294d3a597283d011">&#9670;&nbsp;</a></span>pass_back()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Root::Data <a class="el" href="classcattle_1_1_trans_conv_kernel_layer.html">cattle::TransConvKernelLayer</a>&lt; Scalar, 1 &gt;::pass_back </td>
          <td>(</td>
          <td class="paramtype">typename Root::Data&#160;</td>
          <td class="paramname"><em>out_grad</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It back-propagates the derivative of the error function w.r.t. </p>
<p>the output of the layer updating the gradient of its learnable parameters along the way if there are any.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out_grad</td><td>The derivative of the loss function w.r.t. the output of the layer </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The derivative of the loss function w.r.t. the output of the previous layer or a null tensor if the layer is an input layer. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a7cb51862ef9b87632b5abb8e3ab36dd9">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a03735bb0f5601752db5c420a6bece3ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a03735bb0f5601752db5c420a6bece3ff">&#9670;&nbsp;</a></span>pass_forward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Root::Data <a class="el" href="classcattle_1_1_trans_conv_kernel_layer.html">cattle::TransConvKernelLayer</a>&lt; Scalar, 1 &gt;::pass_forward </td>
          <td>(</td>
          <td class="paramtype">typename Root::Data&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>training</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It has the function represented by the layer applied to the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>A tensor representing a batch of observations. The observations are of the rank specified by the layer's template parameter and the input tensors rank is one greater. </td></tr>
    <tr><td class="paramname">training</td><td>Whether the input is to be processed in training or inference mode. If the forward pass is performed in inference mode, the backward pass is not guaranteed to work. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output of the function represented by the layer applied to the input tensor. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a6c1ea7b25d9f882364b7f2288f02d8da">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/viktorcsomor/git/C-ATTL3/C-ATTL3/layer/kernel/<a class="el" href="_trans_conv_kernel_layer_8hpp_source.html">TransConvKernelLayer.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
