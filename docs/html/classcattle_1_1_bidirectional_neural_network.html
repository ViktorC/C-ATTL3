<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: cattle::BidirectionalNeuralNetwork&lt; Scalar, Rank, MergeType &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecattle.html">cattle</a></li><li class="navelem"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html">BidirectionalNeuralNetwork</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classcattle_1_1_bidirectional_neural_network-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">cattle::BidirectionalNeuralNetwork&lt; Scalar, Rank, MergeType &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>A class template for a bidirectional neural network that takes a unidirectional recurrent network, clones it, reverses the clone's processing direction, and uses the two networks as its parallel sub-modules.  
 <a href="classcattle_1_1_bidirectional_neural_network.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_bidirectional_neural_network_8hpp_source.html">BidirectionalNeuralNetwork.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for cattle::BidirectionalNeuralNetwork&lt; Scalar, Rank, MergeType &gt;:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classcattle_1_1_bidirectional_neural_network.png" usemap="#cattle::BidirectionalNeuralNetwork_3C_20Scalar_2C_20Rank_2C_20MergeType_20_3E_map" alt=""/>
  <map id="cattle::BidirectionalNeuralNetwork_3C_20Scalar_2C_20Rank_2C_20MergeType_20_3E_map" name="cattle::BidirectionalNeuralNetwork_3C_20Scalar_2C_20Rank_2C_20MergeType_20_3E_map">
<area href="classcattle_1_1_composite_neural_network.html" alt="cattle::CompositeNeuralNetwork&lt; Scalar, Rank, true, UnidirectionalNeuralNetwork&lt; Scalar, Rank &gt; &gt;" shape="rect" coords="0,56,587,80"/>
<area href="classcattle_1_1_neural_network.html" title="An abstract neural network class template. " alt="cattle::NeuralNetwork&lt; Scalar, Rank, Sequential &gt;" shape="rect" coords="0,0,587,24"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a3ec916796edf657aa7280330c827e1e9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#a3ec916796edf657aa7280330c827e1e9">BidirectionalNeuralNetwork</a> (UnidirNet &amp;&amp;network, bool foremost=true)</td></tr>
<tr class="separator:a3ec916796edf657aa7280330c827e1e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac3200af26b657df73ee81b230d710fa6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1_neural_network.html">Base</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#ac3200af26b657df73ee81b230d710fa6">clone</a> () const</td></tr>
<tr class="memdesc:ac3200af26b657df73ee81b230d710fa6"><td class="mdescLeft">&#160;</td><td class="mdescRight">A constant method implementing the clone pattern.  <a href="#ac3200af26b657df73ee81b230d710fa6">More...</a><br /></td></tr>
<tr class="separator:ac3200af26b657df73ee81b230d710fa6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeb9d32ff0cc9163beb470f234cc10537"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classcattle_1_1_dimensions.html">Base::Dims</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#aeb9d32ff0cc9163beb470f234cc10537">get_input_dims</a> () const</td></tr>
<tr class="separator:aeb9d32ff0cc9163beb470f234cc10537"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac567c95a4dd332dd2239c5a6714bc75"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classcattle_1_1_dimensions.html">Base::Dims</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#aac567c95a4dd332dd2239c5a6714bc75">get_output_dims</a> () const</td></tr>
<tr class="separator:aac567c95a4dd332dd2239c5a6714bc75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac882ffb4e50ed675dc1cae9f2bbd2d18"><td class="memItemLeft" align="right" valign="top">std::vector&lt; const <a class="el" href="classcattle_1_1_layer.html">Layer</a>&lt; Scalar, Rank &gt; * &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#ac882ffb4e50ed675dc1cae9f2bbd2d18">get_layers</a> () const</td></tr>
<tr class="separator:ac882ffb4e50ed675dc1cae9f2bbd2d18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a052fff2227a28520de4ef74cd8f45352"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="classcattle_1_1_layer.html">Layer</a>&lt; Scalar, Rank &gt; * &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#a052fff2227a28520de4ef74cd8f45352">get_layers</a> ()</td></tr>
<tr class="separator:a052fff2227a28520de4ef74cd8f45352"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9249dbef2dc0bf7955af7a2bd2bc794"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="classcattle_1_1_unidirectional_neural_network.html">UnidirectionalNeuralNetwork</a>&lt; Scalar, Rank &gt; * &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#ae9249dbef2dc0bf7955af7a2bd2bc794">get_modules</a> ()</td></tr>
<tr class="separator:ae9249dbef2dc0bf7955af7a2bd2bc794"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2cd4e95bebb7272f37371f635bb09466"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#a2cd4e95bebb7272f37371f635bb09466">is_foremost</a> () const</td></tr>
<tr class="separator:a2cd4e95bebb7272f37371f635bb09466"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8c18a8cb33b287577ed9ce352b5acf0b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#a8c18a8cb33b287577ed9ce352b5acf0b">set_foremost</a> (bool foremost)</td></tr>
<tr class="memdesc:a8c18a8cb33b287577ed9ce352b5acf0b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the foremost status of the network.  <a href="#a8c18a8cb33b287577ed9ce352b5acf0b">More...</a><br /></td></tr>
<tr class="separator:a8c18a8cb33b287577ed9ce352b5acf0b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03dd8e8bc89e04cb56887463e3fc9d5b"><td class="memItemLeft" align="right" valign="top"><a id="a03dd8e8bc89e04cb56887463e3fc9d5b"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#a03dd8e8bc89e04cb56887463e3fc9d5b">empty_caches</a> ()</td></tr>
<tr class="memdesc:a03dd8e8bc89e04cb56887463e3fc9d5b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Empties the caches of every layer of the network. <br /></td></tr>
<tr class="separator:a03dd8e8bc89e04cb56887463e3fc9d5b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeea3e43b89d4bdd0ac9b9e81c6815aa9"><td class="memItemLeft" align="right" valign="top">Base::Data&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#aeea3e43b89d4bdd0ac9b9e81c6815aa9">propagate</a> (typename Base::Data input, bool training)</td></tr>
<tr class="memdesc:aeea3e43b89d4bdd0ac9b9e81c6815aa9"><td class="mdescLeft">&#160;</td><td class="mdescRight">It propagates the input tensor through the network and outputs its prediction.  <a href="#aeea3e43b89d4bdd0ac9b9e81c6815aa9">More...</a><br /></td></tr>
<tr class="separator:aeea3e43b89d4bdd0ac9b9e81c6815aa9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8fd84ef4bcc7d1a4ab5e7eecfb25340"><td class="memItemLeft" align="right" valign="top">Base::Data&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html#aa8fd84ef4bcc7d1a4ab5e7eecfb25340">backpropagate</a> (typename Base::Data out_grad)</td></tr>
<tr class="memdesc:aa8fd84ef4bcc7d1a4ab5e7eecfb25340"><td class="mdescLeft">&#160;</td><td class="mdescRight">It back-propagates the derivative of the loss function w.r.t.  <a href="#aa8fd84ef4bcc7d1a4ab5e7eecfb25340">More...</a><br /></td></tr>
<tr class="separator:aa8fd84ef4bcc7d1a4ab5e7eecfb25340"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classcattle_1_1_neural_network"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classcattle_1_1_neural_network')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classcattle_1_1_neural_network.html">cattle::NeuralNetwork&lt; Scalar, Rank, Sequential &gt;</a></td></tr>
<tr class="memitem:a94a8c8170471486c5f10ba09a5709ad6 inherit pub_methods_classcattle_1_1_neural_network"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_neural_network.html#a94a8c8170471486c5f10ba09a5709ad6">set_frozen</a> (bool frozen)</td></tr>
<tr class="memdesc:a94a8c8170471486c5f10ba09a5709ad6 inherit pub_methods_classcattle_1_1_neural_network"><td class="mdescLeft">&#160;</td><td class="mdescRight">Invokes the Layer::set_frozen(bool) method of all layers of the network with the provided argument.  <a href="classcattle_1_1_neural_network.html#a94a8c8170471486c5f10ba09a5709ad6">More...</a><br /></td></tr>
<tr class="separator:a94a8c8170471486c5f10ba09a5709ad6 inherit pub_methods_classcattle_1_1_neural_network"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae59c0963d75b1f2de4f18a6c8fe85fa8 inherit pub_methods_classcattle_1_1_neural_network"><td class="memItemLeft" align="right" valign="top"><a id="ae59c0963d75b1f2de4f18a6c8fe85fa8"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_neural_network.html#ae59c0963d75b1f2de4f18a6c8fe85fa8">init</a> ()</td></tr>
<tr class="memdesc:ae59c0963d75b1f2de4f18a6c8fe85fa8 inherit pub_methods_classcattle_1_1_neural_network"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initializes all parameters of the network. <br /></td></tr>
<tr class="separator:ae59c0963d75b1f2de4f18a6c8fe85fa8 inherit pub_methods_classcattle_1_1_neural_network"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac88007e2f8fa2a208de0e51c8ac422cc inherit pub_methods_classcattle_1_1_neural_network"><td class="memItemLeft" align="right" valign="top">virtual Data&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_neural_network.html#ac88007e2f8fa2a208de0e51c8ac422cc">infer</a> (Data input)</td></tr>
<tr class="memdesc:ac88007e2f8fa2a208de0e51c8ac422cc inherit pub_methods_classcattle_1_1_neural_network"><td class="mdescLeft">&#160;</td><td class="mdescRight">It propagates the input through the neural network and outputs its prediction according to its current parameters.  <a href="classcattle_1_1_neural_network.html#ac88007e2f8fa2a208de0e51c8ac422cc">More...</a><br /></td></tr>
<tr class="separator:ac88007e2f8fa2a208de0e51c8ac422cc inherit pub_methods_classcattle_1_1_neural_network"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Scalar, std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt;<br />
class cattle::BidirectionalNeuralNetwork&lt; Scalar, Rank, MergeType &gt;</h3>

<p>A class template for a bidirectional neural network that takes a unidirectional recurrent network, clones it, reverses the clone's processing direction, and uses the two networks as its parallel sub-modules. </p>
<p>The outputs of the two sub-networks can be merged by summation or concatenation either along the lowest (the 3rd after the sample and time-step ranks) or highest rank.</p>
<dl class="section see"><dt>See also</dt><dd><a href="https://pdfs.semanticscholar.org/4b80/89bc9b49f84de43acc2eb8900035f7d492b2.pdf">https://pdfs.semanticscholar.org/4b80/89bc9b49f84de43acc2eb8900035f7d492b2.pdf</a> </dd></dl>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a3ec916796edf657aa7280330c827e1e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3ec916796edf657aa7280330c827e1e9">&#9670;&nbsp;</a></span>BidirectionalNeuralNetwork()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1_bidirectional_neural_network.html">cattle::BidirectionalNeuralNetwork</a>&lt; Scalar, Rank, MergeType &gt;::<a class="el" href="classcattle_1_1_bidirectional_neural_network.html">BidirectionalNeuralNetwork</a> </td>
          <td>(</td>
          <td class="paramtype">UnidirNet &amp;&amp;&#160;</td>
          <td class="paramname"><em>network</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>foremost</em> = <code>true</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">network</td><td>A unique pointer to a unidirectional recurrent neural network that, along with its reversed clone, will constitute the bidirectional network. </td></tr>
    <tr><td class="paramname">foremost</td><td>Whether the network is to function as a foremost network. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="aa8fd84ef4bcc7d1a4ab5e7eecfb25340"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa8fd84ef4bcc7d1a4ab5e7eecfb25340">&#9670;&nbsp;</a></span>backpropagate()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Base::Data <a class="el" href="classcattle_1_1_bidirectional_neural_network.html">cattle::BidirectionalNeuralNetwork</a>&lt; Scalar, Rank, MergeType &gt;::backpropagate </td>
          <td>(</td>
          <td class="paramtype">typename Base::Data&#160;</td>
          <td class="paramname"><em>out_grad</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It back-propagates the derivative of the loss function w.r.t. </p>
<p>the output of the network through its layers updating the gradients on their parameters.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out_grad</td><td>The derivative of the loss function w.r.t. the output of the network. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The derivative of the loss function w.r.t. the input of the network or a null tensor if the network is a foremost network. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_neural_network.html#a550bd7dea6ddac56160b5cafd54e8962">cattle::NeuralNetwork&lt; Scalar, Rank, Sequential &gt;</a>.</p>

</div>
</div>
<a id="ac3200af26b657df73ee81b230d710fa6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac3200af26b657df73ee81b230d710fa6">&#9670;&nbsp;</a></span>clone()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1_neural_network.html">Base</a>* <a class="el" href="classcattle_1_1_bidirectional_neural_network.html">cattle::BidirectionalNeuralNetwork</a>&lt; Scalar, Rank, MergeType &gt;::clone </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>A constant method implementing the clone pattern. </p>
<dl class="section return"><dt>Returns</dt><dd>A pointer to a copy of the instance. The instance does not take ownership of the returned pointer (i.e. the caller is responsible for deleting it). </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_neural_network.html#a2abd58d4e18caa4ae95563da19c8338b">cattle::NeuralNetwork&lt; Scalar, Rank, Sequential &gt;</a>.</p>

</div>
</div>
<a id="aeb9d32ff0cc9163beb470f234cc10537"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeb9d32ff0cc9163beb470f234cc10537">&#9670;&nbsp;</a></span>get_input_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classcattle_1_1_dimensions.html">Base::Dims</a>&amp; <a class="el" href="classcattle_1_1_bidirectional_neural_network.html">cattle::BidirectionalNeuralNetwork</a>&lt; Scalar, Rank, MergeType &gt;::get_input_dims </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>A constant reference to the member variable denoting the dimensions of the tensors accepted by the network as its input along (except for the first rank which denotes the variable sample size and in case of sequential networks the second rank which denotes the variable time steps). </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_neural_network.html#acbea7d3cad12acbd2728e092acba4a25">cattle::NeuralNetwork&lt; Scalar, Rank, Sequential &gt;</a>.</p>

</div>
</div>
<a id="ac882ffb4e50ed675dc1cae9f2bbd2d18"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac882ffb4e50ed675dc1cae9f2bbd2d18">&#9670;&nbsp;</a></span>get_layers() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;const <a class="el" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt;*&gt; <a class="el" href="classcattle_1_1_bidirectional_neural_network.html">cattle::BidirectionalNeuralNetwork</a>&lt; Scalar, Rank, MergeType &gt;::get_layers </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>A vector of pointers to constant layers constituting the network. The ownership of the layers remains with the network. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_neural_network.html#a9e116cf4abef2248b212ef21d58fa4e8">cattle::NeuralNetwork&lt; Scalar, Rank, Sequential &gt;</a>.</p>

</div>
</div>
<a id="a052fff2227a28520de4ef74cd8f45352"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a052fff2227a28520de4ef74cd8f45352">&#9670;&nbsp;</a></span>get_layers() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;<a class="el" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt;*&gt; <a class="el" href="classcattle_1_1_bidirectional_neural_network.html">cattle::BidirectionalNeuralNetwork</a>&lt; Scalar, Rank, MergeType &gt;::get_layers </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>A vector of pointers to the layers of the network. The ownership of the layers remains with the network. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_neural_network.html#a297039d2fff23643c9b73da7b4bb686c">cattle::NeuralNetwork&lt; Scalar, Rank, Sequential &gt;</a>.</p>

</div>
</div>
<a id="ae9249dbef2dc0bf7955af7a2bd2bc794"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae9249dbef2dc0bf7955af7a2bd2bc794">&#9670;&nbsp;</a></span>get_modules()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;<a class="el" href="classcattle_1_1_unidirectional_neural_network.html">UnidirectionalNeuralNetwork</a>&lt;Scalar,Rank&gt;*&gt; <a class="el" href="classcattle_1_1_bidirectional_neural_network.html">cattle::BidirectionalNeuralNetwork</a>&lt; Scalar, Rank, MergeType &gt;::get_modules </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>A vector of pointers pointing to the sub-modules of the composite network instance. The ownership of the modules is not transferred to the caller of the method. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_composite_neural_network.html#ab7f9075535798ac5b144364c390bcc66">cattle::CompositeNeuralNetwork&lt; Scalar, Rank, true, UnidirectionalNeuralNetwork&lt; Scalar, Rank &gt; &gt;</a>.</p>

</div>
</div>
<a id="aac567c95a4dd332dd2239c5a6714bc75"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac567c95a4dd332dd2239c5a6714bc75">&#9670;&nbsp;</a></span>get_output_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classcattle_1_1_dimensions.html">Base::Dims</a>&amp; <a class="el" href="classcattle_1_1_bidirectional_neural_network.html">cattle::BidirectionalNeuralNetwork</a>&lt; Scalar, Rank, MergeType &gt;::get_output_dims </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>A constant reference to the member variable denoting the dimensions of the tensors output by the network (except for the first rank which denotes the variable sample size and in case of sequential networks the second rank which denotes the variable time steps). </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_neural_network.html#abae4c549cee2b29c2b6e072ce0314303">cattle::NeuralNetwork&lt; Scalar, Rank, Sequential &gt;</a>.</p>

</div>
</div>
<a id="a2cd4e95bebb7272f37371f635bb09466"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2cd4e95bebb7272f37371f635bb09466">&#9670;&nbsp;</a></span>is_foremost()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classcattle_1_1_bidirectional_neural_network.html">cattle::BidirectionalNeuralNetwork</a>&lt; Scalar, Rank, MergeType &gt;::is_foremost </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>Whether the instance is a foremost network. If the instance is not a stand-alone network and it is not the first module of a complex network, it is not a foremost network. Foremost networks do not need to back-propagate the gradients all the way given that no other network is expected to depend on them. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_neural_network.html#a5dadb8900281afff9167f02b2d75c86a">cattle::NeuralNetwork&lt; Scalar, Rank, Sequential &gt;</a>.</p>

</div>
</div>
<a id="aeea3e43b89d4bdd0ac9b9e81c6815aa9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeea3e43b89d4bdd0ac9b9e81c6815aa9">&#9670;&nbsp;</a></span>propagate()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Base::Data <a class="el" href="classcattle_1_1_bidirectional_neural_network.html">cattle::BidirectionalNeuralNetwork</a>&lt; Scalar, Rank, MergeType &gt;::propagate </td>
          <td>(</td>
          <td class="paramtype">typename Base::Data&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>training</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It propagates the input tensor through the network and outputs its prediction. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to propagate through. </td></tr>
    <tr><td class="paramname">training</td><td>Whether the input is to be propagated in training mode or not. Propagating the input in training mode may be more time and memory consuming, but is a prerequisite of back-propagation. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor of the network in response to the input. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_neural_network.html#a6ade9cd95110766ff25e7b157c9fddcf">cattle::NeuralNetwork&lt; Scalar, Rank, Sequential &gt;</a>.</p>

</div>
</div>
<a id="a8c18a8cb33b287577ed9ce352b5acf0b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8c18a8cb33b287577ed9ce352b5acf0b">&#9670;&nbsp;</a></span>set_foremost()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank, BidirectionalOutputMergeType MergeType = BIDIRECTIONAL_CONCAT_LO_RANK&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1_bidirectional_neural_network.html">cattle::BidirectionalNeuralNetwork</a>&lt; Scalar, Rank, MergeType &gt;::set_foremost </td>
          <td>(</td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>foremost</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Sets the foremost status of the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">foremost</td><td>Whether the network is to function as a foremost network. </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classcattle_1_1_neural_network.html#ae417618e6c761cf7630f24dff2d3568a">cattle::NeuralNetwork&lt; Scalar, Rank, Sequential &gt;</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>C:/Users/Viktor/git/C-ATTL3/C-ATTL3/neural_network/<a class="el" href="_bidirectional_neural_network_8hpp_source.html">BidirectionalNeuralNetwork.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
