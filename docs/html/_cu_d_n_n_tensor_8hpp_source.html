<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: /Users/viktorcsomor/git/C-ATTL3/C-ATTL3/core/gpu/cudnn/CuDNNTensor.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_b8183163ce8e0490cf11c57c211e66be.html">C-ATTL3</a></li><li class="navelem"><a class="el" href="dir_d7824ce09980932099a987dd9d70823b.html">core</a></li><li class="navelem"><a class="el" href="dir_15b5e1e2b6051de2786d263ad618ae2e.html">gpu</a></li><li class="navelem"><a class="el" href="dir_e7aea75ab8a939289453563a3f200fc4.html">cudnn</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">CuDNNTensor.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/*</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"> * CuDNNTensor.hpp</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> *  Created on: 8 Jul 2018</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> *      Author: Viktor Csomor</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &lt;cmath&gt;</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &lt;cudnn.h&gt;</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &lt;ostream&gt;</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &lt;sstream&gt;</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &lt;string&gt;</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &lt;type_traits&gt;</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#include &lt;utility&gt;</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &quot;core/EigenProxy.hpp&quot;</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &quot;core/gpu/cuda/CUDAArray.hpp&quot;</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include &quot;CuDNNHandle.hpp&quot;</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="preprocessor">#ifndef C_ATTL3_CORE_GPU_CUDNN_CUDNNTENSOR_H_</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="preprocessor">#define C_ATTL3_CORE_GPU_CUDNN_CUDNNTENSOR_H_</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacecattle.html">cattle</a> {</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="keyword">namespace </span>gpu {</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l00030"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">   30</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray</a>&lt;Scalar&gt; {</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;    static_assert(std::is_floating_point&lt;Scalar&gt;::value, <span class="stringliteral">&quot;non floating-point scalar type&quot;</span>);</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray&lt;Scalar&gt;</a> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Base</a>;</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor&lt;Scalar&gt;</a> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;    <span class="keyword">static</span> constexpr cudnnDataType_t DATA_TYPE = std::is_same&lt;Scalar,float&gt;::value ?</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;            CUDNN_DATA_FLOAT : CUDNN_DATA_DOUBLE;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;    <span class="keyword">static</span> constexpr cudnnTensorFormat_t TENSOR_FORMAT = CUDNN_TENSOR_NCHW;</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;    <span class="keyword">static</span> constexpr cudnnNanPropagation_t NAN_PROP = CUDNN_PROPAGATE_NAN;</div><div class="line"><a name="l00047"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a65a43e2a1db06f62805887b0fe15a274">   47</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a65a43e2a1db06f62805887b0fe15a274">CuDNNTensor</a>(Scalar* <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>,</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;            std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>) :</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;                <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Base</a>(<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a> * <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a> * <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a> * <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>),</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;                _samples(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>),</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;                _height(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>),</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;                _width(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>),</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;                _channels(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>),</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;                _desc(),</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;                _filter_desc() {</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>() &gt; 0) {</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#afed1d051b60b5bec470cb343a39b140b">create_tensor_descriptor</a>(_desc, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>);</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2f655c4ac5713c8a79c2f45ffac06ced">create_filter_descriptor</a>(_filter_desc, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>);</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;        }</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;    }</div><div class="line"><a name="l00067"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ac6b7b616ec8965672b82f8186066bc29">   67</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ac6b7b616ec8965672b82f8186066bc29">CuDNNTensor</a>(std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>) :</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Base</a>(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a> * <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a> * <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a> * <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>),</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;            _samples(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>),</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;            _height(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>),</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;            _width(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>),</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;            _channels(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>),</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;            _desc(),</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;            _filter_desc() {</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>() &gt; 0) {</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#afed1d051b60b5bec470cb343a39b140b">create_tensor_descriptor</a>(_desc, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>);</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2f655c4ac5713c8a79c2f45ffac06ced">create_filter_descriptor</a>(_filter_desc, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>);</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;        }</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;    }</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>() :</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a>(0u, 0u, 0u, 0u) { }</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    <span class="keyword">inline</span> CuDNNTensor(<span class="keyword">const</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a>&amp; tensor) :</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;            CuDNNTensor(tensor.dimension(0), tensor.dimension(1), tensor.dimension(2), tensor.dimension(3)) {</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>() &gt; 0) {</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;            <span class="keyword">static</span> std::array&lt;std::size_t,4&gt; eigen_to_cudnn_layout({ 2u, 1u, 2u, 0u });</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;            Tensor&lt;Scalar,4&gt; shuffled_tensor = tensor.shuffle(eigen_to_cudnn_layout);</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a53a0b01db3d84497c5c7c47a8582a22d">Base::copy_from_host</a>(shuffled_tensor.data());</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;        }</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;    }</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a65a43e2a1db06f62805887b0fe15a274">CuDNNTensor</a>(<span class="keyword">const</span> Self&amp; tensor) :</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;            Base(tensor),</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;            _samples(tensor._samples),</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;            _height(tensor._height),</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;            _width(tensor._width),</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;            _channels(tensor._channels),</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;            _desc(tensor._desc),</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;            _filter_desc(tensor._filter_desc) { }</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a65a43e2a1db06f62805887b0fe15a274">CuDNNTensor</a>(Self&amp;&amp; tensor) :</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a65a43e2a1db06f62805887b0fe15a274">CuDNNTensor</a>() {</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;        swap(*<span class="keyword">this</span>, tensor);</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;    }</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;    <span class="keyword">inline</span> ~<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a65a43e2a1db06f62805887b0fe15a274">CuDNNTensor</a>() {</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>() &gt; 0) {</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aae03ac08e0d7c75a1151bf6ba0aeb173">destroy_tensor_descriptor</a>(_desc);</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2a54952cb1443c033f047f8dd7a0338c">destroy_filter_descriptor</a>(_filter_desc);</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;        }</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;    }</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;    <span class="keyword">inline</span> Self&amp; operator=(Self tensor) {</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;        swap(*<span class="keyword">this</span>, tensor);</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;    }</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;    <span class="keyword">inline</span> <span class="keyword">operator</span> Tensor&lt;Scalar,4&gt;() <span class="keyword">const</span> {</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>() == 0)</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;            <span class="keywordflow">return</span> Tensor&lt;Scalar,4&gt;();</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;        Tensor&lt;Scalar,4&gt; out(_width, _height, _channels, _samples);</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#ab3aeb7d6d0bb4583880a3b187a3c5945">Base::copy_to_host</a>(out.data());</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;        <span class="keyword">static</span> std::array&lt;std::size_t,4&gt; cudnn_to_eigen_layout({ 3u, 1u, 0u, 2u });</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;        <span class="keywordflow">return</span> out.shuffle(cudnn_to_eigen_layout);</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;    }</div><div class="line"><a name="l00123"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">  123</a></span>&#160;    <span class="keyword">inline</span> std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;        <span class="keywordflow">return</span> _samples;</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;    }</div><div class="line"><a name="l00129"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">  129</a></span>&#160;    <span class="keyword">inline</span> std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;        <span class="keywordflow">return</span> _height;</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;    }</div><div class="line"><a name="l00135"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">  135</a></span>&#160;    <span class="keyword">inline</span> std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;        <span class="keywordflow">return</span> _width;</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;    }</div><div class="line"><a name="l00141"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">  141</a></span>&#160;    <span class="keyword">inline</span> std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;        <span class="keywordflow">return</span> _channels;</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;    }</div><div class="line"><a name="l00147"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">  147</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> cudnnTensorDescriptor_t&amp; <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;        <span class="keywordflow">return</span> _desc;</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;    }</div><div class="line"><a name="l00153"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ace265c09fcf365ac3900013ff0c971fe">  153</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> cudnnFilterDescriptor_t&amp; <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ace265c09fcf365ac3900013ff0c971fe">filter_desc</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;        <span class="keywordflow">return</span> _filter_desc;</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;    }</div><div class="line"><a name="l00159"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a48fd267290bfb7b49e39a6d1e1b844ab">  159</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a48fd267290bfb7b49e39a6d1e1b844ab">set_values</a>(Scalar value) {</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;        cudnnAssert(cudnnSetTensor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a3e7f931474c7a4d2c5b2550e1e58cb5b">CuDNNHandle::get_instance</a>(), _desc, _data, value));</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;    }</div><div class="line"><a name="l00168"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">  168</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(cudnnReduceTensorOp_t op_type)<span class="keyword"> const </span>{</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> reduced_tensor(1u, 1u, 1u, 1u);</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2d054df2a19f7623dfbda10bfcf639ae">reduce_op</a>(1, *<span class="keyword">this</span>, op_type, 0, reduced_tensor);</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;        Scalar res;</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;        reduced_tensor.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#ab3aeb7d6d0bb4583880a3b187a3c5945">copy_to_host</a>(&amp;res);</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;        <span class="keywordflow">return</span> res;</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;    }</div><div class="line"><a name="l00182"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a794d079d4446a5a55beed6ac65ab4e72">  182</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a794d079d4446a5a55beed6ac65ab4e72">reduce</a>(cudnnReduceTensorOp_t op_type, <span class="keyword">const</span> std::array&lt;bool,4&gt;&amp; ranks)<span class="keyword"> const </span>{</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> reduced_tensor(ranks[0] ? 1u : _samples, ranks[1] ? 1u : _height,</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;                ranks[2] ? 1u : _width, ranks[3] ? 1u : _channels);</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2d054df2a19f7623dfbda10bfcf639ae">reduce_op</a>(1, *<span class="keyword">this</span>, op_type, 0, reduced_tensor);</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;        <span class="keywordflow">return</span> reduced_tensor;</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;    }</div><div class="line"><a name="l00191"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a9094c2bf0bf56e5ca174a8ee9c13d0ee">  191</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a9094c2bf0bf56e5ca174a8ee9c13d0ee">sum</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_ADD);</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;    }</div><div class="line"><a name="l00198"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aea14b2fc6d9f4df9c8e03f5177966899">  198</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aea14b2fc6d9f4df9c8e03f5177966899">sum</a>(<span class="keyword">const</span> std::array&lt;bool,4&gt;&amp; ranks)<span class="keyword"> const </span>{</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_ADD, ranks);</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;    }</div><div class="line"><a name="l00204"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a14fd93aae07810d6e5889015caa7186c">  204</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a14fd93aae07810d6e5889015caa7186c">avg</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_AVG);</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;    }</div><div class="line"><a name="l00211"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a8d8eb060deed9d0fe65ab385d559e4e6">  211</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a8d8eb060deed9d0fe65ab385d559e4e6">avg</a>(<span class="keyword">const</span> std::array&lt;bool,4&gt;&amp; ranks)<span class="keyword"> const </span>{</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_AVG, ranks);</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;    }</div><div class="line"><a name="l00217"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ac6b9a062dd41eb9cefaaccc003f1d44d">  217</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ac6b9a062dd41eb9cefaaccc003f1d44d">min</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_MIN);</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;    }</div><div class="line"><a name="l00224"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ab45c4cf77bc7a4aaabda0ea8a0d57282">  224</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ab45c4cf77bc7a4aaabda0ea8a0d57282">min</a>(<span class="keyword">const</span> std::array&lt;bool,4&gt;&amp; ranks)<span class="keyword"> const </span>{</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_MIN, ranks);</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;    }</div><div class="line"><a name="l00230"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ae2755921f191344ac81f632d6557ef1f">  230</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ae2755921f191344ac81f632d6557ef1f">max</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_MAX);</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;    }</div><div class="line"><a name="l00237"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99a2d7f69a75e98703dbf66b48a53205">  237</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99a2d7f69a75e98703dbf66b48a53205">max</a>(<span class="keyword">const</span> std::array&lt;bool,4&gt;&amp; ranks)<span class="keyword"> const </span>{</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_MAX, ranks);</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;    }</div><div class="line"><a name="l00243"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a79a8c68688400c2eead390233cb28abe">  243</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a79a8c68688400c2eead390233cb28abe">abs_max</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_AMAX);</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;    }</div><div class="line"><a name="l00250"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a4f3906d0cfbfeb10fd7aeed16fe73182">  250</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a4f3906d0cfbfeb10fd7aeed16fe73182">abs_max</a>(<span class="keyword">const</span> std::array&lt;bool,4&gt;&amp; ranks)<span class="keyword"> const </span>{</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_AMAX, ranks);</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;    }</div><div class="line"><a name="l00256"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a80de652665a9fd62cb1e6a26cb3bf40c">  256</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a80de652665a9fd62cb1e6a26cb3bf40c">l1_norm</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_NORM1);</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;    }</div><div class="line"><a name="l00263"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a82878aacda8c60cd8cb4a17eb6d60ccf">  263</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a82878aacda8c60cd8cb4a17eb6d60ccf">l1_norm</a>(<span class="keyword">const</span> std::array&lt;bool,4&gt;&amp; ranks)<span class="keyword"> const </span>{</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_NORM1, ranks);</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;    }</div><div class="line"><a name="l00269"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aac7d2e6127db547aae890c305405bb28">  269</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aac7d2e6127db547aae890c305405bb28">l2_norm</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_NORM2);</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;    }</div><div class="line"><a name="l00276"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a111736834abf5c68e42ea19bfa3ba651">  276</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a111736834abf5c68e42ea19bfa3ba651">l2_norm</a>(<span class="keyword">const</span> std::array&lt;bool,4&gt;&amp; ranks)<span class="keyword"> const </span>{</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a>(CUDNN_REDUCE_TENSOR_NORM2, ranks);</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;    }</div><div class="line"><a name="l00282"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a5f8177e7ea5deb5771c564b56f4fac7f">  282</a></span>&#160;    std::string <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a5f8177e7ea5deb5771c564b56f4fac7f">to_string</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;        std::stringstream strm;</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;        strm &lt;&lt; <span class="stringliteral">&quot;data type: &quot;</span> &lt;&lt; DATA_TYPE &lt;&lt; <span class="stringliteral">&quot;; format: &quot;</span> &lt;&lt; TENSOR_FORMAT &lt;&lt; <span class="stringliteral">&quot;; &quot;</span> &lt;&lt;</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;                <span class="stringliteral">&quot;[N:&quot;</span> &lt;&lt; _samples &lt;&lt; <span class="stringliteral">&quot;, C:&quot;</span> &lt;&lt; _channels &lt;&lt; <span class="stringliteral">&quot;, H:&quot;</span> &lt;&lt; _height &lt;&lt; <span class="stringliteral">&quot;, W:&quot;</span> &lt;&lt; _width &lt;&lt; <span class="stringliteral">&quot;]&quot;</span>;</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;        <span class="keywordflow">return</span> strm.str();</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;    }</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;    <span class="keyword">inline</span> Self&amp; operator+=(<span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aea0e1ef1751ae11624c57bd199cef12b">add</a>(1, rhs, 1, *<span class="keyword">this</span>);</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;    }</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;    <span class="keyword">inline</span> Self&amp; operator-=(<span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aea0e1ef1751ae11624c57bd199cef12b">add</a>(-1, rhs, 1, *<span class="keyword">this</span>);</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;    }</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;    <span class="keyword">inline</span> Self&amp; operator*=(<span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#af5e3f42920bf068b750d71356a41cf1b">op</a>(*<span class="keyword">this</span>, 1, rhs, 1, CUDNN_OP_TENSOR_MUL, 1, *<span class="keyword">this</span>);</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;    }</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;    <span class="keyword">inline</span> Self&amp; operator+=(Scalar rhs) {</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;        Self rhs_tensor(1u, 1u, 1u, 1u);</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;        rhs_tensor.copy_from_host(&amp;rhs);</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#af5e3f42920bf068b750d71356a41cf1b">op</a>(*<span class="keyword">this</span>, 1, rhs_tensor, 1, CUDNN_OP_TENSOR_ADD, 1, *<span class="keyword">this</span>);</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;    }</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;    <span class="keyword">inline</span> Self&amp; operator-=(Scalar rhs) {</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span> += -rhs;</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;    }</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;    <span class="keyword">inline</span> Self&amp; operator*=(Scalar rhs) {</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#acecbeef40e8d5703047aba4ebdfb17c8">scale</a>(rhs, *<span class="keyword">this</span>);</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;    }</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;    <span class="keyword">inline</span> Self&amp; operator/=(Scalar rhs) {</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span> *= (1 / rhs);</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;    }</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator+(Self lhs, <span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;        <span class="keywordflow">return</span> lhs += rhs;</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;    }</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator-(Self lhs, <span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;        <span class="keywordflow">return</span> lhs -= rhs;</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;    }</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator*(Self lhs, <span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;        <span class="keywordflow">return</span> lhs *= rhs;</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;    }</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator+(Self lhs, Scalar rhs) {</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;        <span class="keywordflow">return</span> lhs += rhs;</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;    }</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator-(Self lhs, Scalar rhs) {</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;        <span class="keywordflow">return</span> lhs -= rhs;</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;    }</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator*(Self lhs, Scalar rhs) {</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;        <span class="keywordflow">return</span> lhs *= rhs;</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;    }</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator/(Self lhs, Scalar rhs) {</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;        <span class="keywordflow">return</span> lhs /= rhs;</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;    }</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, <span class="keyword">const</span> Self&amp; tensor) {</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;        <span class="keywordflow">return</span> os &lt;&lt; tensor.to_string() &lt;&lt; std::endl;</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;    }</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> <span class="keywordtype">void</span> swap(Self&amp; tensor1, Self&amp; tensor2) {</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;        <span class="keyword">using</span> std::swap;</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;        swap(static_cast&lt;Base&amp;&gt;(tensor1), static_cast&lt;Base&amp;&gt;(tensor2));</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;        swap(tensor1._samples, tensor2._samples);</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;        swap(tensor1._height, tensor2._height);</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;        swap(tensor1._width, tensor2._width);</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;        swap(tensor1._channels, tensor2._channels);</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;        swap(tensor1._filter, tensor2._filter);</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;        swap(tensor1._desc, tensor2._desc);</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;        swap(tensor1._filter_desc, tensor2._filter_desc);</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;    }</div><div class="line"><a name="l00358"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#afed1d051b60b5bec470cb343a39b140b">  358</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#afed1d051b60b5bec470cb343a39b140b">create_tensor_descriptor</a>(cudnnTensorDescriptor_t&amp; <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>,</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;            std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>) {</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;        cudnnAssert(cudnnCreateTensorDescriptor(&amp;<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>));</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;        cudnnAssert(cudnnSetTensor4dDescriptor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>, TENSOR_FORMAT, DATA_TYPE, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>,</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;                <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>));</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;    }</div><div class="line"><a name="l00367"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aae03ac08e0d7c75a1151bf6ba0aeb173">  367</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aae03ac08e0d7c75a1151bf6ba0aeb173">destroy_tensor_descriptor</a>(<span class="keyword">const</span> cudnnTensorDescriptor_t&amp; <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>) {</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;        cudnnAssert(cudnnDestroyTensorDescriptor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>));</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;    }</div><div class="line"><a name="l00377"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2f655c4ac5713c8a79c2f45ffac06ced">  377</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2f655c4ac5713c8a79c2f45ffac06ced">create_filter_descriptor</a>(cudnnFilterDescriptor_t&amp; <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ace265c09fcf365ac3900013ff0c971fe">filter_desc</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>,</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;            std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>) {</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;        cudnnAssert(cudnnCreateFilterDescriptor(&amp;<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ace265c09fcf365ac3900013ff0c971fe">filter_desc</a>));</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;        cudnnAssert(cudnnSetFilter4dDescriptor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ace265c09fcf365ac3900013ff0c971fe">filter_desc</a>, Base::DATA_TYPE, Base::TENSOR_FORMAT, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>,</div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;                <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>));</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;    }</div><div class="line"><a name="l00386"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2a54952cb1443c033f047f8dd7a0338c">  386</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2a54952cb1443c033f047f8dd7a0338c">destroy_filter_descriptor</a>(<span class="keyword">const</span> cudnnFilterDescriptor_t&amp; <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ace265c09fcf365ac3900013ff0c971fe">filter_desc</a>) {</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;        cudnnAssert(cudnnDestroyFilterDescriptor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ace265c09fcf365ac3900013ff0c971fe">filter_desc</a>));</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;    }</div><div class="line"><a name="l00397"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#acecbeef40e8d5703047aba4ebdfb17c8">  397</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#acecbeef40e8d5703047aba4ebdfb17c8">scale</a>(Scalar alpha, <span class="comment">/* in/out */</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&amp; a) {</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;        cudnnAssert(cudnnScaleTensor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a3e7f931474c7a4d2c5b2550e1e58cb5b">CuDNNHandle::get_instance</a>(), a.desc(), a.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), &amp;alpha));</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;    }</div><div class="line"><a name="l00410"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aea0e1ef1751ae11624c57bd199cef12b">  410</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aea0e1ef1751ae11624c57bd199cef12b">add</a>(Scalar alpha, <span class="keyword">const</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&amp; a, Scalar beta, <span class="comment">/* in/out */</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&amp; b) {</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;        cudnnAssert(cudnnAddTensor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a3e7f931474c7a4d2c5b2550e1e58cb5b">CuDNNHandle::get_instance</a>(), &amp;alpha, a.desc(), a.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), &amp;beta,</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;                b.desc(), b.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>()));</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;    }</div><div class="line"><a name="l00427"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#af5e3f42920bf068b750d71356a41cf1b">  427</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#af5e3f42920bf068b750d71356a41cf1b">op</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&amp; a, Scalar alpha, <span class="keyword">const</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&amp; b, Scalar beta, cudnnOpTensorOp_t op_type,</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;            Scalar gamma, <span class="comment">/* in/out */</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&amp; c) {</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;        cudnnOpTensorDescriptor_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>;</div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;        cudnnAssert(cudnnCreateOpTensorDescriptor(&amp;<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>));</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;        cudnnAssert(cudnnSetOpTensorDescriptor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>, op_type, DATA_TYPE, NAN_PROP));</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;        cudnnAssert(cudnnOpTensor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>, alpha, a.desc(), a.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), beta, b.desc(), b.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(),</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;                gamma, c.desc(), c.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>()));</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;        cudnnAssert(cudnnDestroyOpTensorDescriptor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>));</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;    }</div><div class="line"><a name="l00447"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2d054df2a19f7623dfbda10bfcf639ae">  447</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2d054df2a19f7623dfbda10bfcf639ae">reduce_op</a>(Scalar alpha, <span class="keyword">const</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&amp; a, cudnnReduceTensorOp_t op_type,</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;            Scalar beta, <span class="comment">/* in/out */</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&amp; b) {</div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;        <span class="comment">// Create the reduction operation descriptor.</span></div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;        cudnnReduceTensorDescriptor_t <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>;</div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;        cudnnAssert(createReduceTensorDescriptor_t(&amp;<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>));</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;        cudnnAssert(cudnnSetReduceTensorDescriptor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>, op_type, DATA_TYPE, NAN_PROP,</div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;                CUDNN_REDUCE_TENSOR_NO_INDICES, CUDNN_32BIT_INDICES));</div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;        <span class="comment">// Calculate the array size needed for the indices (should be 0).</span></div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;        std::size_t indices_size;</div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;        cudnnAssert(cudnnGetReductionIndicesSize(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a3e7f931474c7a4d2c5b2550e1e58cb5b">CuDNNHandle::get_instance</a>(), <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>, a.desc(),</div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;                b.desc(), &amp;indices_size));</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Base</a> indices(static_cast&lt;std::size_t&gt;(ceil(static_cast&lt;Scalar&gt;(indices_size) / <span class="keyword">sizeof</span>(Scalar))));</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;        <span class="comment">// Calculate the workspace size.</span></div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;        std::size_t workspace_size;</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;        cudnnAssert(cudnnGetReductionWorkspaceSize(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a3e7f931474c7a4d2c5b2550e1e58cb5b">CuDNNHandle::get_instance</a>(), <a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>, a.desc(),</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;                b.desc(), &amp;workspace_size));</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Base</a> workspace(static_cast&lt;std::size_t&gt;(ceil(static_cast&lt;Scalar&gt;(workspace_size) / <span class="keyword">sizeof</span>(Scalar))));</div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;        <span class="comment">// Perform the reduction.</span></div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;        cudnnAssert(cudnnReduceTensor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a3e7f931474c7a4d2c5b2550e1e58cb5b">CuDNNHandle::get_instance</a>(), indices.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), indices_size,</div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;                workspace.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), workspace_size, &amp;alpha, a.desc(), a.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), &amp;beta, b.desc(), b.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>()));</div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;        <span class="comment">// Free resources.</span></div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;        cudnnAssert(cudnnDestroyReduceTensorDescriptor(<a class="code" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>));</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;    }</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;    std::size_t _samples, _height, _width, _channels;</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;    cudnnTensorDescriptor_t _desc;</div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;    cudnnFilterDescriptor_t _filter_desc;</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;};</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;} <span class="comment">/* namespace gpu */</span></div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;} <span class="comment">/* namespace cattle */</span></div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;</div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;<span class="preprocessor">#endif </span><span class="comment">/* C_ATTL3_CORE_GPU_CUDNN_CUDNNTENSOR_H_ */</span><span class="preprocessor"></span></div><div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a8d8eb060deed9d0fe65ab385d559e4e6"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a8d8eb060deed9d0fe65ab385d559e4e6">cattle::gpu::CuDNNTensor::avg</a></div><div class="ttdeci">Self avg(const std::array&lt; bool, 4 &gt; &amp;ranks) const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:211</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a159a7f5ab933a8a4794cacf894cb3691"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">cattle::gpu::CuDNNTensor::channels</a></div><div class="ttdeci">std::size_t channels() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:141</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a794d079d4446a5a55beed6ac65ab4e72"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a794d079d4446a5a55beed6ac65ab4e72">cattle::gpu::CuDNNTensor::reduce</a></div><div class="ttdeci">Self reduce(cudnnReduceTensorOp_t op_type, const std::array&lt; bool, 4 &gt; &amp;ranks) const</div><div class="ttdoc">Performs a reduction along the specified ranks of the tensor. </div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:182</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a2a54952cb1443c033f047f8dd7a0338c"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2a54952cb1443c033f047f8dd7a0338c">cattle::gpu::CuDNNTensor::destroy_filter_descriptor</a></div><div class="ttdeci">static void destroy_filter_descriptor(const cudnnFilterDescriptor_t &amp;filter_desc)</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:386</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_ace265c09fcf365ac3900013ff0c971fe"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ace265c09fcf365ac3900013ff0c971fe">cattle::gpu::CuDNNTensor::filter_desc</a></div><div class="ttdeci">const cudnnFilterDescriptor_t &amp; filter_desc() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:153</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_ae2755921f191344ac81f632d6557ef1f"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ae2755921f191344ac81f632d6557ef1f">cattle::gpu::CuDNNTensor::max</a></div><div class="ttdeci">Scalar max() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:230</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a65a43e2a1db06f62805887b0fe15a274"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a65a43e2a1db06f62805887b0fe15a274">cattle::gpu::CuDNNTensor::CuDNNTensor</a></div><div class="ttdeci">CuDNNTensor(Scalar *data, std::size_t samples, std::size_t height, std::size_t width, std::size_t channels)</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:47</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a2d054df2a19f7623dfbda10bfcf639ae"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2d054df2a19f7623dfbda10bfcf639ae">cattle::gpu::CuDNNTensor::reduce_op</a></div><div class="ttdeci">static void reduce_op(Scalar alpha, const Self &amp;a, cudnnReduceTensorOp_t op_type, Scalar beta, Self &amp;b)</div><div class="ttdoc">It performs the specified reduction operation on tensor a and adds it to tensor b. </div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:447</div></div>
<div class="ttc" id="namespacecattle_html_a8b9323ad928764340e46f0802bf27fbb"><div class="ttname"><a href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">cattle::Tensor</a></div><div class="ttdeci">Eigen::Tensor&lt; Scalar, Rank, Eigen::ColMajor, std::size_t &gt; Tensor</div><div class="ttdoc">An alias for a tensor of arbitrary rank and scalar type with dynamic dimensionality. </div><div class="ttdef"><b>Definition:</b> EigenProxy.hpp:57</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_aea0e1ef1751ae11624c57bd199cef12b"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aea0e1ef1751ae11624c57bd199cef12b">cattle::gpu::CuDNNTensor::add</a></div><div class="ttdeci">static void add(Scalar alpha, const Self &amp;a, Scalar beta, Self &amp;b)</div><div class="ttdoc">It adds tensor a to tensor b. </div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:410</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a99057790847ce509fbbb377ea8c07aad"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">cattle::gpu::CuDNNTensor::samples</a></div><div class="ttdeci">std::size_t samples() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:123</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a14fd93aae07810d6e5889015caa7186c"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a14fd93aae07810d6e5889015caa7186c">cattle::gpu::CuDNNTensor::avg</a></div><div class="ttdeci">Scalar avg() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:204</div></div>
<div class="ttc" id="namespacecattle_html"><div class="ttname"><a href="namespacecattle.html">cattle</a></div><div class="ttdoc">The namespace containing all classes and typedefs of the C-ATTL3 library. </div><div class="ttdef"><b>Definition:</b> PPMCodec.hpp:20</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a111736834abf5c68e42ea19bfa3ba651"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a111736834abf5c68e42ea19bfa3ba651">cattle::gpu::CuDNNTensor::l2_norm</a></div><div class="ttdeci">Self l2_norm(const std::array&lt; bool, 4 &gt; &amp;ranks) const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:276</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_af5e3f42920bf068b750d71356a41cf1b"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#af5e3f42920bf068b750d71356a41cf1b">cattle::gpu::CuDNNTensor::op</a></div><div class="ttdeci">static void op(const Self &amp;a, Scalar alpha, const Self &amp;b, Scalar beta, cudnnOpTensorOp_t op_type, Scalar gamma, Self &amp;c)</div><div class="ttdoc">It performs the specified operation on tensors a and b and saves the result in c. ...</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:427</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_aae03ac08e0d7c75a1151bf6ba0aeb173"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aae03ac08e0d7c75a1151bf6ba0aeb173">cattle::gpu::CuDNNTensor::destroy_tensor_descriptor</a></div><div class="ttdeci">static void destroy_tensor_descriptor(const cudnnTensorDescriptor_t &amp;desc)</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:367</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a61355129924153169b4f5be6177e4cc3"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">cattle::gpu::CuDNNTensor::height</a></div><div class="ttdeci">std::size_t height() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:129</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a99a2d7f69a75e98703dbf66b48a53205"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99a2d7f69a75e98703dbf66b48a53205">cattle::gpu::CuDNNTensor::max</a></div><div class="ttdeci">Self max(const std::array&lt; bool, 4 &gt; &amp;ranks) const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:237</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a79a8c68688400c2eead390233cb28abe"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a79a8c68688400c2eead390233cb28abe">cattle::gpu::CuDNNTensor::abs_max</a></div><div class="ttdeci">Scalar abs_max() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:243</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_aac7d2e6127db547aae890c305405bb28"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aac7d2e6127db547aae890c305405bb28">cattle::gpu::CuDNNTensor::l2_norm</a></div><div class="ttdeci">Scalar l2_norm() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:269</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a4f3906d0cfbfeb10fd7aeed16fe73182"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a4f3906d0cfbfeb10fd7aeed16fe73182">cattle::gpu::CuDNNTensor::abs_max</a></div><div class="ttdeci">Self abs_max(const std::array&lt; bool, 4 &gt; &amp;ranks) const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:250</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a9094c2bf0bf56e5ca174a8ee9c13d0ee"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a9094c2bf0bf56e5ca174a8ee9c13d0ee">cattle::gpu::CuDNNTensor::sum</a></div><div class="ttdeci">Scalar sum() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:191</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_aea14b2fc6d9f4df9c8e03f5177966899"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aea14b2fc6d9f4df9c8e03f5177966899">cattle::gpu::CuDNNTensor::sum</a></div><div class="ttdeci">Self sum(const std::array&lt; bool, 4 &gt; &amp;ranks) const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:198</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_c_u_d_a_array_html_a3bd7455c00b1cb1cf3d31a849429e4d9"><div class="ttname"><a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">cattle::gpu::CUDAArray::data</a></div><div class="ttdeci">const Scalar * data() const</div><div class="ttdef"><b>Definition:</b> CUDAArray.hpp:78</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a5f8177e7ea5deb5771c564b56f4fac7f"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a5f8177e7ea5deb5771c564b56f4fac7f">cattle::gpu::CuDNNTensor::to_string</a></div><div class="ttdeci">std::string to_string() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:282</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a82878aacda8c60cd8cb4a17eb6d60ccf"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a82878aacda8c60cd8cb4a17eb6d60ccf">cattle::gpu::CuDNNTensor::l1_norm</a></div><div class="ttdeci">Self l1_norm(const std::array&lt; bool, 4 &gt; &amp;ranks) const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:263</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_ad877d89c5fba27e4676659d0fc515faa"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">cattle::gpu::CuDNNTensor::desc</a></div><div class="ttdeci">const cudnnTensorDescriptor_t &amp; desc() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:147</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_ad48aa03288eb330549d7038813183456"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">cattle::gpu::CuDNNTensor::width</a></div><div class="ttdeci">std::size_t width() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:135</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_c_u_d_a_array_html_a5d242f9908e1a4448a4585e220ef7ca1"><div class="ttname"><a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">cattle::gpu::CUDAArray::size</a></div><div class="ttdeci">std::size_t size() const</div><div class="ttdef"><b>Definition:</b> CUDAArray.hpp:71</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_c_u_d_a_array_html_ab3aeb7d6d0bb4583880a3b187a3c5945"><div class="ttname"><a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#ab3aeb7d6d0bb4583880a3b187a3c5945">cattle::gpu::CUDAArray::copy_to_host</a></div><div class="ttdeci">void copy_to_host(Scalar *host_array) const</div><div class="ttdoc">It copies the entire device array to the host memory. </div><div class="ttdef"><b>Definition:</b> CUDAArray.hpp:116</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a80de652665a9fd62cb1e6a26cb3bf40c"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a80de652665a9fd62cb1e6a26cb3bf40c">cattle::gpu::CuDNNTensor::l1_norm</a></div><div class="ttdeci">Scalar l1_norm() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:256</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a></div><div class="ttdoc">A template class for representing row-major cuDNN device tensors of different data types...</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:30</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_handle_html_a3e7f931474c7a4d2c5b2550e1e58cb5b"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_handle.html#a3e7f931474c7a4d2c5b2550e1e58cb5b">cattle::gpu::CuDNNHandle::get_instance</a></div><div class="ttdeci">static const CuDNNHandle &amp; get_instance()</div><div class="ttdef"><b>Definition:</b> CuDNNHandle.hpp:34</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_afed1d051b60b5bec470cb343a39b140b"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#afed1d051b60b5bec470cb343a39b140b">cattle::gpu::CuDNNTensor::create_tensor_descriptor</a></div><div class="ttdeci">static void create_tensor_descriptor(cudnnTensorDescriptor_t &amp;desc, std::size_t samples, std::size_t height, std::size_t width, std::size_t channels)</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:358</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_acecbeef40e8d5703047aba4ebdfb17c8"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#acecbeef40e8d5703047aba4ebdfb17c8">cattle::gpu::CuDNNTensor::scale</a></div><div class="ttdeci">static void scale(Scalar alpha, Self &amp;a)</div><div class="ttdoc">It scales the specified tensor by a certain factor. </div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:397</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a48fd267290bfb7b49e39a6d1e1b844ab"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a48fd267290bfb7b49e39a6d1e1b844ab">cattle::gpu::CuDNNTensor::set_values</a></div><div class="ttdeci">void set_values(Scalar value)</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:159</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_c_u_d_a_array_html"><div class="ttname"><a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">cattle::gpu::CUDAArray</a></div><div class="ttdoc">A template class for CUDA device arrays of different data types. </div><div class="ttdef"><b>Definition:</b> CUDAArray.hpp:24</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_ab45c4cf77bc7a4aaabda0ea8a0d57282"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ab45c4cf77bc7a4aaabda0ea8a0d57282">cattle::gpu::CuDNNTensor::min</a></div><div class="ttdeci">Self min(const std::array&lt; bool, 4 &gt; &amp;ranks) const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:224</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a879177caac8ca874b91a3ccee66af2b3"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">cattle::gpu::CuDNNTensor::reduce</a></div><div class="ttdeci">Scalar reduce(cudnnReduceTensorOp_t op_type) const</div><div class="ttdoc">Performs a reduction along all ranks of the tensor. </div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:168</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_a2f655c4ac5713c8a79c2f45ffac06ced"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2f655c4ac5713c8a79c2f45ffac06ced">cattle::gpu::CuDNNTensor::create_filter_descriptor</a></div><div class="ttdeci">static void create_filter_descriptor(cudnnFilterDescriptor_t &amp;filter_desc, std::size_t samples, std::size_t height, std::size_t width, std::size_t channels)</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:377</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_c_u_d_a_array_html_a53a0b01db3d84497c5c7c47a8582a22d"><div class="ttname"><a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a53a0b01db3d84497c5c7c47a8582a22d">cattle::gpu::CUDAArray::copy_from_host</a></div><div class="ttdeci">void copy_from_host(const Scalar *host_array)</div><div class="ttdoc">It populates the entire device array with data from the host memory. </div><div class="ttdef"><b>Definition:</b> CUDAArray.hpp:106</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_ac6b9a062dd41eb9cefaaccc003f1d44d"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ac6b9a062dd41eb9cefaaccc003f1d44d">cattle::gpu::CuDNNTensor::min</a></div><div class="ttdeci">Scalar min() const</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:217</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_d_n_n_tensor_html_ac6b7b616ec8965672b82f8186066bc29"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ac6b7b616ec8965672b82f8186066bc29">cattle::gpu::CuDNNTensor::CuDNNTensor</a></div><div class="ttdeci">CuDNNTensor(std::size_t samples, std::size_t height, std::size_t width, std::size_t channels)</div><div class="ttdef"><b>Definition:</b> CuDNNTensor.hpp:67</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
