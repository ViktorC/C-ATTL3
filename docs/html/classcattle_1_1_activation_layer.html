<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: cattle::ActivationLayer&lt; Scalar, Rank &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecattle.html">cattle</a></li><li class="navelem"><a class="el" href="classcattle_1_1_activation_layer.html">ActivationLayer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="classcattle_1_1_activation_layer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">cattle::ActivationLayer&lt; Scalar, Rank &gt; Class Template Reference<span class="mlabels"><span class="mlabel">abstract</span></span></div>  </div>
</div><!--header-->
<div class="contents">

<p>An abstract class template that represents an activation function layer.  
 <a href="classcattle_1_1_activation_layer.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_layer_8hpp_source.html">Layer.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for cattle::ActivationLayer&lt; Scalar, Rank &gt;:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classcattle_1_1_activation_layer.png" usemap="#cattle::ActivationLayer_3C_20Scalar_2C_20Rank_20_3E_map" alt=""/>
  <map id="cattle::ActivationLayer_3C_20Scalar_2C_20Rank_20_3E_map" name="cattle::ActivationLayer_3C_20Scalar_2C_20Rank_20_3E_map">
<area href="classcattle_1_1_layer.html" title="An abstract class template representing layers in a neural network. " alt="cattle::Layer&lt; Scalar, Rank &gt;" shape="rect" coords="0,0,299,24"/>
<area href="classcattle_1_1_binary_step_activation_layer.html" title="A class template that represents a binary step activation function that outputs either 1 or 0 based o..." alt="cattle::BinaryStepActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,112,608,136"/>
<area href="classcattle_1_1_e_l_u_activation_layer.html" title="A class template representing an exponential linear unit (ELU) activation function. " alt="cattle::ELUActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,168,608,192"/>
<area href="classcattle_1_1_identity_activation_layer.html" title="A class template representing an identity activation layer that merely outputs its input..." alt="cattle::IdentityActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,224,608,248"/>
<area href="classcattle_1_1_leaky_re_l_u_activation_layer.html" title="A class template representing a leaky rectified linear unit activation function. " alt="cattle::LeakyReLUActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,280,608,304"/>
<area href="classcattle_1_1_p_re_l_u_activation_layer.html" title="A class template representing a parametric rectified linear unit (PReLU) activation function..." alt="cattle::PReLUActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,336,608,360"/>
<area href="classcattle_1_1_p_swish_activation_layer.html" title="A class template representing the parametric Swish activation function with learnable beta values..." alt="cattle::PSwishActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,392,608,416"/>
<area href="classcattle_1_1_re_l_u_activation_layer.html" title="A class template representing a rectified linear unit (ReLU) activation function. ..." alt="cattle::ReLUActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,448,608,472"/>
<area href="classcattle_1_1_scaled_activation_layer.html" title="A class template that represents a linearly scaling activation layer. " alt="cattle::ScaledActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,504,608,528"/>
<area href="classcattle_1_1_sigmoid_activation_layer.html" title="A class template representing a sigmoid activation function layer. " alt="cattle::SigmoidActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,560,608,584"/>
<area href="classcattle_1_1_softmax_activation_layer.html" title="A class template for a softmax activation function layer. " alt="cattle::SoftmaxActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,616,608,640"/>
<area href="classcattle_1_1_softplus_activation_layer.html" title="A class template representing a softplus activation function layer. " alt="cattle::SoftplusActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,672,608,696"/>
<area href="classcattle_1_1_softsign_activation_layer.html" title="A class template representing a softsign activation function layer, an alternative to the tanh layer..." alt="cattle::SoftsignActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,728,608,752"/>
<area href="classcattle_1_1_swish_activation_layer.html" title="A class template representing the Swish activation function. " alt="cattle::SwishActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,784,608,808"/>
<area href="classcattle_1_1_tanh_activation_layer.html" title="A class template representing a hyperbolic tangent activation function layer. " alt="cattle::TanhActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="309,840,608,864"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:acfbb6290f425e0f5d94dbc14d9aabfae"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classcattle_1_1_layer.html">Base</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#acfbb6290f425e0f5d94dbc14d9aabfae">clone</a> () const =0</td></tr>
<tr class="memdesc:acfbb6290f425e0f5d94dbc14d9aabfae"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a clone of the layer instance.  <a href="#acfbb6290f425e0f5d94dbc14d9aabfae">More...</a><br /></td></tr>
<tr class="separator:acfbb6290f425e0f5d94dbc14d9aabfae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ff3acc579905c6a26c219caaa018993"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1_layer.html">Base</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#a2ff3acc579905c6a26c219caaa018993">clone_with_shared_params</a> ()</td></tr>
<tr class="memdesc:a2ff3acc579905c6a26c219caaa018993"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a clone of the layer instance using a reference to the original's parameters.  <a href="#a2ff3acc579905c6a26c219caaa018993">More...</a><br /></td></tr>
<tr class="separator:a2ff3acc579905c6a26c219caaa018993"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a261c832c58e43392cdede3257e666dec"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classcattle_1_1_layer.html">Base</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#a261c832c58e43392cdede3257e666dec">get_params_owner</a> () const</td></tr>
<tr class="memdesc:a261c832c58e43392cdede3257e666dec"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a reference to the layer owning the parameters used.  <a href="#a261c832c58e43392cdede3257e666dec">More...</a><br /></td></tr>
<tr class="separator:a261c832c58e43392cdede3257e666dec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4550c77e6341cd77a62a751eb129e44e"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classcattle_1_1_dimensions.html">Dimensions</a>&lt; std::size_t, Rank &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#a4550c77e6341cd77a62a751eb129e44e">get_input_dims</a> () const</td></tr>
<tr class="memdesc:a4550c77e6341cd77a62a751eb129e44e"><td class="mdescLeft">&#160;</td><td class="mdescRight">A simple constant getter method for the input dimensionality of the layer.  <a href="#a4550c77e6341cd77a62a751eb129e44e">More...</a><br /></td></tr>
<tr class="separator:a4550c77e6341cd77a62a751eb129e44e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30f2215af291a00e008fa09de8a32cf7"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classcattle_1_1_dimensions.html">Dimensions</a>&lt; std::size_t, Rank &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#a30f2215af291a00e008fa09de8a32cf7">get_output_dims</a> () const</td></tr>
<tr class="memdesc:a30f2215af291a00e008fa09de8a32cf7"><td class="mdescLeft">&#160;</td><td class="mdescRight">A simple constant getter method for the output dimensionality of the layer.  <a href="#a30f2215af291a00e008fa09de8a32cf7">More...</a><br /></td></tr>
<tr class="separator:a30f2215af291a00e008fa09de8a32cf7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab38d6acf3933fb2ac0c3e33bb15405ab"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt; Scalar &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#ab38d6acf3933fb2ac0c3e33bb15405ab">get_params</a> () const</td></tr>
<tr class="memdesc:ab38d6acf3933fb2ac0c3e33bb15405ab"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a constant reference to the learnable parameters of the layer.  <a href="#ab38d6acf3933fb2ac0c3e33bb15405ab">More...</a><br /></td></tr>
<tr class="separator:ab38d6acf3933fb2ac0c3e33bb15405ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08946304d56287db036990d9d890f18e"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt; Scalar &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#a08946304d56287db036990d9d890f18e">get_params_grad</a> () const</td></tr>
<tr class="memdesc:a08946304d56287db036990d9d890f18e"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a constant reference to the gradient of the learnable parameters of the layer.  <a href="#a08946304d56287db036990d9d890f18e">More...</a><br /></td></tr>
<tr class="separator:a08946304d56287db036990d9d890f18e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae46130f5336ab1271537f28458d7a162"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#ae46130f5336ab1271537f28458d7a162">is_frozen</a> () const</td></tr>
<tr class="memdesc:ae46130f5336ab1271537f28458d7a162"><td class="mdescLeft">&#160;</td><td class="mdescRight">It determines whether the parameters of the layer, if there are any, are to be updated during optimization.  <a href="#ae46130f5336ab1271537f28458d7a162">More...</a><br /></td></tr>
<tr class="separator:ae46130f5336ab1271537f28458d7a162"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee201eb78f434c69319f42a7645081c8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#aee201eb78f434c69319f42a7645081c8">set_frozen</a> (bool frozen)</td></tr>
<tr class="memdesc:aee201eb78f434c69319f42a7645081c8"><td class="mdescLeft">&#160;</td><td class="mdescRight">It sets whether the parameters of the layer should not be updated during optimization.  <a href="#aee201eb78f434c69319f42a7645081c8">More...</a><br /></td></tr>
<tr class="separator:aee201eb78f434c69319f42a7645081c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03f8dc5fe0d781b983e4494ab8413f5f"><td class="memItemLeft" align="right" valign="top"><a id="a03f8dc5fe0d781b983e4494ab8413f5f"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#a03f8dc5fe0d781b983e4494ab8413f5f">init</a> ()</td></tr>
<tr class="memdesc:a03f8dc5fe0d781b983e4494ab8413f5f"><td class="mdescLeft">&#160;</td><td class="mdescRight">It initializes the layer and its parameters. <br /></td></tr>
<tr class="separator:a03f8dc5fe0d781b983e4494ab8413f5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classcattle_1_1_layer"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classcattle_1_1_layer')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classcattle_1_1_layer.html">cattle::Layer&lt; Scalar, Rank &gt;</a></td></tr>
<tr class="memitem:ac92d606818b5a240d0ce898e35afe63d inherit pub_methods_classcattle_1_1_layer"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">is_shared_params_clone</a> () const</td></tr>
<tr class="memdesc:ac92d606818b5a240d0ce898e35afe63d inherit pub_methods_classcattle_1_1_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">It determines whether the layer instance is a clone using the shared parameters of another instance.  <a href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">More...</a><br /></td></tr>
<tr class="separator:ac92d606818b5a240d0ce898e35afe63d inherit pub_methods_classcattle_1_1_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ba02f76506a7f8a72f44be78693209e inherit pub_methods_classcattle_1_1_layer"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a3ba02f76506a7f8a72f44be78693209e">is_parametric</a> () const</td></tr>
<tr class="memdesc:a3ba02f76506a7f8a72f44be78693209e inherit pub_methods_classcattle_1_1_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">A method that returns whether the layer has parameters that can be learned.  <a href="classcattle_1_1_layer.html#a3ba02f76506a7f8a72f44be78693209e">More...</a><br /></td></tr>
<tr class="separator:a3ba02f76506a7f8a72f44be78693209e inherit pub_methods_classcattle_1_1_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a984f124ef5a2de9b2466ccb5a591eca2 inherit pub_methods_classcattle_1_1_layer"><td class="memItemLeft" align="right" valign="top">virtual std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a984f124ef5a2de9b2466ccb5a591eca2">to_string</a> () const</td></tr>
<tr class="separator:a984f124ef5a2de9b2466ccb5a591eca2 inherit pub_methods_classcattle_1_1_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:a3733446d064f63f86f8a48bd30c0dbcb"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#a3733446d064f63f86f8a48bd30c0dbcb">is_input_layer</a> () const</td></tr>
<tr class="memdesc:a3733446d064f63f86f8a48bd30c0dbcb"><td class="mdescLeft">&#160;</td><td class="mdescRight">A constant method that returns whether this layer functions as an input layer.  <a href="#a3733446d064f63f86f8a48bd30c0dbcb">More...</a><br /></td></tr>
<tr class="separator:a3733446d064f63f86f8a48bd30c0dbcb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34972577a520dc5e4d34d40c448f127b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#a34972577a520dc5e4d34d40c448f127b">set_input_layer</a> (bool input_layer)</td></tr>
<tr class="memdesc:a34972577a520dc5e4d34d40c448f127b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets this instance's input layer status to the given value.  <a href="#a34972577a520dc5e4d34d40c448f127b">More...</a><br /></td></tr>
<tr class="separator:a34972577a520dc5e4d34d40c448f127b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab97e38ad519af40007f659120f3f7fe1"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt; Scalar &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#ab97e38ad519af40007f659120f3f7fe1">get_params</a> ()</td></tr>
<tr class="memdesc:ab97e38ad519af40007f659120f3f7fe1"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a reference to the learnable parameters of the layer.  <a href="#ab97e38ad519af40007f659120f3f7fe1">More...</a><br /></td></tr>
<tr class="separator:ab97e38ad519af40007f659120f3f7fe1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9822a94073cb72e2db4de62c2126d54"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt; Scalar &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#af9822a94073cb72e2db4de62c2126d54">get_params_grad</a> ()</td></tr>
<tr class="memdesc:af9822a94073cb72e2db4de62c2126d54"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a reference to the gradient of the learnable parameters of the layer.  <a href="#af9822a94073cb72e2db4de62c2126d54">More...</a><br /></td></tr>
<tr class="separator:af9822a94073cb72e2db4de62c2126d54"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff288c69e4af006db23d2e998d84e847"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#aff288c69e4af006db23d2e998d84e847">regularize</a> ()</td></tr>
<tr class="memdesc:aff288c69e4af006db23d2e998d84e847"><td class="mdescLeft">&#160;</td><td class="mdescRight">It computes the derivative of the regularization function w.r.t.  <a href="#aff288c69e4af006db23d2e998d84e847">More...</a><br /></td></tr>
<tr class="separator:aff288c69e4af006db23d2e998d84e847"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a245b781c1e5ae253816389c2091565a1"><td class="memItemLeft" align="right" valign="top">Scalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#a245b781c1e5ae253816389c2091565a1">get_regularization_penalty</a> () const</td></tr>
<tr class="memdesc:a245b781c1e5ae253816389c2091565a1"><td class="mdescLeft">&#160;</td><td class="mdescRight">It calculates the regularization penalty of the layer's parameters.  <a href="#a245b781c1e5ae253816389c2091565a1">More...</a><br /></td></tr>
<tr class="separator:a245b781c1e5ae253816389c2091565a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2722517029fa18cb0ee1b9038a643da9"><td class="memItemLeft" align="right" valign="top"><a id="a2722517029fa18cb0ee1b9038a643da9"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#a2722517029fa18cb0ee1b9038a643da9">enforce_constraints</a> ()</td></tr>
<tr class="memdesc:a2722517029fa18cb0ee1b9038a643da9"><td class="mdescLeft">&#160;</td><td class="mdescRight">It applies constraints such as max-norm to the parameters of the layer (if applicable). <br /></td></tr>
<tr class="separator:a2722517029fa18cb0ee1b9038a643da9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ea3acc95aef44eac905481020f3f946"><td class="memItemLeft" align="right" valign="top"><a id="a3ea3acc95aef44eac905481020f3f946"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_activation_layer.html#a3ea3acc95aef44eac905481020f3f946">empty_cache</a> ()</td></tr>
<tr class="memdesc:a3ea3acc95aef44eac905481020f3f946"><td class="mdescLeft">&#160;</td><td class="mdescRight">It empties the layer's caches such as those required for the derivation of the function represented by the layer. <br /></td></tr>
<tr class="separator:a3ea3acc95aef44eac905481020f3f946"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_methods_classcattle_1_1_layer"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_classcattle_1_1_layer')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="classcattle_1_1_layer.html">cattle::Layer&lt; Scalar, Rank &gt;</a></td></tr>
<tr class="memitem:a6c1ea7b25d9f882364b7f2288f02d8da inherit pro_methods_classcattle_1_1_layer"><td class="memItemLeft" align="right" valign="top">virtual Data&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a6c1ea7b25d9f882364b7f2288f02d8da">pass_forward</a> (Data in, bool training)=0</td></tr>
<tr class="memdesc:a6c1ea7b25d9f882364b7f2288f02d8da inherit pro_methods_classcattle_1_1_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">It has the function represented by the layer applied to the input tensor.  <a href="classcattle_1_1_layer.html#a6c1ea7b25d9f882364b7f2288f02d8da">More...</a><br /></td></tr>
<tr class="separator:a6c1ea7b25d9f882364b7f2288f02d8da inherit pro_methods_classcattle_1_1_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7cb51862ef9b87632b5abb8e3ab36dd9 inherit pro_methods_classcattle_1_1_layer"><td class="memItemLeft" align="right" valign="top">virtual Data&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a7cb51862ef9b87632b5abb8e3ab36dd9">pass_back</a> (Data out_grad)=0</td></tr>
<tr class="memdesc:a7cb51862ef9b87632b5abb8e3ab36dd9 inherit pro_methods_classcattle_1_1_layer"><td class="mdescLeft">&#160;</td><td class="mdescRight">It back-propagates the derivative of the error function w.r.t.  <a href="classcattle_1_1_layer.html#a7cb51862ef9b87632b5abb8e3ab36dd9">More...</a><br /></td></tr>
<tr class="separator:a7cb51862ef9b87632b5abb8e3ab36dd9 inherit pro_methods_classcattle_1_1_layer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Scalar, std::size_t Rank&gt;<br />
class cattle::ActivationLayer&lt; Scalar, Rank &gt;</h3>

<p>An abstract class template that represents an activation function layer. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="acfbb6290f425e0f5d94dbc14d9aabfae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acfbb6290f425e0f5d94dbc14d9aabfae">&#9670;&nbsp;</a></span>clone()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classcattle_1_1_layer.html">Base</a>* <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::clone </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a clone of the layer instance. </p>
<dl class="section return"><dt>Returns</dt><dd>A pointer to a copy of the instance. The instance does not take ownership of the returned pointer (i.e. the caller is responsible for deleting it). </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a46db46c62f3d46c6bbef5a482d7fcb00">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

<p>Implemented in <a class="el" href="classcattle_1_1_p_swish_activation_layer.html#a8908ccf599442daa45682028d79a0871">cattle::PSwishActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_swish_activation_layer.html#aeeacccc1907003c77578d71b38d1f481">cattle::SwishActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_p_re_l_u_activation_layer.html#a822da21b34e644180efda947c185e13e">cattle::PReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_e_l_u_activation_layer.html#aa8542434a8430319aaa149363151e777">cattle::ELUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#a82d876e1484fd0e695ad72eb20ccadc4">cattle::LeakyReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_re_l_u_activation_layer.html#a9f15affc9a835583ed6745496b1dd0c7">cattle::ReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softmax_activation_layer.html#a970361710856c4497c4bb8fd6f1e9ac9">cattle::SoftmaxActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softplus_activation_layer.html#ad3a362dd884f047371f20981cb50dcdd">cattle::SoftplusActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softsign_activation_layer.html#a02f3977bb217af6dd52f0dcb63120bcd">cattle::SoftsignActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_tanh_activation_layer.html#a7896bd20f2379a0b2e84390510219482">cattle::TanhActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_sigmoid_activation_layer.html#a4b9fa7dc1973c543265dcbc49e065fa8">cattle::SigmoidActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_binary_step_activation_layer.html#a79f59f919c1223cc78750d6d20b72003">cattle::BinaryStepActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_scaled_activation_layer.html#a5560ddd8c97a5c8feb8752ccce16d167">cattle::ScaledActivationLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_identity_activation_layer.html#af53b6179ca817e02269113a944f2f08f">cattle::IdentityActivationLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a2ff3acc579905c6a26c219caaa018993"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2ff3acc579905c6a26c219caaa018993">&#9670;&nbsp;</a></span>clone_with_shared_params()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1_layer.html">Base</a>* <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::clone_with_shared_params </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a clone of the layer instance using a reference to the original's parameters. </p>
<p>Non-parametric layers do not need to support parameter sharing and thus are just expected to return a normal clone.</p>
<dl class="section return"><dt>Returns</dt><dd>A clone of the original layer instance sharing the same parameters with the original. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a074a197df04250449a059d97a4e6e120">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

<p>Reimplemented in <a class="el" href="classcattle_1_1_p_swish_activation_layer.html#a0d6f194ac78749343dbf7eb0e378cc55">cattle::PSwishActivationLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_p_re_l_u_activation_layer.html#a01e678cea84bc7f952303bc5747e7c3f">cattle::PReLUActivationLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a4550c77e6341cd77a62a751eb129e44e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4550c77e6341cd77a62a751eb129e44e">&#9670;&nbsp;</a></span>get_input_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classcattle_1_1_dimensions.html">Dimensions</a>&lt;std::size_t,Rank&gt;&amp; <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::get_input_dims </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>A simple constant getter method for the input dimensionality of the layer. </p>
<dl class="section return"><dt>Returns</dt><dd>A constant reference to the member variable denoting the dimensions of the tensors accepted by the layer as its input (except for the first rank which denotes the variable sample size). </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a616670d011b739c619fe2c8f6d14baa4">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a30f2215af291a00e008fa09de8a32cf7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30f2215af291a00e008fa09de8a32cf7">&#9670;&nbsp;</a></span>get_output_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classcattle_1_1_dimensions.html">Dimensions</a>&lt;std::size_t,Rank&gt;&amp; <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::get_output_dims </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>A simple constant getter method for the output dimensionality of the layer. </p>
<dl class="section return"><dt>Returns</dt><dd>A constant reference to the member variable denoting the dimensions of the tensors output by the layer along all ranks except the first one. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a26f50624ba25185ae1c9a7c855ffc0d6">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="ab38d6acf3933fb2ac0c3e33bb15405ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab38d6acf3933fb2ac0c3e33bb15405ab">&#9670;&nbsp;</a></span>get_params() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt;Scalar&gt;&amp; <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::get_params </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a constant reference to the learnable parameters of the layer. </p>
<dl class="section return"><dt>Returns</dt><dd>A constant reference to the parameters of the layer that are to be learned. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#ab67312e1fc860a8a246f6f9aeadffbb4">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="ab97e38ad519af40007f659120f3f7fe1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab97e38ad519af40007f659120f3f7fe1">&#9670;&nbsp;</a></span>get_params() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt;Scalar&gt;&amp; <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::get_params </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a reference to the learnable parameters of the layer. </p>
<dl class="section return"><dt>Returns</dt><dd>A non-constant reference to the parameters of the layer that are to be learned. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#abd799a16024c5aee49dbc0a5fe2f3183">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a08946304d56287db036990d9d890f18e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a08946304d56287db036990d9d890f18e">&#9670;&nbsp;</a></span>get_params_grad() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt;Scalar&gt;&amp; <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::get_params_grad </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a constant reference to the gradient of the learnable parameters of the layer. </p>
<dl class="section return"><dt>Returns</dt><dd>A constant reference to the gradient of the parameters of the layer. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a60fbc161deece174499e4be12b730255">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="af9822a94073cb72e2db4de62c2126d54"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af9822a94073cb72e2db4de62c2126d54">&#9670;&nbsp;</a></span>get_params_grad() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt;Scalar&gt;&amp; <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::get_params_grad </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a reference to the gradient of the learnable parameters of the layer. </p>
<dl class="section return"><dt>Returns</dt><dd>A non-constant reference to the gradient of the parameters of the layer. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a6e2e726f9677758ea61c6916a5c88b92">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a261c832c58e43392cdede3257e666dec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a261c832c58e43392cdede3257e666dec">&#9670;&nbsp;</a></span>get_params_owner()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classcattle_1_1_layer.html">Base</a>&amp; <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::get_params_owner </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a reference to the layer owning the parameters used. </p>
<p>If this owner goes out of scope (in case this one is a clone with shared parameters), the behavior of the clone is undefined.</p>
<dl class="section return"><dt>Returns</dt><dd>A reference to the layer owning the parameters. If this layer is not using shared parameters, it returns a reference to itself. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a683f9b67748863329938da07e86ecd8c">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a245b781c1e5ae253816389c2091565a1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a245b781c1e5ae253816389c2091565a1">&#9670;&nbsp;</a></span>get_regularization_penalty()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Scalar <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::get_regularization_penalty </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It calculates the regularization penalty of the layer's parameters. </p>
<p>If the layer is not parametric, 0 is returned.</p>
<dl class="section return"><dt>Returns</dt><dd>A scalar representing the penalty on the magnitude of the layer's parameters. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#ab3719ffa784c45277252f2fb16b209d5">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

<p>Reimplemented in <a class="el" href="classcattle_1_1_p_swish_activation_layer.html#a8b8ff178771ca116934695127ed9ade8">cattle::PSwishActivationLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_p_re_l_u_activation_layer.html#aea1064a99c89f7c06a7deaf0b87cb8a9">cattle::PReLUActivationLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="ae46130f5336ab1271537f28458d7a162"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae46130f5336ab1271537f28458d7a162">&#9670;&nbsp;</a></span>is_frozen()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::is_frozen </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It determines whether the parameters of the layer, if there are any, are to be updated during optimization. </p>
<dl class="section return"><dt>Returns</dt><dd>Whether the parameters should not be updated during optimization. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a9b9374ca0299ed3b599c0403174a79af">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a3733446d064f63f86f8a48bd30c0dbcb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3733446d064f63f86f8a48bd30c0dbcb">&#9670;&nbsp;</a></span>is_input_layer()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::is_input_layer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>A constant method that returns whether this layer functions as an input layer. </p>
<p>An input layer does not need to propagate the gradients all the way during the backward pass as it is assumed that no other layer needs them derive the gradient on its parameters. It is therefore possible for an input layer to simply return a null tensor as the output of its backward pass.</p>
<dl class="section return"><dt>Returns</dt><dd>Whether this layer is the input layer of the neural network that contains it. </dd></dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#af208065ae34cbebcdc932c84383ea159">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="aff288c69e4af006db23d2e998d84e847"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff288c69e4af006db23d2e998d84e847">&#9670;&nbsp;</a></span>regularize()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::regularize </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It computes the derivative of the regularization function w.r.t. </p>
<p>the parameters of the layer and adds it to their gradient. If the layer is not parametric, calling this method has no effect. </p>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#aae685cf7e708e0c4f32ddc4c10254046">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

<p>Reimplemented in <a class="el" href="classcattle_1_1_p_swish_activation_layer.html#af217f7a8a67fa7cff16930a071616ec6">cattle::PSwishActivationLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_p_re_l_u_activation_layer.html#a7bb2f7bd02261af5aae033d9727c00c8">cattle::PReLUActivationLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="aee201eb78f434c69319f42a7645081c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee201eb78f434c69319f42a7645081c8">&#9670;&nbsp;</a></span>set_frozen()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::set_frozen </td>
          <td>(</td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>frozen</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It sets whether the parameters of the layer should not be updated during optimization. </p>
<p>Frozen layers are not regularized either.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">frozen</td><td>Whether the parameters of the layer are to be frozen, i.e. not updatable via optimization. </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a2efa46d4b10ec998cb7b09a3c430e025">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a34972577a520dc5e4d34d40c448f127b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34972577a520dc5e4d34d40c448f127b">&#9670;&nbsp;</a></span>set_input_layer()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar , std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a>&lt; Scalar, Rank &gt;::set_input_layer </td>
          <td>(</td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>input_layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Sets this instance's input layer status to the given value. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_layer</td><td>Whether this layer is to be an input layer or not. </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classcattle_1_1_layer.html#a9557e077d940b2ff0c280e9a78c4b52e">cattle::Layer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>C:/Users/Viktor/git/C-ATTL3/C-ATTL3/<a class="el" href="_layer_8hpp_source.html">Layer.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
