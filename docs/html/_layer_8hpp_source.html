<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: C:/Users/A6714/git/C-ATTL3/C-ATTL3/Layer.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_b8183163ce8e0490cf11c57c211e66be.html">C-ATTL3</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Layer.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/*</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"> * Layer.hpp</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> *  Created on: 04.12.2017</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> *      Author: Viktor Csomor</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#ifndef CATTL3_LAYER_H_</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#define CATTL3_LAYER_H_</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#ifdef CATTL3_USE_CUDA</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#define CATTL3_USE_CUBLAS</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#define CATTL3_USE_CUDNN</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &lt;algorithm&gt;</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &lt;array&gt;</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include &lt;cassert&gt;</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#include &lt;cmath&gt;</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="preprocessor">#include &lt;cstddef&gt;</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="preprocessor">#include &lt;iomanip&gt;</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="preprocessor">#include &lt;memory&gt;</span></div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="preprocessor">#include &lt;sstream&gt;</span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#include &lt;type_traits&gt;</span></div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#include &lt;utility&gt;</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="preprocessor">#include &quot;Dimensions.hpp&quot;</span></div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="preprocessor">#include &quot;ParameterRegularization.hpp&quot;</span></div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="preprocessor">#include &quot;utils/EigenProxy.hpp&quot;</span></div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="preprocessor">#include &quot;utils/NumericUtils.hpp&quot;</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="preprocessor">#include &quot;WeightInitialization.hpp&quot;</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="preprocessor">#ifdef CATTL3_USE_CUBLAS</span></div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="preprocessor">#include &quot;gpu/CuBLASHandle.hpp&quot;</span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="preprocessor">#ifdef CATTL3_USE_CUDNN</span></div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="preprocessor">#include &quot;gpu/CuDNNHandle.hpp&quot;</span></div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacecattle.html">cattle</a> {</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="comment">// TODO FFT and/or Winograd filtering for CPU convolution.</span></div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l00050"></a><span class="lineno"><a class="line" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">   50</a></span>&#160;<span class="keyword">using</span> <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr</a> = std::shared_ptr&lt;WeightInitialization&lt;Scalar&gt;&gt;;</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l00056"></a><span class="lineno"><a class="line" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">   56</a></span>&#160;<span class="keyword">using</span> <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr</a> = std::shared_ptr&lt;ParamaterRegularization&lt;Scalar&gt;&gt;;</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="comment">// Forward declarations to NeuralNetwork and Optimizer so they can be friended.</span></div><div class="line"><a name="l00059"></a><span class="lineno"><a class="line" href="classcattle_1_1_neural_network.html">   59</a></span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank, <span class="keywordtype">bool</span> Sequential&gt; <span class="keyword">class </span><a class="code" href="classcattle_1_1_neural_network.html">NeuralNetwork</a>;</div><div class="line"><a name="l00060"></a><span class="lineno"><a class="line" href="classcattle_1_1_optimizer.html">   60</a></span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank, <span class="keywordtype">bool</span> Sequential&gt; <span class="keyword">class </span><a class="code" href="classcattle_1_1_optimizer.html">Optimizer</a>;</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l00066"></a><span class="lineno"><a class="line" href="classcattle_1_1_layer.html">   66</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;    static_assert(std::is_floating_point&lt;Scalar&gt;::value, <span class="stringliteral">&quot;non floating-point scalar type&quot;</span>);</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;    static_assert(Rank &gt; 0 &amp;&amp; Rank &lt; 4, <span class="stringliteral">&quot;illegal rank&quot;</span>);</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    <span class="keyword">friend</span> <span class="keyword">class </span><a class="code" href="classcattle_1_1_neural_network.html">NeuralNetwork</a>&lt;Scalar,Rank,true&gt;;</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    <span class="keyword">friend</span> <span class="keyword">class </span><a class="code" href="classcattle_1_1_neural_network.html">NeuralNetwork</a>&lt;Scalar,Rank,false&gt;;</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    <span class="keyword">friend</span> <span class="keyword">class </span><a class="code" href="classcattle_1_1_optimizer.html">Optimizer</a>&lt;Scalar,Rank,true&gt;;</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    <span class="keyword">friend</span> <span class="keyword">class </span><a class="code" href="classcattle_1_1_optimizer.html">Optimizer</a>&lt;Scalar,Rank,false&gt;;</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;    <span class="keyword">static</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> NO_PARAM_REG;</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;    <span class="keyword">virtual</span> ~<a class="code" href="classcattle_1_1_layer.html">Layer</a>() = <span class="keywordflow">default</span>;</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    <span class="keyword">virtual</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_layer.html#a46db46c62f3d46c6bbef5a482d7fcb00">clone</a>() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;    <span class="keyword">virtual</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_layer.html#a074a197df04250449a059d97a4e6e120">clone_with_shared_params</a>() = 0;</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    <span class="keyword">virtual</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_layer.html#a683f9b67748863329938da07e86ecd8c">get_params_owner</a>() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;    <span class="keyword">virtual</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_layer.html#a616670d011b739c619fe2c8f6d14baa4">get_input_dims</a>() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;    <span class="keyword">virtual</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_layer.html#a26f50624ba25185ae1c9a7c855ffc0d6">get_output_dims</a>() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;    <span class="keyword">virtual</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_layer.html#ab67312e1fc860a8a246f6f9aeadffbb4">get_params</a>() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;    <span class="keyword">virtual</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_layer.html#a60fbc161deece174499e4be12b730255">get_params_grad</a>() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_layer.html#a9b9374ca0299ed3b599c0403174a79af">is_frozen</a>() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_layer.html#a2efa46d4b10ec998cb7b09a3c430e025">set_frozen</a>(<span class="keywordtype">bool</span> frozen) = 0;</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_layer.html#aae8baf56035b9c2130eec90881e27bad">init</a>() = 0;</div><div class="line"><a name="l00154"></a><span class="lineno"><a class="line" href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">  154</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">is_shared_params_clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">this</span> != &amp;<a class="code" href="classcattle_1_1_layer.html#a683f9b67748863329938da07e86ecd8c">get_params_owner</a>();</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;    }</div><div class="line"><a name="l00162"></a><span class="lineno"><a class="line" href="classcattle_1_1_layer.html#a3ba02f76506a7f8a72f44be78693209e">  162</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_layer.html#a3ba02f76506a7f8a72f44be78693209e">is_parametric</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1_layer.html#ab67312e1fc860a8a246f6f9aeadffbb4">get_params</a>().rows() &gt; 0 &amp;&amp; <a class="code" href="classcattle_1_1_layer.html#ab67312e1fc860a8a246f6f9aeadffbb4">get_params</a>().cols() &gt; 0;</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;    }</div><div class="line"><a name="l00168"></a><span class="lineno"><a class="line" href="classcattle_1_1_layer.html#a984f124ef5a2de9b2466ccb5a591eca2">  168</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">virtual</span> std::string <a class="code" href="classcattle_1_1_layer.html#a984f124ef5a2de9b2466ccb5a591eca2">to_string</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;        <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">int</span> header_length = 128;</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;        std::stringstream strm;</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;        std::stringstream id_num_strm;</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;        id_num_strm &lt;&lt; <span class="keyword">this</span>;</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;        std::string <span class="keywordtype">id</span> = <span class="stringliteral">&quot;&lt;&quot;</span> + std::string(<span class="keyword">typeid</span>(*this).name()) + id_num_strm.str() + <span class="stringliteral">&quot;&gt;&quot;</span>;</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;        strm &lt;&lt; <span class="keywordtype">id</span> &lt;&lt; std::string(std::max(0, (<span class="keywordtype">int</span>) (header_length - <span class="keywordtype">id</span>.length())), <span class="charliteral">&#39;-&#39;</span>) &lt;&lt; std::endl;</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;        strm &lt;&lt; <span class="stringliteral">&quot;\tinput dims: &quot;</span> &lt;&lt; <a class="code" href="classcattle_1_1_layer.html#a616670d011b739c619fe2c8f6d14baa4">get_input_dims</a>().<a class="code" href="classcattle_1_1_dim_expression.html#ae51ed9575f019bc86402615cf08e97d8">to_string</a>() &lt;&lt; std::endl;</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;        strm &lt;&lt; <span class="stringliteral">&quot;\toutput dims: &quot;</span> &lt;&lt; <a class="code" href="classcattle_1_1_layer.html#a26f50624ba25185ae1c9a7c855ffc0d6">get_output_dims</a>().<a class="code" href="classcattle_1_1_dim_expression.html#ae51ed9575f019bc86402615cf08e97d8">to_string</a>() &lt;&lt; std::endl;</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_layer.html#a3ba02f76506a7f8a72f44be78693209e">is_parametric</a>()) {</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;            strm &lt;&lt; <span class="stringliteral">&quot;\tparams:&quot;</span> &lt;&lt; std::endl;</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;            <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; params = <a class="code" href="classcattle_1_1_layer.html#ab67312e1fc860a8a246f6f9aeadffbb4">get_params</a>();</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; params.rows(); ++j) {</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;                strm &lt;&lt; <span class="stringliteral">&quot;\t[ &quot;</span>;</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = 0; k &lt; params.cols(); ++k) {</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;                    strm &lt;&lt; std::setw(11) &lt;&lt; std::setprecision(4) &lt;&lt; params(j,k);</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;                    <span class="keywordflow">if</span> (k != params.cols() - 1)</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;                        strm &lt;&lt; <span class="stringliteral">&quot;, &quot;</span>;</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;                }</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;                strm &lt;&lt; <span class="stringliteral">&quot; ]&quot;</span> &lt;&lt; std::endl;</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;            }</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;        }</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;        <span class="keywordflow">return</span> strm.str();</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;    }</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;    <span class="keyword">friend</span> std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const Layer&lt;Scalar,Rank&gt;&amp; layer) {</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;        <span class="keywordflow">return</span> os &lt;&lt; layer.to_string() &lt;&lt; std::flush;</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;    }</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;    <span class="comment">// Rank is increased by one to allow for batch training.</span></div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;    <span class="keyword">static</span> constexpr std::size_t DATA_RANK = Rank + 1;</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;    <span class="keyword">typedef</span> Tensor&lt;Scalar,DATA_RANK&gt; Data;</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;    <span class="comment">/* Only expose methods that allow for the modification of the layer&#39;s state to friends and</span></div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;<span class="comment">     * sub-classes (except the initialization method). */</span></div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_layer.html#af208065ae34cbebcdc932c84383ea159">is_input_layer</a>() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_layer.html#a9557e077d940b2ff0c280e9a78c4b52e">set_input_layer</a>(<span class="keywordtype">bool</span> input_layer) = 0;</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_layer.html#ae3d00e9fb6079e4b4990b3a14625a93d">empty_cache</a>() = 0;</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;    <span class="keyword">virtual</span> Matrix&lt;Scalar&gt;&amp; <a class="code" href="classcattle_1_1_layer.html#ab67312e1fc860a8a246f6f9aeadffbb4">get_params</a>() = 0;</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;    <span class="keyword">virtual</span> Matrix&lt;Scalar&gt;&amp; <a class="code" href="classcattle_1_1_layer.html#a60fbc161deece174499e4be12b730255">get_params_grad</a>() = 0;</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_layer.html#aae685cf7e708e0c4f32ddc4c10254046">regularize</a>() = 0;</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;    <span class="keyword">virtual</span> Scalar <a class="code" href="classcattle_1_1_layer.html#ab3719ffa784c45277252f2fb16b209d5">get_regularization_penalty</a>() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_layer.html#ac74dd19ed2f3a253cfbb1d1785f56197">enforce_constraints</a>() = 0;</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;    <span class="keyword">virtual</span> Data <a class="code" href="classcattle_1_1_layer.html#a6c1ea7b25d9f882364b7f2288f02d8da">pass_forward</a>(Data in, <span class="keywordtype">bool</span> training) = 0;</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;    <span class="keyword">virtual</span> Data <a class="code" href="classcattle_1_1_layer.html#a7cb51862ef9b87632b5abb8e3ab36dd9">pass_back</a>(Data out_grad) = 0;</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;};</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;<span class="comment">// Initialize the static default regularization penalty.</span></div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;<span class="keyword">const</span> ParamRegSharedPtr&lt;Scalar&gt; Layer&lt;Scalar,Rank&gt;::NO_PARAM_REG = std::make_shared&lt;NoParameterRegularization&lt;Scalar&gt;&gt;();</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l00287"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html">  287</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;    <span class="keyword">virtual</span> ~<a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer</a>() = <span class="keywordflow">default</span>;</div><div class="line"><a name="l00291"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#a08d25e205022e91c9d13db75fe1babe1">  291</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>&amp; <a class="code" href="classcattle_1_1_kernel_layer.html#a08d25e205022e91c9d13db75fe1babe1">get_params_owner</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;        <span class="keywordflow">return</span> owner;</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;    }</div><div class="line"><a name="l00294"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#a5633fa5220ac376441846002ff8ff22d">  294</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_kernel_layer.html#a5633fa5220ac376441846002ff8ff22d">get_input_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;        <span class="keywordflow">return</span> input_dims;</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;    }</div><div class="line"><a name="l00297"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#a08ee9d5c6877d2ca969be895be1bafb3">  297</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_kernel_layer.html#a08ee9d5c6877d2ca969be895be1bafb3">get_output_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;        <span class="keywordflow">return</span> output_dims;</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;    }</div><div class="line"><a name="l00300"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#a9120bb46be48a022463aa07a35801074">  300</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_kernel_layer.html#a9120bb46be48a022463aa07a35801074">get_params</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;        <span class="keywordflow">return</span> weights_ref;</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;    }</div><div class="line"><a name="l00303"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#a60063073706819b0625db87b01b6fc5c">  303</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_kernel_layer.html#a60063073706819b0625db87b01b6fc5c">get_params_grad</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;        <span class="keywordflow">return</span> weights_grad;</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;    }</div><div class="line"><a name="l00306"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#aa4fbd5c1c230270282c2501348e3f446">  306</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_kernel_layer.html#aa4fbd5c1c230270282c2501348e3f446">is_frozen</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;        <span class="keywordflow">return</span> frozen;</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;    }</div><div class="line"><a name="l00309"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#ab12e754d7fa7dd9cbeb77ebe50286bdd">  309</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_kernel_layer.html#ab12e754d7fa7dd9cbeb77ebe50286bdd">set_frozen</a>(<span class="keywordtype">bool</span> frozen) {</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;        this-&gt;frozen = frozen;</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;    }</div><div class="line"><a name="l00312"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#af6cb82a9e05d72dc92d8a36274e71a63">  312</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_kernel_layer.html#af6cb82a9e05d72dc92d8a36274e71a63">init</a>() {</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;        weight_init-&gt;apply(weights_ref);</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;        weights_grad.setZero(weights_grad.rows(), weights_grad.cols());</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;    }</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; input_dims, <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a> output_dims,</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;            <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr&lt;Scalar&gt;</a> weight_init, <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> weight_reg, std::size_t weight_rows,</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;            std::size_t weight_cols, Scalar max_norm_constraint) :</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;                input_dims(input_dims),</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;                output_dims(output_dims),</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;                weight_init(weight_init),</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;                weight_reg(weight_reg),</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;                max_norm_constraint(max_norm_constraint),</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;                max_norm(internal::NumericUtils&lt;Scalar&gt;::decidedly_greater(max_norm_constraint, (Scalar) 0)),</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;                input_layer(false),</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;                frozen(false),</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;                weights(weight_rows, weight_cols),</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;                weights_grad(weight_rows, weight_cols),</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;                weights_ref(weights),</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;                owner(*this) {</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;        assert(weight_init != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;        assert(weight_reg != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;    }</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;    <span class="keyword">inline</span> KernelLayer(<span class="keyword">const</span> KernelLayer&lt;Scalar,Rank&gt;&amp; layer) :</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;            input_dims(layer.input_dims),</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;            output_dims(layer.output_dims),</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;            weight_init(layer.weight_init),</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;            weight_reg(layer.weight_reg),</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;            max_norm_constraint(layer.max_norm_constraint),</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;            max_norm(layer.max_norm),</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;            frozen(layer.frozen),</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;            weights(layer.weights),</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;            weights_grad(layer.weights_grad),</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;            weights_ref(layer.<a class="code" href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">is_shared_params_clone</a>() ? layer.weights_ref : weights),</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;            owner(layer.<a class="code" href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">is_shared_params_clone</a>() ? layer.owner : *this) { }</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;    <span class="keyword">inline</span> KernelLayer(KernelLayer&lt;Scalar,Rank&gt;&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;            input_dims(layer.input_dims),</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;            output_dims(layer.output_dims),</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;            weight_init(layer.weight_init),</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;            weight_reg(layer.weight_reg),</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;            max_norm_constraint(layer.max_norm_constraint),</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;            max_norm(layer.max_norm),</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;            frozen(layer.frozen),</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;            weights(share_params ? <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt;Scalar&gt;(0, 0) : layer.weights),</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;            weights_grad(layer.weights_grad),</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;            weights_ref(share_params ? layer.weights_ref : weights),</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;            owner(share_params ? layer.owner : *this) { }</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;    KernelLayer&lt;Scalar,Rank&gt;* operator=(<span class="keyword">const</span> KernelLayer&lt;Scalar,Rank&gt;&amp; layer) {</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;        input_dims = layer.input_dims;</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;        output_dims = layer.output_dims;</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;        weight_init = layer.weight_init;</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;        weight_reg = layer.weight_reg;</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;        max_norm_constraint = layer.max_norm_constraint;</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;        max_norm = layer.max_norm;</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;        input_layer = layer.input_layer;</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;        frozen = layer.frozen;</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;        weights = layer.weights;</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;        weights_grad = layer.weights_grad;</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;        weights_ref = (layer.is_shared_params_clone() ? layer.weights_ref : weights);</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;        owner = (layer.is_shared_params_clone() ? layer.owner : *<span class="keyword">this</span>);</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;    }</div><div class="line"><a name="l00375"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">  375</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">is_input_layer</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;    }</div><div class="line"><a name="l00378"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#a2cfd231e456e1f828dc3638b3a5eb0c7">  378</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_kernel_layer.html#a2cfd231e456e1f828dc3638b3a5eb0c7">set_input_layer</a>(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;    }</div><div class="line"><a name="l00381"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#a9b9896f4bd8461df9021f9ae0c03c5b8">  381</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_kernel_layer.html#a9b9896f4bd8461df9021f9ae0c03c5b8">get_params</a>() {</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;        <span class="keywordflow">return</span> weights_ref;</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;    }</div><div class="line"><a name="l00384"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#aa2956ff7c87760f05d4e0d906ed16b10">  384</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_kernel_layer.html#aa2956ff7c87760f05d4e0d906ed16b10">get_params_grad</a>() {</div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;        <span class="keywordflow">return</span> weights_grad;</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;    }</div><div class="line"><a name="l00387"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#a403029b832ce6534577e87dbe4163ccb">  387</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_kernel_layer.html#a403029b832ce6534577e87dbe4163ccb">regularize</a>() {</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;        weights_grad.topRows(weights_grad.rows() - 1) +=</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;                weight_reg-&gt;d_function(weights_ref.topRows(weights_ref.rows() - 1));</div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;    }</div><div class="line"><a name="l00391"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#a197971b8fe62e3c29177e5c28ff6f5f2">  391</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1_kernel_layer.html#a197971b8fe62e3c29177e5c28ff6f5f2">get_regularization_penalty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;        <span class="keywordflow">return</span> weight_reg-&gt;function(weights_ref.topRows(weights_ref.rows() - 1));</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;    }</div><div class="line"><a name="l00394"></a><span class="lineno"><a class="line" href="classcattle_1_1_kernel_layer.html#ad324ff93b576e8e542962a4d2d5d18f4">  394</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_kernel_layer.html#ad324ff93b576e8e542962a4d2d5d18f4">enforce_constraints</a>() {</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;        <span class="keywordflow">if</span> (max_norm) {</div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;            Scalar l2_norm = weights_ref.topRows(weights_ref.rows() - 1).squaredNorm();</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;            <span class="keywordflow">if</span> (l2_norm &gt; max_norm_constraint)</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;                weights_ref.topRows(weights_ref.rows() - 1) *= (max_norm_constraint / l2_norm);</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;        }</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;    }</div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;    <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a> input_dims;</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;    <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a> output_dims;</div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;    <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr&lt;Scalar&gt;</a> weight_init;</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;    <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> weight_reg;</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;    <span class="keyword">const</span> Scalar max_norm_constraint;</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> max_norm;</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;    <span class="comment">/* Eigen matrices are backed by arrays allocated on the heap, so these</span></div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;<span class="comment">     * members do not burden the stack. */</span></div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> weights_grad;</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; weights_ref;</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;    <span class="keywordtype">bool</span> frozen;</div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> weights;</div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;    <span class="keyword">const</span> Base&amp; owner;</div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;};</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank = 1&gt;</div><div class="line"><a name="l00422"></a><span class="lineno"><a class="line" href="classcattle_1_1_dense_kernel_layer.html">  422</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_dense_kernel_layer.html">DenseKernelLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,Root::DATA_RANK&gt; RankwiseArray;</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00436"></a><span class="lineno"><a class="line" href="classcattle_1_1_dense_kernel_layer.html#a131a2e0c7b6ae0faf070555bda0d39a6">  436</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_dense_kernel_layer.html#a131a2e0c7b6ae0faf070555bda0d39a6">DenseKernelLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; input_dims, std::size_t output_size,</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;            <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr&lt;Scalar&gt;</a> weight_init, <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> weight_reg = Root::NO_PARAM_REG,</div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;            Scalar max_norm_constraint = 0) :</div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;                <a class="code" href="classcattle_1_1_layer.html">Base</a>::<a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer</a>(input_dims, <a class="code" href="classcattle_1_1_dimensions.html">Dimensions</a>&lt;std::size_t,Rank&gt;({ output_size }), weight_init, weight_reg,</div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;                        input_dims.get_volume() + 1, output_size, max_norm_constraint),</div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;                out_conversion_dims(Base::output_dims.<span class="keyword">template</span> promote&lt;&gt;()),</div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;                prev_out_conversion_dims(Base::input_dims.<span class="keyword">template</span> promote&lt;&gt;()) { }</div><div class="line"><a name="l00443"></a><span class="lineno"><a class="line" href="classcattle_1_1_dense_kernel_layer.html#ac70aa473ee0b2cd7c18a4575dcadaa0e">  443</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_dense_kernel_layer.html#ac70aa473ee0b2cd7c18a4575dcadaa0e">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_dense_kernel_layer.html#a131a2e0c7b6ae0faf070555bda0d39a6">DenseKernelLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;    }</div><div class="line"><a name="l00446"></a><span class="lineno"><a class="line" href="classcattle_1_1_dense_kernel_layer.html#a849b12085e90cba66e75f6011f0274a9">  446</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_dense_kernel_layer.html#a849b12085e90cba66e75f6011f0274a9">clone_with_shared_params</a>() {</div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_dense_kernel_layer.html#a131a2e0c7b6ae0faf070555bda0d39a6">DenseKernelLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;    }</div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_dense_kernel_layer.html#a131a2e0c7b6ae0faf070555bda0d39a6">DenseKernelLayer</a>(<a class="code" href="classcattle_1_1_dense_kernel_layer.html">DenseKernelLayer&lt;Scalar,Rank&gt;</a>&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;            Base::<a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer</a>(layer, share_params),</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;            out_conversion_dims(layer.out_conversion_dims),</div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;            prev_out_conversion_dims(layer.prev_out_conversion_dims),</div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;            biased_in_mat(layer.biased_in_mat) { }</div><div class="line"><a name="l00455"></a><span class="lineno"><a class="line" href="classcattle_1_1_dense_kernel_layer.html#a937d64c683eb3415c6eedfd1855c4ae0">  455</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_dense_kernel_layer.html#a937d64c683eb3415c6eedfd1855c4ae0">empty_cache</a>() {</div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;        biased_in_mat = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(0, 0);</div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;    }</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;<span class="preprocessor">#ifndef CATTL3_USE_CUBLAS</span></div><div class="line"><a name="l00459"></a><span class="lineno"><a class="line" href="classcattle_1_1_dense_kernel_layer.html#a89706a4d8b43b46dd3df65f2c0340969">  459</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_dense_kernel_layer.html#a89706a4d8b43b46dd3df65f2c0340969">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Root::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::input_dims);</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;        <span class="keywordtype">unsigned</span> input_size = Base::input_dims.get_volume();</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;        <span class="comment">// Add a 1-column to the input for the bias trick.</span></div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;        biased_in_mat = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(in.dimension(0), input_size + 1);</div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;        biased_in_mat.leftCols(input_size) = <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a>(in.data(), in.dimension(0), input_size);</div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;        biased_in_mat.col(input_size).setOnes();</div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out_mat = biased_in_mat * Base::weights_ref;</div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;        out_conversion_dims[0] = out_mat.rows();</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Root::DATA_RANK&gt;</a>(out_mat.data(), out_conversion_dims);</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;    }</div><div class="line"><a name="l00471"></a><span class="lineno"><a class="line" href="classcattle_1_1_dense_kernel_layer.html#a38cac34fd04b0cde05f4f803d5aac5c1">  471</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_dense_kernel_layer.html#a38cac34fd04b0cde05f4f803d5aac5c1">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Root::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::output_dims);</div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; biased_in_mat.rows() == out_grad.dimension(0));</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;        <span class="comment">// Compute the gradient of the outputs with respect to the weights.</span></div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;        <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> out_grad_mat(out_grad.data(), out_grad.dimension(0), Base::output_dims.get_volume());</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;        Base::weights_grad = biased_in_mat.transpose() * out_grad_mat;</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">Base::is_input_layer</a>())</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;            <span class="keywordflow">return</span> <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;        <span class="comment">/* Remove the bias row from the weight matrix, transpose it, and compute the derivative w.r.t. the</span></div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;<span class="comment">         * previous layer&#39;s output. */</span></div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> prev_out_grad_mat = out_grad_mat * Base::weights_ref.topRows(Base::input_dims.get_volume()).transpose();</div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;        prev_out_conversion_dims[0] = prev_out_grad_mat.rows();</div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Root::DATA_RANK&gt;</a>(prev_out_grad_mat.data(), prev_out_conversion_dims);</div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;    }</div><div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_dense_kernel_layer.html#a89706a4d8b43b46dd3df65f2c0340969">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Root::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::input_dims);</div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;        <span class="keywordtype">unsigned</span> input_size = Base::input_dims.get_volume();</div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;        biased_in_mat = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(in.dimension(0), input_size + 1);</div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;        biased_in_mat.leftCols(input_size) = <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a>(in.data(), in.dimension(0), input_size);</div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;        biased_in_mat.col(input_size).setOnes();</div><div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;        out_conversion_dims[0] = biased_in_mat.rows();</div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;        <span class="keyword">typename</span> Root::Data out(out_conversion_dims);</div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#aeed972c3e81eab21836a014787d8baf6">internal::CuBLASHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#a608acc1a5e1f61d2d86eebf0d62ff948">matrix_mul</a>(biased_in_mat.data(), biased_in_mat.rows(), biased_in_mat.cols(),</div><div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;                <span class="keyword">false</span>, Base::weights_ref.data(), Base::weights_ref.rows(), Base::weights_ref.cols(), <span class="keyword">false</span>, out.data());</div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;    }</div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_dense_kernel_layer.html#a38cac34fd04b0cde05f4f803d5aac5c1">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;        assert((Dimensions&lt;std::size_t,Root::DATA_RANK&gt;(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::output_dims);</div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; biased_in_mat.rows() == out_grad.dimension(0));</div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;        std::size_t out_grad_rows = out_grad.dimension(0);</div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;        std::size_t out_grad_cols = out_grad.size() / out_grad_rows;</div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#aeed972c3e81eab21836a014787d8baf6">internal::CuBLASHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#a608acc1a5e1f61d2d86eebf0d62ff948">matrix_mul</a>(biased_in_mat.data(), biased_in_mat.rows(), biased_in_mat.cols(),</div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;                <span class="keyword">true</span>, out_grad.data(), out_grad_rows, out_grad_cols, <span class="keyword">false</span>, Base::weights_grad.data());</div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">Base::is_input_layer</a>())</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;            <span class="keywordflow">return</span> <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;        Matrix&lt;Scalar&gt; weights_without_bias = Base::weights_ref.topRows(Base::input_dims.get_volume());</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;        prev_out_conversion_dims[0] = out_grad_rows;</div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;        <span class="keyword">typename</span> Root::Data prev_out_grad(prev_out_conversion_dims);</div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#aeed972c3e81eab21836a014787d8baf6">internal::CuBLASHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#a608acc1a5e1f61d2d86eebf0d62ff948">matrix_mul</a>(out_grad.data(), out_grad_rows, out_grad_cols, <span class="keyword">false</span>,</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;                weights_without_bias.data(), weights_without_bias.rows(), weights_without_bias.cols(), <span class="keyword">true</span>,</div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;                prev_out_grad.data());</div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;    }</div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;    RankwiseArray out_conversion_dims;</div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;    RankwiseArray prev_out_conversion_dims;</div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;    <span class="comment">// Staged computation caches</span></div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;    Matrix&lt;Scalar&gt; biased_in_mat;</div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;};</div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;<span class="preprocessor">#ifndef CATTL3_USE_CUDNN</span></div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l00529"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_base.html">  529</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,4&gt; Array4;</div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::pair&lt;std::size_t,std::size_t&gt;,4&gt; PaddingsArray4;</div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; input_dims, std::size_t filters,</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;            <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr&lt;Scalar&gt;</a> weight_init, <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> weight_reg, std::size_t receptor_height,</div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;            std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride,</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;            std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation,</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;            Scalar max_norm_constraint) :</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;                <span class="comment">/* For every filter, there is a column in the weight matrix with the same number of</span></div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;<span class="comment">                 * elements as the area of the receptive field (F * F * D) + 1 for the bias row. */</span></div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;                Base::KernelLayer(input_dims, calculate_adjusted_output_dims(input_dims, filters,</div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;                        receptor_height, receptor_width, vertical_padding, horizontal_padding,</div><div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;                        vertical_stride, horizontal_stride, vertical_dilation, horizontal_dilation),</div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;                        weight_init, weight_reg,</div><div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;                        receptor_height * receptor_width * input_dims.template extend&lt;3 - Rank&gt;()(2) + 1,</div><div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;                        filters, max_norm_constraint),</div><div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;                filters(filters),</div><div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;                receptor_height(receptor_height),</div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;                receptor_width(receptor_width),</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;                vertical_padding(vertical_padding),</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;                horizontal_padding(horizontal_padding),</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;                vertical_stride(vertical_stride),</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;                horizontal_stride(horizontal_stride),</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;                vertical_dilation(vertical_dilation),</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;                horizontal_dilation(horizontal_dilation),</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;                ext_input_dims(input_dims.template extend&lt;3 - Rank&gt;()),</div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;                ext_output_dims(calculate_output_dims(ext_input_dims, filters, receptor_height, receptor_width,</div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;                        vertical_padding, horizontal_padding, vertical_stride, horizontal_stride,</div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;                        vertical_dilation, horizontal_dilation)),</div><div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;                padded_height(ext_input_dims(0) + 2 * vertical_padding),</div><div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;                padded_width(ext_input_dims(1) + 2 * horizontal_padding),</div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;                dil_receptor_height(receptor_height + (receptor_height - 1) * vertical_dilation),</div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;                dil_receptor_width(receptor_width + (receptor_width - 1) * horizontal_dilation),</div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;                patches_per_sample(ext_output_dims(0) * ext_output_dims(1)),</div><div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;                out_conversion_dims({ 0u, ext_output_dims(0), ext_output_dims(1), ext_output_dims(2) }),</div><div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;                patch_offsets({ 0u, 0u, 0u, 0u }),</div><div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;                patch_extents({ 0u, dil_receptor_height, dil_receptor_width, ext_input_dims(2) }),</div><div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;                dil_strides({ 1u, vertical_dilation + 1u, horizontal_dilation + 1u, 1u }),</div><div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;                no_padding_offsets({ 0u, vertical_padding, horizontal_padding, 0u }),</div><div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;                no_padding_extents({ 0u, ext_input_dims(0), ext_input_dims(1), ext_input_dims(2) }),</div><div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;                paddings({ std::make_pair(0, 0), std::make_pair(vertical_padding, vertical_padding),</div><div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;                        std::make_pair(horizontal_padding, horizontal_padding), std::make_pair(0, 0) }) {</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;        assert(filters &gt; 0);</div><div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;        assert(receptor_height &gt; 0);</div><div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;        assert(receptor_width &gt; 0);</div><div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;        assert(vertical_stride &gt; 0 &amp;&amp; horizontal_stride &gt; 0);</div><div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;        assert(ext_input_dims(0) + 2 * vertical_padding &gt;= dil_receptor_height &amp;&amp;</div><div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;                ext_input_dims(1) + 2 * horizontal_padding &gt;= dil_receptor_width);</div><div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;    }</div><div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a>(<a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase&lt;Scalar,Rank&gt;</a>&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;            Base::KernelLayer(layer, share_params),</div><div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;            ext_input_dims(layer.ext_input_dims),</div><div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;            ext_output_dims(layer.ext_output_dims),</div><div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;            filters(layer.filters),</div><div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;            receptor_height(layer.receptor_height),</div><div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;            receptor_width(layer.receptor_width),</div><div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;            vertical_padding(layer.vertical_padding),</div><div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;            horizontal_padding(layer.horizontal_padding),</div><div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;            vertical_stride(layer.vertical_stride),</div><div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;            horizontal_stride(layer.horizontal_stride),</div><div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;            vertical_dilation(layer.vertical_dilation),</div><div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;            horizontal_dilation(layer.horizontal_dilation),</div><div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160;            padded_height(layer.padded_height),</div><div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160;            padded_width(layer.padded_width),</div><div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;            dil_receptor_height(layer.dil_receptor_height),</div><div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;            dil_receptor_width(layer.dil_receptor_width),</div><div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;            patches_per_sample(layer.patches_per_sample),</div><div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;            out_conversion_dims(layer.out_conversion_dims),</div><div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;            patch_offsets(layer.patch_offsets),</div><div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;            patch_extents(layer.patch_extents),</div><div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;            dil_strides(layer.dil_strides),</div><div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;            no_padding_offsets(layer.no_padding_offsets),</div><div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;            no_padding_extents(layer.no_padding_extents),</div><div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;            paddings(layer.paddings),</div><div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;            biased_in_conv_mat(layer.biased_in_conv_mat) { }</div><div class="line"><a name="l00607"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_base.html#afd721c979e18de71d6b2a7dd6a3d5030">  607</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html#afd721c979e18de71d6b2a7dd6a3d5030">empty_cache</a>() {</div><div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;        biased_in_conv_mat = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(0, 0);</div><div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;    }</div><div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;<span class="preprocessor">#ifndef CATTL3_USE_CUBLAS</span></div><div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> _pass_forward(<a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;        <span class="comment">// Spatial padding.</span></div><div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;        <span class="keywordflow">if</span> (vertical_padding &gt; 0 || horizontal_padding &gt; 0)</div><div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;            in = <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a>(in.pad(paddings));</div><div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;        std::size_t total_patches = rows * patches_per_sample;</div><div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;        std::size_t receptor_vol = Base::weights_ref.rows() - 1;</div><div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;        <span class="comment">/* Flatten the receptor cuboids into row vectors and concatenate them. Each row stands for one stretched</span></div><div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;<span class="comment">         * out receptor of one sample. The same receptor location along all samples of the batch is represented</span></div><div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;<span class="comment">         * by a contiguous block of these rows. */</span></div><div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;        std::size_t patch_ind = 0;</div><div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;        patch_extents[0] = rows;</div><div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;        biased_in_conv_mat = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(total_patches, receptor_vol + 1);</div><div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt;= padded_width - dil_receptor_width; i += horizontal_stride) {</div><div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;            patch_offsets[2] = i;</div><div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt;= padded_height - dil_receptor_height; j += vertical_stride) {</div><div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;                patch_offsets[1] = j;</div><div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;                <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> patch;</div><div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;                <span class="comment">// If the patch is dilated, skip the spatial gaps when flattening it into a matrix.</span></div><div class="line"><a name="l00630"></a><span class="lineno">  630</span>&#160;                <span class="keywordflow">if</span> (vertical_dilation &gt; 0 || horizontal_dilation &gt; 0)</div><div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;                    patch = in.slice(patch_offsets, patch_extents).stride(dil_strides);</div><div class="line"><a name="l00632"></a><span class="lineno">  632</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;                    patch = in.slice(patch_offsets, patch_extents);</div><div class="line"><a name="l00634"></a><span class="lineno">  634</span>&#160;                biased_in_conv_mat.block(patch_ind, 0, rows, receptor_vol) = <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a>(patch.data(), rows, receptor_vol);</div><div class="line"><a name="l00635"></a><span class="lineno">  635</span>&#160;                patch_ind += rows;</div><div class="line"><a name="l00636"></a><span class="lineno">  636</span>&#160;            }</div><div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;        }</div><div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;        assert(patch_ind == total_patches);</div><div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;        <span class="comment">// Bias trick.</span></div><div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160;        biased_in_conv_mat.col(receptor_vol).setOnes();</div><div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;        Matrix&lt;Scalar&gt; out_mat = biased_in_conv_mat * Base::weights_ref;</div><div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;        out_conversion_dims[0] = rows;</div><div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;        <span class="keywordflow">return</span> TensorMap&lt;Scalar,4&gt;(out_mat.data(), out_conversion_dims);</div><div class="line"><a name="l00644"></a><span class="lineno">  644</span>&#160;    }</div><div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;    <span class="keyword">inline</span> Tensor&lt;Scalar,4&gt; _pass_back(Tensor&lt;Scalar,4&gt; out_grad) {</div><div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160;        std::size_t rows = out_grad.dimension(0);</div><div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160;        std::size_t total_patches = rows * patches_per_sample;</div><div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;        std::size_t receptor_vol = Base::weights_ref.rows() - 1;</div><div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;        MatrixMap&lt;Scalar&gt; out_grad_mat(out_grad.data(), total_patches, filters);</div><div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;        Base::weights_grad = biased_in_conv_mat.transpose() * out_grad_mat;</div><div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">Base::is_input_layer</a>())</div><div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;            <span class="keywordflow">return</span> Tensor&lt;Scalar,4&gt;();</div><div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;        <span class="comment">/* Remove the bias row from the weight matrix, transpose it, and compute the gradient of the</span></div><div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;<span class="comment">         * previous layer&#39;s output. */</span></div><div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;        Matrix&lt;Scalar&gt; prev_out_grad_conv_mat = out_grad_mat * Base::weights_ref.topRows(receptor_vol).transpose();</div><div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;        <span class="comment">/* Given the gradient of the stretched out receptor patches, perform a &#39;backwards&#39; convolution</span></div><div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;<span class="comment">         * to get the derivative w.r.t. the individual input nodes. */</span></div><div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;        Tensor&lt;Scalar,4&gt; prev_out_grad(rows, padded_height, padded_width, ext_input_dims(2));</div><div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;        prev_out_grad.setZero();</div><div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160;        std::size_t patch_ind = 0;</div><div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160;        patch_extents[0] = rows;</div><div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt;= padded_width - dil_receptor_width; i += horizontal_stride) {</div><div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;            patch_offsets[2] = i;</div><div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt;= padded_height - dil_receptor_height; j += vertical_stride) {</div><div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;                patch_offsets[1] = j;</div><div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;                <span class="comment">// Accumulate the gradients where the receptor-patch-tensors overlap.</span></div><div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;                Matrix&lt;Scalar&gt; prev_out_grad_conv_mat_block = prev_out_grad_conv_mat.block(patch_ind, 0,</div><div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;                        rows, receptor_vol);</div><div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;                TensorMap&lt;Scalar,4&gt; prev_out_grad_patch(prev_out_grad_conv_mat_block.data(), rows,</div><div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;                        receptor_height, receptor_width, ext_input_dims(2));</div><div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;                <span class="keywordflow">if</span> (vertical_dilation &gt; 0 || horizontal_dilation &gt; 0)</div><div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;                    prev_out_grad.slice(patch_offsets, patch_extents).stride(dil_strides) += prev_out_grad_patch;</div><div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;                    prev_out_grad.slice(patch_offsets, patch_extents) += prev_out_grad_patch;</div><div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;                patch_ind += rows;</div><div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160;            }</div><div class="line"><a name="l00677"></a><span class="lineno">  677</span>&#160;        }</div><div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;        assert(patch_ind == prev_out_grad_conv_mat.rows());</div><div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;        <span class="keywordflow">if</span> (vertical_padding &gt; 0 || horizontal_padding &gt; 0) {</div><div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160;            <span class="comment">// Cut off the padding.</span></div><div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;            no_padding_extents[0] = rows;</div><div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160;            <span class="keywordflow">return</span> prev_out_grad.slice(no_padding_offsets, no_padding_extents);</div><div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;        } <span class="keywordflow">else</span></div><div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160;            <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;    }</div><div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;    <span class="keyword">inline</span> Tensor&lt;Scalar,4&gt; _pass_forward(Tensor&lt;Scalar,4&gt; in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;        <span class="keywordflow">if</span> (vertical_padding &gt; 0 || horizontal_padding &gt; 0)</div><div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;            in = Tensor&lt;Scalar,4&gt;(in.pad(paddings));</div><div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;        std::size_t total_patches = rows * patches_per_sample;</div><div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160;        std::size_t receptor_vol = Base::weights_ref.rows() - 1;</div><div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;        std::size_t patch_ind = 0;</div><div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160;        patch_extents[0] = rows;</div><div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;        biased_in_conv_mat = Matrix&lt;Scalar&gt;(total_patches, receptor_vol + 1);</div><div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt;= padded_width - dil_receptor_width; i += horizontal_stride) {</div><div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;            patch_offsets[2] = i;</div><div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt;= padded_height - dil_receptor_height; j += vertical_stride) {</div><div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;                patch_offsets[1] = j;</div><div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;                Tensor&lt;Scalar,4&gt; patch;</div><div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;                <span class="keywordflow">if</span> (vertical_dilation &gt; 0 || horizontal_dilation &gt; 0)</div><div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160;                    patch = in.slice(patch_offsets, patch_extents).stride(dil_strides);</div><div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;                    patch = in.slice(patch_offsets, patch_extents);</div><div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;                biased_in_conv_mat.block(patch_ind, 0, rows, receptor_vol) = MatrixMap&lt;Scalar&gt;(patch.data(), rows, receptor_vol);</div><div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;                patch_ind += rows;</div><div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;            }</div><div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;        }</div><div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;        assert(patch_ind == total_patches);</div><div class="line"><a name="l00710"></a><span class="lineno">  710</span>&#160;        biased_in_conv_mat.col(receptor_vol).setOnes();</div><div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;        out_conversion_dims[0] = rows;</div><div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;        Tensor&lt;Scalar,4&gt; out(out_conversion_dims);</div><div class="line"><a name="l00713"></a><span class="lineno">  713</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#aeed972c3e81eab21836a014787d8baf6">internal::CuBLASHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#a608acc1a5e1f61d2d86eebf0d62ff948">matrix_mul</a>(biased_in_conv_mat.data(), biased_in_conv_mat.rows(),</div><div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160;                biased_in_conv_mat.cols(), <span class="keyword">false</span>, Base::weights_ref.data(), Base::weights_ref.rows(), Base::weights_ref.cols(),</div><div class="line"><a name="l00715"></a><span class="lineno">  715</span>&#160;                <span class="keyword">false</span>, out.data());</div><div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;    }</div><div class="line"><a name="l00718"></a><span class="lineno">  718</span>&#160;    <span class="keyword">inline</span> Tensor&lt;Scalar,4&gt; _pass_back(Tensor&lt;Scalar,4&gt; out_grad) {</div><div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;        std::size_t rows = out_grad.dimension(0);</div><div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;        std::size_t total_patches = rows * patches_per_sample;</div><div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;        std::size_t receptor_vol = Base::weights_ref.rows() - 1;</div><div class="line"><a name="l00722"></a><span class="lineno">  722</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#aeed972c3e81eab21836a014787d8baf6">internal::CuBLASHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#a608acc1a5e1f61d2d86eebf0d62ff948">matrix_mul</a>(biased_in_conv_mat.data(), biased_in_conv_mat.rows(),</div><div class="line"><a name="l00723"></a><span class="lineno">  723</span>&#160;                biased_in_conv_mat.cols(), <span class="keyword">true</span>, out_grad.data(), total_patches, filters, <span class="keyword">false</span>, Base::weights_grad.data());</div><div class="line"><a name="l00724"></a><span class="lineno">  724</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">Base::is_input_layer</a>())</div><div class="line"><a name="l00725"></a><span class="lineno">  725</span>&#160;            <span class="keywordflow">return</span> Tensor&lt;Scalar,4&gt;();</div><div class="line"><a name="l00726"></a><span class="lineno">  726</span>&#160;        Matrix&lt;Scalar&gt; prev_out_grad_conv_mat(total_patches, receptor_vol);</div><div class="line"><a name="l00727"></a><span class="lineno">  727</span>&#160;        {</div><div class="line"><a name="l00728"></a><span class="lineno">  728</span>&#160;            Matrix&lt;Scalar&gt; weights_without_bias = Base::weights_ref.topRows(receptor_vol);</div><div class="line"><a name="l00729"></a><span class="lineno">  729</span>&#160;            <a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#aeed972c3e81eab21836a014787d8baf6">internal::CuBLASHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#a608acc1a5e1f61d2d86eebf0d62ff948">matrix_mul</a>(out_grad.data(), total_patches, filters, <span class="keyword">false</span>,</div><div class="line"><a name="l00730"></a><span class="lineno">  730</span>&#160;                    weights_without_bias.data(), receptor_vol, filters, <span class="keyword">true</span>, prev_out_grad_conv_mat.data());</div><div class="line"><a name="l00731"></a><span class="lineno">  731</span>&#160;        }</div><div class="line"><a name="l00732"></a><span class="lineno">  732</span>&#160;        Tensor&lt;Scalar,4&gt; prev_out_grad(rows, padded_height, padded_width, ext_input_dims(2));</div><div class="line"><a name="l00733"></a><span class="lineno">  733</span>&#160;        prev_out_grad.setZero();</div><div class="line"><a name="l00734"></a><span class="lineno">  734</span>&#160;        std::size_t patch_ind = 0;</div><div class="line"><a name="l00735"></a><span class="lineno">  735</span>&#160;        patch_extents[0] = rows;</div><div class="line"><a name="l00736"></a><span class="lineno">  736</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt;= padded_width - dil_receptor_width; i += horizontal_stride) {</div><div class="line"><a name="l00737"></a><span class="lineno">  737</span>&#160;            patch_offsets[2] = i;</div><div class="line"><a name="l00738"></a><span class="lineno">  738</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt;= padded_height - dil_receptor_height; j += vertical_stride) {</div><div class="line"><a name="l00739"></a><span class="lineno">  739</span>&#160;                patch_offsets[1] = j;</div><div class="line"><a name="l00740"></a><span class="lineno">  740</span>&#160;                Matrix&lt;Scalar&gt; prev_out_grad_conv_mat_block = prev_out_grad_conv_mat.block(patch_ind, 0,</div><div class="line"><a name="l00741"></a><span class="lineno">  741</span>&#160;                        rows, receptor_vol);</div><div class="line"><a name="l00742"></a><span class="lineno">  742</span>&#160;                TensorMap&lt;Scalar,4&gt; prev_out_grad_patch(prev_out_grad_conv_mat_block.data(), rows,</div><div class="line"><a name="l00743"></a><span class="lineno">  743</span>&#160;                        receptor_height, receptor_width, ext_input_dims(2));</div><div class="line"><a name="l00744"></a><span class="lineno">  744</span>&#160;                <span class="keywordflow">if</span> (vertical_dilation &gt; 0 || horizontal_dilation &gt; 0)</div><div class="line"><a name="l00745"></a><span class="lineno">  745</span>&#160;                    prev_out_grad.slice(patch_offsets, patch_extents).stride(dil_strides) += prev_out_grad_patch;</div><div class="line"><a name="l00746"></a><span class="lineno">  746</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l00747"></a><span class="lineno">  747</span>&#160;                    prev_out_grad.slice(patch_offsets, patch_extents) += prev_out_grad_patch;</div><div class="line"><a name="l00748"></a><span class="lineno">  748</span>&#160;                patch_ind += rows;</div><div class="line"><a name="l00749"></a><span class="lineno">  749</span>&#160;            }</div><div class="line"><a name="l00750"></a><span class="lineno">  750</span>&#160;        }</div><div class="line"><a name="l00751"></a><span class="lineno">  751</span>&#160;        assert(patch_ind == prev_out_grad_conv_mat.rows());</div><div class="line"><a name="l00752"></a><span class="lineno">  752</span>&#160;        <span class="keywordflow">if</span> (vertical_padding &gt; 0 || horizontal_padding &gt; 0) {</div><div class="line"><a name="l00753"></a><span class="lineno">  753</span>&#160;            no_padding_extents[0] = rows;</div><div class="line"><a name="l00754"></a><span class="lineno">  754</span>&#160;            <span class="keywordflow">return</span> prev_out_grad.slice(no_padding_offsets, no_padding_extents);</div><div class="line"><a name="l00755"></a><span class="lineno">  755</span>&#160;        } <span class="keywordflow">else</span></div><div class="line"><a name="l00756"></a><span class="lineno">  756</span>&#160;            <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l00757"></a><span class="lineno">  757</span>&#160;    }</div><div class="line"><a name="l00758"></a><span class="lineno">  758</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00759"></a><span class="lineno">  759</span>&#160;    <span class="comment">// The defining attributes of the convolutional layer.</span></div><div class="line"><a name="l00760"></a><span class="lineno">  760</span>&#160;    <span class="keyword">const</span> std::size_t filters;</div><div class="line"><a name="l00761"></a><span class="lineno">  761</span>&#160;    <span class="keyword">const</span> std::size_t receptor_height;</div><div class="line"><a name="l00762"></a><span class="lineno">  762</span>&#160;    <span class="keyword">const</span> std::size_t receptor_width;</div><div class="line"><a name="l00763"></a><span class="lineno">  763</span>&#160;    <span class="keyword">const</span> std::size_t vertical_padding;</div><div class="line"><a name="l00764"></a><span class="lineno">  764</span>&#160;    <span class="keyword">const</span> std::size_t horizontal_padding;</div><div class="line"><a name="l00765"></a><span class="lineno">  765</span>&#160;    <span class="keyword">const</span> std::size_t vertical_stride;</div><div class="line"><a name="l00766"></a><span class="lineno">  766</span>&#160;    <span class="keyword">const</span> std::size_t horizontal_stride;</div><div class="line"><a name="l00767"></a><span class="lineno">  767</span>&#160;    <span class="keyword">const</span> std::size_t vertical_dilation;</div><div class="line"><a name="l00768"></a><span class="lineno">  768</span>&#160;    <span class="keyword">const</span> std::size_t horizontal_dilation;</div><div class="line"><a name="l00769"></a><span class="lineno">  769</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00770"></a><span class="lineno">  770</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> std::size_t calculate_spatial_output_dim(std::size_t input_dim, std::size_t receptor_size, std::size_t padding,</div><div class="line"><a name="l00771"></a><span class="lineno">  771</span>&#160;            std::size_t dilation, std::size_t stride) {</div><div class="line"><a name="l00772"></a><span class="lineno">  772</span>&#160;        <span class="keywordflow">return</span> (input_dim - receptor_size - (receptor_size - 1) * dilation + 2 * padding) / stride + 1;</div><div class="line"><a name="l00773"></a><span class="lineno">  773</span>&#160;    }</div><div class="line"><a name="l00774"></a><span class="lineno">  774</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> Dimensions&lt;std::size_t,3&gt; calculate_output_dims(<span class="keyword">const</span> Dimensions&lt;std::size_t,3&gt;&amp; input_dims, std::size_t filters,</div><div class="line"><a name="l00775"></a><span class="lineno">  775</span>&#160;            std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding,</div><div class="line"><a name="l00776"></a><span class="lineno">  776</span>&#160;            std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation) {</div><div class="line"><a name="l00777"></a><span class="lineno">  777</span>&#160;        <span class="keywordflow">return</span> { calculate_spatial_output_dim(input_dims(0), receptor_height, vertical_padding, vertical_dilation, vertical_stride),</div><div class="line"><a name="l00778"></a><span class="lineno">  778</span>&#160;                calculate_spatial_output_dim(input_dims(1), receptor_width, horizontal_padding, horizontal_dilation, horizontal_stride),</div><div class="line"><a name="l00779"></a><span class="lineno">  779</span>&#160;                filters };</div><div class="line"><a name="l00780"></a><span class="lineno">  780</span>&#160;    }</div><div class="line"><a name="l00781"></a><span class="lineno">  781</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> Dimensions&lt;std::size_t,Rank&gt; calculate_adjusted_output_dims(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; input_dims,</div><div class="line"><a name="l00782"></a><span class="lineno">  782</span>&#160;            std::size_t filters, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding,</div><div class="line"><a name="l00783"></a><span class="lineno">  783</span>&#160;            std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride,</div><div class="line"><a name="l00784"></a><span class="lineno">  784</span>&#160;            std::size_t vertical_dilation, std::size_t horizontal_dilation) {</div><div class="line"><a name="l00785"></a><span class="lineno">  785</span>&#160;        <span class="keyword">auto</span> output_dims = calculate_output_dims(input_dims.template extend&lt;3 - Rank&gt;(), filters, receptor_height, receptor_width,</div><div class="line"><a name="l00786"></a><span class="lineno">  786</span>&#160;                vertical_padding, horizontal_padding, vertical_stride, horizontal_stride, vertical_dilation, horizontal_dilation);</div><div class="line"><a name="l00787"></a><span class="lineno">  787</span>&#160;        output_dims(2) /= filters;</div><div class="line"><a name="l00788"></a><span class="lineno">  788</span>&#160;        output_dims(Rank - 1) *= filters;</div><div class="line"><a name="l00789"></a><span class="lineno">  789</span>&#160;        <span class="keywordflow">return</span> output_dims.template contract&lt;3 - Rank&gt;();</div><div class="line"><a name="l00790"></a><span class="lineno">  790</span>&#160;    }</div><div class="line"><a name="l00791"></a><span class="lineno">  791</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,3&gt; ext_input_dims;</div><div class="line"><a name="l00792"></a><span class="lineno">  792</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,3&gt; ext_output_dims;</div><div class="line"><a name="l00793"></a><span class="lineno">  793</span>&#160;    <span class="comment">// Pre-computed values to improve propagation-time performance.</span></div><div class="line"><a name="l00794"></a><span class="lineno">  794</span>&#160;    <span class="keyword">const</span> std::size_t padded_height;</div><div class="line"><a name="l00795"></a><span class="lineno">  795</span>&#160;    <span class="keyword">const</span> std::size_t padded_width;</div><div class="line"><a name="l00796"></a><span class="lineno">  796</span>&#160;    <span class="keyword">const</span> std::size_t dil_receptor_height;</div><div class="line"><a name="l00797"></a><span class="lineno">  797</span>&#160;    <span class="keyword">const</span> std::size_t dil_receptor_width;</div><div class="line"><a name="l00798"></a><span class="lineno">  798</span>&#160;    <span class="keyword">const</span> std::size_t patches_per_sample;</div><div class="line"><a name="l00799"></a><span class="lineno">  799</span>&#160;    Array4 out_conversion_dims;</div><div class="line"><a name="l00800"></a><span class="lineno">  800</span>&#160;    Array4 patch_offsets;</div><div class="line"><a name="l00801"></a><span class="lineno">  801</span>&#160;    Array4 patch_extents;</div><div class="line"><a name="l00802"></a><span class="lineno">  802</span>&#160;    Array4 dil_strides;</div><div class="line"><a name="l00803"></a><span class="lineno">  803</span>&#160;    Array4 no_padding_offsets;</div><div class="line"><a name="l00804"></a><span class="lineno">  804</span>&#160;    Array4 no_padding_extents;</div><div class="line"><a name="l00805"></a><span class="lineno">  805</span>&#160;    PaddingsArray4 paddings;</div><div class="line"><a name="l00806"></a><span class="lineno">  806</span>&#160;    <span class="comment">// Staged computation caches</span></div><div class="line"><a name="l00807"></a><span class="lineno">  807</span>&#160;    Matrix&lt;Scalar&gt; biased_in_conv_mat;</div><div class="line"><a name="l00808"></a><span class="lineno">  808</span>&#160;};</div><div class="line"><a name="l00809"></a><span class="lineno">  809</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l00810"></a><span class="lineno">  810</span>&#160;</div><div class="line"><a name="l00813"></a><span class="lineno">  813</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l00814"></a><span class="lineno">  814</span>&#160;<span class="keyword">class </span>ConvKernelLayerBase : <span class="keyword">public</span> KernelLayer&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l00815"></a><span class="lineno">  815</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,Rank&gt; Root;</div><div class="line"><a name="l00816"></a><span class="lineno">  816</span>&#160;    <span class="keyword">typedef</span> KernelLayer&lt;Scalar,Rank&gt; Base;</div><div class="line"><a name="l00817"></a><span class="lineno">  817</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,4&gt; Array4;</div><div class="line"><a name="l00818"></a><span class="lineno">  818</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::pair&lt;std::size_t,std::size_t&gt;,4&gt; PaddingsArray4;</div><div class="line"><a name="l00819"></a><span class="lineno">  819</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l00820"></a><span class="lineno">  820</span>&#160;    <span class="keyword">inline</span> ConvKernelLayerBase(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; input_dims, std::size_t filters,</div><div class="line"><a name="l00821"></a><span class="lineno">  821</span>&#160;            WeightInitSharedPtr&lt;Scalar&gt; weight_init, ParamRegSharedPtr&lt;Scalar&gt; weight_reg, std::size_t receptor_height,</div><div class="line"><a name="l00822"></a><span class="lineno">  822</span>&#160;            std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride,</div><div class="line"><a name="l00823"></a><span class="lineno">  823</span>&#160;            std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation,</div><div class="line"><a name="l00824"></a><span class="lineno">  824</span>&#160;            Scalar max_norm_constraint) :</div><div class="line"><a name="l00825"></a><span class="lineno">  825</span>&#160;                Base::KernelLayer(input_dims, calculate_adjusted_output_dims(input_dims, filters,</div><div class="line"><a name="l00826"></a><span class="lineno">  826</span>&#160;                        receptor_height, receptor_width, vertical_padding, horizontal_padding,</div><div class="line"><a name="l00827"></a><span class="lineno">  827</span>&#160;                        vertical_stride, horizontal_stride, vertical_dilation, horizontal_dilation),</div><div class="line"><a name="l00828"></a><span class="lineno">  828</span>&#160;                        weight_init, weight_reg,</div><div class="line"><a name="l00829"></a><span class="lineno">  829</span>&#160;                        receptor_height * receptor_width * input_dims.template extend&lt;3 - Rank&gt;()(2) + 1,</div><div class="line"><a name="l00830"></a><span class="lineno">  830</span>&#160;                        filters, max_norm_constraint),</div><div class="line"><a name="l00831"></a><span class="lineno">  831</span>&#160;                filters(filters),</div><div class="line"><a name="l00832"></a><span class="lineno">  832</span>&#160;                receptor_height(receptor_height),</div><div class="line"><a name="l00833"></a><span class="lineno">  833</span>&#160;                receptor_width(receptor_width),</div><div class="line"><a name="l00834"></a><span class="lineno">  834</span>&#160;                vertical_padding(vertical_padding),</div><div class="line"><a name="l00835"></a><span class="lineno">  835</span>&#160;                horizontal_padding(horizontal_padding),</div><div class="line"><a name="l00836"></a><span class="lineno">  836</span>&#160;                vertical_stride(vertical_stride),</div><div class="line"><a name="l00837"></a><span class="lineno">  837</span>&#160;                horizontal_stride(horizontal_stride),</div><div class="line"><a name="l00838"></a><span class="lineno">  838</span>&#160;                vertical_dilation(vertical_dilation),</div><div class="line"><a name="l00839"></a><span class="lineno">  839</span>&#160;                horizontal_dilation(horizontal_dilation),</div><div class="line"><a name="l00840"></a><span class="lineno">  840</span>&#160;                in_batch_dims(input_dims.template extend&lt;3 - Rank&gt;().template promote&lt;&gt;()),</div><div class="line"><a name="l00841"></a><span class="lineno">  841</span>&#160;                out_batch_dims(calculate_output_dims(in_batch_dims, filters, receptor_height, receptor_width,</div><div class="line"><a name="l00842"></a><span class="lineno">  842</span>&#160;                        vertical_padding, horizontal_padding, vertical_stride, horizontal_stride,</div><div class="line"><a name="l00843"></a><span class="lineno">  843</span>&#160;                        vertical_dilation, horizontal_dilation)) {</div><div class="line"><a name="l00844"></a><span class="lineno">  844</span>&#160;        assert(filters &gt; 0);</div><div class="line"><a name="l00845"></a><span class="lineno">  845</span>&#160;        assert(receptor_height &gt; 0);</div><div class="line"><a name="l00846"></a><span class="lineno">  846</span>&#160;        assert(receptor_width &gt; 0);</div><div class="line"><a name="l00847"></a><span class="lineno">  847</span>&#160;        assert(vertical_stride &gt; 0 &amp;&amp; horizontal_stride &gt; 0);</div><div class="line"><a name="l00848"></a><span class="lineno">  848</span>&#160;        assert(in_batch_dims[1] + 2 * vertical_padding &gt;= dil_receptor_height &amp;&amp;</div><div class="line"><a name="l00849"></a><span class="lineno">  849</span>&#160;                in_batch_dims[2] + 2 * horizontal_padding &gt;= dil_receptor_width);</div><div class="line"><a name="l00850"></a><span class="lineno">  850</span>&#160;    }</div><div class="line"><a name="l00851"></a><span class="lineno">  851</span>&#160;    <span class="keyword">inline</span> ConvKernelLayerBase(ConvKernelLayerBase&lt;Scalar,Rank&gt;&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l00852"></a><span class="lineno">  852</span>&#160;            Base::KernelLayer(layer, share_params),</div><div class="line"><a name="l00853"></a><span class="lineno">  853</span>&#160;            filters(layer.filters),</div><div class="line"><a name="l00854"></a><span class="lineno">  854</span>&#160;            receptor_height(layer.receptor_height),</div><div class="line"><a name="l00855"></a><span class="lineno">  855</span>&#160;            receptor_width(layer.receptor_width),</div><div class="line"><a name="l00856"></a><span class="lineno">  856</span>&#160;            vertical_padding(layer.vertical_padding),</div><div class="line"><a name="l00857"></a><span class="lineno">  857</span>&#160;            horizontal_padding(layer.horizontal_padding),</div><div class="line"><a name="l00858"></a><span class="lineno">  858</span>&#160;            vertical_stride(layer.vertical_stride),</div><div class="line"><a name="l00859"></a><span class="lineno">  859</span>&#160;            horizontal_stride(layer.horizontal_stride),</div><div class="line"><a name="l00860"></a><span class="lineno">  860</span>&#160;            vertical_dilation(layer.vertical_dilation),</div><div class="line"><a name="l00861"></a><span class="lineno">  861</span>&#160;            horizontal_dilation(layer.horizontal_dilation),</div><div class="line"><a name="l00862"></a><span class="lineno">  862</span>&#160;            in_batch_dims(layer.in_batch_dims),</div><div class="line"><a name="l00863"></a><span class="lineno">  863</span>&#160;            out_batch_dims(layer.out_batch_dims) { }</div><div class="line"><a name="l00864"></a><span class="lineno">  864</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html#afd721c979e18de71d6b2a7dd6a3d5030">empty_cache</a>() {</div><div class="line"><a name="l00865"></a><span class="lineno">  865</span>&#160;        input = Tensor&lt;Scalar,4&gt;();</div><div class="line"><a name="l00866"></a><span class="lineno">  866</span>&#160;    }</div><div class="line"><a name="l00867"></a><span class="lineno">  867</span>&#160;    <span class="keyword">inline</span> Tensor&lt;Scalar,4&gt; _pass_forward(Tensor&lt;Scalar,4&gt; in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l00868"></a><span class="lineno">  868</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l00869"></a><span class="lineno">  869</span>&#160;        in_batch_dims[0] = rows;</div><div class="line"><a name="l00870"></a><span class="lineno">  870</span>&#160;        out_batch_dims[0] = rows;</div><div class="line"><a name="l00871"></a><span class="lineno">  871</span>&#160;        input = std::move(in);</div><div class="line"><a name="l00872"></a><span class="lineno">  872</span>&#160;        Matrix&lt;Scalar&gt; filter = Base::weights_ref.topRows(Base::weights_ref.rows() - 1);</div><div class="line"><a name="l00873"></a><span class="lineno">  873</span>&#160;        Matrix&lt;Scalar&gt; bias = Base::weights_ref.bottomRows(1);</div><div class="line"><a name="l00874"></a><span class="lineno">  874</span>&#160;        Tensor&lt;Scalar,4&gt; out(out_batch_dims);</div><div class="line"><a name="l00875"></a><span class="lineno">  875</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a11d9ff0d2bf96e04b13e142fd57fb99e">convolution2d_fwd</a>(input.data(), filter.data(), bias.data(),</div><div class="line"><a name="l00876"></a><span class="lineno">  876</span>&#160;                in_batch_dims, out_batch_dims, receptor_height, receptor_width, vertical_padding, horizontal_padding,</div><div class="line"><a name="l00877"></a><span class="lineno">  877</span>&#160;                vertical_stride, horizontal_stride, vertical_dilation + 1, horizontal_dilation + 1, out.data());</div><div class="line"><a name="l00878"></a><span class="lineno">  878</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l00879"></a><span class="lineno">  879</span>&#160;    }</div><div class="line"><a name="l00880"></a><span class="lineno">  880</span>&#160;    <span class="keyword">inline</span> Tensor&lt;Scalar,4&gt; _pass_back(Tensor&lt;Scalar,4&gt; out_grad) {</div><div class="line"><a name="l00881"></a><span class="lineno">  881</span>&#160;        Tensor&lt;Scalar,4&gt; prev_out_grad(in_batch_dims);</div><div class="line"><a name="l00882"></a><span class="lineno">  882</span>&#160;        Matrix&lt;Scalar&gt; filter = Base::weights_ref.topRows(Base::weights_ref.rows() - 1);</div><div class="line"><a name="l00883"></a><span class="lineno">  883</span>&#160;        Matrix&lt;Scalar&gt; bias = Base::weights_ref.bottomRows(1);</div><div class="line"><a name="l00884"></a><span class="lineno">  884</span>&#160;        Matrix&lt;Scalar&gt; filter_grad(filter.rows(), filter.cols());</div><div class="line"><a name="l00885"></a><span class="lineno">  885</span>&#160;        Matrix&lt;Scalar&gt; bias_grad(bias.rows(), bias.cols());</div><div class="line"><a name="l00886"></a><span class="lineno">  886</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a39f10a0e8df9b93dd041d23100d49c57">convolution2d_bwd</a>(input.data(), out_grad.data(), filter.data(),</div><div class="line"><a name="l00887"></a><span class="lineno">  887</span>&#160;                bias.data(), in_batch_dims, out_batch_dims, receptor_height, receptor_width, vertical_padding,</div><div class="line"><a name="l00888"></a><span class="lineno">  888</span>&#160;                horizontal_padding, vertical_stride, horizontal_stride, vertical_dilation + 1, horizontal_dilation + 1,</div><div class="line"><a name="l00889"></a><span class="lineno">  889</span>&#160;                prev_out_grad.data(), filter_grad.data(), bias_grad.data());</div><div class="line"><a name="l00890"></a><span class="lineno">  890</span>&#160;        Base::weights_grad.topRows(filter_grad.rows()) = filter_grad;</div><div class="line"><a name="l00891"></a><span class="lineno">  891</span>&#160;        Base::weights_grad.bottomRows(bias_grad.rows()) = bias_grad;</div><div class="line"><a name="l00892"></a><span class="lineno">  892</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l00893"></a><span class="lineno">  893</span>&#160;    }</div><div class="line"><a name="l00894"></a><span class="lineno">  894</span>&#160;    <span class="keyword">const</span> std::size_t filters;</div><div class="line"><a name="l00895"></a><span class="lineno">  895</span>&#160;    <span class="keyword">const</span> std::size_t receptor_height;</div><div class="line"><a name="l00896"></a><span class="lineno">  896</span>&#160;    <span class="keyword">const</span> std::size_t receptor_width;</div><div class="line"><a name="l00897"></a><span class="lineno">  897</span>&#160;    <span class="keyword">const</span> std::size_t vertical_padding;</div><div class="line"><a name="l00898"></a><span class="lineno">  898</span>&#160;    <span class="keyword">const</span> std::size_t horizontal_padding;</div><div class="line"><a name="l00899"></a><span class="lineno">  899</span>&#160;    <span class="keyword">const</span> std::size_t vertical_stride;</div><div class="line"><a name="l00900"></a><span class="lineno">  900</span>&#160;    <span class="keyword">const</span> std::size_t horizontal_stride;</div><div class="line"><a name="l00901"></a><span class="lineno">  901</span>&#160;    <span class="keyword">const</span> std::size_t vertical_dilation;</div><div class="line"><a name="l00902"></a><span class="lineno">  902</span>&#160;    <span class="keyword">const</span> std::size_t horizontal_dilation;</div><div class="line"><a name="l00903"></a><span class="lineno">  903</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00904"></a><span class="lineno">  904</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> Array4 calculate_output_dims(<span class="keyword">const</span> Array4&amp; input_dims, std::size_t filters, std::size_t receptor_height,</div><div class="line"><a name="l00905"></a><span class="lineno">  905</span>&#160;            std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride,</div><div class="line"><a name="l00906"></a><span class="lineno">  906</span>&#160;            std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation) {</div><div class="line"><a name="l00907"></a><span class="lineno">  907</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#acd5781e6e3acdcb1a6d888cddf616843">conv2d_output_dims</a>(input_dims, filters, receptor_height,</div><div class="line"><a name="l00908"></a><span class="lineno">  908</span>&#160;                receptor_width, vertical_padding, horizontal_padding, vertical_stride, horizontal_stride, vertical_dilation + 1,</div><div class="line"><a name="l00909"></a><span class="lineno">  909</span>&#160;                horizontal_dilation + 1);</div><div class="line"><a name="l00910"></a><span class="lineno">  910</span>&#160;    }</div><div class="line"><a name="l00911"></a><span class="lineno">  911</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> Dimensions&lt;std::size_t,Rank&gt; calculate_adjusted_output_dims(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; input_dims,</div><div class="line"><a name="l00912"></a><span class="lineno">  912</span>&#160;            std::size_t filters, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding,</div><div class="line"><a name="l00913"></a><span class="lineno">  913</span>&#160;            std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride,</div><div class="line"><a name="l00914"></a><span class="lineno">  914</span>&#160;            std::size_t vertical_dilation, std::size_t horizontal_dilation) {</div><div class="line"><a name="l00915"></a><span class="lineno">  915</span>&#160;        <span class="keyword">auto</span> output_dims = calculate_output_dims(input_dims.template extend&lt;3 - Rank&gt;().template promote&lt;&gt;(), filters,</div><div class="line"><a name="l00916"></a><span class="lineno">  916</span>&#160;                receptor_height, receptor_width, vertical_padding, horizontal_padding, vertical_stride, horizontal_stride,</div><div class="line"><a name="l00917"></a><span class="lineno">  917</span>&#160;                vertical_dilation, horizontal_dilation);</div><div class="line"><a name="l00918"></a><span class="lineno">  918</span>&#160;        output_dims[3] /= filters;</div><div class="line"><a name="l00919"></a><span class="lineno">  919</span>&#160;        output_dims[Rank] *= filters;</div><div class="line"><a name="l00920"></a><span class="lineno">  920</span>&#160;        <span class="keywordflow">return</span> Dimensions&lt;std::size_t,4&gt;(output_dims).<span class="keyword">template</span> demote&lt;&gt;().template contract&lt;3 - Rank&gt;();</div><div class="line"><a name="l00921"></a><span class="lineno">  921</span>&#160;    }</div><div class="line"><a name="l00922"></a><span class="lineno">  922</span>&#160;    Array4 in_batch_dims;</div><div class="line"><a name="l00923"></a><span class="lineno">  923</span>&#160;    Array4 out_batch_dims;</div><div class="line"><a name="l00924"></a><span class="lineno">  924</span>&#160;    Tensor&lt;Scalar,4&gt; input;</div><div class="line"><a name="l00925"></a><span class="lineno">  925</span>&#160;};</div><div class="line"><a name="l00926"></a><span class="lineno">  926</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00927"></a><span class="lineno">  927</span>&#160;</div><div class="line"><a name="l00933"></a><span class="lineno">  933</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank = 3&gt;</div><div class="line"><a name="l00934"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer.html">  934</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_conv_kernel_layer.html">ConvKernelLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l00935"></a><span class="lineno">  935</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l00936"></a><span class="lineno">  936</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelBase</a>;</div><div class="line"><a name="l00937"></a><span class="lineno">  937</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvBase</a>;</div><div class="line"><a name="l00938"></a><span class="lineno">  938</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00961"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">  961</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">ConvKernelLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>&amp; input_dims, std::size_t filters, <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr&lt;Scalar&gt;</a> weight_init,</div><div class="line"><a name="l00962"></a><span class="lineno">  962</span>&#160;            <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> weight_reg = Root::NO_PARAM_REG, std::size_t receptor_height = 3, std::size_t receptor_width = 3,</div><div class="line"><a name="l00963"></a><span class="lineno">  963</span>&#160;            std::size_t vertical_padding = 1, std::size_t horizontal_padding = 1, std::size_t vertical_stride = 1,</div><div class="line"><a name="l00964"></a><span class="lineno">  964</span>&#160;            std::size_t horizontal_stride = 1, std::size_t vertical_dilation = 0, std::size_t horizontal_dilation = 0,</div><div class="line"><a name="l00965"></a><span class="lineno">  965</span>&#160;            Scalar max_norm_constraint = 0) :</div><div class="line"><a name="l00966"></a><span class="lineno">  966</span>&#160;                <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvBase</a>::<a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a>(input_dims, filters, weight_init, weight_reg, receptor_height, receptor_width,</div><div class="line"><a name="l00967"></a><span class="lineno">  967</span>&#160;                        vertical_padding, horizontal_padding, vertical_stride, horizontal_stride, vertical_dilation, horizontal_dilation,</div><div class="line"><a name="l00968"></a><span class="lineno">  968</span>&#160;                        max_norm_constraint) { }</div><div class="line"><a name="l00969"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer.html#a205e894a1bd2a0c8c0a210813c232c21">  969</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_conv_kernel_layer.html#a205e894a1bd2a0c8c0a210813c232c21">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00970"></a><span class="lineno">  970</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">ConvKernelLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l00971"></a><span class="lineno">  971</span>&#160;    }</div><div class="line"><a name="l00972"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer.html#a12ec3c5520108283dabf16f90dc9c850">  972</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_conv_kernel_layer.html#a12ec3c5520108283dabf16f90dc9c850">clone_with_shared_params</a>() {</div><div class="line"><a name="l00973"></a><span class="lineno">  973</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">ConvKernelLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l00974"></a><span class="lineno">  974</span>&#160;    }</div><div class="line"><a name="l00975"></a><span class="lineno">  975</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l00976"></a><span class="lineno">  976</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">ConvKernelLayer</a>(<a class="code" href="classcattle_1_1_conv_kernel_layer.html">ConvKernelLayer&lt;Scalar,Rank&gt;</a>&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l00977"></a><span class="lineno">  977</span>&#160;            ConvBase::<a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a>(layer, share_params),</div><div class="line"><a name="l00978"></a><span class="lineno">  978</span>&#160;            batch_size(layer.batch_size) { }</div><div class="line"><a name="l00979"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer.html#abb6ecb02b8f801f151e345a2735efd2a">  979</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_conv_kernel_layer.html#abb6ecb02b8f801f151e345a2735efd2a">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l00980"></a><span class="lineno">  980</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,4&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::input_dims);</div><div class="line"><a name="l00981"></a><span class="lineno">  981</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l00982"></a><span class="lineno">  982</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l00983"></a><span class="lineno">  983</span>&#160;        <span class="keywordflow">return</span> ConvBase::_pass_forward(std::move(in), training);</div><div class="line"><a name="l00984"></a><span class="lineno">  984</span>&#160;    }</div><div class="line"><a name="l00985"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer.html#af1423e99f6cbf2fe5ea5780aa46945a2">  985</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_conv_kernel_layer.html#af1423e99f6cbf2fe5ea5780aa46945a2">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l00986"></a><span class="lineno">  986</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,4&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::output_dims);</div><div class="line"><a name="l00987"></a><span class="lineno">  987</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l00988"></a><span class="lineno">  988</span>&#160;        <span class="keywordflow">return</span> ConvBase::_pass_back(std::move(out_grad));</div><div class="line"><a name="l00989"></a><span class="lineno">  989</span>&#160;    }</div><div class="line"><a name="l00990"></a><span class="lineno">  990</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00991"></a><span class="lineno">  991</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l00992"></a><span class="lineno">  992</span>&#160;};</div><div class="line"><a name="l00993"></a><span class="lineno">  993</span>&#160;</div><div class="line"><a name="l00999"></a><span class="lineno">  999</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l01000"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html"> 1000</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_conv_kernel_layer.html">ConvKernelLayer</a>&lt;Scalar,2&gt; : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a>&lt;Scalar,2&gt; {</div><div class="line"><a name="l01001"></a><span class="lineno"> 1001</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l01002"></a><span class="lineno"> 1002</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelBase</a>;</div><div class="line"><a name="l01003"></a><span class="lineno"> 1003</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvBase</a>;</div><div class="line"><a name="l01004"></a><span class="lineno"> 1004</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01027"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a062ba6c4dafdaf89f81fbfbdeeb42a39"> 1027</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a062ba6c4dafdaf89f81fbfbdeeb42a39">ConvKernelLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>&amp; input_dims, std::size_t filters, <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr&lt;Scalar&gt;</a> weight_init,</div><div class="line"><a name="l01028"></a><span class="lineno"> 1028</span>&#160;            <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> weight_reg = Root::NO_PARAM_REG, std::size_t receptor_height = 3, std::size_t receptor_width = 3,</div><div class="line"><a name="l01029"></a><span class="lineno"> 1029</span>&#160;            std::size_t vertical_padding = 1, std::size_t horizontal_padding = 1, std::size_t vertical_stride = 1,</div><div class="line"><a name="l01030"></a><span class="lineno"> 1030</span>&#160;            std::size_t horizontal_stride = 1, std::size_t vertical_dilation = 0, std::size_t horizontal_dilation = 0,</div><div class="line"><a name="l01031"></a><span class="lineno"> 1031</span>&#160;            Scalar max_norm_constraint = 0) :</div><div class="line"><a name="l01032"></a><span class="lineno"> 1032</span>&#160;                <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvBase</a>::<a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a>(input_dims, filters, weight_init, weight_reg, receptor_height, receptor_width,</div><div class="line"><a name="l01033"></a><span class="lineno"> 1033</span>&#160;                        vertical_padding, horizontal_padding, vertical_stride, horizontal_stride, vertical_dilation, horizontal_dilation,</div><div class="line"><a name="l01034"></a><span class="lineno"> 1034</span>&#160;                        max_norm_constraint) { }</div><div class="line"><a name="l01035"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a5bc6b37c61ab96080ff9615915871212"> 1035</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a5bc6b37c61ab96080ff9615915871212">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01036"></a><span class="lineno"> 1036</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">ConvKernelLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01037"></a><span class="lineno"> 1037</span>&#160;    }</div><div class="line"><a name="l01038"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#aae11392cc9350c8ac87a0fe0db278a19"> 1038</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#aae11392cc9350c8ac87a0fe0db278a19">clone_with_shared_params</a>() {</div><div class="line"><a name="l01039"></a><span class="lineno"> 1039</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">ConvKernelLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l01040"></a><span class="lineno"> 1040</span>&#160;    }</div><div class="line"><a name="l01041"></a><span class="lineno"> 1041</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01042"></a><span class="lineno"> 1042</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">ConvKernelLayer</a>(<a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html">ConvKernelLayer&lt;Scalar,2&gt;</a>&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l01043"></a><span class="lineno"> 1043</span>&#160;            ConvBase::<a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a>(layer, share_params),</div><div class="line"><a name="l01044"></a><span class="lineno"> 1044</span>&#160;            batch_size(layer.batch_size) { }</div><div class="line"><a name="l01045"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#ac391887510fae8472b7ea92b7f4d6114"> 1045</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#ac391887510fae8472b7ea92b7f4d6114">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01046"></a><span class="lineno"> 1046</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::input_dims);</div><div class="line"><a name="l01047"></a><span class="lineno"> 1047</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01048"></a><span class="lineno"> 1048</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l01049"></a><span class="lineno"> 1049</span>&#160;        <span class="keywordflow">return</span> ConvBase::_pass_forward(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(in.data(), { batch_size, in.dimension(1), in.dimension(2), 1u }), training)</div><div class="line"><a name="l01050"></a><span class="lineno"> 1050</span>&#160;                .reshape(std::array&lt;std::size_t,3&gt;({ batch_size, KernelBase::output_dims(0), KernelBase::output_dims(1) }));</div><div class="line"><a name="l01051"></a><span class="lineno"> 1051</span>&#160;    }</div><div class="line"><a name="l01052"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a2379f9e643bf7e47a33f4e0a5e7bc2c1"> 1052</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a2379f9e643bf7e47a33f4e0a5e7bc2c1">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01053"></a><span class="lineno"> 1053</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::output_dims);</div><div class="line"><a name="l01054"></a><span class="lineno"> 1054</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l01055"></a><span class="lineno"> 1055</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> prev_out_grad = ConvBase::_pass_back(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(out_grad.data(),</div><div class="line"><a name="l01056"></a><span class="lineno"> 1056</span>&#160;                { batch_size, KernelBase::output_dims(0), KernelBase::output_dims(1) / ConvBase::filters, ConvBase::filters }));</div><div class="line"><a name="l01057"></a><span class="lineno"> 1057</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">KernelBase::is_input_layer</a>())</div><div class="line"><a name="l01058"></a><span class="lineno"> 1058</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,3&gt;</a>();</div><div class="line"><a name="l01059"></a><span class="lineno"> 1059</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,3&gt;</a>(prev_out_grad.data(), { batch_size, KernelBase::input_dims(0), KernelBase::input_dims(1) });</div><div class="line"><a name="l01060"></a><span class="lineno"> 1060</span>&#160;    }</div><div class="line"><a name="l01061"></a><span class="lineno"> 1061</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01062"></a><span class="lineno"> 1062</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l01063"></a><span class="lineno"> 1063</span>&#160;};</div><div class="line"><a name="l01064"></a><span class="lineno"> 1064</span>&#160;</div><div class="line"><a name="l01065"></a><span class="lineno"> 1065</span>&#160;</div><div class="line"><a name="l01071"></a><span class="lineno"> 1071</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l01072"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html"> 1072</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_conv_kernel_layer.html">ConvKernelLayer</a>&lt;Scalar,1&gt; : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a>&lt;Scalar,1&gt; {</div><div class="line"><a name="l01073"></a><span class="lineno"> 1073</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l01074"></a><span class="lineno"> 1074</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelBase</a>;</div><div class="line"><a name="l01075"></a><span class="lineno"> 1075</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvBase</a>;</div><div class="line"><a name="l01076"></a><span class="lineno"> 1076</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01092"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aabc6223fac8bd0c8bd8a3093fd3e333c"> 1092</a></span>&#160;    <a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aabc6223fac8bd0c8bd8a3093fd3e333c">ConvKernelLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,1&gt;</a>&amp; input_dims, std::size_t filters, <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr&lt;Scalar&gt;</a> weight_init,</div><div class="line"><a name="l01093"></a><span class="lineno"> 1093</span>&#160;            <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> weight_reg = Root::NO_PARAM_REG, std::size_t receptor_length = 3, std::size_t padding = 1,</div><div class="line"><a name="l01094"></a><span class="lineno"> 1094</span>&#160;            std::size_t stride = 1, std::size_t dilation = 0, Scalar max_norm_constraint = 0) :</div><div class="line"><a name="l01095"></a><span class="lineno"> 1095</span>&#160;                <a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvBase</a>::<a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a>(input_dims, filters, weight_init, weight_reg, receptor_length, 1, padding, 0,</div><div class="line"><a name="l01096"></a><span class="lineno"> 1096</span>&#160;                        stride, 1, dilation, 0, max_norm_constraint) { }</div><div class="line"><a name="l01097"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aeaa3fa2d91460475a2e9b970deed5ad2"> 1097</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aeaa3fa2d91460475a2e9b970deed5ad2">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01098"></a><span class="lineno"> 1098</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">ConvKernelLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01099"></a><span class="lineno"> 1099</span>&#160;    }</div><div class="line"><a name="l01100"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a9dcaad150e53f16071543ad8d19079a1"> 1100</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a9dcaad150e53f16071543ad8d19079a1">clone_with_shared_params</a>() {</div><div class="line"><a name="l01101"></a><span class="lineno"> 1101</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">ConvKernelLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l01102"></a><span class="lineno"> 1102</span>&#160;    }</div><div class="line"><a name="l01103"></a><span class="lineno"> 1103</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01104"></a><span class="lineno"> 1104</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">ConvKernelLayer</a>(<a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html">ConvKernelLayer&lt;Scalar,1&gt;</a>&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l01105"></a><span class="lineno"> 1105</span>&#160;            ConvBase::<a class="code" href="classcattle_1_1_conv_kernel_layer_base.html">ConvKernelLayerBase</a>(layer, share_params),</div><div class="line"><a name="l01106"></a><span class="lineno"> 1106</span>&#160;            batch_size(layer.batch_size) { }</div><div class="line"><a name="l01107"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aaf1ed54777882941a705fdd94595fc5c"> 1107</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aaf1ed54777882941a705fdd94595fc5c">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01108"></a><span class="lineno"> 1108</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::input_dims);</div><div class="line"><a name="l01109"></a><span class="lineno"> 1109</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01110"></a><span class="lineno"> 1110</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l01111"></a><span class="lineno"> 1111</span>&#160;        <span class="keywordflow">return</span> ConvBase::_pass_forward(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(in.data(), { batch_size, in.dimension(1), 1u, 1u }), training)</div><div class="line"><a name="l01112"></a><span class="lineno"> 1112</span>&#160;                .reshape(std::array&lt;std::size_t,2&gt;({ batch_size, KernelBase::output_dims(0) }));</div><div class="line"><a name="l01113"></a><span class="lineno"> 1113</span>&#160;    }</div><div class="line"><a name="l01114"></a><span class="lineno"><a class="line" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a93619900866409b99543510a099855b3"> 1114</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a93619900866409b99543510a099855b3">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01115"></a><span class="lineno"> 1115</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::output_dims);</div><div class="line"><a name="l01116"></a><span class="lineno"> 1116</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l01117"></a><span class="lineno"> 1117</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> prev_out_grad = ConvBase::_pass_back(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(out_grad.data(),</div><div class="line"><a name="l01118"></a><span class="lineno"> 1118</span>&#160;                { batch_size, KernelBase::output_dims(0) / ConvBase::filters, 1, ConvBase::filters }));</div><div class="line"><a name="l01119"></a><span class="lineno"> 1119</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">KernelBase::is_input_layer</a>())</div><div class="line"><a name="l01120"></a><span class="lineno"> 1120</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,2&gt;</a>();</div><div class="line"><a name="l01121"></a><span class="lineno"> 1121</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,2&gt;</a>(prev_out_grad.data(), { batch_size, KernelBase::input_dims(0) });</div><div class="line"><a name="l01122"></a><span class="lineno"> 1122</span>&#160;    }</div><div class="line"><a name="l01123"></a><span class="lineno"> 1123</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01124"></a><span class="lineno"> 1124</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l01125"></a><span class="lineno"> 1125</span>&#160;};</div><div class="line"><a name="l01126"></a><span class="lineno"> 1126</span>&#160;</div><div class="line"><a name="l01130"></a><span class="lineno"> 1130</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l01131"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_base.html"> 1131</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l01132"></a><span class="lineno"> 1132</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l01133"></a><span class="lineno"> 1133</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l01134"></a><span class="lineno"> 1134</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,4&gt; Array4;</div><div class="line"><a name="l01135"></a><span class="lineno"> 1135</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::pair&lt;std::size_t,std::size_t&gt;,4&gt; PaddingsArray4;</div><div class="line"><a name="l01136"></a><span class="lineno"> 1136</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01137"></a><span class="lineno"> 1137</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; input_dims, std::size_t filters,</div><div class="line"><a name="l01138"></a><span class="lineno"> 1138</span>&#160;            <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr&lt;Scalar&gt;</a> weight_init, <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> weight_reg, std::size_t receptor_height,</div><div class="line"><a name="l01139"></a><span class="lineno"> 1139</span>&#160;            std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride,</div><div class="line"><a name="l01140"></a><span class="lineno"> 1140</span>&#160;            std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation,</div><div class="line"><a name="l01141"></a><span class="lineno"> 1141</span>&#160;            Scalar max_norm_constraint) :</div><div class="line"><a name="l01142"></a><span class="lineno"> 1142</span>&#160;                Base::KernelLayer(input_dims, calculate_adjusted_output_dims(input_dims, filters,</div><div class="line"><a name="l01143"></a><span class="lineno"> 1143</span>&#160;                        receptor_height, receptor_width, vertical_padding, horizontal_padding,</div><div class="line"><a name="l01144"></a><span class="lineno"> 1144</span>&#160;                        vertical_stride, horizontal_stride, vertical_dilation, horizontal_dilation),</div><div class="line"><a name="l01145"></a><span class="lineno"> 1145</span>&#160;                        weight_init, weight_reg,</div><div class="line"><a name="l01146"></a><span class="lineno"> 1146</span>&#160;                        input_dims.template extend&lt;3 - Rank&gt;()(2) + 1, receptor_height * receptor_width * filters,</div><div class="line"><a name="l01147"></a><span class="lineno"> 1147</span>&#160;                        max_norm_constraint),</div><div class="line"><a name="l01148"></a><span class="lineno"> 1148</span>&#160;                filters(filters),</div><div class="line"><a name="l01149"></a><span class="lineno"> 1149</span>&#160;                receptor_height(receptor_height),</div><div class="line"><a name="l01150"></a><span class="lineno"> 1150</span>&#160;                receptor_width(receptor_width),</div><div class="line"><a name="l01151"></a><span class="lineno"> 1151</span>&#160;                vertical_padding(vertical_padding),</div><div class="line"><a name="l01152"></a><span class="lineno"> 1152</span>&#160;                horizontal_padding(horizontal_padding),</div><div class="line"><a name="l01153"></a><span class="lineno"> 1153</span>&#160;                vertical_stride(vertical_stride),</div><div class="line"><a name="l01154"></a><span class="lineno"> 1154</span>&#160;                horizontal_stride(horizontal_stride),</div><div class="line"><a name="l01155"></a><span class="lineno"> 1155</span>&#160;                vertical_dilation(vertical_dilation),</div><div class="line"><a name="l01156"></a><span class="lineno"> 1156</span>&#160;                horizontal_dilation(horizontal_dilation),</div><div class="line"><a name="l01157"></a><span class="lineno"> 1157</span>&#160;                ext_input_dims(input_dims.template extend&lt;3 - Rank&gt;()),</div><div class="line"><a name="l01158"></a><span class="lineno"> 1158</span>&#160;                ext_output_dims(calculate_output_dims(ext_input_dims, filters, receptor_height, receptor_width,</div><div class="line"><a name="l01159"></a><span class="lineno"> 1159</span>&#160;                        vertical_padding, horizontal_padding, vertical_stride, horizontal_stride,</div><div class="line"><a name="l01160"></a><span class="lineno"> 1160</span>&#160;                        vertical_dilation, horizontal_dilation)),</div><div class="line"><a name="l01161"></a><span class="lineno"> 1161</span>&#160;                padded_height(ext_output_dims(0) + 2 * vertical_padding),</div><div class="line"><a name="l01162"></a><span class="lineno"> 1162</span>&#160;                padded_width(ext_output_dims(1) + 2 * horizontal_padding),</div><div class="line"><a name="l01163"></a><span class="lineno"> 1163</span>&#160;                dil_receptor_height(receptor_height + (receptor_height - 1) * vertical_dilation),</div><div class="line"><a name="l01164"></a><span class="lineno"> 1164</span>&#160;                dil_receptor_width(receptor_width + (receptor_width - 1) * horizontal_dilation),</div><div class="line"><a name="l01165"></a><span class="lineno"> 1165</span>&#160;                patches_per_sample(ext_input_dims(0) * ext_input_dims(1)),</div><div class="line"><a name="l01166"></a><span class="lineno"> 1166</span>&#160;                prev_out_conversion_dims({ 0u, ext_input_dims(0), ext_input_dims(1), ext_input_dims(2) }),</div><div class="line"><a name="l01167"></a><span class="lineno"> 1167</span>&#160;                patch_offsets({ 0u, 0u, 0u, 0u }),</div><div class="line"><a name="l01168"></a><span class="lineno"> 1168</span>&#160;                patch_extents({ 0u, dil_receptor_height, dil_receptor_width, filters }),</div><div class="line"><a name="l01169"></a><span class="lineno"> 1169</span>&#160;                dil_strides({ 1u, vertical_dilation + 1u, horizontal_dilation + 1u, 1u }),</div><div class="line"><a name="l01170"></a><span class="lineno"> 1170</span>&#160;                no_padding_offsets({ 0u, vertical_padding, horizontal_padding, 0u }),</div><div class="line"><a name="l01171"></a><span class="lineno"> 1171</span>&#160;                no_padding_extents({ 0u, ext_output_dims(0), ext_output_dims(1), ext_output_dims(2) }),</div><div class="line"><a name="l01172"></a><span class="lineno"> 1172</span>&#160;                paddings({ std::make_pair(0, 0), std::make_pair(vertical_padding, vertical_padding),</div><div class="line"><a name="l01173"></a><span class="lineno"> 1173</span>&#160;                        std::make_pair(horizontal_padding, horizontal_padding), std::make_pair(0, 0) }) {</div><div class="line"><a name="l01174"></a><span class="lineno"> 1174</span>&#160;        assert(filters &gt; 0);</div><div class="line"><a name="l01175"></a><span class="lineno"> 1175</span>&#160;        assert(receptor_height &gt; 0);</div><div class="line"><a name="l01176"></a><span class="lineno"> 1176</span>&#160;        assert(receptor_width &gt; 0);</div><div class="line"><a name="l01177"></a><span class="lineno"> 1177</span>&#160;        assert(vertical_stride &gt; 0 &amp;&amp; horizontal_stride &gt; 0);</div><div class="line"><a name="l01178"></a><span class="lineno"> 1178</span>&#160;        assert(ext_output_dims(0) + 2 * vertical_padding &gt;= dil_receptor_height &amp;&amp;</div><div class="line"><a name="l01179"></a><span class="lineno"> 1179</span>&#160;                ext_output_dims(1) + 2 * horizontal_padding &gt;= dil_receptor_width);</div><div class="line"><a name="l01180"></a><span class="lineno"> 1180</span>&#160;    }</div><div class="line"><a name="l01181"></a><span class="lineno"> 1181</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01182"></a><span class="lineno"> 1182</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a>(<a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase&lt;Scalar,Rank&gt;</a>&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l01183"></a><span class="lineno"> 1183</span>&#160;            Base::KernelLayer(layer, share_params),</div><div class="line"><a name="l01184"></a><span class="lineno"> 1184</span>&#160;            filters(layer.filters),</div><div class="line"><a name="l01185"></a><span class="lineno"> 1185</span>&#160;            receptor_height(layer.receptor_height),</div><div class="line"><a name="l01186"></a><span class="lineno"> 1186</span>&#160;            receptor_width(layer.receptor_width),</div><div class="line"><a name="l01187"></a><span class="lineno"> 1187</span>&#160;            vertical_padding(layer.vertical_padding),</div><div class="line"><a name="l01188"></a><span class="lineno"> 1188</span>&#160;            horizontal_padding(layer.horizontal_padding),</div><div class="line"><a name="l01189"></a><span class="lineno"> 1189</span>&#160;            vertical_stride(layer.vertical_stride),</div><div class="line"><a name="l01190"></a><span class="lineno"> 1190</span>&#160;            horizontal_stride(layer.horizontal_stride),</div><div class="line"><a name="l01191"></a><span class="lineno"> 1191</span>&#160;            vertical_dilation(layer.vertical_dilation),</div><div class="line"><a name="l01192"></a><span class="lineno"> 1192</span>&#160;            horizontal_dilation(layer.horizontal_dilation),</div><div class="line"><a name="l01193"></a><span class="lineno"> 1193</span>&#160;            padded_height(layer.padded_height),</div><div class="line"><a name="l01194"></a><span class="lineno"> 1194</span>&#160;            padded_width(layer.padded_width),</div><div class="line"><a name="l01195"></a><span class="lineno"> 1195</span>&#160;            dil_receptor_height(layer.dil_receptor_height),</div><div class="line"><a name="l01196"></a><span class="lineno"> 1196</span>&#160;            dil_receptor_width(layer.dil_receptor_width),</div><div class="line"><a name="l01197"></a><span class="lineno"> 1197</span>&#160;            patches_per_sample(layer.patches_per_sample),</div><div class="line"><a name="l01198"></a><span class="lineno"> 1198</span>&#160;            prev_out_conversion_dims(layer.prev_out_conversion_dims),</div><div class="line"><a name="l01199"></a><span class="lineno"> 1199</span>&#160;            patch_offsets(layer.patch_offsets),</div><div class="line"><a name="l01200"></a><span class="lineno"> 1200</span>&#160;            patch_extents(layer.patch_extents),</div><div class="line"><a name="l01201"></a><span class="lineno"> 1201</span>&#160;            dil_strides(layer.dil_strides),</div><div class="line"><a name="l01202"></a><span class="lineno"> 1202</span>&#160;            no_padding_offsets(layer.no_padding_offsets),</div><div class="line"><a name="l01203"></a><span class="lineno"> 1203</span>&#160;            no_padding_extents(layer.no_padding_extents),</div><div class="line"><a name="l01204"></a><span class="lineno"> 1204</span>&#160;            paddings(layer.paddings),</div><div class="line"><a name="l01205"></a><span class="lineno"> 1205</span>&#160;            biased_in_mat(layer.biased_in_mat) { }</div><div class="line"><a name="l01206"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_base.html#a8806cde9facfcb881881758bf5801c2b"> 1206</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html#a8806cde9facfcb881881758bf5801c2b">empty_cache</a>() {</div><div class="line"><a name="l01207"></a><span class="lineno"> 1207</span>&#160;        biased_in_mat = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(0, 0);</div><div class="line"><a name="l01208"></a><span class="lineno"> 1208</span>&#160;    }</div><div class="line"><a name="l01209"></a><span class="lineno"> 1209</span>&#160;<span class="preprocessor">#ifndef CATTL3_USE_CUBLAS</span></div><div class="line"><a name="l01210"></a><span class="lineno"> 1210</span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> _pass_forward(<a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01211"></a><span class="lineno"> 1211</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l01212"></a><span class="lineno"> 1212</span>&#160;        std::size_t depth = ext_input_dims(2);</div><div class="line"><a name="l01213"></a><span class="lineno"> 1213</span>&#160;        std::size_t receptor_vol = Base::weights_ref.cols();</div><div class="line"><a name="l01214"></a><span class="lineno"> 1214</span>&#160;        std::size_t total_patches = rows * patches_per_sample;</div><div class="line"><a name="l01215"></a><span class="lineno"> 1215</span>&#160;        biased_in_mat = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(total_patches, depth + 1);</div><div class="line"><a name="l01216"></a><span class="lineno"> 1216</span>&#160;        biased_in_mat.block(0, 0, total_patches, depth) = <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a>(in.data(), total_patches, depth);</div><div class="line"><a name="l01217"></a><span class="lineno"> 1217</span>&#160;        biased_in_mat.col(depth).setOnes();</div><div class="line"><a name="l01218"></a><span class="lineno"> 1218</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out_conv_mat = biased_in_mat * Base::weights_ref;</div><div class="line"><a name="l01219"></a><span class="lineno"> 1219</span>&#160;        <span class="comment">/* Given the values of the stretched out receptor patches, accumulate them in the output tensor. */</span></div><div class="line"><a name="l01220"></a><span class="lineno"> 1220</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> out(rows, padded_height, padded_width, ext_output_dims(2));</div><div class="line"><a name="l01221"></a><span class="lineno"> 1221</span>&#160;        out.setZero();</div><div class="line"><a name="l01222"></a><span class="lineno"> 1222</span>&#160;        std::size_t patch_ind = 0;</div><div class="line"><a name="l01223"></a><span class="lineno"> 1223</span>&#160;        patch_extents[0] = rows;</div><div class="line"><a name="l01224"></a><span class="lineno"> 1224</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt;= padded_width - dil_receptor_width; i += horizontal_stride) {</div><div class="line"><a name="l01225"></a><span class="lineno"> 1225</span>&#160;            patch_offsets[2] = i;</div><div class="line"><a name="l01226"></a><span class="lineno"> 1226</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt;= padded_height - dil_receptor_height; j += vertical_stride) {</div><div class="line"><a name="l01227"></a><span class="lineno"> 1227</span>&#160;                patch_offsets[1] = j;</div><div class="line"><a name="l01228"></a><span class="lineno"> 1228</span>&#160;                <span class="comment">// Accumulate the gradients where the receptor-patch-tensors overlap.</span></div><div class="line"><a name="l01229"></a><span class="lineno"> 1229</span>&#160;                <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out_conv_mat_block = out_conv_mat.block(patch_ind, 0, rows, receptor_vol);</div><div class="line"><a name="l01230"></a><span class="lineno"> 1230</span>&#160;                <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a> out_patch(out_conv_mat_block.data(), rows, receptor_height,</div><div class="line"><a name="l01231"></a><span class="lineno"> 1231</span>&#160;                        receptor_width, ext_output_dims(2));</div><div class="line"><a name="l01232"></a><span class="lineno"> 1232</span>&#160;                <span class="keywordflow">if</span> (vertical_dilation &gt; 0 || horizontal_dilation &gt; 0)</div><div class="line"><a name="l01233"></a><span class="lineno"> 1233</span>&#160;                    out.slice(patch_offsets, patch_extents).stride(dil_strides) += out_patch;</div><div class="line"><a name="l01234"></a><span class="lineno"> 1234</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l01235"></a><span class="lineno"> 1235</span>&#160;                    out.slice(patch_offsets, patch_extents) += out_patch;</div><div class="line"><a name="l01236"></a><span class="lineno"> 1236</span>&#160;                patch_ind += rows;</div><div class="line"><a name="l01237"></a><span class="lineno"> 1237</span>&#160;            }</div><div class="line"><a name="l01238"></a><span class="lineno"> 1238</span>&#160;        }</div><div class="line"><a name="l01239"></a><span class="lineno"> 1239</span>&#160;        assert(patch_ind == total_patches);</div><div class="line"><a name="l01240"></a><span class="lineno"> 1240</span>&#160;        <span class="keywordflow">if</span> (vertical_padding &gt; 0 || horizontal_padding &gt; 0) {</div><div class="line"><a name="l01241"></a><span class="lineno"> 1241</span>&#160;            <span class="comment">// Cut off the padding.</span></div><div class="line"><a name="l01242"></a><span class="lineno"> 1242</span>&#160;            no_padding_extents[0] = rows;</div><div class="line"><a name="l01243"></a><span class="lineno"> 1243</span>&#160;            <span class="keywordflow">return</span> out.slice(no_padding_offsets, no_padding_extents);</div><div class="line"><a name="l01244"></a><span class="lineno"> 1244</span>&#160;        } <span class="keywordflow">else</span></div><div class="line"><a name="l01245"></a><span class="lineno"> 1245</span>&#160;            <span class="keywordflow">return</span> out;</div><div class="line"><a name="l01246"></a><span class="lineno"> 1246</span>&#160;    }</div><div class="line"><a name="l01247"></a><span class="lineno"> 1247</span>&#160;    <span class="keyword">inline</span> Tensor&lt;Scalar,4&gt; _pass_back(Tensor&lt;Scalar,4&gt; out_grad) {</div><div class="line"><a name="l01248"></a><span class="lineno"> 1248</span>&#160;        <span class="comment">// Spatial padding.</span></div><div class="line"><a name="l01249"></a><span class="lineno"> 1249</span>&#160;        <span class="keywordflow">if</span> (vertical_padding &gt; 0 || horizontal_padding &gt; 0)</div><div class="line"><a name="l01250"></a><span class="lineno"> 1250</span>&#160;            out_grad = Tensor&lt;Scalar,4&gt;(out_grad.pad(paddings));</div><div class="line"><a name="l01251"></a><span class="lineno"> 1251</span>&#160;        std::size_t rows = out_grad.dimension(0);</div><div class="line"><a name="l01252"></a><span class="lineno"> 1252</span>&#160;        std::size_t depth = ext_input_dims(2);</div><div class="line"><a name="l01253"></a><span class="lineno"> 1253</span>&#160;        std::size_t receptor_vol = Base::weights_ref.cols();</div><div class="line"><a name="l01254"></a><span class="lineno"> 1254</span>&#160;        std::size_t total_patches = rows * patches_per_sample;</div><div class="line"><a name="l01255"></a><span class="lineno"> 1255</span>&#160;        std::size_t patch_ind = 0;</div><div class="line"><a name="l01256"></a><span class="lineno"> 1256</span>&#160;        patch_extents[0] = rows;</div><div class="line"><a name="l01257"></a><span class="lineno"> 1257</span>&#160;        Matrix&lt;Scalar&gt; out_grad_conv_mat(total_patches, receptor_vol);</div><div class="line"><a name="l01258"></a><span class="lineno"> 1258</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt;= padded_width - dil_receptor_width; i += horizontal_stride) {</div><div class="line"><a name="l01259"></a><span class="lineno"> 1259</span>&#160;            patch_offsets[2] = i;</div><div class="line"><a name="l01260"></a><span class="lineno"> 1260</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt;= padded_height - dil_receptor_height; j += vertical_stride) {</div><div class="line"><a name="l01261"></a><span class="lineno"> 1261</span>&#160;                patch_offsets[1] = j;</div><div class="line"><a name="l01262"></a><span class="lineno"> 1262</span>&#160;                Tensor&lt;Scalar,4&gt; patch;</div><div class="line"><a name="l01263"></a><span class="lineno"> 1263</span>&#160;                <span class="comment">// If the patch is dilated, skip the spatial gaps when flattening it into a matrix.</span></div><div class="line"><a name="l01264"></a><span class="lineno"> 1264</span>&#160;                <span class="keywordflow">if</span> (vertical_dilation &gt; 0 || horizontal_dilation &gt; 0)</div><div class="line"><a name="l01265"></a><span class="lineno"> 1265</span>&#160;                    patch = out_grad.slice(patch_offsets, patch_extents).stride(dil_strides);</div><div class="line"><a name="l01266"></a><span class="lineno"> 1266</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l01267"></a><span class="lineno"> 1267</span>&#160;                    patch = out_grad.slice(patch_offsets, patch_extents);</div><div class="line"><a name="l01268"></a><span class="lineno"> 1268</span>&#160;                out_grad_conv_mat.block(patch_ind, 0, rows, receptor_vol) = MatrixMap&lt;Scalar&gt;(patch.data(),</div><div class="line"><a name="l01269"></a><span class="lineno"> 1269</span>&#160;                        rows, receptor_vol);</div><div class="line"><a name="l01270"></a><span class="lineno"> 1270</span>&#160;                patch_ind += rows;</div><div class="line"><a name="l01271"></a><span class="lineno"> 1271</span>&#160;            }</div><div class="line"><a name="l01272"></a><span class="lineno"> 1272</span>&#160;        }</div><div class="line"><a name="l01273"></a><span class="lineno"> 1273</span>&#160;        assert(patch_ind == total_patches);</div><div class="line"><a name="l01274"></a><span class="lineno"> 1274</span>&#160;        Base::weights_grad = biased_in_mat.transpose() * out_grad_conv_mat;</div><div class="line"><a name="l01275"></a><span class="lineno"> 1275</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">Base::is_input_layer</a>())</div><div class="line"><a name="l01276"></a><span class="lineno"> 1276</span>&#160;            <span class="keywordflow">return</span> Tensor&lt;Scalar,4&gt;();</div><div class="line"><a name="l01277"></a><span class="lineno"> 1277</span>&#160;        Matrix&lt;Scalar&gt; prev_out_grad = out_grad_conv_mat * Base::weights_ref.topRows(depth).transpose();</div><div class="line"><a name="l01278"></a><span class="lineno"> 1278</span>&#160;        prev_out_conversion_dims[0] = rows;</div><div class="line"><a name="l01279"></a><span class="lineno"> 1279</span>&#160;        <span class="keywordflow">return</span> TensorMap&lt;Scalar,4&gt;(prev_out_grad.data(), prev_out_conversion_dims);</div><div class="line"><a name="l01280"></a><span class="lineno"> 1280</span>&#160;    }</div><div class="line"><a name="l01281"></a><span class="lineno"> 1281</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l01282"></a><span class="lineno"> 1282</span>&#160;    <span class="keyword">inline</span> Tensor&lt;Scalar,4&gt; _pass_forward(Tensor&lt;Scalar,4&gt; in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01283"></a><span class="lineno"> 1283</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l01284"></a><span class="lineno"> 1284</span>&#160;        std::size_t depth = ext_input_dims(2);</div><div class="line"><a name="l01285"></a><span class="lineno"> 1285</span>&#160;        std::size_t receptor_vol = Base::weights_ref.cols();</div><div class="line"><a name="l01286"></a><span class="lineno"> 1286</span>&#160;        std::size_t total_patches = rows * patches_per_sample;</div><div class="line"><a name="l01287"></a><span class="lineno"> 1287</span>&#160;        biased_in_mat = Matrix&lt;Scalar&gt;(total_patches, depth + 1);</div><div class="line"><a name="l01288"></a><span class="lineno"> 1288</span>&#160;        biased_in_mat.block(0, 0, total_patches, depth) = MatrixMap&lt;Scalar&gt;(in.data(), total_patches, depth);</div><div class="line"><a name="l01289"></a><span class="lineno"> 1289</span>&#160;        biased_in_mat.col(depth).setOnes();</div><div class="line"><a name="l01290"></a><span class="lineno"> 1290</span>&#160;        Matrix&lt;Scalar&gt; out_conv_mat(total_patches, Base::weights_ref.cols());</div><div class="line"><a name="l01291"></a><span class="lineno"> 1291</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#aeed972c3e81eab21836a014787d8baf6">internal::CuBLASHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#a608acc1a5e1f61d2d86eebf0d62ff948">matrix_mul</a>(biased_in_mat.data(), biased_in_mat.rows(),</div><div class="line"><a name="l01292"></a><span class="lineno"> 1292</span>&#160;                biased_in_mat.cols(), <span class="keyword">false</span>, Base::weights_ref.data(), Base::weights_ref.rows(),</div><div class="line"><a name="l01293"></a><span class="lineno"> 1293</span>&#160;                Base::weights_ref.cols(), <span class="keyword">false</span>, out_conv_mat.data());</div><div class="line"><a name="l01294"></a><span class="lineno"> 1294</span>&#160;        Tensor&lt;Scalar,4&gt; out(rows, padded_height, padded_width, ext_output_dims(2));</div><div class="line"><a name="l01295"></a><span class="lineno"> 1295</span>&#160;        out.setZero();</div><div class="line"><a name="l01296"></a><span class="lineno"> 1296</span>&#160;        std::size_t patch_ind = 0;</div><div class="line"><a name="l01297"></a><span class="lineno"> 1297</span>&#160;        patch_extents[0] = rows;</div><div class="line"><a name="l01298"></a><span class="lineno"> 1298</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt;= padded_width - dil_receptor_width; i += horizontal_stride) {</div><div class="line"><a name="l01299"></a><span class="lineno"> 1299</span>&#160;            patch_offsets[2] = i;</div><div class="line"><a name="l01300"></a><span class="lineno"> 1300</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt;= padded_height - dil_receptor_height; j += vertical_stride) {</div><div class="line"><a name="l01301"></a><span class="lineno"> 1301</span>&#160;                patch_offsets[1] = j;</div><div class="line"><a name="l01302"></a><span class="lineno"> 1302</span>&#160;                Matrix&lt;Scalar&gt; out_conv_mat_block = out_conv_mat.block(patch_ind, 0, rows, receptor_vol);</div><div class="line"><a name="l01303"></a><span class="lineno"> 1303</span>&#160;                TensorMap&lt;Scalar,4&gt; out_patch(out_conv_mat_block.data(), rows, receptor_height,</div><div class="line"><a name="l01304"></a><span class="lineno"> 1304</span>&#160;                        receptor_width, ext_output_dims(2));</div><div class="line"><a name="l01305"></a><span class="lineno"> 1305</span>&#160;                <span class="keywordflow">if</span> (vertical_dilation &gt; 0 || horizontal_dilation &gt; 0)</div><div class="line"><a name="l01306"></a><span class="lineno"> 1306</span>&#160;                    out.slice(patch_offsets, patch_extents).stride(dil_strides) += out_patch;</div><div class="line"><a name="l01307"></a><span class="lineno"> 1307</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l01308"></a><span class="lineno"> 1308</span>&#160;                    out.slice(patch_offsets, patch_extents) += out_patch;</div><div class="line"><a name="l01309"></a><span class="lineno"> 1309</span>&#160;                patch_ind += rows;</div><div class="line"><a name="l01310"></a><span class="lineno"> 1310</span>&#160;            }</div><div class="line"><a name="l01311"></a><span class="lineno"> 1311</span>&#160;        }</div><div class="line"><a name="l01312"></a><span class="lineno"> 1312</span>&#160;        assert(patch_ind == total_patches);</div><div class="line"><a name="l01313"></a><span class="lineno"> 1313</span>&#160;        <span class="keywordflow">if</span> (vertical_padding &gt; 0 || horizontal_padding &gt; 0) {</div><div class="line"><a name="l01314"></a><span class="lineno"> 1314</span>&#160;            no_padding_extents[0] = rows;</div><div class="line"><a name="l01315"></a><span class="lineno"> 1315</span>&#160;            <span class="keywordflow">return</span> out.slice(no_padding_offsets, no_padding_extents);</div><div class="line"><a name="l01316"></a><span class="lineno"> 1316</span>&#160;        } <span class="keywordflow">else</span></div><div class="line"><a name="l01317"></a><span class="lineno"> 1317</span>&#160;            <span class="keywordflow">return</span> out;</div><div class="line"><a name="l01318"></a><span class="lineno"> 1318</span>&#160;    }</div><div class="line"><a name="l01319"></a><span class="lineno"> 1319</span>&#160;    <span class="keyword">inline</span> Tensor&lt;Scalar,4&gt; _pass_back(Tensor&lt;Scalar,4&gt; out_grad) {</div><div class="line"><a name="l01320"></a><span class="lineno"> 1320</span>&#160;        <span class="keywordflow">if</span> (vertical_padding &gt; 0 || horizontal_padding &gt; 0)</div><div class="line"><a name="l01321"></a><span class="lineno"> 1321</span>&#160;            out_grad = Tensor&lt;Scalar,4&gt;(out_grad.pad(paddings));</div><div class="line"><a name="l01322"></a><span class="lineno"> 1322</span>&#160;        std::size_t rows = out_grad.dimension(0);</div><div class="line"><a name="l01323"></a><span class="lineno"> 1323</span>&#160;        std::size_t depth = ext_input_dims(2);</div><div class="line"><a name="l01324"></a><span class="lineno"> 1324</span>&#160;        std::size_t receptor_vol = Base::weights_ref.cols();</div><div class="line"><a name="l01325"></a><span class="lineno"> 1325</span>&#160;        std::size_t total_patches = rows * patches_per_sample;</div><div class="line"><a name="l01326"></a><span class="lineno"> 1326</span>&#160;        std::size_t patch_ind = 0;</div><div class="line"><a name="l01327"></a><span class="lineno"> 1327</span>&#160;        patch_extents[0] = rows;</div><div class="line"><a name="l01328"></a><span class="lineno"> 1328</span>&#160;        Matrix&lt;Scalar&gt; out_grad_conv_mat(total_patches, receptor_vol);</div><div class="line"><a name="l01329"></a><span class="lineno"> 1329</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt;= padded_width - dil_receptor_width; i += horizontal_stride) {</div><div class="line"><a name="l01330"></a><span class="lineno"> 1330</span>&#160;            patch_offsets[2] = i;</div><div class="line"><a name="l01331"></a><span class="lineno"> 1331</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt;= padded_height - dil_receptor_height; j += vertical_stride) {</div><div class="line"><a name="l01332"></a><span class="lineno"> 1332</span>&#160;                patch_offsets[1] = j;</div><div class="line"><a name="l01333"></a><span class="lineno"> 1333</span>&#160;                Tensor&lt;Scalar,4&gt; patch;</div><div class="line"><a name="l01334"></a><span class="lineno"> 1334</span>&#160;                <span class="keywordflow">if</span> (vertical_dilation &gt; 0 || horizontal_dilation &gt; 0)</div><div class="line"><a name="l01335"></a><span class="lineno"> 1335</span>&#160;                    patch = out_grad.slice(patch_offsets, patch_extents).stride(dil_strides);</div><div class="line"><a name="l01336"></a><span class="lineno"> 1336</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l01337"></a><span class="lineno"> 1337</span>&#160;                    patch = out_grad.slice(patch_offsets, patch_extents);</div><div class="line"><a name="l01338"></a><span class="lineno"> 1338</span>&#160;                out_grad_conv_mat.block(patch_ind, 0, rows, receptor_vol) = MatrixMap&lt;Scalar&gt;(patch.data(),</div><div class="line"><a name="l01339"></a><span class="lineno"> 1339</span>&#160;                        rows, receptor_vol);</div><div class="line"><a name="l01340"></a><span class="lineno"> 1340</span>&#160;                patch_ind += rows;</div><div class="line"><a name="l01341"></a><span class="lineno"> 1341</span>&#160;            }</div><div class="line"><a name="l01342"></a><span class="lineno"> 1342</span>&#160;        }</div><div class="line"><a name="l01343"></a><span class="lineno"> 1343</span>&#160;        assert(patch_ind == total_patches);</div><div class="line"><a name="l01344"></a><span class="lineno"> 1344</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#aeed972c3e81eab21836a014787d8baf6">internal::CuBLASHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#a608acc1a5e1f61d2d86eebf0d62ff948">matrix_mul</a>(biased_in_mat.data(), biased_in_mat.rows(),</div><div class="line"><a name="l01345"></a><span class="lineno"> 1345</span>&#160;                biased_in_mat.cols(), <span class="keyword">true</span>, out_grad_conv_mat.data(), total_patches, receptor_vol, <span class="keyword">false</span>,</div><div class="line"><a name="l01346"></a><span class="lineno"> 1346</span>&#160;                Base::weights_grad.data());</div><div class="line"><a name="l01347"></a><span class="lineno"> 1347</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">Base::is_input_layer</a>())</div><div class="line"><a name="l01348"></a><span class="lineno"> 1348</span>&#160;            <span class="keywordflow">return</span> Tensor&lt;Scalar,4&gt;();</div><div class="line"><a name="l01349"></a><span class="lineno"> 1349</span>&#160;        prev_out_conversion_dims[0] = rows;</div><div class="line"><a name="l01350"></a><span class="lineno"> 1350</span>&#160;        Tensor&lt;Scalar,4&gt; prev_out(prev_out_conversion_dims);</div><div class="line"><a name="l01351"></a><span class="lineno"> 1351</span>&#160;        {</div><div class="line"><a name="l01352"></a><span class="lineno"> 1352</span>&#160;            Matrix&lt;Scalar&gt; weights_without_bias = Base::weights_ref.topRows(depth);</div><div class="line"><a name="l01353"></a><span class="lineno"> 1353</span>&#160;            <a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#aeed972c3e81eab21836a014787d8baf6">internal::CuBLASHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#a608acc1a5e1f61d2d86eebf0d62ff948">matrix_mul</a>(out_grad_conv_mat.data(), total_patches,</div><div class="line"><a name="l01354"></a><span class="lineno"> 1354</span>&#160;                    receptor_vol, <span class="keyword">false</span>, weights_without_bias.data(), depth, weights_without_bias.cols(),</div><div class="line"><a name="l01355"></a><span class="lineno"> 1355</span>&#160;                    <span class="keyword">true</span>, prev_out.data());</div><div class="line"><a name="l01356"></a><span class="lineno"> 1356</span>&#160;        }</div><div class="line"><a name="l01357"></a><span class="lineno"> 1357</span>&#160;        <span class="keywordflow">return</span> prev_out;</div><div class="line"><a name="l01358"></a><span class="lineno"> 1358</span>&#160;    }</div><div class="line"><a name="l01359"></a><span class="lineno"> 1359</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l01360"></a><span class="lineno"> 1360</span>&#160;    <span class="comment">// The defining attributes of the deconvolutional layer.</span></div><div class="line"><a name="l01361"></a><span class="lineno"> 1361</span>&#160;    <span class="keyword">const</span> std::size_t filters;</div><div class="line"><a name="l01362"></a><span class="lineno"> 1362</span>&#160;    <span class="keyword">const</span> std::size_t receptor_height;</div><div class="line"><a name="l01363"></a><span class="lineno"> 1363</span>&#160;    <span class="keyword">const</span> std::size_t receptor_width;</div><div class="line"><a name="l01364"></a><span class="lineno"> 1364</span>&#160;    <span class="keyword">const</span> std::size_t vertical_padding;</div><div class="line"><a name="l01365"></a><span class="lineno"> 1365</span>&#160;    <span class="keyword">const</span> std::size_t horizontal_padding;</div><div class="line"><a name="l01366"></a><span class="lineno"> 1366</span>&#160;    <span class="keyword">const</span> std::size_t vertical_stride;</div><div class="line"><a name="l01367"></a><span class="lineno"> 1367</span>&#160;    <span class="keyword">const</span> std::size_t horizontal_stride;</div><div class="line"><a name="l01368"></a><span class="lineno"> 1368</span>&#160;    <span class="keyword">const</span> std::size_t vertical_dilation;</div><div class="line"><a name="l01369"></a><span class="lineno"> 1369</span>&#160;    <span class="keyword">const</span> std::size_t horizontal_dilation;</div><div class="line"><a name="l01370"></a><span class="lineno"> 1370</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01371"></a><span class="lineno"> 1371</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> std::size_t calculate_spatial_output_dim(std::size_t input_dim, std::size_t receptor_size, std::size_t padding,</div><div class="line"><a name="l01372"></a><span class="lineno"> 1372</span>&#160;            std::size_t dilation, std::size_t stride) {</div><div class="line"><a name="l01373"></a><span class="lineno"> 1373</span>&#160;        <span class="keywordflow">return</span> (input_dim - 1) * stride + receptor_size + (receptor_size - 1) * dilation - 2 * padding;</div><div class="line"><a name="l01374"></a><span class="lineno"> 1374</span>&#160;    }</div><div class="line"><a name="l01375"></a><span class="lineno"> 1375</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> Dimensions&lt;std::size_t,3&gt; calculate_output_dims(<span class="keyword">const</span> Dimensions&lt;std::size_t,3&gt;&amp; input_dims, std::size_t filters,</div><div class="line"><a name="l01376"></a><span class="lineno"> 1376</span>&#160;            std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding,</div><div class="line"><a name="l01377"></a><span class="lineno"> 1377</span>&#160;            std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation) {</div><div class="line"><a name="l01378"></a><span class="lineno"> 1378</span>&#160;        <span class="keywordflow">return</span> { calculate_spatial_output_dim(input_dims(0), receptor_height, vertical_padding, vertical_dilation, vertical_stride),</div><div class="line"><a name="l01379"></a><span class="lineno"> 1379</span>&#160;                calculate_spatial_output_dim(input_dims(1), receptor_width, horizontal_padding, horizontal_dilation, horizontal_stride),</div><div class="line"><a name="l01380"></a><span class="lineno"> 1380</span>&#160;                filters };</div><div class="line"><a name="l01381"></a><span class="lineno"> 1381</span>&#160;    }</div><div class="line"><a name="l01382"></a><span class="lineno"> 1382</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> Dimensions&lt;std::size_t,Rank&gt; calculate_adjusted_output_dims(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; input_dims,</div><div class="line"><a name="l01383"></a><span class="lineno"> 1383</span>&#160;            std::size_t filters, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding,</div><div class="line"><a name="l01384"></a><span class="lineno"> 1384</span>&#160;            std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride,</div><div class="line"><a name="l01385"></a><span class="lineno"> 1385</span>&#160;            std::size_t vertical_dilation, std::size_t horizontal_dilation) {</div><div class="line"><a name="l01386"></a><span class="lineno"> 1386</span>&#160;        <span class="keyword">auto</span> output_dims = calculate_output_dims(input_dims.template extend&lt;3 - Rank&gt;(), filters, receptor_height, receptor_width,</div><div class="line"><a name="l01387"></a><span class="lineno"> 1387</span>&#160;                vertical_padding, horizontal_padding, vertical_stride, horizontal_stride, vertical_dilation, horizontal_dilation);</div><div class="line"><a name="l01388"></a><span class="lineno"> 1388</span>&#160;        output_dims(2) /= filters;</div><div class="line"><a name="l01389"></a><span class="lineno"> 1389</span>&#160;        output_dims(Rank - 1) *= filters;</div><div class="line"><a name="l01390"></a><span class="lineno"> 1390</span>&#160;        <span class="keywordflow">return</span> output_dims.template contract&lt;3 - Rank&gt;();</div><div class="line"><a name="l01391"></a><span class="lineno"> 1391</span>&#160;    }</div><div class="line"><a name="l01392"></a><span class="lineno"> 1392</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,3&gt; ext_input_dims;</div><div class="line"><a name="l01393"></a><span class="lineno"> 1393</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,3&gt; ext_output_dims;</div><div class="line"><a name="l01394"></a><span class="lineno"> 1394</span>&#160;    <span class="comment">// Pre-computed values to improve propagation-time performance.</span></div><div class="line"><a name="l01395"></a><span class="lineno"> 1395</span>&#160;    <span class="keyword">const</span> std::size_t padded_height;</div><div class="line"><a name="l01396"></a><span class="lineno"> 1396</span>&#160;    <span class="keyword">const</span> std::size_t padded_width;</div><div class="line"><a name="l01397"></a><span class="lineno"> 1397</span>&#160;    <span class="keyword">const</span> std::size_t dil_receptor_height;</div><div class="line"><a name="l01398"></a><span class="lineno"> 1398</span>&#160;    <span class="keyword">const</span> std::size_t dil_receptor_width;</div><div class="line"><a name="l01399"></a><span class="lineno"> 1399</span>&#160;    <span class="keyword">const</span> std::size_t patches_per_sample;</div><div class="line"><a name="l01400"></a><span class="lineno"> 1400</span>&#160;    Array4 prev_out_conversion_dims;</div><div class="line"><a name="l01401"></a><span class="lineno"> 1401</span>&#160;    Array4 patch_offsets;</div><div class="line"><a name="l01402"></a><span class="lineno"> 1402</span>&#160;    Array4 patch_extents;</div><div class="line"><a name="l01403"></a><span class="lineno"> 1403</span>&#160;    Array4 dil_strides;</div><div class="line"><a name="l01404"></a><span class="lineno"> 1404</span>&#160;    Array4 no_padding_offsets;</div><div class="line"><a name="l01405"></a><span class="lineno"> 1405</span>&#160;    Array4 no_padding_extents;</div><div class="line"><a name="l01406"></a><span class="lineno"> 1406</span>&#160;    PaddingsArray4 paddings;</div><div class="line"><a name="l01407"></a><span class="lineno"> 1407</span>&#160;    <span class="comment">// Staged computation caches</span></div><div class="line"><a name="l01408"></a><span class="lineno"> 1408</span>&#160;    Matrix&lt;Scalar&gt; biased_in_mat;</div><div class="line"><a name="l01409"></a><span class="lineno"> 1409</span>&#160;};</div><div class="line"><a name="l01410"></a><span class="lineno"> 1410</span>&#160;</div><div class="line"><a name="l01418"></a><span class="lineno"> 1418</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank = 3&gt;</div><div class="line"><a name="l01419"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer.html"> 1419</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_deconv_kernel_layer.html">DeconvKernelLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l01420"></a><span class="lineno"> 1420</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l01421"></a><span class="lineno"> 1421</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelBase</a>;</div><div class="line"><a name="l01422"></a><span class="lineno"> 1422</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvBase</a>;</div><div class="line"><a name="l01423"></a><span class="lineno"> 1423</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01444"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc"> 1444</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc">DeconvKernelLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>&amp; input_dims, std::size_t filters, <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr&lt;Scalar&gt;</a> weight_init,</div><div class="line"><a name="l01445"></a><span class="lineno"> 1445</span>&#160;            <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> weight_reg = Root::NO_PARAM_REG, std::size_t receptor_height = 3, std::size_t receptor_width = 3,</div><div class="line"><a name="l01446"></a><span class="lineno"> 1446</span>&#160;            std::size_t vertical_padding = 1, std::size_t horizontal_padding = 1, std::size_t vertical_stride = 1,</div><div class="line"><a name="l01447"></a><span class="lineno"> 1447</span>&#160;            std::size_t horizontal_stride = 1, std::size_t vertical_dilation = 0, std::size_t horizontal_dilation = 0,</div><div class="line"><a name="l01448"></a><span class="lineno"> 1448</span>&#160;            Scalar max_norm_constraint = 0) :</div><div class="line"><a name="l01449"></a><span class="lineno"> 1449</span>&#160;                <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvBase</a>::<a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a>(input_dims, filters, weight_init, weight_reg, receptor_height, receptor_width,</div><div class="line"><a name="l01450"></a><span class="lineno"> 1450</span>&#160;                        vertical_padding, horizontal_padding, vertical_stride, horizontal_stride, vertical_dilation, horizontal_dilation,</div><div class="line"><a name="l01451"></a><span class="lineno"> 1451</span>&#160;                        max_norm_constraint) { }</div><div class="line"><a name="l01452"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer.html#aa7f0a5c55c5e7dc0f37b4a4fb7368551"> 1452</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#aa7f0a5c55c5e7dc0f37b4a4fb7368551">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01453"></a><span class="lineno"> 1453</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc">DeconvKernelLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01454"></a><span class="lineno"> 1454</span>&#160;    }</div><div class="line"><a name="l01455"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer.html#a781eb0a003bcd29b85ad6a98a1bdfb46"> 1455</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a781eb0a003bcd29b85ad6a98a1bdfb46">clone_with_shared_params</a>() {</div><div class="line"><a name="l01456"></a><span class="lineno"> 1456</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc">DeconvKernelLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l01457"></a><span class="lineno"> 1457</span>&#160;    }</div><div class="line"><a name="l01458"></a><span class="lineno"> 1458</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01459"></a><span class="lineno"> 1459</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc">DeconvKernelLayer</a>(<a class="code" href="classcattle_1_1_deconv_kernel_layer.html">DeconvKernelLayer&lt;Scalar,3&gt;</a>&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l01460"></a><span class="lineno"> 1460</span>&#160;            DeconvBase::<a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a>(layer, share_params),</div><div class="line"><a name="l01461"></a><span class="lineno"> 1461</span>&#160;            batch_size(layer.batch_size) { }</div><div class="line"><a name="l01462"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer.html#a34b6db12d2d0aa7d29434be0878f632a"> 1462</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a34b6db12d2d0aa7d29434be0878f632a">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01463"></a><span class="lineno"> 1463</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,4&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::input_dims);</div><div class="line"><a name="l01464"></a><span class="lineno"> 1464</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01465"></a><span class="lineno"> 1465</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l01466"></a><span class="lineno"> 1466</span>&#160;        <span class="keywordflow">return</span> DeconvBase::_pass_forward(std::move(in), training);</div><div class="line"><a name="l01467"></a><span class="lineno"> 1467</span>&#160;    }</div><div class="line"><a name="l01468"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer.html#ac89d36d1e61efb112f241ed8e2966337"> 1468</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#ac89d36d1e61efb112f241ed8e2966337">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01469"></a><span class="lineno"> 1469</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,4&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::output_dims);</div><div class="line"><a name="l01470"></a><span class="lineno"> 1470</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l01471"></a><span class="lineno"> 1471</span>&#160;        <span class="keywordflow">return</span> DeconvBase::_pass_back(std::move(out_grad));</div><div class="line"><a name="l01472"></a><span class="lineno"> 1472</span>&#160;    }</div><div class="line"><a name="l01473"></a><span class="lineno"> 1473</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01474"></a><span class="lineno"> 1474</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l01475"></a><span class="lineno"> 1475</span>&#160;};</div><div class="line"><a name="l01476"></a><span class="lineno"> 1476</span>&#160;</div><div class="line"><a name="l01484"></a><span class="lineno"> 1484</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l01485"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html"> 1485</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_deconv_kernel_layer.html">DeconvKernelLayer</a>&lt;Scalar,2&gt; : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a>&lt;Scalar,2&gt; {</div><div class="line"><a name="l01486"></a><span class="lineno"> 1486</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l01487"></a><span class="lineno"> 1487</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelBase</a>;</div><div class="line"><a name="l01488"></a><span class="lineno"> 1488</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvBase</a>;</div><div class="line"><a name="l01489"></a><span class="lineno"> 1489</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01512"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#ab151ba52fa5ab583252c75af73555274"> 1512</a></span>&#160;    <a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#ab151ba52fa5ab583252c75af73555274">DeconvKernelLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>&amp; input_dims, std::size_t filters, <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr&lt;Scalar&gt;</a> weight_init,</div><div class="line"><a name="l01513"></a><span class="lineno"> 1513</span>&#160;            <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> weight_reg = Root::NO_PARAM_REG, std::size_t receptor_height = 3, std::size_t receptor_width = 3,</div><div class="line"><a name="l01514"></a><span class="lineno"> 1514</span>&#160;            std::size_t vertical_padding = 1, std::size_t horizontal_padding = 1, std::size_t vertical_stride = 1,</div><div class="line"><a name="l01515"></a><span class="lineno"> 1515</span>&#160;            std::size_t horizontal_stride = 1, std::size_t vertical_dilation = 0, std::size_t horizontal_dilation = 0,</div><div class="line"><a name="l01516"></a><span class="lineno"> 1516</span>&#160;            Scalar max_norm_constraint = 0) :</div><div class="line"><a name="l01517"></a><span class="lineno"> 1517</span>&#160;                <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvBase</a>::<a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a>(input_dims, filters, weight_init, weight_reg, receptor_height, receptor_width,</div><div class="line"><a name="l01518"></a><span class="lineno"> 1518</span>&#160;                        vertical_padding, horizontal_padding, vertical_stride, horizontal_stride, vertical_dilation, horizontal_dilation,</div><div class="line"><a name="l01519"></a><span class="lineno"> 1519</span>&#160;                        max_norm_constraint) { }</div><div class="line"><a name="l01520"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a44c8abc3fc0c11875969a0586fbb2f95"> 1520</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a44c8abc3fc0c11875969a0586fbb2f95">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01521"></a><span class="lineno"> 1521</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc">DeconvKernelLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01522"></a><span class="lineno"> 1522</span>&#160;    }</div><div class="line"><a name="l01523"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a482fdde9c3f36efcdd4ea8ae4cd8100a"> 1523</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a482fdde9c3f36efcdd4ea8ae4cd8100a">clone_with_shared_params</a>() {</div><div class="line"><a name="l01524"></a><span class="lineno"> 1524</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc">DeconvKernelLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l01525"></a><span class="lineno"> 1525</span>&#160;    }</div><div class="line"><a name="l01526"></a><span class="lineno"> 1526</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01527"></a><span class="lineno"> 1527</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc">DeconvKernelLayer</a>(<a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html">DeconvKernelLayer&lt;Scalar,2&gt;</a>&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l01528"></a><span class="lineno"> 1528</span>&#160;            DeconvBase::<a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a>(layer, share_params),</div><div class="line"><a name="l01529"></a><span class="lineno"> 1529</span>&#160;            batch_size(layer.batch_size) { }</div><div class="line"><a name="l01530"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a5d9a6e54673186b9686410b1d9e11047"> 1530</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a5d9a6e54673186b9686410b1d9e11047">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01531"></a><span class="lineno"> 1531</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::input_dims);</div><div class="line"><a name="l01532"></a><span class="lineno"> 1532</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01533"></a><span class="lineno"> 1533</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l01534"></a><span class="lineno"> 1534</span>&#160;        <span class="keywordflow">return</span> DeconvBase::_pass_forward(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(in.data(), { batch_size, in.dimension(1), in.dimension(2), 1u }), training)</div><div class="line"><a name="l01535"></a><span class="lineno"> 1535</span>&#160;                .reshape(std::array&lt;std::size_t,3&gt;({ batch_size, KernelBase::output_dims(0), KernelBase::output_dims(1) }));</div><div class="line"><a name="l01536"></a><span class="lineno"> 1536</span>&#160;    }</div><div class="line"><a name="l01537"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a301dadf7765a2ac52a592207fa6db5d9"> 1537</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a301dadf7765a2ac52a592207fa6db5d9">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01538"></a><span class="lineno"> 1538</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::output_dims);</div><div class="line"><a name="l01539"></a><span class="lineno"> 1539</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l01540"></a><span class="lineno"> 1540</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> prev_out_grad = DeconvBase::_pass_back(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(out_grad.data(),</div><div class="line"><a name="l01541"></a><span class="lineno"> 1541</span>&#160;                { batch_size, KernelBase::output_dims(0), KernelBase::output_dims(1) / DeconvBase::filters, DeconvBase::filters }));</div><div class="line"><a name="l01542"></a><span class="lineno"> 1542</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">KernelBase::is_input_layer</a>())</div><div class="line"><a name="l01543"></a><span class="lineno"> 1543</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,3&gt;</a>();</div><div class="line"><a name="l01544"></a><span class="lineno"> 1544</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,3&gt;</a>(prev_out_grad.data(), { batch_size, KernelBase::input_dims(0), KernelBase::input_dims(1) });</div><div class="line"><a name="l01545"></a><span class="lineno"> 1545</span>&#160;    }</div><div class="line"><a name="l01546"></a><span class="lineno"> 1546</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01547"></a><span class="lineno"> 1547</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l01548"></a><span class="lineno"> 1548</span>&#160;};</div><div class="line"><a name="l01549"></a><span class="lineno"> 1549</span>&#160;</div><div class="line"><a name="l01557"></a><span class="lineno"> 1557</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l01558"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html"> 1558</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_deconv_kernel_layer.html">DeconvKernelLayer</a>&lt;Scalar,1&gt; : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a>&lt;Scalar,1&gt; {</div><div class="line"><a name="l01559"></a><span class="lineno"> 1559</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l01560"></a><span class="lineno"> 1560</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelLayer&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_kernel_layer.html">KernelBase</a>;</div><div class="line"><a name="l01561"></a><span class="lineno"> 1561</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvBase</a>;</div><div class="line"><a name="l01562"></a><span class="lineno"> 1562</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01578"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#adcc32375c88da7cb099f1aa02cfbaf6c"> 1578</a></span>&#160;    <a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#adcc32375c88da7cb099f1aa02cfbaf6c">DeconvKernelLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,1&gt;</a>&amp; input_dims, std::size_t filters, <a class="code" href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">WeightInitSharedPtr&lt;Scalar&gt;</a> weight_init,</div><div class="line"><a name="l01579"></a><span class="lineno"> 1579</span>&#160;            <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> weight_reg = Root::NO_PARAM_REG, std::size_t receptor_length = 3, std::size_t padding = 1,</div><div class="line"><a name="l01580"></a><span class="lineno"> 1580</span>&#160;            std::size_t stride = 1, std::size_t dilation = 0, Scalar max_norm_constraint = 0) :</div><div class="line"><a name="l01581"></a><span class="lineno"> 1581</span>&#160;                <a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvBase</a>::<a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a>(input_dims, filters, weight_init, weight_reg, receptor_length, 1, padding, 0,</div><div class="line"><a name="l01582"></a><span class="lineno"> 1582</span>&#160;                        stride, 1, dilation, 0, max_norm_constraint) { }</div><div class="line"><a name="l01583"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#a6a34796d715b879c89b3721b4cec4f7f"> 1583</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#a6a34796d715b879c89b3721b4cec4f7f">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01584"></a><span class="lineno"> 1584</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc">DeconvKernelLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01585"></a><span class="lineno"> 1585</span>&#160;    }</div><div class="line"><a name="l01586"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#a56ae483bf59bf85c8e01416f79f4b13c"> 1586</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#a56ae483bf59bf85c8e01416f79f4b13c">clone_with_shared_params</a>() {</div><div class="line"><a name="l01587"></a><span class="lineno"> 1587</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc">DeconvKernelLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l01588"></a><span class="lineno"> 1588</span>&#160;    }</div><div class="line"><a name="l01589"></a><span class="lineno"> 1589</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01590"></a><span class="lineno"> 1590</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc">DeconvKernelLayer</a>(<a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html">DeconvKernelLayer&lt;Scalar,1&gt;</a>&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l01591"></a><span class="lineno"> 1591</span>&#160;            DeconvBase::<a class="code" href="classcattle_1_1_deconv_kernel_layer_base.html">DeconvKernelLayerBase</a>(layer, share_params),</div><div class="line"><a name="l01592"></a><span class="lineno"> 1592</span>&#160;            batch_size(layer.batch_size) { }</div><div class="line"><a name="l01593"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#a307c7269d977540fcfb070f1b9376cf6"> 1593</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#a307c7269d977540fcfb070f1b9376cf6">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01594"></a><span class="lineno"> 1594</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::input_dims);</div><div class="line"><a name="l01595"></a><span class="lineno"> 1595</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01596"></a><span class="lineno"> 1596</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l01597"></a><span class="lineno"> 1597</span>&#160;        <span class="keywordflow">return</span> DeconvBase::_pass_forward(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(in.data(), { batch_size, in.dimension(1), 1u, 1u }), training)</div><div class="line"><a name="l01598"></a><span class="lineno"> 1598</span>&#160;                .reshape(std::array&lt;std::size_t,2&gt;({ batch_size, KernelBase::output_dims(0) }));</div><div class="line"><a name="l01599"></a><span class="lineno"> 1599</span>&#160;    }</div><div class="line"><a name="l01600"></a><span class="lineno"><a class="line" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#adbc814d4f313739c0bf5c34d195507a5"> 1600</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#adbc814d4f313739c0bf5c34d195507a5">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01601"></a><span class="lineno"> 1601</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == KernelBase::output_dims);</div><div class="line"><a name="l01602"></a><span class="lineno"> 1602</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l01603"></a><span class="lineno"> 1603</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> prev_out_grad = DeconvBase::_pass_back(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(out_grad.data(),</div><div class="line"><a name="l01604"></a><span class="lineno"> 1604</span>&#160;                { batch_size, KernelBase::output_dims(0) / DeconvBase::filters, 1, DeconvBase::filters }));</div><div class="line"><a name="l01605"></a><span class="lineno"> 1605</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">KernelBase::is_input_layer</a>())</div><div class="line"><a name="l01606"></a><span class="lineno"> 1606</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,2&gt;</a>();</div><div class="line"><a name="l01607"></a><span class="lineno"> 1607</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,2&gt;</a>(prev_out_grad.data(), { batch_size, KernelBase::input_dims(0) });</div><div class="line"><a name="l01608"></a><span class="lineno"> 1608</span>&#160;    }</div><div class="line"><a name="l01609"></a><span class="lineno"> 1609</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01610"></a><span class="lineno"> 1610</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l01611"></a><span class="lineno"> 1611</span>&#160;};</div><div class="line"><a name="l01612"></a><span class="lineno"> 1612</span>&#160;</div><div class="line"><a name="l01616"></a><span class="lineno"> 1616</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l01617"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html"> 1617</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l01618"></a><span class="lineno"> 1618</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l01619"></a><span class="lineno"> 1619</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01620"></a><span class="lineno"> 1620</span>&#160;    <span class="keyword">virtual</span> ~<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>() = <span class="keywordflow">default</span>;</div><div class="line"><a name="l01621"></a><span class="lineno"> 1621</span>&#160;    <span class="keyword">virtual</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_activation_layer.html#acfbb6290f425e0f5d94dbc14d9aabfae">clone</a>() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l01622"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#a2ff3acc579905c6a26c219caaa018993"> 1622</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_activation_layer.html#a2ff3acc579905c6a26c219caaa018993">clone_with_shared_params</a>() {</div><div class="line"><a name="l01623"></a><span class="lineno"> 1623</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1_activation_layer.html#acfbb6290f425e0f5d94dbc14d9aabfae">clone</a>();</div><div class="line"><a name="l01624"></a><span class="lineno"> 1624</span>&#160;    }</div><div class="line"><a name="l01625"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#a261c832c58e43392cdede3257e666dec"> 1625</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>&amp; <a class="code" href="classcattle_1_1_activation_layer.html#a261c832c58e43392cdede3257e666dec">get_params_owner</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01626"></a><span class="lineno"> 1626</span>&#160;        <span class="keywordflow">return</span> owner;</div><div class="line"><a name="l01627"></a><span class="lineno"> 1627</span>&#160;    }</div><div class="line"><a name="l01628"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#a4550c77e6341cd77a62a751eb129e44e"> 1628</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_activation_layer.html#a4550c77e6341cd77a62a751eb129e44e">get_input_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01629"></a><span class="lineno"> 1629</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l01630"></a><span class="lineno"> 1630</span>&#160;    }</div><div class="line"><a name="l01631"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#a30f2215af291a00e008fa09de8a32cf7"> 1631</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_activation_layer.html#a30f2215af291a00e008fa09de8a32cf7">get_output_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01632"></a><span class="lineno"> 1632</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l01633"></a><span class="lineno"> 1633</span>&#160;    }</div><div class="line"><a name="l01634"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#ab38d6acf3933fb2ac0c3e33bb15405ab"> 1634</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_activation_layer.html#ab38d6acf3933fb2ac0c3e33bb15405ab">get_params</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01635"></a><span class="lineno"> 1635</span>&#160;        <span class="keywordflow">return</span> params_ref;</div><div class="line"><a name="l01636"></a><span class="lineno"> 1636</span>&#160;    }</div><div class="line"><a name="l01637"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#a08946304d56287db036990d9d890f18e"> 1637</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_activation_layer.html#a08946304d56287db036990d9d890f18e">get_params_grad</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01638"></a><span class="lineno"> 1638</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l01639"></a><span class="lineno"> 1639</span>&#160;    }</div><div class="line"><a name="l01640"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#ae46130f5336ab1271537f28458d7a162"> 1640</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_activation_layer.html#ae46130f5336ab1271537f28458d7a162">is_frozen</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01641"></a><span class="lineno"> 1641</span>&#160;        <span class="keywordflow">return</span> frozen;</div><div class="line"><a name="l01642"></a><span class="lineno"> 1642</span>&#160;    }</div><div class="line"><a name="l01643"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#aee201eb78f434c69319f42a7645081c8"> 1643</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_activation_layer.html#aee201eb78f434c69319f42a7645081c8">set_frozen</a>(<span class="keywordtype">bool</span> frozen) {</div><div class="line"><a name="l01644"></a><span class="lineno"> 1644</span>&#160;        this-&gt;frozen = frozen;</div><div class="line"><a name="l01645"></a><span class="lineno"> 1645</span>&#160;    }</div><div class="line"><a name="l01646"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#a03f8dc5fe0d781b983e4494ab8413f5f"> 1646</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_activation_layer.html#a03f8dc5fe0d781b983e4494ab8413f5f">init</a>() { }</div><div class="line"><a name="l01647"></a><span class="lineno"> 1647</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01648"></a><span class="lineno"> 1648</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims, std::size_t param_rows = 0,</div><div class="line"><a name="l01649"></a><span class="lineno"> 1649</span>&#160;            std::size_t params_cols = 0) :</div><div class="line"><a name="l01650"></a><span class="lineno"> 1650</span>&#160;                dims(dims),</div><div class="line"><a name="l01651"></a><span class="lineno"> 1651</span>&#160;                input_layer(false),</div><div class="line"><a name="l01652"></a><span class="lineno"> 1652</span>&#160;                frozen(false),</div><div class="line"><a name="l01653"></a><span class="lineno"> 1653</span>&#160;                params(param_rows, params_cols),</div><div class="line"><a name="l01654"></a><span class="lineno"> 1654</span>&#160;                params_grad(param_rows, params_cols),</div><div class="line"><a name="l01655"></a><span class="lineno"> 1655</span>&#160;                params_ref(params),</div><div class="line"><a name="l01656"></a><span class="lineno"> 1656</span>&#160;                owner(*this) { }</div><div class="line"><a name="l01657"></a><span class="lineno"> 1657</span>&#160;    <span class="keyword">inline</span> ActivationLayer(<span class="keyword">const</span> ActivationLayer&lt;Scalar,Rank&gt;&amp; layer) :</div><div class="line"><a name="l01658"></a><span class="lineno"> 1658</span>&#160;            dims(layer.dims),</div><div class="line"><a name="l01659"></a><span class="lineno"> 1659</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l01660"></a><span class="lineno"> 1660</span>&#160;            frozen(layer.frozen),</div><div class="line"><a name="l01661"></a><span class="lineno"> 1661</span>&#160;            params(layer.params),</div><div class="line"><a name="l01662"></a><span class="lineno"> 1662</span>&#160;            params_grad(layer.params_grad),</div><div class="line"><a name="l01663"></a><span class="lineno"> 1663</span>&#160;            params_ref(layer.<a class="code" href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">is_shared_params_clone</a>() ? layer.params_ref : params),</div><div class="line"><a name="l01664"></a><span class="lineno"> 1664</span>&#160;            owner(layer.<a class="code" href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">is_shared_params_clone</a>() ? layer.owner : *this) { }</div><div class="line"><a name="l01665"></a><span class="lineno"> 1665</span>&#160;    <span class="keyword">inline</span> ActivationLayer(ActivationLayer&lt;Scalar,Rank&gt;&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l01666"></a><span class="lineno"> 1666</span>&#160;            dims(layer.dims),</div><div class="line"><a name="l01667"></a><span class="lineno"> 1667</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l01668"></a><span class="lineno"> 1668</span>&#160;            frozen(layer.frozen),</div><div class="line"><a name="l01669"></a><span class="lineno"> 1669</span>&#160;            params(share_params ? <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt;Scalar&gt;(0, 0) : layer.params),</div><div class="line"><a name="l01670"></a><span class="lineno"> 1670</span>&#160;            params_grad(layer.params_grad),</div><div class="line"><a name="l01671"></a><span class="lineno"> 1671</span>&#160;            params_ref(share_params ? layer.params_ref : params),</div><div class="line"><a name="l01672"></a><span class="lineno"> 1672</span>&#160;            owner(share_params ? layer.owner : *this){ }</div><div class="line"><a name="l01673"></a><span class="lineno"> 1673</span>&#160;    <span class="keyword">inline</span> ActivationLayer&lt;Scalar,Rank&gt;&amp; operator=(<span class="keyword">const</span> ActivationLayer&lt;Scalar,Rank&gt;&amp; layer) {</div><div class="line"><a name="l01674"></a><span class="lineno"> 1674</span>&#160;        dims = layer.dims;</div><div class="line"><a name="l01675"></a><span class="lineno"> 1675</span>&#160;        input_layer = layer.input_layer;</div><div class="line"><a name="l01676"></a><span class="lineno"> 1676</span>&#160;        frozen = layer.frozen;</div><div class="line"><a name="l01677"></a><span class="lineno"> 1677</span>&#160;        params = layer.params;</div><div class="line"><a name="l01678"></a><span class="lineno"> 1678</span>&#160;        params_grad = layer.params_grad;</div><div class="line"><a name="l01679"></a><span class="lineno"> 1679</span>&#160;        params_ref = (layer.is_shared_params_clone() ? layer.params_ref : params);</div><div class="line"><a name="l01680"></a><span class="lineno"> 1680</span>&#160;        owner = (layer.is_shared_params_clone() ? layer.owner : *<span class="keyword">this</span>);</div><div class="line"><a name="l01681"></a><span class="lineno"> 1681</span>&#160;    }</div><div class="line"><a name="l01682"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#a3733446d064f63f86f8a48bd30c0dbcb"> 1682</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_activation_layer.html#a3733446d064f63f86f8a48bd30c0dbcb">is_input_layer</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01683"></a><span class="lineno"> 1683</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l01684"></a><span class="lineno"> 1684</span>&#160;    }</div><div class="line"><a name="l01685"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#a34972577a520dc5e4d34d40c448f127b"> 1685</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_activation_layer.html#a34972577a520dc5e4d34d40c448f127b">set_input_layer</a>(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l01686"></a><span class="lineno"> 1686</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l01687"></a><span class="lineno"> 1687</span>&#160;    }</div><div class="line"><a name="l01688"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#ab97e38ad519af40007f659120f3f7fe1"> 1688</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_activation_layer.html#ab97e38ad519af40007f659120f3f7fe1">get_params</a>() {</div><div class="line"><a name="l01689"></a><span class="lineno"> 1689</span>&#160;        <span class="keywordflow">return</span> params_ref;</div><div class="line"><a name="l01690"></a><span class="lineno"> 1690</span>&#160;    }</div><div class="line"><a name="l01691"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#af9822a94073cb72e2db4de62c2126d54"> 1691</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_activation_layer.html#af9822a94073cb72e2db4de62c2126d54">get_params_grad</a>() {</div><div class="line"><a name="l01692"></a><span class="lineno"> 1692</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l01693"></a><span class="lineno"> 1693</span>&#160;    }</div><div class="line"><a name="l01694"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#aff288c69e4af006db23d2e998d84e847"> 1694</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_activation_layer.html#aff288c69e4af006db23d2e998d84e847">regularize</a>() { }</div><div class="line"><a name="l01695"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#a245b781c1e5ae253816389c2091565a1"> 1695</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1_activation_layer.html#a245b781c1e5ae253816389c2091565a1">get_regularization_penalty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01696"></a><span class="lineno"> 1696</span>&#160;        <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l01697"></a><span class="lineno"> 1697</span>&#160;    }</div><div class="line"><a name="l01698"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#a2722517029fa18cb0ee1b9038a643da9"> 1698</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_activation_layer.html#a2722517029fa18cb0ee1b9038a643da9">enforce_constraints</a>() { }</div><div class="line"><a name="l01699"></a><span class="lineno"><a class="line" href="classcattle_1_1_activation_layer.html#a3ea3acc95aef44eac905481020f3f946"> 1699</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_activation_layer.html#a3ea3acc95aef44eac905481020f3f946">empty_cache</a>() { }</div><div class="line"><a name="l01700"></a><span class="lineno"> 1700</span>&#160;    <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a> dims;</div><div class="line"><a name="l01701"></a><span class="lineno"> 1701</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> params_grad;</div><div class="line"><a name="l01702"></a><span class="lineno"> 1702</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; params_ref;</div><div class="line"><a name="l01703"></a><span class="lineno"> 1703</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01704"></a><span class="lineno"> 1704</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l01705"></a><span class="lineno"> 1705</span>&#160;    <span class="keywordtype">bool</span> frozen;</div><div class="line"><a name="l01706"></a><span class="lineno"> 1706</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> params;</div><div class="line"><a name="l01707"></a><span class="lineno"> 1707</span>&#160;    <span class="keyword">const</span> Base&amp; owner;</div><div class="line"><a name="l01708"></a><span class="lineno"> 1708</span>&#160;};</div><div class="line"><a name="l01709"></a><span class="lineno"> 1709</span>&#160;</div><div class="line"><a name="l01716"></a><span class="lineno"> 1716</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l01717"></a><span class="lineno"><a class="line" href="classcattle_1_1_identity_activation_layer.html"> 1717</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_identity_activation_layer.html">IdentityActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l01718"></a><span class="lineno"> 1718</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l01719"></a><span class="lineno"> 1719</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l01720"></a><span class="lineno"> 1720</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01724"></a><span class="lineno"><a class="line" href="classcattle_1_1_identity_activation_layer.html#a76d0cd6edb8434e33a845b171b305967"> 1724</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_identity_activation_layer.html#a76d0cd6edb8434e33a845b171b305967">IdentityActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims) :</div><div class="line"><a name="l01725"></a><span class="lineno"> 1725</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims) { }</div><div class="line"><a name="l01726"></a><span class="lineno"><a class="line" href="classcattle_1_1_identity_activation_layer.html#a90c6d2eca9a8d5913d5186b96df2f82e"> 1726</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_identity_activation_layer.html#a90c6d2eca9a8d5913d5186b96df2f82e">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01727"></a><span class="lineno"> 1727</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_identity_activation_layer.html#a76d0cd6edb8434e33a845b171b305967">IdentityActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01728"></a><span class="lineno"> 1728</span>&#160;    }</div><div class="line"><a name="l01729"></a><span class="lineno"> 1729</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01730"></a><span class="lineno"><a class="line" href="classcattle_1_1_identity_activation_layer.html#aa66b095d8084fecdddaaeade76728bb6"> 1730</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_identity_activation_layer.html#aa66b095d8084fecdddaaeade76728bb6">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01731"></a><span class="lineno"> 1731</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01732"></a><span class="lineno"> 1732</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01733"></a><span class="lineno"> 1733</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l01734"></a><span class="lineno"> 1734</span>&#160;        <span class="keywordflow">return</span> in;</div><div class="line"><a name="l01735"></a><span class="lineno"> 1735</span>&#160;    }</div><div class="line"><a name="l01736"></a><span class="lineno"><a class="line" href="classcattle_1_1_identity_activation_layer.html#ab6e4a91524b3a535c74b7804e8c0097f"> 1736</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_identity_activation_layer.html#ab6e4a91524b3a535c74b7804e8c0097f">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01737"></a><span class="lineno"> 1737</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01738"></a><span class="lineno"> 1738</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l01739"></a><span class="lineno"> 1739</span>&#160;        <span class="keywordflow">return</span> out_grad;</div><div class="line"><a name="l01740"></a><span class="lineno"> 1740</span>&#160;    }</div><div class="line"><a name="l01741"></a><span class="lineno"> 1741</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01742"></a><span class="lineno"> 1742</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l01743"></a><span class="lineno"> 1743</span>&#160;};</div><div class="line"><a name="l01744"></a><span class="lineno"> 1744</span>&#160;</div><div class="line"><a name="l01750"></a><span class="lineno"> 1750</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l01751"></a><span class="lineno"><a class="line" href="classcattle_1_1_scaled_activation_layer.html"> 1751</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_scaled_activation_layer.html">ScaledActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l01752"></a><span class="lineno"> 1752</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l01753"></a><span class="lineno"> 1753</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l01754"></a><span class="lineno"> 1754</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01759"></a><span class="lineno"><a class="line" href="classcattle_1_1_scaled_activation_layer.html#ab0915b571e2ac239d0b0aec7cee2374b"> 1759</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_scaled_activation_layer.html#ab0915b571e2ac239d0b0aec7cee2374b">ScaledActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims, Scalar scale) :</div><div class="line"><a name="l01760"></a><span class="lineno"> 1760</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims),</div><div class="line"><a name="l01761"></a><span class="lineno"> 1761</span>&#160;            scale(scale) { }</div><div class="line"><a name="l01762"></a><span class="lineno"><a class="line" href="classcattle_1_1_scaled_activation_layer.html#ab329b830fef5bd4df9ebd9efda83b879"> 1762</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_scaled_activation_layer.html#ab329b830fef5bd4df9ebd9efda83b879">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01763"></a><span class="lineno"> 1763</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_scaled_activation_layer.html#ab0915b571e2ac239d0b0aec7cee2374b">ScaledActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01764"></a><span class="lineno"> 1764</span>&#160;    }</div><div class="line"><a name="l01765"></a><span class="lineno"> 1765</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01766"></a><span class="lineno"><a class="line" href="classcattle_1_1_scaled_activation_layer.html#a42aa507a420c05fb92231beb2771384e"> 1766</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_scaled_activation_layer.html#a42aa507a420c05fb92231beb2771384e">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01767"></a><span class="lineno"> 1767</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01768"></a><span class="lineno"> 1768</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01769"></a><span class="lineno"> 1769</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l01770"></a><span class="lineno"> 1770</span>&#160;        <span class="keywordflow">return</span> in * scale;</div><div class="line"><a name="l01771"></a><span class="lineno"> 1771</span>&#160;    }</div><div class="line"><a name="l01772"></a><span class="lineno"><a class="line" href="classcattle_1_1_scaled_activation_layer.html#ab734027e0de3a17a15e4cb3f0fac4da2"> 1772</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_scaled_activation_layer.html#ab734027e0de3a17a15e4cb3f0fac4da2">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01773"></a><span class="lineno"> 1773</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01774"></a><span class="lineno"> 1774</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l01775"></a><span class="lineno"> 1775</span>&#160;        <span class="keywordflow">return</span> out_grad * scale;</div><div class="line"><a name="l01776"></a><span class="lineno"> 1776</span>&#160;    }</div><div class="line"><a name="l01777"></a><span class="lineno"> 1777</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01778"></a><span class="lineno"> 1778</span>&#160;    <span class="keyword">const</span> Scalar scale;</div><div class="line"><a name="l01779"></a><span class="lineno"> 1779</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l01780"></a><span class="lineno"> 1780</span>&#160;};</div><div class="line"><a name="l01781"></a><span class="lineno"> 1781</span>&#160;</div><div class="line"><a name="l01793"></a><span class="lineno"> 1793</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l01794"></a><span class="lineno"><a class="line" href="classcattle_1_1_binary_step_activation_layer.html"> 1794</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_binary_step_activation_layer.html">BinaryStepActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l01795"></a><span class="lineno"> 1795</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l01796"></a><span class="lineno"> 1796</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l01797"></a><span class="lineno"> 1797</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01801"></a><span class="lineno"><a class="line" href="classcattle_1_1_binary_step_activation_layer.html#af7dcd32d6982b8405bae6f25a2859e62"> 1801</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_binary_step_activation_layer.html#af7dcd32d6982b8405bae6f25a2859e62">BinaryStepActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims) :</div><div class="line"><a name="l01802"></a><span class="lineno"> 1802</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims) { }</div><div class="line"><a name="l01803"></a><span class="lineno"><a class="line" href="classcattle_1_1_binary_step_activation_layer.html#a7be1597139f721c9b5f259adadc30a8a"> 1803</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_binary_step_activation_layer.html#a7be1597139f721c9b5f259adadc30a8a">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01804"></a><span class="lineno"> 1804</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_binary_step_activation_layer.html#af7dcd32d6982b8405bae6f25a2859e62">BinaryStepActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01805"></a><span class="lineno"> 1805</span>&#160;    }</div><div class="line"><a name="l01806"></a><span class="lineno"> 1806</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01807"></a><span class="lineno"><a class="line" href="classcattle_1_1_binary_step_activation_layer.html#ac4ea89bab72ee953cb38dcd31b89041e"> 1807</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_binary_step_activation_layer.html#ac4ea89bab72ee953cb38dcd31b89041e">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01808"></a><span class="lineno"> 1808</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01809"></a><span class="lineno"> 1809</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01810"></a><span class="lineno"> 1810</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l01811"></a><span class="lineno"> 1811</span>&#160;        <span class="keywordflow">return</span> in.unaryExpr([](Scalar i) { <span class="keywordflow">return</span> (Scalar) (i &gt;= .0 ? 1.0 : .0); });</div><div class="line"><a name="l01812"></a><span class="lineno"> 1812</span>&#160;    }</div><div class="line"><a name="l01813"></a><span class="lineno"><a class="line" href="classcattle_1_1_binary_step_activation_layer.html#a934bfb1068ace14920a2ccc0277668e2"> 1813</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_binary_step_activation_layer.html#a934bfb1068ace14920a2ccc0277668e2">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01814"></a><span class="lineno"> 1814</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01815"></a><span class="lineno"> 1815</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l01816"></a><span class="lineno"> 1816</span>&#160;        <span class="keywordflow">return</span> out_grad.constant(0);</div><div class="line"><a name="l01817"></a><span class="lineno"> 1817</span>&#160;    }</div><div class="line"><a name="l01818"></a><span class="lineno"> 1818</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01819"></a><span class="lineno"> 1819</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l01820"></a><span class="lineno"> 1820</span>&#160;};</div><div class="line"><a name="l01821"></a><span class="lineno"> 1821</span>&#160;</div><div class="line"><a name="l01822"></a><span class="lineno"> 1822</span>&#160;<span class="preprocessor">#ifndef CATTL3_USE_CUDNN</span></div><div class="line"><a name="l01823"></a><span class="lineno"> 1823</span>&#160;</div><div class="line"><a name="l01828"></a><span class="lineno"> 1828</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l01829"></a><span class="lineno"><a class="line" href="classcattle_1_1_sigmoid_activation_layer.html"> 1829</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_sigmoid_activation_layer.html">SigmoidActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l01830"></a><span class="lineno"> 1830</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l01831"></a><span class="lineno"> 1831</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l01832"></a><span class="lineno"> 1832</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01836"></a><span class="lineno"><a class="line" href="classcattle_1_1_sigmoid_activation_layer.html#a9b6f4ebb210c70b972e9831831bac6fd"> 1836</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#a9b6f4ebb210c70b972e9831831bac6fd">SigmoidActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims) :</div><div class="line"><a name="l01837"></a><span class="lineno"> 1837</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims) { }</div><div class="line"><a name="l01838"></a><span class="lineno"><a class="line" href="classcattle_1_1_sigmoid_activation_layer.html#a6093c9a63f0a3d4a368eb9bb13aa707f"> 1838</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#a6093c9a63f0a3d4a368eb9bb13aa707f">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01839"></a><span class="lineno"> 1839</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#a9b6f4ebb210c70b972e9831831bac6fd">SigmoidActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01840"></a><span class="lineno"> 1840</span>&#160;    }</div><div class="line"><a name="l01841"></a><span class="lineno"> 1841</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01842"></a><span class="lineno"><a class="line" href="classcattle_1_1_sigmoid_activation_layer.html#af39afa34fcfd33a14a95fc2518be1c19"> 1842</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#af39afa34fcfd33a14a95fc2518be1c19">empty_cache</a>() {</div><div class="line"><a name="l01843"></a><span class="lineno"> 1843</span>&#160;        out = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l01844"></a><span class="lineno"> 1844</span>&#160;    }</div><div class="line"><a name="l01845"></a><span class="lineno"><a class="line" href="classcattle_1_1_sigmoid_activation_layer.html#aa5501e54efa3a5ec8bc7e1dc7025d102"> 1845</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#aa5501e54efa3a5ec8bc7e1dc7025d102">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01846"></a><span class="lineno"> 1846</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01847"></a><span class="lineno"> 1847</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01848"></a><span class="lineno"> 1848</span>&#160;        <span class="keyword">auto</span> out = ((-in).exp() + in.constant(1)).inverse();</div><div class="line"><a name="l01849"></a><span class="lineno"> 1849</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l01850"></a><span class="lineno"> 1850</span>&#160;            this-&gt;out = out;</div><div class="line"><a name="l01851"></a><span class="lineno"> 1851</span>&#160;            <span class="keywordflow">return</span> this-&gt;out;</div><div class="line"><a name="l01852"></a><span class="lineno"> 1852</span>&#160;        }</div><div class="line"><a name="l01853"></a><span class="lineno"> 1853</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l01854"></a><span class="lineno"> 1854</span>&#160;    }</div><div class="line"><a name="l01855"></a><span class="lineno"><a class="line" href="classcattle_1_1_sigmoid_activation_layer.html#a1b3bf686340f3b716d11425fc93431d4"> 1855</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#a1b3bf686340f3b716d11425fc93431d4">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01856"></a><span class="lineno"> 1856</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01857"></a><span class="lineno"> 1857</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; out.dimension(0) == out_grad.dimension(0));</div><div class="line"><a name="l01858"></a><span class="lineno"> 1858</span>&#160;        <span class="keywordflow">return</span> (out * (out.constant(1) - out)) * out_grad;</div><div class="line"><a name="l01859"></a><span class="lineno"> 1859</span>&#160;    }</div><div class="line"><a name="l01860"></a><span class="lineno"> 1860</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01861"></a><span class="lineno"> 1861</span>&#160;    <span class="comment">// Staged computation cache.</span></div><div class="line"><a name="l01862"></a><span class="lineno"> 1862</span>&#160;    <span class="keyword">typename</span> Root::Data out;</div><div class="line"><a name="l01863"></a><span class="lineno"> 1863</span>&#160;};</div><div class="line"><a name="l01864"></a><span class="lineno"> 1864</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l01865"></a><span class="lineno"> 1865</span>&#160;</div><div class="line"><a name="l01870"></a><span class="lineno"> 1870</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l01871"></a><span class="lineno"> 1871</span>&#160;<span class="keyword">class </span>SigmoidActivationLayer : <span class="keyword">public</span> ActivationLayer&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l01872"></a><span class="lineno"> 1872</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,Rank&gt; Root;</div><div class="line"><a name="l01873"></a><span class="lineno"> 1873</span>&#160;    <span class="keyword">typedef</span> ActivationLayer&lt;Scalar,Rank&gt; Base;</div><div class="line"><a name="l01874"></a><span class="lineno"> 1874</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01878"></a><span class="lineno"> 1878</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#a9b6f4ebb210c70b972e9831831bac6fd">SigmoidActivationLayer</a>(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; dims) :</div><div class="line"><a name="l01879"></a><span class="lineno"> 1879</span>&#160;            ActivationLayer&lt;Scalar,Rank&gt;::ActivationLayer(dims),</div><div class="line"><a name="l01880"></a><span class="lineno"> 1880</span>&#160;            ext_batch_dims(dims.template extend&lt;3 - Rank&gt;().template promote&lt;&gt;()) { }</div><div class="line"><a name="l01881"></a><span class="lineno"> 1881</span>&#160;    <span class="keyword">inline</span> Layer&lt;Scalar,Rank&gt;* <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#a6093c9a63f0a3d4a368eb9bb13aa707f">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01882"></a><span class="lineno"> 1882</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#a9b6f4ebb210c70b972e9831831bac6fd">SigmoidActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01883"></a><span class="lineno"> 1883</span>&#160;    }</div><div class="line"><a name="l01884"></a><span class="lineno"> 1884</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01885"></a><span class="lineno"> 1885</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#af39afa34fcfd33a14a95fc2518be1c19">empty_cache</a>() {</div><div class="line"><a name="l01886"></a><span class="lineno"> 1886</span>&#160;        in = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l01887"></a><span class="lineno"> 1887</span>&#160;        out = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l01888"></a><span class="lineno"> 1888</span>&#160;    }</div><div class="line"><a name="l01889"></a><span class="lineno"> 1889</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#aa5501e54efa3a5ec8bc7e1dc7025d102">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01890"></a><span class="lineno"> 1890</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01891"></a><span class="lineno"> 1891</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01892"></a><span class="lineno"> 1892</span>&#160;        ext_batch_dims[0] = in.dimension(0);</div><div class="line"><a name="l01893"></a><span class="lineno"> 1893</span>&#160;        this-&gt;in = std::move(in);</div><div class="line"><a name="l01894"></a><span class="lineno"> 1894</span>&#160;        out = <span class="keyword">typename</span> Root::Data(this-&gt;in.dimensions());</div><div class="line"><a name="l01895"></a><span class="lineno"> 1895</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a46b5ef9ed5403f8e934dc35038c377c9">activation_fwd</a>(this-&gt;in.data(), ext_batch_dims,</div><div class="line"><a name="l01896"></a><span class="lineno"> 1896</span>&#160;                CUDNN_ACTIVATION_SIGMOID, 0, out.data());</div><div class="line"><a name="l01897"></a><span class="lineno"> 1897</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l01898"></a><span class="lineno"> 1898</span>&#160;    }</div><div class="line"><a name="l01899"></a><span class="lineno"> 1899</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_sigmoid_activation_layer.html#a1b3bf686340f3b716d11425fc93431d4">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01900"></a><span class="lineno"> 1900</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01901"></a><span class="lineno"> 1901</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; ext_batch_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l01902"></a><span class="lineno"> 1902</span>&#160;        <span class="keyword">typename</span> Root::Data prev_out_grad(in.dimensions());</div><div class="line"><a name="l01903"></a><span class="lineno"> 1903</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#ae958103fd306a6ad9c1e0d50d9e13d57">activation_bwd</a>(in.data(), out.data(), out_grad.data(),</div><div class="line"><a name="l01904"></a><span class="lineno"> 1904</span>&#160;                ext_batch_dims, CUDNN_ACTIVATION_SIGMOID, 0, prev_out_grad.data());</div><div class="line"><a name="l01905"></a><span class="lineno"> 1905</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l01906"></a><span class="lineno"> 1906</span>&#160;    }</div><div class="line"><a name="l01907"></a><span class="lineno"> 1907</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01908"></a><span class="lineno"> 1908</span>&#160;    std::array&lt;std::size_t,4&gt; ext_batch_dims;</div><div class="line"><a name="l01909"></a><span class="lineno"> 1909</span>&#160;    <span class="keyword">typename</span> Root::Data in;</div><div class="line"><a name="l01910"></a><span class="lineno"> 1910</span>&#160;    <span class="keyword">typename</span> Root::Data out;</div><div class="line"><a name="l01911"></a><span class="lineno"> 1911</span>&#160;};</div><div class="line"><a name="l01912"></a><span class="lineno"> 1912</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l01913"></a><span class="lineno"> 1913</span>&#160;</div><div class="line"><a name="l01914"></a><span class="lineno"> 1914</span>&#160;<span class="preprocessor">#ifndef CATTL3_USE_CUDNN</span></div><div class="line"><a name="l01915"></a><span class="lineno"> 1915</span>&#160;</div><div class="line"><a name="l01920"></a><span class="lineno"> 1920</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l01921"></a><span class="lineno"><a class="line" href="classcattle_1_1_tanh_activation_layer.html"> 1921</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_tanh_activation_layer.html">TanhActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l01922"></a><span class="lineno"> 1922</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l01923"></a><span class="lineno"> 1923</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l01924"></a><span class="lineno"> 1924</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01928"></a><span class="lineno"><a class="line" href="classcattle_1_1_tanh_activation_layer.html#a67d44e760962f78b74c182b1b1cf528d"> 1928</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_tanh_activation_layer.html#a67d44e760962f78b74c182b1b1cf528d">TanhActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims) :</div><div class="line"><a name="l01929"></a><span class="lineno"> 1929</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims) { }</div><div class="line"><a name="l01930"></a><span class="lineno"><a class="line" href="classcattle_1_1_tanh_activation_layer.html#a7896bd20f2379a0b2e84390510219482"> 1930</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_tanh_activation_layer.html#a7896bd20f2379a0b2e84390510219482">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01931"></a><span class="lineno"> 1931</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_tanh_activation_layer.html#a67d44e760962f78b74c182b1b1cf528d">TanhActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01932"></a><span class="lineno"> 1932</span>&#160;    }</div><div class="line"><a name="l01933"></a><span class="lineno"> 1933</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01934"></a><span class="lineno"><a class="line" href="classcattle_1_1_tanh_activation_layer.html#ad0164a3bcb90574df7b5865e6a3c4a33"> 1934</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_tanh_activation_layer.html#ad0164a3bcb90574df7b5865e6a3c4a33">empty_cache</a>() {</div><div class="line"><a name="l01935"></a><span class="lineno"> 1935</span>&#160;        out = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l01936"></a><span class="lineno"> 1936</span>&#160;    }</div><div class="line"><a name="l01937"></a><span class="lineno"><a class="line" href="classcattle_1_1_tanh_activation_layer.html#a8376f4a0a7162753dafa16f5c10bb220"> 1937</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_tanh_activation_layer.html#a8376f4a0a7162753dafa16f5c10bb220">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01938"></a><span class="lineno"> 1938</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01939"></a><span class="lineno"> 1939</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01940"></a><span class="lineno"> 1940</span>&#160;        <span class="keyword">auto</span> out = in.tanh();</div><div class="line"><a name="l01941"></a><span class="lineno"> 1941</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l01942"></a><span class="lineno"> 1942</span>&#160;            this-&gt;out = out;</div><div class="line"><a name="l01943"></a><span class="lineno"> 1943</span>&#160;            <span class="keywordflow">return</span> this-&gt;out;</div><div class="line"><a name="l01944"></a><span class="lineno"> 1944</span>&#160;        }</div><div class="line"><a name="l01945"></a><span class="lineno"> 1945</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l01946"></a><span class="lineno"> 1946</span>&#160;    }</div><div class="line"><a name="l01947"></a><span class="lineno"><a class="line" href="classcattle_1_1_tanh_activation_layer.html#ab22a9baac0d6e0285f837b8c8c8f2e07"> 1947</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_tanh_activation_layer.html#ab22a9baac0d6e0285f837b8c8c8f2e07">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01948"></a><span class="lineno"> 1948</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01949"></a><span class="lineno"> 1949</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; out.dimension(0) == out_grad.dimension(0));</div><div class="line"><a name="l01950"></a><span class="lineno"> 1950</span>&#160;        <span class="keywordflow">return</span> (out.constant(1) - out * out) * out_grad;</div><div class="line"><a name="l01951"></a><span class="lineno"> 1951</span>&#160;    }</div><div class="line"><a name="l01952"></a><span class="lineno"> 1952</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01953"></a><span class="lineno"> 1953</span>&#160;    <span class="keyword">typename</span> Root::Data out;</div><div class="line"><a name="l01954"></a><span class="lineno"> 1954</span>&#160;};</div><div class="line"><a name="l01955"></a><span class="lineno"> 1955</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l01956"></a><span class="lineno"> 1956</span>&#160;</div><div class="line"><a name="l01961"></a><span class="lineno"> 1961</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l01962"></a><span class="lineno"> 1962</span>&#160;<span class="keyword">class </span>TanhActivationLayer : <span class="keyword">public</span> ActivationLayer&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l01963"></a><span class="lineno"> 1963</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,Rank&gt; Root;</div><div class="line"><a name="l01964"></a><span class="lineno"> 1964</span>&#160;    <span class="keyword">typedef</span> ActivationLayer&lt;Scalar,Rank&gt; Base;</div><div class="line"><a name="l01965"></a><span class="lineno"> 1965</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l01969"></a><span class="lineno"> 1969</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_tanh_activation_layer.html#a67d44e760962f78b74c182b1b1cf528d">TanhActivationLayer</a>(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; dims) :</div><div class="line"><a name="l01970"></a><span class="lineno"> 1970</span>&#160;            ActivationLayer&lt;Scalar,Rank&gt;::ActivationLayer(dims),</div><div class="line"><a name="l01971"></a><span class="lineno"> 1971</span>&#160;            ext_batch_dims(dims.template extend&lt;3 - Rank&gt;().template promote&lt;&gt;()) { }</div><div class="line"><a name="l01972"></a><span class="lineno"> 1972</span>&#160;    <span class="keyword">inline</span> Layer&lt;Scalar,Rank&gt;* <a class="code" href="classcattle_1_1_tanh_activation_layer.html#a7896bd20f2379a0b2e84390510219482">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l01973"></a><span class="lineno"> 1973</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_tanh_activation_layer.html#a67d44e760962f78b74c182b1b1cf528d">TanhActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l01974"></a><span class="lineno"> 1974</span>&#160;    }</div><div class="line"><a name="l01975"></a><span class="lineno"> 1975</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l01976"></a><span class="lineno"> 1976</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_tanh_activation_layer.html#ad0164a3bcb90574df7b5865e6a3c4a33">empty_cache</a>() {</div><div class="line"><a name="l01977"></a><span class="lineno"> 1977</span>&#160;        in = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l01978"></a><span class="lineno"> 1978</span>&#160;        out = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l01979"></a><span class="lineno"> 1979</span>&#160;    }</div><div class="line"><a name="l01980"></a><span class="lineno"> 1980</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_tanh_activation_layer.html#a8376f4a0a7162753dafa16f5c10bb220">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l01981"></a><span class="lineno"> 1981</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01982"></a><span class="lineno"> 1982</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l01983"></a><span class="lineno"> 1983</span>&#160;        ext_batch_dims[0] = in.dimension(0);</div><div class="line"><a name="l01984"></a><span class="lineno"> 1984</span>&#160;        this-&gt;in = std::move(in);</div><div class="line"><a name="l01985"></a><span class="lineno"> 1985</span>&#160;        out = <span class="keyword">typename</span> Root::Data(this-&gt;in.dimensions());</div><div class="line"><a name="l01986"></a><span class="lineno"> 1986</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a46b5ef9ed5403f8e934dc35038c377c9">activation_fwd</a>(this-&gt;in.data(), ext_batch_dims,</div><div class="line"><a name="l01987"></a><span class="lineno"> 1987</span>&#160;                CUDNN_ACTIVATION_TANH, 0, out.data());</div><div class="line"><a name="l01988"></a><span class="lineno"> 1988</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l01989"></a><span class="lineno"> 1989</span>&#160;    }</div><div class="line"><a name="l01990"></a><span class="lineno"> 1990</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_tanh_activation_layer.html#ab22a9baac0d6e0285f837b8c8c8f2e07">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l01991"></a><span class="lineno"> 1991</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l01992"></a><span class="lineno"> 1992</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; ext_batch_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l01993"></a><span class="lineno"> 1993</span>&#160;        <span class="keyword">typename</span> Root::Data prev_out_grad(in.dimensions());</div><div class="line"><a name="l01994"></a><span class="lineno"> 1994</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#ae958103fd306a6ad9c1e0d50d9e13d57">activation_bwd</a>(in.data(), out.data(), out_grad.data(),</div><div class="line"><a name="l01995"></a><span class="lineno"> 1995</span>&#160;                ext_batch_dims, CUDNN_ACTIVATION_TANH, 0, prev_out_grad.data());</div><div class="line"><a name="l01996"></a><span class="lineno"> 1996</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l01997"></a><span class="lineno"> 1997</span>&#160;    }</div><div class="line"><a name="l01998"></a><span class="lineno"> 1998</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l01999"></a><span class="lineno"> 1999</span>&#160;    std::array&lt;std::size_t,4&gt; ext_batch_dims;</div><div class="line"><a name="l02000"></a><span class="lineno"> 2000</span>&#160;    <span class="keyword">typename</span> Root::Data in;</div><div class="line"><a name="l02001"></a><span class="lineno"> 2001</span>&#160;    <span class="keyword">typename</span> Root::Data out;</div><div class="line"><a name="l02002"></a><span class="lineno"> 2002</span>&#160;};</div><div class="line"><a name="l02003"></a><span class="lineno"> 2003</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l02004"></a><span class="lineno"> 2004</span>&#160;</div><div class="line"><a name="l02011"></a><span class="lineno"> 2011</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02012"></a><span class="lineno"><a class="line" href="classcattle_1_1_softsign_activation_layer.html"> 2012</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_softsign_activation_layer.html">SoftsignActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02013"></a><span class="lineno"> 2013</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l02014"></a><span class="lineno"> 2014</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l02015"></a><span class="lineno"> 2015</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02019"></a><span class="lineno"><a class="line" href="classcattle_1_1_softsign_activation_layer.html#a212ef821664165b0f1e5656bb48b40ee"> 2019</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_softsign_activation_layer.html#a212ef821664165b0f1e5656bb48b40ee">SoftsignActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims) :</div><div class="line"><a name="l02020"></a><span class="lineno"> 2020</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims) { }</div><div class="line"><a name="l02021"></a><span class="lineno"><a class="line" href="classcattle_1_1_softsign_activation_layer.html#a02f3977bb217af6dd52f0dcb63120bcd"> 2021</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_softsign_activation_layer.html#a02f3977bb217af6dd52f0dcb63120bcd">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02022"></a><span class="lineno"> 2022</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_softsign_activation_layer.html#a212ef821664165b0f1e5656bb48b40ee">SoftsignActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02023"></a><span class="lineno"> 2023</span>&#160;    }</div><div class="line"><a name="l02024"></a><span class="lineno"> 2024</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02025"></a><span class="lineno"><a class="line" href="classcattle_1_1_softsign_activation_layer.html#a22932a2f01f7b000cf8e7f58bf81b0ec"> 2025</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_softsign_activation_layer.html#a22932a2f01f7b000cf8e7f58bf81b0ec">empty_cache</a>() {</div><div class="line"><a name="l02026"></a><span class="lineno"> 2026</span>&#160;        denominator = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l02027"></a><span class="lineno"> 2027</span>&#160;    }</div><div class="line"><a name="l02028"></a><span class="lineno"><a class="line" href="classcattle_1_1_softsign_activation_layer.html#ac1c1cf2b0fdcd49fd896c12147995ca1"> 2028</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_softsign_activation_layer.html#ac1c1cf2b0fdcd49fd896c12147995ca1">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02029"></a><span class="lineno"> 2029</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02030"></a><span class="lineno"> 2030</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02031"></a><span class="lineno"> 2031</span>&#160;        <span class="keyword">auto</span> denominator = in.constant(1) + in.abs();</div><div class="line"><a name="l02032"></a><span class="lineno"> 2032</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l02033"></a><span class="lineno"> 2033</span>&#160;            this-&gt;denominator = denominator;</div><div class="line"><a name="l02034"></a><span class="lineno"> 2034</span>&#160;            <span class="keywordflow">return</span> in / this-&gt;denominator;</div><div class="line"><a name="l02035"></a><span class="lineno"> 2035</span>&#160;        }</div><div class="line"><a name="l02036"></a><span class="lineno"> 2036</span>&#160;        <span class="keywordflow">return</span> in / denominator;</div><div class="line"><a name="l02037"></a><span class="lineno"> 2037</span>&#160;    }</div><div class="line"><a name="l02038"></a><span class="lineno"><a class="line" href="classcattle_1_1_softsign_activation_layer.html#a10ece7c1af4ebfdfaf03f2c64b05c2b5"> 2038</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_softsign_activation_layer.html#a10ece7c1af4ebfdfaf03f2c64b05c2b5">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02039"></a><span class="lineno"> 2039</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02040"></a><span class="lineno"> 2040</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; denominator.dimension(0) == out_grad.dimension(0));</div><div class="line"><a name="l02041"></a><span class="lineno"> 2041</span>&#160;        <span class="keywordflow">return</span> denominator.square().inverse() * out_grad;</div><div class="line"><a name="l02042"></a><span class="lineno"> 2042</span>&#160;    }</div><div class="line"><a name="l02043"></a><span class="lineno"> 2043</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02044"></a><span class="lineno"> 2044</span>&#160;    <span class="comment">// Staged computation cache.</span></div><div class="line"><a name="l02045"></a><span class="lineno"> 2045</span>&#160;    <span class="keyword">typename</span> Root::Data denominator;</div><div class="line"><a name="l02046"></a><span class="lineno"> 2046</span>&#160;};</div><div class="line"><a name="l02047"></a><span class="lineno"> 2047</span>&#160;</div><div class="line"><a name="l02054"></a><span class="lineno"> 2054</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02055"></a><span class="lineno"><a class="line" href="classcattle_1_1_softplus_activation_layer.html"> 2055</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_softplus_activation_layer.html">SoftplusActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02056"></a><span class="lineno"> 2056</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l02057"></a><span class="lineno"> 2057</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l02058"></a><span class="lineno"> 2058</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02062"></a><span class="lineno"><a class="line" href="classcattle_1_1_softplus_activation_layer.html#ac1533119d3423aa2130d01eb95b12431"> 2062</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_softplus_activation_layer.html#ac1533119d3423aa2130d01eb95b12431">SoftplusActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims) :</div><div class="line"><a name="l02063"></a><span class="lineno"> 2063</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims) { }</div><div class="line"><a name="l02064"></a><span class="lineno"><a class="line" href="classcattle_1_1_softplus_activation_layer.html#ad3a362dd884f047371f20981cb50dcdd"> 2064</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_softplus_activation_layer.html#ad3a362dd884f047371f20981cb50dcdd">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02065"></a><span class="lineno"> 2065</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_softplus_activation_layer.html#ac1533119d3423aa2130d01eb95b12431">SoftplusActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02066"></a><span class="lineno"> 2066</span>&#160;    }</div><div class="line"><a name="l02067"></a><span class="lineno"> 2067</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02068"></a><span class="lineno"><a class="line" href="classcattle_1_1_softplus_activation_layer.html#a751103bc7ec61c943727e81e60a495c1"> 2068</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_softplus_activation_layer.html#a751103bc7ec61c943727e81e60a495c1">empty_cache</a>() {</div><div class="line"><a name="l02069"></a><span class="lineno"> 2069</span>&#160;        in = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l02070"></a><span class="lineno"> 2070</span>&#160;    }</div><div class="line"><a name="l02071"></a><span class="lineno"><a class="line" href="classcattle_1_1_softplus_activation_layer.html#a4cff59f6b0eab448d9ca41ba99261c31"> 2071</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_softplus_activation_layer.html#a4cff59f6b0eab448d9ca41ba99261c31">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02072"></a><span class="lineno"> 2072</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02073"></a><span class="lineno"> 2073</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02074"></a><span class="lineno"> 2074</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l02075"></a><span class="lineno"> 2075</span>&#160;            this-&gt;in = std::move(in);</div><div class="line"><a name="l02076"></a><span class="lineno"> 2076</span>&#160;            <span class="keywordflow">return</span> (this-&gt;in.exp() + this-&gt;in.constant(1)).log();</div><div class="line"><a name="l02077"></a><span class="lineno"> 2077</span>&#160;        }</div><div class="line"><a name="l02078"></a><span class="lineno"> 2078</span>&#160;        <span class="keywordflow">return</span> (in.exp() + in.constant(1)).log();</div><div class="line"><a name="l02079"></a><span class="lineno"> 2079</span>&#160;    }</div><div class="line"><a name="l02080"></a><span class="lineno"><a class="line" href="classcattle_1_1_softplus_activation_layer.html#a93b157a4de8aad27a722f9acb5e6aaff"> 2080</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_softplus_activation_layer.html#a93b157a4de8aad27a722f9acb5e6aaff">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02081"></a><span class="lineno"> 2081</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02082"></a><span class="lineno"> 2082</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; in.dimension(0) == out_grad.dimension(0));</div><div class="line"><a name="l02083"></a><span class="lineno"> 2083</span>&#160;        <span class="keywordflow">return</span> ((-in).exp() + in.constant(1)).inverse() * out_grad;</div><div class="line"><a name="l02084"></a><span class="lineno"> 2084</span>&#160;    }</div><div class="line"><a name="l02085"></a><span class="lineno"> 2085</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02086"></a><span class="lineno"> 2086</span>&#160;    <span class="comment">// Staged computation cache.</span></div><div class="line"><a name="l02087"></a><span class="lineno"> 2087</span>&#160;    <span class="keyword">typename</span> Root::Data in;</div><div class="line"><a name="l02088"></a><span class="lineno"> 2088</span>&#160;};</div><div class="line"><a name="l02089"></a><span class="lineno"> 2089</span>&#160;</div><div class="line"><a name="l02090"></a><span class="lineno"> 2090</span>&#160;<span class="preprocessor">#ifndef CATTL3_USE_CUDNN</span></div><div class="line"><a name="l02091"></a><span class="lineno"> 2091</span>&#160;</div><div class="line"><a name="l02099"></a><span class="lineno"> 2099</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02100"></a><span class="lineno"><a class="line" href="classcattle_1_1_softmax_activation_layer.html"> 2100</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_softmax_activation_layer.html">SoftmaxActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02101"></a><span class="lineno"> 2101</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l02102"></a><span class="lineno"> 2102</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l02103"></a><span class="lineno"> 2103</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,Root::DATA_RANK&gt; RankwiseArray;</div><div class="line"><a name="l02104"></a><span class="lineno"> 2104</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02109"></a><span class="lineno"><a class="line" href="classcattle_1_1_softmax_activation_layer.html#a2a8be6bee1fb6cf884f4f2d3f613257a"> 2109</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a2a8be6bee1fb6cf884f4f2d3f613257a">SoftmaxActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims, Scalar epsilon = <a class="code" href="classcattle_1_1internal_1_1_numeric_utils.html">internal::NumericUtils&lt;Scalar&gt;::EPSILON2</a>) :</div><div class="line"><a name="l02110"></a><span class="lineno"> 2110</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims),</div><div class="line"><a name="l02111"></a><span class="lineno"> 2111</span>&#160;            epsilon(epsilon),</div><div class="line"><a name="l02112"></a><span class="lineno"> 2112</span>&#160;            conversion_dims(dims.template promote&lt;&gt;()) { }</div><div class="line"><a name="l02113"></a><span class="lineno"><a class="line" href="classcattle_1_1_softmax_activation_layer.html#a970361710856c4497c4bb8fd6f1e9ac9"> 2113</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a970361710856c4497c4bb8fd6f1e9ac9">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02114"></a><span class="lineno"> 2114</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a2a8be6bee1fb6cf884f4f2d3f613257a">SoftmaxActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02115"></a><span class="lineno"> 2115</span>&#160;    }</div><div class="line"><a name="l02116"></a><span class="lineno"> 2116</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02117"></a><span class="lineno"><a class="line" href="classcattle_1_1_softmax_activation_layer.html#a7c642043ac4d852b0a6b7373c57a2206"> 2117</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a7c642043ac4d852b0a6b7373c57a2206">empty_cache</a>() {</div><div class="line"><a name="l02118"></a><span class="lineno"> 2118</span>&#160;        out = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(0, 0);</div><div class="line"><a name="l02119"></a><span class="lineno"> 2119</span>&#160;    }</div><div class="line"><a name="l02120"></a><span class="lineno"><a class="line" href="classcattle_1_1_softmax_activation_layer.html#a627e9ccac859cacac5e7ade52be93142"> 2120</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a627e9ccac859cacac5e7ade52be93142">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02121"></a><span class="lineno"> 2121</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02122"></a><span class="lineno"> 2122</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02123"></a><span class="lineno"> 2123</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l02124"></a><span class="lineno"> 2124</span>&#160;        <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> in_mat(in.data(), rows, in.size() / rows);</div><div class="line"><a name="l02125"></a><span class="lineno"> 2125</span>&#160;        <span class="comment">/* First subtract the value of the greatest coefficient from each element row-wise</span></div><div class="line"><a name="l02126"></a><span class="lineno"> 2126</span>&#160;<span class="comment">         * to avoid an overflow due to raising e to great powers. */</span></div><div class="line"><a name="l02127"></a><span class="lineno"> 2127</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> act = (in_mat.array().colwise() - in_mat.array().rowwise().maxCoeff()).exp();</div><div class="line"><a name="l02128"></a><span class="lineno"> 2128</span>&#160;        act = act.array().colwise() / (act.array().rowwise().sum() + epsilon);</div><div class="line"><a name="l02129"></a><span class="lineno"> 2129</span>&#160;        conversion_dims[0] = rows;</div><div class="line"><a name="l02130"></a><span class="lineno"> 2130</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l02131"></a><span class="lineno"> 2131</span>&#160;            out = std::move(act);</div><div class="line"><a name="l02132"></a><span class="lineno"> 2132</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Root::DATA_RANK&gt;</a>(out.data(), conversion_dims);</div><div class="line"><a name="l02133"></a><span class="lineno"> 2133</span>&#160;        }</div><div class="line"><a name="l02134"></a><span class="lineno"> 2134</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Root::DATA_RANK&gt;</a>(act.data(), conversion_dims);</div><div class="line"><a name="l02135"></a><span class="lineno"> 2135</span>&#160;    }</div><div class="line"><a name="l02136"></a><span class="lineno"><a class="line" href="classcattle_1_1_softmax_activation_layer.html#a8ccc8f03783ec2791aabf328ebcc855e"> 2136</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a8ccc8f03783ec2791aabf328ebcc855e">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02137"></a><span class="lineno"> 2137</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02138"></a><span class="lineno"> 2138</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; out.rows() == out_grad.dimension(0));</div><div class="line"><a name="l02139"></a><span class="lineno"> 2139</span>&#160;        std::size_t rows = out_grad.dimension(0);</div><div class="line"><a name="l02140"></a><span class="lineno"> 2140</span>&#160;        <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> out_grad_mat(out_grad.data(), rows, out_grad.size() / rows);</div><div class="line"><a name="l02141"></a><span class="lineno"> 2141</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> prev_out_grad(out.rows(), out.cols());</div><div class="line"><a name="l02142"></a><span class="lineno"> 2142</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; prev_out_grad.rows(); ++i) {</div><div class="line"><a name="l02143"></a><span class="lineno"> 2143</span>&#160;            <a class="code" href="namespacecattle.html#a23ebf4fefd4f6b9dc0cd34afb1ce1b65">RowVector&lt;Scalar&gt;</a> row_i = out.row(i);</div><div class="line"><a name="l02144"></a><span class="lineno"> 2144</span>&#160;            <span class="comment">// FIXME Do not evaluate the expressions into a temporary variable.</span></div><div class="line"><a name="l02145"></a><span class="lineno"> 2145</span>&#160;            <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> jacobian = row_i.asDiagonal();</div><div class="line"><a name="l02146"></a><span class="lineno"> 2146</span>&#160;            jacobian -= row_i.transpose() * row_i;</div><div class="line"><a name="l02147"></a><span class="lineno"> 2147</span>&#160;            prev_out_grad.row(i) = out_grad_mat.row(i) * jacobian;</div><div class="line"><a name="l02148"></a><span class="lineno"> 2148</span>&#160;        }</div><div class="line"><a name="l02149"></a><span class="lineno"> 2149</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Root::DATA_RANK&gt;</a>(prev_out_grad.data(), conversion_dims);</div><div class="line"><a name="l02150"></a><span class="lineno"> 2150</span>&#160;    }</div><div class="line"><a name="l02151"></a><span class="lineno"> 2151</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02152"></a><span class="lineno"> 2152</span>&#160;    <span class="keyword">const</span> Scalar epsilon;</div><div class="line"><a name="l02153"></a><span class="lineno"> 2153</span>&#160;    RankwiseArray conversion_dims;</div><div class="line"><a name="l02154"></a><span class="lineno"> 2154</span>&#160;    <span class="comment">// Staged computation cache matrix.</span></div><div class="line"><a name="l02155"></a><span class="lineno"> 2155</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out;</div><div class="line"><a name="l02156"></a><span class="lineno"> 2156</span>&#160;};</div><div class="line"><a name="l02157"></a><span class="lineno"> 2157</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l02158"></a><span class="lineno"> 2158</span>&#160;</div><div class="line"><a name="l02166"></a><span class="lineno"> 2166</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02167"></a><span class="lineno"> 2167</span>&#160;<span class="keyword">class </span>SoftmaxActivationLayer : <span class="keyword">public</span> ActivationLayer&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02168"></a><span class="lineno"> 2168</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,Rank&gt; Root;</div><div class="line"><a name="l02169"></a><span class="lineno"> 2169</span>&#160;    <span class="keyword">typedef</span> ActivationLayer&lt;Scalar,Rank&gt; Base;</div><div class="line"><a name="l02170"></a><span class="lineno"> 2170</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02174"></a><span class="lineno"> 2174</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a2a8be6bee1fb6cf884f4f2d3f613257a">SoftmaxActivationLayer</a>(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; dims) :</div><div class="line"><a name="l02175"></a><span class="lineno"> 2175</span>&#160;            ActivationLayer&lt;Scalar,Rank&gt;::ActivationLayer(dims),</div><div class="line"><a name="l02176"></a><span class="lineno"> 2176</span>&#160;            ext_batch_dims(dims.template extend&lt;3 - Rank&gt;().template promote&lt;&gt;()) { }</div><div class="line"><a name="l02177"></a><span class="lineno"> 2177</span>&#160;    <span class="keyword">inline</span> Layer&lt;Scalar,Rank&gt;* <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a970361710856c4497c4bb8fd6f1e9ac9">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02178"></a><span class="lineno"> 2178</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a2a8be6bee1fb6cf884f4f2d3f613257a">SoftmaxActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02179"></a><span class="lineno"> 2179</span>&#160;    }</div><div class="line"><a name="l02180"></a><span class="lineno"> 2180</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02181"></a><span class="lineno"> 2181</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a7c642043ac4d852b0a6b7373c57a2206">empty_cache</a>() {</div><div class="line"><a name="l02182"></a><span class="lineno"> 2182</span>&#160;        out = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l02183"></a><span class="lineno"> 2183</span>&#160;    }</div><div class="line"><a name="l02184"></a><span class="lineno"> 2184</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a627e9ccac859cacac5e7ade52be93142">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02185"></a><span class="lineno"> 2185</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02186"></a><span class="lineno"> 2186</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02187"></a><span class="lineno"> 2187</span>&#160;        ext_batch_dims[0] = in.dimension(0);</div><div class="line"><a name="l02188"></a><span class="lineno"> 2188</span>&#160;        out = <span class="keyword">typename</span> Root::Data(in.dimensions());</div><div class="line"><a name="l02189"></a><span class="lineno"> 2189</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#ae6ca224fc2b1b651fa8076e95b477cad">softmax_fwd</a>(in.data(), ext_batch_dims, out.data());</div><div class="line"><a name="l02190"></a><span class="lineno"> 2190</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l02191"></a><span class="lineno"> 2191</span>&#160;    }</div><div class="line"><a name="l02192"></a><span class="lineno"> 2192</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_softmax_activation_layer.html#a8ccc8f03783ec2791aabf328ebcc855e">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02193"></a><span class="lineno"> 2193</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02194"></a><span class="lineno"> 2194</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; ext_batch_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l02195"></a><span class="lineno"> 2195</span>&#160;        <span class="keyword">typename</span> Root::Data prev_out_grad(out_grad.dimensions());</div><div class="line"><a name="l02196"></a><span class="lineno"> 2196</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a2da9235cdf411aa8c37c6a5554bc415d">softmax_bwd</a>(out.data(), out_grad.data(), ext_batch_dims,</div><div class="line"><a name="l02197"></a><span class="lineno"> 2197</span>&#160;                prev_out_grad.data());</div><div class="line"><a name="l02198"></a><span class="lineno"> 2198</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l02199"></a><span class="lineno"> 2199</span>&#160;    }</div><div class="line"><a name="l02200"></a><span class="lineno"> 2200</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02201"></a><span class="lineno"> 2201</span>&#160;    std::array&lt;std::size_t,4&gt; ext_batch_dims;</div><div class="line"><a name="l02202"></a><span class="lineno"> 2202</span>&#160;    <span class="keyword">typename</span> Root::Data out;</div><div class="line"><a name="l02203"></a><span class="lineno"> 2203</span>&#160;};</div><div class="line"><a name="l02204"></a><span class="lineno"> 2204</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l02205"></a><span class="lineno"> 2205</span>&#160;</div><div class="line"><a name="l02206"></a><span class="lineno"> 2206</span>&#160;<span class="preprocessor">#ifndef CATTL3_USE_CUDNN</span></div><div class="line"><a name="l02207"></a><span class="lineno"> 2207</span>&#160;</div><div class="line"><a name="l02218"></a><span class="lineno"> 2218</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02219"></a><span class="lineno"><a class="line" href="classcattle_1_1_re_l_u_activation_layer.html"> 2219</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_re_l_u_activation_layer.html">ReLUActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02220"></a><span class="lineno"> 2220</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l02221"></a><span class="lineno"> 2221</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l02222"></a><span class="lineno"> 2222</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02226"></a><span class="lineno"><a class="line" href="classcattle_1_1_re_l_u_activation_layer.html#a413bba29e917c3de534cf9fcf7f85d11"> 2226</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#a413bba29e917c3de534cf9fcf7f85d11">ReLUActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims) :</div><div class="line"><a name="l02227"></a><span class="lineno"> 2227</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims) { }</div><div class="line"><a name="l02228"></a><span class="lineno"><a class="line" href="classcattle_1_1_re_l_u_activation_layer.html#a9f15affc9a835583ed6745496b1dd0c7"> 2228</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#a9f15affc9a835583ed6745496b1dd0c7">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02229"></a><span class="lineno"> 2229</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#a413bba29e917c3de534cf9fcf7f85d11">ReLUActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02230"></a><span class="lineno"> 2230</span>&#160;    }</div><div class="line"><a name="l02231"></a><span class="lineno"> 2231</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02232"></a><span class="lineno"><a class="line" href="classcattle_1_1_re_l_u_activation_layer.html#ad9fecbc7c7a552e89eae61034ad89cf9"> 2232</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#ad9fecbc7c7a552e89eae61034ad89cf9">empty_cache</a>() {</div><div class="line"><a name="l02233"></a><span class="lineno"> 2233</span>&#160;        in = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l02234"></a><span class="lineno"> 2234</span>&#160;    }</div><div class="line"><a name="l02235"></a><span class="lineno"><a class="line" href="classcattle_1_1_re_l_u_activation_layer.html#ae53d86eece7966ace131af941bb6e095"> 2235</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#ae53d86eece7966ace131af941bb6e095">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02236"></a><span class="lineno"> 2236</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02237"></a><span class="lineno"> 2237</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02238"></a><span class="lineno"> 2238</span>&#160;        <span class="keywordflow">if</span> (training)</div><div class="line"><a name="l02239"></a><span class="lineno"> 2239</span>&#160;            this-&gt;in = in;</div><div class="line"><a name="l02240"></a><span class="lineno"> 2240</span>&#160;        <span class="keywordflow">return</span> in.cwiseMax((Scalar) 0);</div><div class="line"><a name="l02241"></a><span class="lineno"> 2241</span>&#160;    }</div><div class="line"><a name="l02242"></a><span class="lineno"><a class="line" href="classcattle_1_1_re_l_u_activation_layer.html#a3f50854f7aaf891eccf373b8f70cb3d7"> 2242</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#a3f50854f7aaf891eccf373b8f70cb3d7">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02243"></a><span class="lineno"> 2243</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02244"></a><span class="lineno"> 2244</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; in.dimension(0) == out_grad.dimension(0));</div><div class="line"><a name="l02245"></a><span class="lineno"> 2245</span>&#160;        <span class="keywordflow">return</span> in.unaryExpr([](Scalar i) { <span class="keywordflow">return</span> (Scalar) (i &gt;= 0); }) * out_grad;</div><div class="line"><a name="l02246"></a><span class="lineno"> 2246</span>&#160;    }</div><div class="line"><a name="l02247"></a><span class="lineno"> 2247</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02248"></a><span class="lineno"> 2248</span>&#160;    <span class="keyword">typename</span> Root::Data in;</div><div class="line"><a name="l02249"></a><span class="lineno"> 2249</span>&#160;};</div><div class="line"><a name="l02250"></a><span class="lineno"> 2250</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l02251"></a><span class="lineno"> 2251</span>&#160;</div><div class="line"><a name="l02262"></a><span class="lineno"> 2262</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02263"></a><span class="lineno"> 2263</span>&#160;<span class="keyword">class </span>ReLUActivationLayer : <span class="keyword">public</span> ActivationLayer&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02264"></a><span class="lineno"> 2264</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,Rank&gt; Root;</div><div class="line"><a name="l02265"></a><span class="lineno"> 2265</span>&#160;    <span class="keyword">typedef</span> ActivationLayer&lt;Scalar,Rank&gt; Base;</div><div class="line"><a name="l02266"></a><span class="lineno"> 2266</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02270"></a><span class="lineno"> 2270</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#a413bba29e917c3de534cf9fcf7f85d11">ReLUActivationLayer</a>(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; dims) :</div><div class="line"><a name="l02271"></a><span class="lineno"> 2271</span>&#160;            ActivationLayer&lt;Scalar,Rank&gt;::ActivationLayer(dims),</div><div class="line"><a name="l02272"></a><span class="lineno"> 2272</span>&#160;            ext_batch_dims(dims.template extend&lt;3 - Rank&gt;().template promote&lt;&gt;()) { }</div><div class="line"><a name="l02273"></a><span class="lineno"> 2273</span>&#160;    <span class="keyword">inline</span> Layer&lt;Scalar,Rank&gt;* <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#a9f15affc9a835583ed6745496b1dd0c7">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02274"></a><span class="lineno"> 2274</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#a413bba29e917c3de534cf9fcf7f85d11">ReLUActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02275"></a><span class="lineno"> 2275</span>&#160;    }</div><div class="line"><a name="l02276"></a><span class="lineno"> 2276</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02277"></a><span class="lineno"> 2277</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#ad9fecbc7c7a552e89eae61034ad89cf9">empty_cache</a>() {</div><div class="line"><a name="l02278"></a><span class="lineno"> 2278</span>&#160;        in = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l02279"></a><span class="lineno"> 2279</span>&#160;        out = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l02280"></a><span class="lineno"> 2280</span>&#160;    }</div><div class="line"><a name="l02281"></a><span class="lineno"> 2281</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#ae53d86eece7966ace131af941bb6e095">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02282"></a><span class="lineno"> 2282</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02283"></a><span class="lineno"> 2283</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02284"></a><span class="lineno"> 2284</span>&#160;        ext_batch_dims[0] = in.dimension(0);</div><div class="line"><a name="l02285"></a><span class="lineno"> 2285</span>&#160;        this-&gt;in = std::move(in);</div><div class="line"><a name="l02286"></a><span class="lineno"> 2286</span>&#160;        out = <span class="keyword">typename</span> Root::Data(this-&gt;in.dimensions());</div><div class="line"><a name="l02287"></a><span class="lineno"> 2287</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a46b5ef9ed5403f8e934dc35038c377c9">activation_fwd</a>(this-&gt;in.data(), ext_batch_dims,</div><div class="line"><a name="l02288"></a><span class="lineno"> 2288</span>&#160;                CUDNN_ACTIVATION_RELU, 0, out.data());</div><div class="line"><a name="l02289"></a><span class="lineno"> 2289</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l02290"></a><span class="lineno"> 2290</span>&#160;    }</div><div class="line"><a name="l02291"></a><span class="lineno"> 2291</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_re_l_u_activation_layer.html#a3f50854f7aaf891eccf373b8f70cb3d7">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02292"></a><span class="lineno"> 2292</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02293"></a><span class="lineno"> 2293</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; ext_batch_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l02294"></a><span class="lineno"> 2294</span>&#160;        <span class="keyword">typename</span> Root::Data prev_out_grad(in.dimensions());</div><div class="line"><a name="l02295"></a><span class="lineno"> 2295</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#ae958103fd306a6ad9c1e0d50d9e13d57">activation_bwd</a>(in.data(), out.data(), out_grad.data(),</div><div class="line"><a name="l02296"></a><span class="lineno"> 2296</span>&#160;                ext_batch_dims, CUDNN_ACTIVATION_RELU, 0, prev_out_grad.data());</div><div class="line"><a name="l02297"></a><span class="lineno"> 2297</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l02298"></a><span class="lineno"> 2298</span>&#160;    }</div><div class="line"><a name="l02299"></a><span class="lineno"> 2299</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02300"></a><span class="lineno"> 2300</span>&#160;    std::array&lt;std::size_t,4&gt; ext_batch_dims;</div><div class="line"><a name="l02301"></a><span class="lineno"> 2301</span>&#160;    <span class="keyword">typename</span> Root::Data in;</div><div class="line"><a name="l02302"></a><span class="lineno"> 2302</span>&#160;    <span class="keyword">typename</span> Root::Data out;</div><div class="line"><a name="l02303"></a><span class="lineno"> 2303</span>&#160;};</div><div class="line"><a name="l02304"></a><span class="lineno"> 2304</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l02305"></a><span class="lineno"> 2305</span>&#160;</div><div class="line"><a name="l02320"></a><span class="lineno"> 2320</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02321"></a><span class="lineno"><a class="line" href="classcattle_1_1_leaky_re_l_u_activation_layer.html"> 2321</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_leaky_re_l_u_activation_layer.html">LeakyReLUActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02322"></a><span class="lineno"> 2322</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l02323"></a><span class="lineno"> 2323</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l02324"></a><span class="lineno"> 2324</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02329"></a><span class="lineno"><a class="line" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#ab2363872da292de34c35c3983d5b97ee"> 2329</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#ab2363872da292de34c35c3983d5b97ee">LeakyReLUActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims, Scalar alpha = 1e-1) :</div><div class="line"><a name="l02330"></a><span class="lineno"> 2330</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims),</div><div class="line"><a name="l02331"></a><span class="lineno"> 2331</span>&#160;            alpha(alpha) { }</div><div class="line"><a name="l02332"></a><span class="lineno"><a class="line" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#a82d876e1484fd0e695ad72eb20ccadc4"> 2332</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#a82d876e1484fd0e695ad72eb20ccadc4">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02333"></a><span class="lineno"> 2333</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#ab2363872da292de34c35c3983d5b97ee">LeakyReLUActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02334"></a><span class="lineno"> 2334</span>&#160;    }</div><div class="line"><a name="l02335"></a><span class="lineno"> 2335</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02336"></a><span class="lineno"><a class="line" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#a3ca83e1f497e8d9e07dd043fecf9cd10"> 2336</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#a3ca83e1f497e8d9e07dd043fecf9cd10">empty_cache</a>() {</div><div class="line"><a name="l02337"></a><span class="lineno"> 2337</span>&#160;        in = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l02338"></a><span class="lineno"> 2338</span>&#160;    }</div><div class="line"><a name="l02339"></a><span class="lineno"><a class="line" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#aa9ac55adebb9725a86db28ed148d22f0"> 2339</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#aa9ac55adebb9725a86db28ed148d22f0">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02340"></a><span class="lineno"> 2340</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02341"></a><span class="lineno"> 2341</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02342"></a><span class="lineno"> 2342</span>&#160;        <span class="keywordflow">if</span> (training)</div><div class="line"><a name="l02343"></a><span class="lineno"> 2343</span>&#160;            this-&gt;in = in;</div><div class="line"><a name="l02344"></a><span class="lineno"> 2344</span>&#160;        <span class="keywordflow">return</span> in.cwiseMax(in * alpha);</div><div class="line"><a name="l02345"></a><span class="lineno"> 2345</span>&#160;    }</div><div class="line"><a name="l02346"></a><span class="lineno"><a class="line" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#aea6e407de7b9a8c3dd366e6f89823bc4"> 2346</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#aea6e407de7b9a8c3dd366e6f89823bc4">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02347"></a><span class="lineno"> 2347</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02348"></a><span class="lineno"> 2348</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; in.dimension(0) == out_grad.dimension(0));</div><div class="line"><a name="l02349"></a><span class="lineno"> 2349</span>&#160;        <span class="keywordflow">return</span> in.unaryExpr([<span class="keyword">this</span>](Scalar i) { <span class="keywordflow">return</span> (Scalar) (i &gt;= 0 ? 1 : alpha); }) * out_grad;</div><div class="line"><a name="l02350"></a><span class="lineno"> 2350</span>&#160;    }</div><div class="line"><a name="l02351"></a><span class="lineno"> 2351</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02352"></a><span class="lineno"> 2352</span>&#160;    <span class="keyword">const</span> Scalar alpha;</div><div class="line"><a name="l02353"></a><span class="lineno"> 2353</span>&#160;    <span class="keyword">typename</span> Root::Data in;</div><div class="line"><a name="l02354"></a><span class="lineno"> 2354</span>&#160;};</div><div class="line"><a name="l02355"></a><span class="lineno"> 2355</span>&#160;</div><div class="line"><a name="l02356"></a><span class="lineno"> 2356</span>&#160;<span class="preprocessor">#ifndef CATTL3_USE_CUDNN</span></div><div class="line"><a name="l02357"></a><span class="lineno"> 2357</span>&#160;</div><div class="line"><a name="l02371"></a><span class="lineno"> 2371</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02372"></a><span class="lineno"><a class="line" href="classcattle_1_1_e_l_u_activation_layer.html"> 2372</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_e_l_u_activation_layer.html">ELUActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02373"></a><span class="lineno"> 2373</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l02374"></a><span class="lineno"> 2374</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l02375"></a><span class="lineno"> 2375</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,Root::DATA_RANK&gt; RankwiseArray;</div><div class="line"><a name="l02376"></a><span class="lineno"> 2376</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02381"></a><span class="lineno"><a class="line" href="classcattle_1_1_e_l_u_activation_layer.html#a4f95c5a7dab61b50bf2c55304a253f14"> 2381</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#a4f95c5a7dab61b50bf2c55304a253f14">ELUActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims, Scalar alpha = 1e-1) :</div><div class="line"><a name="l02382"></a><span class="lineno"> 2382</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims),</div><div class="line"><a name="l02383"></a><span class="lineno"> 2383</span>&#160;            alpha(alpha),</div><div class="line"><a name="l02384"></a><span class="lineno"> 2384</span>&#160;            conversion_dims(dims.template promote&lt;&gt;()) { }</div><div class="line"><a name="l02385"></a><span class="lineno"><a class="line" href="classcattle_1_1_e_l_u_activation_layer.html#aa8542434a8430319aaa149363151e777"> 2385</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#aa8542434a8430319aaa149363151e777">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02386"></a><span class="lineno"> 2386</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#a4f95c5a7dab61b50bf2c55304a253f14">ELUActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02387"></a><span class="lineno"> 2387</span>&#160;    }</div><div class="line"><a name="l02388"></a><span class="lineno"> 2388</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02389"></a><span class="lineno"><a class="line" href="classcattle_1_1_e_l_u_activation_layer.html#a04933fe8b46478f608062e88ac549ed9"> 2389</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#a04933fe8b46478f608062e88ac549ed9">empty_cache</a>() {</div><div class="line"><a name="l02390"></a><span class="lineno"> 2390</span>&#160;        in = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(0, 0);</div><div class="line"><a name="l02391"></a><span class="lineno"> 2391</span>&#160;        out = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(0, 0);</div><div class="line"><a name="l02392"></a><span class="lineno"> 2392</span>&#160;    }</div><div class="line"><a name="l02393"></a><span class="lineno"><a class="line" href="classcattle_1_1_e_l_u_activation_layer.html#a67800526be3ccda15d3b5c6f8c2d4f2e"> 2393</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#a67800526be3ccda15d3b5c6f8c2d4f2e">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02394"></a><span class="lineno"> 2394</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02395"></a><span class="lineno"> 2395</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02396"></a><span class="lineno"> 2396</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l02397"></a><span class="lineno"> 2397</span>&#160;            this-&gt;in = <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a>(in.data(), in.dimension(0), Base::dims.get_volume());</div><div class="line"><a name="l02398"></a><span class="lineno"> 2398</span>&#160;            out = this-&gt;in.unaryExpr([<span class="keyword">this</span>](Scalar i) {</div><div class="line"><a name="l02399"></a><span class="lineno"> 2399</span>&#160;                <span class="keywordflow">return</span> (Scalar) (i &gt;= 0 ? i : (alpha * (exp(i) - 1)));</div><div class="line"><a name="l02400"></a><span class="lineno"> 2400</span>&#160;            });</div><div class="line"><a name="l02401"></a><span class="lineno"> 2401</span>&#160;            conversion_dims[0] = out.rows();</div><div class="line"><a name="l02402"></a><span class="lineno"> 2402</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Root::DATA_RANK&gt;</a>(out.data(), conversion_dims);</div><div class="line"><a name="l02403"></a><span class="lineno"> 2403</span>&#160;        }</div><div class="line"><a name="l02404"></a><span class="lineno"> 2404</span>&#160;        <span class="keywordflow">return</span> in.unaryExpr([<span class="keyword">this</span>](Scalar i) { <span class="keywordflow">return</span> (Scalar) (i &gt;= 0 ? i : (alpha * (exp(i) - 1))); });</div><div class="line"><a name="l02405"></a><span class="lineno"> 2405</span>&#160;    }</div><div class="line"><a name="l02406"></a><span class="lineno"><a class="line" href="classcattle_1_1_e_l_u_activation_layer.html#a712f1ee68d924b13db82dce302ba2b20"> 2406</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#a712f1ee68d924b13db82dce302ba2b20">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02407"></a><span class="lineno"> 2407</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02408"></a><span class="lineno"> 2408</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; conversion_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l02409"></a><span class="lineno"> 2409</span>&#160;        <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> out_grad_mat(out_grad.data(), conversion_dims[0], Base::dims.get_volume());</div><div class="line"><a name="l02410"></a><span class="lineno"> 2410</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> prev_out_grad(in.rows(), in.cols());</div><div class="line"><a name="l02411"></a><span class="lineno"> 2411</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; in.cols(); ++i) {</div><div class="line"><a name="l02412"></a><span class="lineno"> 2412</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; in.rows(); ++j)</div><div class="line"><a name="l02413"></a><span class="lineno"> 2413</span>&#160;                prev_out_grad(j,i) = (Scalar) ((in(j,i) &gt;= 0 ? 1 : (out(j,i) + alpha)) * out_grad_mat(j,i));</div><div class="line"><a name="l02414"></a><span class="lineno"> 2414</span>&#160;        }</div><div class="line"><a name="l02415"></a><span class="lineno"> 2415</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Root::DATA_RANK&gt;</a>(prev_out_grad.data(), conversion_dims);</div><div class="line"><a name="l02416"></a><span class="lineno"> 2416</span>&#160;    }</div><div class="line"><a name="l02417"></a><span class="lineno"> 2417</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02418"></a><span class="lineno"> 2418</span>&#160;    <span class="keyword">const</span> Scalar alpha;</div><div class="line"><a name="l02419"></a><span class="lineno"> 2419</span>&#160;    RankwiseArray conversion_dims;</div><div class="line"><a name="l02420"></a><span class="lineno"> 2420</span>&#160;    <span class="comment">// Staged computation caches.</span></div><div class="line"><a name="l02421"></a><span class="lineno"> 2421</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> in;</div><div class="line"><a name="l02422"></a><span class="lineno"> 2422</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out;</div><div class="line"><a name="l02423"></a><span class="lineno"> 2423</span>&#160;};</div><div class="line"><a name="l02424"></a><span class="lineno"> 2424</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l02425"></a><span class="lineno"> 2425</span>&#160;</div><div class="line"><a name="l02439"></a><span class="lineno"> 2439</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02440"></a><span class="lineno"> 2440</span>&#160;<span class="keyword">class </span>ELUActivationLayer : <span class="keyword">public</span> ActivationLayer&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02441"></a><span class="lineno"> 2441</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,Rank&gt; Root;</div><div class="line"><a name="l02442"></a><span class="lineno"> 2442</span>&#160;    <span class="keyword">typedef</span> ActivationLayer&lt;Scalar,Rank&gt; Base;</div><div class="line"><a name="l02443"></a><span class="lineno"> 2443</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02448"></a><span class="lineno"> 2448</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#a4f95c5a7dab61b50bf2c55304a253f14">ELUActivationLayer</a>(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; dims, Scalar alpha = 1e-1) :</div><div class="line"><a name="l02449"></a><span class="lineno"> 2449</span>&#160;            ActivationLayer&lt;Scalar,Rank&gt;::ActivationLayer(dims),</div><div class="line"><a name="l02450"></a><span class="lineno"> 2450</span>&#160;            alpha(alpha),</div><div class="line"><a name="l02451"></a><span class="lineno"> 2451</span>&#160;            ext_batch_dims(dims.template extend&lt;3 - Rank&gt;().template promote&lt;&gt;()) { }</div><div class="line"><a name="l02452"></a><span class="lineno"> 2452</span>&#160;    <span class="keyword">inline</span> Layer&lt;Scalar,Rank&gt;* <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#aa8542434a8430319aaa149363151e777">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02453"></a><span class="lineno"> 2453</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#a4f95c5a7dab61b50bf2c55304a253f14">ELUActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02454"></a><span class="lineno"> 2454</span>&#160;    }</div><div class="line"><a name="l02455"></a><span class="lineno"> 2455</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02456"></a><span class="lineno"> 2456</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#a04933fe8b46478f608062e88ac549ed9">empty_cache</a>() {</div><div class="line"><a name="l02457"></a><span class="lineno"> 2457</span>&#160;        in = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l02458"></a><span class="lineno"> 2458</span>&#160;        out = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l02459"></a><span class="lineno"> 2459</span>&#160;    }</div><div class="line"><a name="l02460"></a><span class="lineno"> 2460</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#a67800526be3ccda15d3b5c6f8c2d4f2e">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02461"></a><span class="lineno"> 2461</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02462"></a><span class="lineno"> 2462</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02463"></a><span class="lineno"> 2463</span>&#160;        ext_batch_dims[0] = in.dimension(0);</div><div class="line"><a name="l02464"></a><span class="lineno"> 2464</span>&#160;        this-&gt;in = std::move(in);</div><div class="line"><a name="l02465"></a><span class="lineno"> 2465</span>&#160;        out = <span class="keyword">typename</span> Root::Data(this-&gt;in.dimensions());</div><div class="line"><a name="l02466"></a><span class="lineno"> 2466</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a46b5ef9ed5403f8e934dc35038c377c9">activation_fwd</a>(this-&gt;in.data(), ext_batch_dims,</div><div class="line"><a name="l02467"></a><span class="lineno"> 2467</span>&#160;                CUDNN_ACTIVATION_ELU, alpha, out.data());</div><div class="line"><a name="l02468"></a><span class="lineno"> 2468</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l02469"></a><span class="lineno"> 2469</span>&#160;    }</div><div class="line"><a name="l02470"></a><span class="lineno"> 2470</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_e_l_u_activation_layer.html#a712f1ee68d924b13db82dce302ba2b20">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02471"></a><span class="lineno"> 2471</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02472"></a><span class="lineno"> 2472</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; ext_batch_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l02473"></a><span class="lineno"> 2473</span>&#160;        <span class="keyword">typename</span> Root::Data prev_out_grad(in.dimensions());</div><div class="line"><a name="l02474"></a><span class="lineno"> 2474</span>&#160;        <a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">internal::CuDNNHandle&lt;Scalar&gt;::get_instance</a>().<a class="code" href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#ae958103fd306a6ad9c1e0d50d9e13d57">activation_bwd</a>(in.data(), out.data(), out_grad.data(),</div><div class="line"><a name="l02475"></a><span class="lineno"> 2475</span>&#160;                ext_batch_dims, CUDNN_ACTIVATION_ELU, alpha, prev_out_grad.data());</div><div class="line"><a name="l02476"></a><span class="lineno"> 2476</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l02477"></a><span class="lineno"> 2477</span>&#160;    }</div><div class="line"><a name="l02478"></a><span class="lineno"> 2478</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02479"></a><span class="lineno"> 2479</span>&#160;    <span class="keyword">const</span> Scalar alpha;</div><div class="line"><a name="l02480"></a><span class="lineno"> 2480</span>&#160;    std::array&lt;std::size_t,4&gt; ext_batch_dims;</div><div class="line"><a name="l02481"></a><span class="lineno"> 2481</span>&#160;    <span class="keyword">typename</span> Root::Data in;</div><div class="line"><a name="l02482"></a><span class="lineno"> 2482</span>&#160;    <span class="keyword">typename</span> Root::Data out;</div><div class="line"><a name="l02483"></a><span class="lineno"> 2483</span>&#160;};</div><div class="line"><a name="l02484"></a><span class="lineno"> 2484</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l02485"></a><span class="lineno"> 2485</span>&#160;</div><div class="line"><a name="l02500"></a><span class="lineno"> 2500</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02501"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_re_l_u_activation_layer.html"> 2501</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html">PReLUActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02502"></a><span class="lineno"> 2502</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l02503"></a><span class="lineno"> 2503</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l02504"></a><span class="lineno"> 2504</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,Root::DATA_RANK&gt; RankwiseArray;</div><div class="line"><a name="l02505"></a><span class="lineno"> 2505</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02513"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_re_l_u_activation_layer.html#a30914840f4fc20d25805b8a3ac0c6e51"> 2513</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a30914840f4fc20d25805b8a3ac0c6e51">PReLUActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims, <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> param_reg = Root::NO_PARAM_REG,</div><div class="line"><a name="l02514"></a><span class="lineno"> 2514</span>&#160;            Scalar init_alpha = 1e-1, Scalar max_norm_constraint = 0) :</div><div class="line"><a name="l02515"></a><span class="lineno"> 2515</span>&#160;                <a class="code" href="classcattle_1_1_layer.html">Base</a>::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims, 1, dims.get_volume()),</div><div class="line"><a name="l02516"></a><span class="lineno"> 2516</span>&#160;                param_reg(param_reg),</div><div class="line"><a name="l02517"></a><span class="lineno"> 2517</span>&#160;                init_alpha(init_alpha),</div><div class="line"><a name="l02518"></a><span class="lineno"> 2518</span>&#160;                max_norm_constraint(max_norm_constraint),</div><div class="line"><a name="l02519"></a><span class="lineno"> 2519</span>&#160;                max_norm(internal::NumericUtils&lt;Scalar&gt;::decidedly_greater(max_norm_constraint, (Scalar) 0)),</div><div class="line"><a name="l02520"></a><span class="lineno"> 2520</span>&#160;                conversion_dims(dims.template promote&lt;&gt;()) {</div><div class="line"><a name="l02521"></a><span class="lineno"> 2521</span>&#160;        assert(param_reg != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l02522"></a><span class="lineno"> 2522</span>&#160;    }</div><div class="line"><a name="l02523"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_re_l_u_activation_layer.html#a822da21b34e644180efda947c185e13e"> 2523</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a822da21b34e644180efda947c185e13e">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02524"></a><span class="lineno"> 2524</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a30914840f4fc20d25805b8a3ac0c6e51">PReLUActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02525"></a><span class="lineno"> 2525</span>&#160;    }</div><div class="line"><a name="l02526"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_re_l_u_activation_layer.html#a01e678cea84bc7f952303bc5747e7c3f"> 2526</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a01e678cea84bc7f952303bc5747e7c3f">clone_with_shared_params</a>() {</div><div class="line"><a name="l02527"></a><span class="lineno"> 2527</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a30914840f4fc20d25805b8a3ac0c6e51">PReLUActivationLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l02528"></a><span class="lineno"> 2528</span>&#160;    }</div><div class="line"><a name="l02529"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_re_l_u_activation_layer.html#a26107800b142f95b0d34a9519b801e9c"> 2529</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a26107800b142f95b0d34a9519b801e9c">init</a>() {</div><div class="line"><a name="l02530"></a><span class="lineno"> 2530</span>&#160;        Base::params_ref.setConstant(init_alpha);</div><div class="line"><a name="l02531"></a><span class="lineno"> 2531</span>&#160;        Base::params_grad.setZero(1, Base::dims.get_volume());</div><div class="line"><a name="l02532"></a><span class="lineno"> 2532</span>&#160;    }</div><div class="line"><a name="l02533"></a><span class="lineno"> 2533</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02534"></a><span class="lineno"> 2534</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a30914840f4fc20d25805b8a3ac0c6e51">PReLUActivationLayer</a>(<a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html">PReLUActivationLayer&lt;Scalar,Rank&gt;</a>&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l02535"></a><span class="lineno"> 2535</span>&#160;            Base::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(layer, share_params),</div><div class="line"><a name="l02536"></a><span class="lineno"> 2536</span>&#160;            param_reg(layer.param_reg),</div><div class="line"><a name="l02537"></a><span class="lineno"> 2537</span>&#160;            init_alpha(layer.init_alpha),</div><div class="line"><a name="l02538"></a><span class="lineno"> 2538</span>&#160;            max_norm_constraint(layer.max_norm_constraint),</div><div class="line"><a name="l02539"></a><span class="lineno"> 2539</span>&#160;            max_norm(layer.max_norm),</div><div class="line"><a name="l02540"></a><span class="lineno"> 2540</span>&#160;            conversion_dims(layer.conversion_dims) { }</div><div class="line"><a name="l02541"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_re_l_u_activation_layer.html#a7ac09416efe5d2cd6cc73df9890e9725"> 2541</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a7ac09416efe5d2cd6cc73df9890e9725">empty_cache</a>() {</div><div class="line"><a name="l02542"></a><span class="lineno"> 2542</span>&#160;        in = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(0, 0);</div><div class="line"><a name="l02543"></a><span class="lineno"> 2543</span>&#160;    }</div><div class="line"><a name="l02544"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_re_l_u_activation_layer.html#a7bb2f7bd02261af5aae033d9727c00c8"> 2544</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a7bb2f7bd02261af5aae033d9727c00c8">regularize</a>() {</div><div class="line"><a name="l02545"></a><span class="lineno"> 2545</span>&#160;        Base::params_grad += param_reg-&gt;d_function(Base::params_ref);</div><div class="line"><a name="l02546"></a><span class="lineno"> 2546</span>&#160;    }</div><div class="line"><a name="l02547"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_re_l_u_activation_layer.html#aea1064a99c89f7c06a7deaf0b87cb8a9"> 2547</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#aea1064a99c89f7c06a7deaf0b87cb8a9">get_regularization_penalty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02548"></a><span class="lineno"> 2548</span>&#160;        <span class="keywordflow">return</span> param_reg-&gt;function(Base::params_ref);</div><div class="line"><a name="l02549"></a><span class="lineno"> 2549</span>&#160;    }</div><div class="line"><a name="l02550"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_re_l_u_activation_layer.html#a22b686f15e500942fb894063ae65bda8"> 2550</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a22b686f15e500942fb894063ae65bda8">enforce_constraints</a>() {</div><div class="line"><a name="l02551"></a><span class="lineno"> 2551</span>&#160;        <span class="keywordflow">if</span> (max_norm) {</div><div class="line"><a name="l02552"></a><span class="lineno"> 2552</span>&#160;            Scalar l2_norm = Base::params_ref.squaredNorm();</div><div class="line"><a name="l02553"></a><span class="lineno"> 2553</span>&#160;            <span class="keywordflow">if</span> (l2_norm &gt; max_norm_constraint)</div><div class="line"><a name="l02554"></a><span class="lineno"> 2554</span>&#160;                Base::params_ref *= (max_norm_constraint / l2_norm);</div><div class="line"><a name="l02555"></a><span class="lineno"> 2555</span>&#160;        }</div><div class="line"><a name="l02556"></a><span class="lineno"> 2556</span>&#160;    }</div><div class="line"><a name="l02557"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_re_l_u_activation_layer.html#a2c4c775a8f711ecce2636d71b4d31c77"> 2557</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a2c4c775a8f711ecce2636d71b4d31c77">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02558"></a><span class="lineno"> 2558</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02559"></a><span class="lineno"> 2559</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02560"></a><span class="lineno"> 2560</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l02561"></a><span class="lineno"> 2561</span>&#160;        this-&gt;in = <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a>(in.data(), rows, Base::dims.get_volume());</div><div class="line"><a name="l02562"></a><span class="lineno"> 2562</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out = this-&gt;in.cwiseMax(this-&gt;in * Base::params_ref.row(0).asDiagonal());</div><div class="line"><a name="l02563"></a><span class="lineno"> 2563</span>&#160;        conversion_dims[0] = rows;</div><div class="line"><a name="l02564"></a><span class="lineno"> 2564</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Root::DATA_RANK&gt;</a>(out.data(), conversion_dims);</div><div class="line"><a name="l02565"></a><span class="lineno"> 2565</span>&#160;    }</div><div class="line"><a name="l02566"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_re_l_u_activation_layer.html#a03db64ab6a9f91966257269af1662373"> 2566</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_p_re_l_u_activation_layer.html#a03db64ab6a9f91966257269af1662373">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02567"></a><span class="lineno"> 2567</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02568"></a><span class="lineno"> 2568</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; conversion_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l02569"></a><span class="lineno"> 2569</span>&#160;        Base::params_grad.row(0).setZero();</div><div class="line"><a name="l02570"></a><span class="lineno"> 2570</span>&#160;        <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> out_grad_map(out_grad.data(), conversion_dims[0], Base::dims.get_volume());</div><div class="line"><a name="l02571"></a><span class="lineno"> 2571</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> prev_out_grad = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(in.rows(), in.cols());</div><div class="line"><a name="l02572"></a><span class="lineno"> 2572</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; in.cols(); ++i) {</div><div class="line"><a name="l02573"></a><span class="lineno"> 2573</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; in.rows(); ++j) {</div><div class="line"><a name="l02574"></a><span class="lineno"> 2574</span>&#160;                Scalar in_ji = in(j,i);</div><div class="line"><a name="l02575"></a><span class="lineno"> 2575</span>&#160;                <span class="keywordflow">if</span> (in_ji &gt;= 0)</div><div class="line"><a name="l02576"></a><span class="lineno"> 2576</span>&#160;                    prev_out_grad(j,i) = out_grad_map(j,i);</div><div class="line"><a name="l02577"></a><span class="lineno"> 2577</span>&#160;                <span class="keywordflow">else</span> {</div><div class="line"><a name="l02578"></a><span class="lineno"> 2578</span>&#160;                    Scalar out_ji = out_grad_map(j,i);</div><div class="line"><a name="l02579"></a><span class="lineno"> 2579</span>&#160;                    prev_out_grad(j,i) = Base::params_ref(0,i) * out_ji;</div><div class="line"><a name="l02580"></a><span class="lineno"> 2580</span>&#160;                    Base::params_grad(0,i) += in_ji * out_ji;</div><div class="line"><a name="l02581"></a><span class="lineno"> 2581</span>&#160;                }</div><div class="line"><a name="l02582"></a><span class="lineno"> 2582</span>&#160;            }</div><div class="line"><a name="l02583"></a><span class="lineno"> 2583</span>&#160;        }</div><div class="line"><a name="l02584"></a><span class="lineno"> 2584</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Root::DATA_RANK&gt;</a>(prev_out_grad.data(), conversion_dims);</div><div class="line"><a name="l02585"></a><span class="lineno"> 2585</span>&#160;    }</div><div class="line"><a name="l02586"></a><span class="lineno"> 2586</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02587"></a><span class="lineno"> 2587</span>&#160;    <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> param_reg;</div><div class="line"><a name="l02588"></a><span class="lineno"> 2588</span>&#160;    <span class="keyword">const</span> Scalar init_alpha;</div><div class="line"><a name="l02589"></a><span class="lineno"> 2589</span>&#160;    <span class="keyword">const</span> Scalar max_norm_constraint;</div><div class="line"><a name="l02590"></a><span class="lineno"> 2590</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> max_norm;</div><div class="line"><a name="l02591"></a><span class="lineno"> 2591</span>&#160;    RankwiseArray conversion_dims;</div><div class="line"><a name="l02592"></a><span class="lineno"> 2592</span>&#160;    <span class="comment">// Staged computation caches.</span></div><div class="line"><a name="l02593"></a><span class="lineno"> 2593</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> in;</div><div class="line"><a name="l02594"></a><span class="lineno"> 2594</span>&#160;};</div><div class="line"><a name="l02595"></a><span class="lineno"> 2595</span>&#160;</div><div class="line"><a name="l02603"></a><span class="lineno"> 2603</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02604"></a><span class="lineno"><a class="line" href="classcattle_1_1_swish_activation_layer.html"> 2604</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_swish_activation_layer.html">SwishActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02605"></a><span class="lineno"> 2605</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l02606"></a><span class="lineno"> 2606</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l02607"></a><span class="lineno"> 2607</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02613"></a><span class="lineno"><a class="line" href="classcattle_1_1_swish_activation_layer.html#a87b1c9e1f24d354b6e3bf92e411afa16"> 2613</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_swish_activation_layer.html#a87b1c9e1f24d354b6e3bf92e411afa16">SwishActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims, Scalar beta = 1) :</div><div class="line"><a name="l02614"></a><span class="lineno"> 2614</span>&#160;            <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt;::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims),</div><div class="line"><a name="l02615"></a><span class="lineno"> 2615</span>&#160;            beta(beta) { }</div><div class="line"><a name="l02616"></a><span class="lineno"><a class="line" href="classcattle_1_1_swish_activation_layer.html#aeeacccc1907003c77578d71b38d1f481"> 2616</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a>* <a class="code" href="classcattle_1_1_swish_activation_layer.html#aeeacccc1907003c77578d71b38d1f481">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02617"></a><span class="lineno"> 2617</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_swish_activation_layer.html#a87b1c9e1f24d354b6e3bf92e411afa16">SwishActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02618"></a><span class="lineno"> 2618</span>&#160;    }</div><div class="line"><a name="l02619"></a><span class="lineno"> 2619</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02620"></a><span class="lineno"><a class="line" href="classcattle_1_1_swish_activation_layer.html#af2792078dedd9be1de647c1998f9c75e"> 2620</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_swish_activation_layer.html#af2792078dedd9be1de647c1998f9c75e">empty_cache</a>() {</div><div class="line"><a name="l02621"></a><span class="lineno"> 2621</span>&#160;        in = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l02622"></a><span class="lineno"> 2622</span>&#160;        sig_out = <span class="keyword">typename</span> Root::Data();</div><div class="line"><a name="l02623"></a><span class="lineno"> 2623</span>&#160;    }</div><div class="line"><a name="l02624"></a><span class="lineno"><a class="line" href="classcattle_1_1_swish_activation_layer.html#ad2d918f28cb80019cde160152d85650e"> 2624</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_swish_activation_layer.html#ad2d918f28cb80019cde160152d85650e">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02625"></a><span class="lineno"> 2625</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02626"></a><span class="lineno"> 2626</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02627"></a><span class="lineno"> 2627</span>&#160;        <span class="keyword">auto</span> sig_denom = (-beta * in).exp() + in.constant(1);</div><div class="line"><a name="l02628"></a><span class="lineno"> 2628</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l02629"></a><span class="lineno"> 2629</span>&#160;            sig_out = sig_denom.inverse();</div><div class="line"><a name="l02630"></a><span class="lineno"> 2630</span>&#160;            this-&gt;in = std::move(in);</div><div class="line"><a name="l02631"></a><span class="lineno"> 2631</span>&#160;            <span class="keywordflow">return</span> this-&gt;in * sig_out;</div><div class="line"><a name="l02632"></a><span class="lineno"> 2632</span>&#160;        }</div><div class="line"><a name="l02633"></a><span class="lineno"> 2633</span>&#160;        <span class="keywordflow">return</span> in / sig_denom;</div><div class="line"><a name="l02634"></a><span class="lineno"> 2634</span>&#160;    }</div><div class="line"><a name="l02635"></a><span class="lineno"><a class="line" href="classcattle_1_1_swish_activation_layer.html#a5434963c7955b090aed37844ab47441b"> 2635</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_swish_activation_layer.html#a5434963c7955b090aed37844ab47441b">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02636"></a><span class="lineno"> 2636</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02637"></a><span class="lineno"> 2637</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; sig_out.dimension(0) == out_grad.dimension(0));</div><div class="line"><a name="l02638"></a><span class="lineno"> 2638</span>&#160;        <span class="keywordflow">return</span> sig_out * ((sig_out.constant(1) - sig_out) * beta * in + sig_out.constant(1)) * out_grad;</div><div class="line"><a name="l02639"></a><span class="lineno"> 2639</span>&#160;    }</div><div class="line"><a name="l02640"></a><span class="lineno"> 2640</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02641"></a><span class="lineno"> 2641</span>&#160;    <span class="keyword">const</span> Scalar beta;</div><div class="line"><a name="l02642"></a><span class="lineno"> 2642</span>&#160;    <span class="comment">// Staged computation cache.</span></div><div class="line"><a name="l02643"></a><span class="lineno"> 2643</span>&#160;    <span class="keyword">typename</span> Root::Data in;</div><div class="line"><a name="l02644"></a><span class="lineno"> 2644</span>&#160;    <span class="keyword">typename</span> Root::Data sig_out;</div><div class="line"><a name="l02645"></a><span class="lineno"> 2645</span>&#160;};</div><div class="line"><a name="l02646"></a><span class="lineno"> 2646</span>&#160;</div><div class="line"><a name="l02655"></a><span class="lineno"> 2655</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02656"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_swish_activation_layer.html"> 2656</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_p_swish_activation_layer.html">PSwishActivationLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02657"></a><span class="lineno"> 2657</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l02658"></a><span class="lineno"> 2658</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l02659"></a><span class="lineno"> 2659</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,Root::DATA_RANK&gt; RankwiseArray;</div><div class="line"><a name="l02660"></a><span class="lineno"> 2660</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02669"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_swish_activation_layer.html#ac760278b4e9f632d4bfea91bd22b1ccf"> 2669</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#ac760278b4e9f632d4bfea91bd22b1ccf">PSwishActivationLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims, <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> param_reg = Root::NO_PARAM_REG,</div><div class="line"><a name="l02670"></a><span class="lineno"> 2670</span>&#160;            Scalar init_beta = 1e-1, Scalar max_norm_constraint = 0) :</div><div class="line"><a name="l02671"></a><span class="lineno"> 2671</span>&#160;                <a class="code" href="classcattle_1_1_layer.html">Base</a>::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(dims, 1, dims.get_volume()),</div><div class="line"><a name="l02672"></a><span class="lineno"> 2672</span>&#160;                param_reg(param_reg),</div><div class="line"><a name="l02673"></a><span class="lineno"> 2673</span>&#160;                init_beta(init_beta),</div><div class="line"><a name="l02674"></a><span class="lineno"> 2674</span>&#160;                max_norm_constraint(max_norm_constraint),</div><div class="line"><a name="l02675"></a><span class="lineno"> 2675</span>&#160;                max_norm(internal::NumericUtils&lt;Scalar&gt;::decidedly_greater(max_norm_constraint, (Scalar) 0)),</div><div class="line"><a name="l02676"></a><span class="lineno"> 2676</span>&#160;                conversion_dims(dims.template promote&lt;&gt;()) {</div><div class="line"><a name="l02677"></a><span class="lineno"> 2677</span>&#160;        assert(param_reg != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l02678"></a><span class="lineno"> 2678</span>&#160;    }</div><div class="line"><a name="l02679"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_swish_activation_layer.html#a8908ccf599442daa45682028d79a0871"> 2679</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#a8908ccf599442daa45682028d79a0871">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02680"></a><span class="lineno"> 2680</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#ac760278b4e9f632d4bfea91bd22b1ccf">PSwishActivationLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02681"></a><span class="lineno"> 2681</span>&#160;    }</div><div class="line"><a name="l02682"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_swish_activation_layer.html#a0d6f194ac78749343dbf7eb0e378cc55"> 2682</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#a0d6f194ac78749343dbf7eb0e378cc55">clone_with_shared_params</a>() {</div><div class="line"><a name="l02683"></a><span class="lineno"> 2683</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#ac760278b4e9f632d4bfea91bd22b1ccf">PSwishActivationLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l02684"></a><span class="lineno"> 2684</span>&#160;    }</div><div class="line"><a name="l02685"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_swish_activation_layer.html#ad9ddf16a25f9a6708f1569e1b9d48bff"> 2685</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#ad9ddf16a25f9a6708f1569e1b9d48bff">init</a>() {</div><div class="line"><a name="l02686"></a><span class="lineno"> 2686</span>&#160;        Base::params_ref.setConstant(init_beta);</div><div class="line"><a name="l02687"></a><span class="lineno"> 2687</span>&#160;        Base::params_grad.setZero(1, Base::dims.get_volume());</div><div class="line"><a name="l02688"></a><span class="lineno"> 2688</span>&#160;    }</div><div class="line"><a name="l02689"></a><span class="lineno"> 2689</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02690"></a><span class="lineno"> 2690</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#ac760278b4e9f632d4bfea91bd22b1ccf">PSwishActivationLayer</a>(<a class="code" href="classcattle_1_1_p_swish_activation_layer.html">PSwishActivationLayer&lt;Scalar,Rank&gt;</a>&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l02691"></a><span class="lineno"> 2691</span>&#160;            Base::<a class="code" href="classcattle_1_1_activation_layer.html">ActivationLayer</a>(layer, share_params),</div><div class="line"><a name="l02692"></a><span class="lineno"> 2692</span>&#160;            param_reg(layer.param_reg),</div><div class="line"><a name="l02693"></a><span class="lineno"> 2693</span>&#160;            init_beta(layer.init_beta),</div><div class="line"><a name="l02694"></a><span class="lineno"> 2694</span>&#160;            max_norm_constraint(layer.max_norm_constraint),</div><div class="line"><a name="l02695"></a><span class="lineno"> 2695</span>&#160;            max_norm(layer.max_norm),</div><div class="line"><a name="l02696"></a><span class="lineno"> 2696</span>&#160;            conversion_dims(layer.conversion_dims) { }</div><div class="line"><a name="l02697"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_swish_activation_layer.html#a5fb5bc049a3bbb788ad362ae790c4134"> 2697</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#a5fb5bc049a3bbb788ad362ae790c4134">empty_cache</a>() {</div><div class="line"><a name="l02698"></a><span class="lineno"> 2698</span>&#160;        in = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(0, 0);</div><div class="line"><a name="l02699"></a><span class="lineno"> 2699</span>&#160;        sig_out = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(0, 0);</div><div class="line"><a name="l02700"></a><span class="lineno"> 2700</span>&#160;    }</div><div class="line"><a name="l02701"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_swish_activation_layer.html#af217f7a8a67fa7cff16930a071616ec6"> 2701</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#af217f7a8a67fa7cff16930a071616ec6">regularize</a>() {</div><div class="line"><a name="l02702"></a><span class="lineno"> 2702</span>&#160;        Base::params_grad += param_reg-&gt;d_function(Base::params_ref);</div><div class="line"><a name="l02703"></a><span class="lineno"> 2703</span>&#160;    }</div><div class="line"><a name="l02704"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_swish_activation_layer.html#a8b8ff178771ca116934695127ed9ade8"> 2704</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#a8b8ff178771ca116934695127ed9ade8">get_regularization_penalty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02705"></a><span class="lineno"> 2705</span>&#160;        <span class="keywordflow">return</span> param_reg-&gt;function(Base::params_ref);</div><div class="line"><a name="l02706"></a><span class="lineno"> 2706</span>&#160;    }</div><div class="line"><a name="l02707"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_swish_activation_layer.html#a647a6edc649ca0713cb448546635175b"> 2707</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#a647a6edc649ca0713cb448546635175b">enforce_constraints</a>() {</div><div class="line"><a name="l02708"></a><span class="lineno"> 2708</span>&#160;        <span class="keywordflow">if</span> (max_norm) {</div><div class="line"><a name="l02709"></a><span class="lineno"> 2709</span>&#160;            Scalar l2_norm = Base::params_ref.squaredNorm();</div><div class="line"><a name="l02710"></a><span class="lineno"> 2710</span>&#160;            <span class="keywordflow">if</span> (l2_norm &gt; max_norm_constraint)</div><div class="line"><a name="l02711"></a><span class="lineno"> 2711</span>&#160;                Base::params_ref *= (max_norm_constraint / l2_norm);</div><div class="line"><a name="l02712"></a><span class="lineno"> 2712</span>&#160;        }</div><div class="line"><a name="l02713"></a><span class="lineno"> 2713</span>&#160;    }</div><div class="line"><a name="l02714"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_swish_activation_layer.html#a55177f124396da9ed5d9a6356cd676f5"> 2714</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#a55177f124396da9ed5d9a6356cd676f5">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02715"></a><span class="lineno"> 2715</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02716"></a><span class="lineno"> 2716</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02717"></a><span class="lineno"> 2717</span>&#160;        conversion_dims[0] = in.dimension(0);</div><div class="line"><a name="l02718"></a><span class="lineno"> 2718</span>&#160;        this-&gt;in = <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a>(in.data(), conversion_dims[0], in.size() / conversion_dims[0]);</div><div class="line"><a name="l02719"></a><span class="lineno"> 2719</span>&#160;        <span class="keyword">auto</span> sig_out = ((this-&gt;in * (Base::params_ref.row(0).asDiagonal() * -1)).array().exp() + 1);</div><div class="line"><a name="l02720"></a><span class="lineno"> 2720</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out;</div><div class="line"><a name="l02721"></a><span class="lineno"> 2721</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l02722"></a><span class="lineno"> 2722</span>&#160;            this-&gt;sig_out = sig_out.inverse();</div><div class="line"><a name="l02723"></a><span class="lineno"> 2723</span>&#160;            out = this-&gt;in.cwiseProduct(this-&gt;sig_out);</div><div class="line"><a name="l02724"></a><span class="lineno"> 2724</span>&#160;        } <span class="keywordflow">else</span></div><div class="line"><a name="l02725"></a><span class="lineno"> 2725</span>&#160;            out = this-&gt;in.array() / sig_out;</div><div class="line"><a name="l02726"></a><span class="lineno"> 2726</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Root::DATA_RANK&gt;</a>(out.data(), conversion_dims);</div><div class="line"><a name="l02727"></a><span class="lineno"> 2727</span>&#160;    }</div><div class="line"><a name="l02728"></a><span class="lineno"><a class="line" href="classcattle_1_1_p_swish_activation_layer.html#a1d5a8b953b4d2533e4d8e2baf2b24860"> 2728</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_p_swish_activation_layer.html#a1d5a8b953b4d2533e4d8e2baf2b24860">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02729"></a><span class="lineno"> 2729</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == Base::dims);</div><div class="line"><a name="l02730"></a><span class="lineno"> 2730</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; conversion_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l02731"></a><span class="lineno"> 2731</span>&#160;        <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> out_grad_mat(out_grad.data(), conversion_dims[0], out_grad.size() / conversion_dims[0]);</div><div class="line"><a name="l02732"></a><span class="lineno"> 2732</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> one_min_sig_out = 1 - sig_out.array();</div><div class="line"><a name="l02733"></a><span class="lineno"> 2733</span>&#160;        Base::params_grad = sig_out.cwiseProduct(one_min_sig_out).cwiseProduct(in).cwiseProduct(in)</div><div class="line"><a name="l02734"></a><span class="lineno"> 2734</span>&#160;                .cwiseProduct(out_grad_mat).colwise().sum();</div><div class="line"><a name="l02735"></a><span class="lineno"> 2735</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> prev_out_grad = sig_out.cwiseProduct(((one_min_sig_out * Base::params_ref.row(0).asDiagonal()).array() *</div><div class="line"><a name="l02736"></a><span class="lineno"> 2736</span>&#160;                in.array() + 1).matrix()).cwiseProduct(out_grad_mat);</div><div class="line"><a name="l02737"></a><span class="lineno"> 2737</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Root::DATA_RANK&gt;</a>(prev_out_grad.data(), conversion_dims);</div><div class="line"><a name="l02738"></a><span class="lineno"> 2738</span>&#160;    }</div><div class="line"><a name="l02739"></a><span class="lineno"> 2739</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02740"></a><span class="lineno"> 2740</span>&#160;    <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> param_reg;</div><div class="line"><a name="l02741"></a><span class="lineno"> 2741</span>&#160;    <span class="keyword">const</span> Scalar init_beta;</div><div class="line"><a name="l02742"></a><span class="lineno"> 2742</span>&#160;    <span class="keyword">const</span> Scalar max_norm_constraint;</div><div class="line"><a name="l02743"></a><span class="lineno"> 2743</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> max_norm;</div><div class="line"><a name="l02744"></a><span class="lineno"> 2744</span>&#160;    RankwiseArray conversion_dims;</div><div class="line"><a name="l02745"></a><span class="lineno"> 2745</span>&#160;    <span class="comment">// Staged computation caches.</span></div><div class="line"><a name="l02746"></a><span class="lineno"> 2746</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> in;</div><div class="line"><a name="l02747"></a><span class="lineno"> 2747</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> sig_out;</div><div class="line"><a name="l02748"></a><span class="lineno"> 2748</span>&#160;};</div><div class="line"><a name="l02749"></a><span class="lineno"> 2749</span>&#160;</div><div class="line"><a name="l02750"></a><span class="lineno"> 2750</span>&#160;<span class="preprocessor">#ifndef CATTL3_USE_CUDNN</span></div><div class="line"><a name="l02751"></a><span class="lineno"> 2751</span>&#160;</div><div class="line"><a name="l02754"></a><span class="lineno"> 2754</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02755"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html"> 2755</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02756"></a><span class="lineno"> 2756</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l02757"></a><span class="lineno"> 2757</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02758"></a><span class="lineno"> 2758</span>&#160;    <span class="keyword">virtual</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_pool_layer.html#a40d43922450a2d28e36057256905403e">clone</a>() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l02759"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#a2197c18cdbc8c8e80bc059d8f36a4d5c"> 2759</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_pool_layer.html#a2197c18cdbc8c8e80bc059d8f36a4d5c">clone_with_shared_params</a>() {</div><div class="line"><a name="l02760"></a><span class="lineno"> 2760</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classcattle_1_1_pool_layer.html#a40d43922450a2d28e36057256905403e">clone</a>();</div><div class="line"><a name="l02761"></a><span class="lineno"> 2761</span>&#160;    }</div><div class="line"><a name="l02762"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#a5920113d2477183eb7f64a5e92fa2ab6"> 2762</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>&amp; <a class="code" href="classcattle_1_1_pool_layer.html#a5920113d2477183eb7f64a5e92fa2ab6">get_params_owner</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02763"></a><span class="lineno"> 2763</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l02764"></a><span class="lineno"> 2764</span>&#160;    }</div><div class="line"><a name="l02765"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#a5f6dcc02c8ac98701607ab697951b25f"> 2765</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_pool_layer.html#a5f6dcc02c8ac98701607ab697951b25f">get_input_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02766"></a><span class="lineno"> 2766</span>&#160;        <span class="keywordflow">return</span> input_dims;</div><div class="line"><a name="l02767"></a><span class="lineno"> 2767</span>&#160;    }</div><div class="line"><a name="l02768"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#a75260941d25afbe9d8c47b495c998ad3"> 2768</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_pool_layer.html#a75260941d25afbe9d8c47b495c998ad3">get_output_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02769"></a><span class="lineno"> 2769</span>&#160;        <span class="keywordflow">return</span> output_dims;</div><div class="line"><a name="l02770"></a><span class="lineno"> 2770</span>&#160;    }</div><div class="line"><a name="l02771"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#a872d8b4156c8a7e719e4ae1dafd763f1"> 2771</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_pool_layer.html#a872d8b4156c8a7e719e4ae1dafd763f1">get_params</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02772"></a><span class="lineno"> 2772</span>&#160;        <span class="keywordflow">return</span> params;</div><div class="line"><a name="l02773"></a><span class="lineno"> 2773</span>&#160;    }</div><div class="line"><a name="l02774"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#a560c5f9614ad83cbc4429cc99a36d9b6"> 2774</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_pool_layer.html#a560c5f9614ad83cbc4429cc99a36d9b6">get_params_grad</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02775"></a><span class="lineno"> 2775</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l02776"></a><span class="lineno"> 2776</span>&#160;    }</div><div class="line"><a name="l02777"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#a883b154da497fcf7ca074f0aa2b46e9d"> 2777</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_pool_layer.html#a883b154da497fcf7ca074f0aa2b46e9d">is_frozen</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02778"></a><span class="lineno"> 2778</span>&#160;        <span class="keywordflow">return</span> frozen;</div><div class="line"><a name="l02779"></a><span class="lineno"> 2779</span>&#160;    }</div><div class="line"><a name="l02780"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#ac99f3186190c5d1d61e26e05427eb5df"> 2780</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_pool_layer.html#ac99f3186190c5d1d61e26e05427eb5df">set_frozen</a>(<span class="keywordtype">bool</span> frozen) {</div><div class="line"><a name="l02781"></a><span class="lineno"> 2781</span>&#160;        this-&gt;frozen = frozen;</div><div class="line"><a name="l02782"></a><span class="lineno"> 2782</span>&#160;    }</div><div class="line"><a name="l02783"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#a7837c89a4d3ac765c78507da09c35f8b"> 2783</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_pool_layer.html#a7837c89a4d3ac765c78507da09c35f8b">init</a>() { }</div><div class="line"><a name="l02784"></a><span class="lineno"> 2784</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02785"></a><span class="lineno"> 2785</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,4&gt; Array4;</div><div class="line"><a name="l02786"></a><span class="lineno"> 2786</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,2&gt; ReductionRanksArray2D;</div><div class="line"><a name="l02787"></a><span class="lineno"> 2787</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; input_dims, std::size_t receptor_height, std::size_t receptor_width,</div><div class="line"><a name="l02788"></a><span class="lineno"> 2788</span>&#160;            std::size_t vertical_stride, std::size_t horizontal_stride) :</div><div class="line"><a name="l02789"></a><span class="lineno"> 2789</span>&#160;                ext_input_dims(input_dims.template extend&lt;3 - Rank&gt;()),</div><div class="line"><a name="l02790"></a><span class="lineno"> 2790</span>&#160;                ext_output_dims(calculate_output_dims(ext_input_dims, receptor_height, receptor_width, vertical_stride,</div><div class="line"><a name="l02791"></a><span class="lineno"> 2791</span>&#160;                        horizontal_stride)),</div><div class="line"><a name="l02792"></a><span class="lineno"> 2792</span>&#160;                input_dims(input_dims),</div><div class="line"><a name="l02793"></a><span class="lineno"> 2793</span>&#160;                output_dims(ext_output_dims.template contract&lt;3 - Rank&gt;()),</div><div class="line"><a name="l02794"></a><span class="lineno"> 2794</span>&#160;                receptor_height(receptor_height),</div><div class="line"><a name="l02795"></a><span class="lineno"> 2795</span>&#160;                receptor_width(receptor_width),</div><div class="line"><a name="l02796"></a><span class="lineno"> 2796</span>&#160;                vertical_stride(vertical_stride),</div><div class="line"><a name="l02797"></a><span class="lineno"> 2797</span>&#160;                horizontal_stride(horizontal_stride),</div><div class="line"><a name="l02798"></a><span class="lineno"> 2798</span>&#160;                height_rem(ext_input_dims(0) - receptor_height),</div><div class="line"><a name="l02799"></a><span class="lineno"> 2799</span>&#160;                width_rem(ext_input_dims(1) - receptor_width),</div><div class="line"><a name="l02800"></a><span class="lineno"> 2800</span>&#160;                input_layer(false),</div><div class="line"><a name="l02801"></a><span class="lineno"> 2801</span>&#160;                frozen(false),</div><div class="line"><a name="l02802"></a><span class="lineno"> 2802</span>&#160;                reduction_ranks({ 1u, 2u }),</div><div class="line"><a name="l02803"></a><span class="lineno"> 2803</span>&#160;                broadcast({ 1u, receptor_height, receptor_width, 1u }),</div><div class="line"><a name="l02804"></a><span class="lineno"> 2804</span>&#160;                patch_offsets({ 0u, 0u, 0u, 0u }),</div><div class="line"><a name="l02805"></a><span class="lineno"> 2805</span>&#160;                patch_extents({ 0u, receptor_height, receptor_width, ext_input_dims(2) }),</div><div class="line"><a name="l02806"></a><span class="lineno"> 2806</span>&#160;                reduced_patch_offsets({ 0u, 0u, 0u, 0u }),</div><div class="line"><a name="l02807"></a><span class="lineno"> 2807</span>&#160;                reduced_patch_extents({ 0u, 1u, 1u, ext_input_dims(2) }),</div><div class="line"><a name="l02808"></a><span class="lineno"> 2808</span>&#160;                params(0, 0),</div><div class="line"><a name="l02809"></a><span class="lineno"> 2809</span>&#160;                params_grad(0, 0) {</div><div class="line"><a name="l02810"></a><span class="lineno"> 2810</span>&#160;        assert(receptor_height &gt; 0 &amp;&amp; receptor_width &gt; 0);</div><div class="line"><a name="l02811"></a><span class="lineno"> 2811</span>&#160;        assert(vertical_stride &gt; 0 &amp;&amp; horizontal_stride &gt; 0);</div><div class="line"><a name="l02812"></a><span class="lineno"> 2812</span>&#160;        assert(ext_input_dims(0) &gt;= receptor_height &amp;&amp; ext_input_dims(1) &gt;= receptor_width);</div><div class="line"><a name="l02813"></a><span class="lineno"> 2813</span>&#160;    }</div><div class="line"><a name="l02817"></a><span class="lineno"> 2817</span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_pool_layer.html#ae5c4d2b057b9f7edc6eb3ca4c1b9ade8">_init_cache</a>() = 0;</div><div class="line"><a name="l02825"></a><span class="lineno"> 2825</span>&#160;    <span class="keyword">virtual</span> Tensor&lt;Scalar,4&gt; <a class="code" href="classcattle_1_1_pool_layer.html#af4ba868123db71633f79628f5112fa06">_reduce</a>(<span class="keyword">const</span> Tensor&lt;Scalar,4&gt;&amp; patch, std::size_t patch_ind) = 0;</div><div class="line"><a name="l02834"></a><span class="lineno"> 2834</span>&#160;    <span class="keyword">virtual</span> Tensor&lt;Scalar,4&gt; <a class="code" href="classcattle_1_1_pool_layer.html#a88b451faf349bb303657bc6c6d60abf8">_d_reduce</a>(<span class="keyword">const</span> Tensor&lt;Scalar,4&gt;&amp; grad, std::size_t patch_ind) = 0;</div><div class="line"><a name="l02835"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#a1f08f1fb9ee99afb1a899a38ff12adbf"> 2835</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_pool_layer.html#a1f08f1fb9ee99afb1a899a38ff12adbf">is_input_layer</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02836"></a><span class="lineno"> 2836</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l02837"></a><span class="lineno"> 2837</span>&#160;    }</div><div class="line"><a name="l02838"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#a584687e28d220062f36ec67d0cf90054"> 2838</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_pool_layer.html#a584687e28d220062f36ec67d0cf90054">set_input_layer</a>(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l02839"></a><span class="lineno"> 2839</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l02840"></a><span class="lineno"> 2840</span>&#160;    }</div><div class="line"><a name="l02841"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#aeb164eb34a28a3109b1713f50980286e"> 2841</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_pool_layer.html#aeb164eb34a28a3109b1713f50980286e">get_params</a>() {</div><div class="line"><a name="l02842"></a><span class="lineno"> 2842</span>&#160;        <span class="keywordflow">return</span> params;</div><div class="line"><a name="l02843"></a><span class="lineno"> 2843</span>&#160;    }</div><div class="line"><a name="l02844"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#ac554223ce79c3d18511c5ad9c3c95101"> 2844</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_pool_layer.html#ac554223ce79c3d18511c5ad9c3c95101">get_params_grad</a>() {</div><div class="line"><a name="l02845"></a><span class="lineno"> 2845</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l02846"></a><span class="lineno"> 2846</span>&#160;    }</div><div class="line"><a name="l02847"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#aa0dcd228d7973b19201ea507146d8b67"> 2847</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_pool_layer.html#aa0dcd228d7973b19201ea507146d8b67">regularize</a>() { }</div><div class="line"><a name="l02848"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#a971e2f47a2e4f46e859b17dc60e07910"> 2848</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1_pool_layer.html#a971e2f47a2e4f46e859b17dc60e07910">get_regularization_penalty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02849"></a><span class="lineno"> 2849</span>&#160;        <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l02850"></a><span class="lineno"> 2850</span>&#160;    }</div><div class="line"><a name="l02851"></a><span class="lineno"><a class="line" href="classcattle_1_1_pool_layer.html#ae3d67e9ff5577d153ef7ce8ffc7c7e9c"> 2851</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_pool_layer.html#ae3d67e9ff5577d153ef7ce8ffc7c7e9c">enforce_constraints</a>() { }</div><div class="line"><a name="l02852"></a><span class="lineno"> 2852</span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> _pass_forward(<a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02853"></a><span class="lineno"> 2853</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l02854"></a><span class="lineno"> 2854</span>&#160;        patch_extents[0] = rows;</div><div class="line"><a name="l02855"></a><span class="lineno"> 2855</span>&#160;        reduced_patch_extents[0] = rows;</div><div class="line"><a name="l02856"></a><span class="lineno"> 2856</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> out(rows, ext_output_dims(0), ext_output_dims(1), ext_output_dims(2));</div><div class="line"><a name="l02857"></a><span class="lineno"> 2857</span>&#160;        <a class="code" href="classcattle_1_1_pool_layer.html#ae5c4d2b057b9f7edc6eb3ca4c1b9ade8">_init_cache</a>();</div><div class="line"><a name="l02858"></a><span class="lineno"> 2858</span>&#160;        std::size_t patch_ind = 0;</div><div class="line"><a name="l02859"></a><span class="lineno"> 2859</span>&#160;        std::size_t out_i = 0;</div><div class="line"><a name="l02860"></a><span class="lineno"> 2860</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt;= width_rem; i += horizontal_stride, ++out_i) {</div><div class="line"><a name="l02861"></a><span class="lineno"> 2861</span>&#160;            patch_offsets[2] = i;</div><div class="line"><a name="l02862"></a><span class="lineno"> 2862</span>&#160;            reduced_patch_offsets[2] = out_i;</div><div class="line"><a name="l02863"></a><span class="lineno"> 2863</span>&#160;            std::size_t out_j = 0;</div><div class="line"><a name="l02864"></a><span class="lineno"> 2864</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt;= height_rem; j += vertical_stride, ++out_j) {</div><div class="line"><a name="l02865"></a><span class="lineno"> 2865</span>&#160;                patch_offsets[1] = j;</div><div class="line"><a name="l02866"></a><span class="lineno"> 2866</span>&#160;                reduced_patch_offsets[1] = out_j;</div><div class="line"><a name="l02867"></a><span class="lineno"> 2867</span>&#160;                <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> patch = in.slice(patch_offsets, patch_extents);</div><div class="line"><a name="l02868"></a><span class="lineno"> 2868</span>&#160;                out.slice(reduced_patch_offsets, reduced_patch_extents) = <a class="code" href="classcattle_1_1_pool_layer.html#af4ba868123db71633f79628f5112fa06">_reduce</a>(patch, patch_ind++);</div><div class="line"><a name="l02869"></a><span class="lineno"> 2869</span>&#160;            }</div><div class="line"><a name="l02870"></a><span class="lineno"> 2870</span>&#160;        }</div><div class="line"><a name="l02871"></a><span class="lineno"> 2871</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l02872"></a><span class="lineno"> 2872</span>&#160;    }</div><div class="line"><a name="l02873"></a><span class="lineno"> 2873</span>&#160;    <span class="keyword">inline</span> Tensor&lt;Scalar,4&gt; _pass_back(Tensor&lt;Scalar,4&gt; out_grad) {</div><div class="line"><a name="l02874"></a><span class="lineno"> 2874</span>&#160;        <span class="keywordflow">if</span> (input_layer)</div><div class="line"><a name="l02875"></a><span class="lineno"> 2875</span>&#160;            <span class="keywordflow">return</span> Tensor&lt;Scalar,4&gt;();</div><div class="line"><a name="l02876"></a><span class="lineno"> 2876</span>&#160;        Tensor&lt;Scalar,4&gt; prev_out_grad(patch_extents[0], ext_input_dims(0), ext_input_dims(1),  ext_input_dims(2));</div><div class="line"><a name="l02877"></a><span class="lineno"> 2877</span>&#160;        prev_out_grad.setZero();</div><div class="line"><a name="l02878"></a><span class="lineno"> 2878</span>&#160;        std::size_t patch_ind = 0;</div><div class="line"><a name="l02879"></a><span class="lineno"> 2879</span>&#160;        std::size_t out_grad_i = 0;</div><div class="line"><a name="l02880"></a><span class="lineno"> 2880</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt;= width_rem; i += horizontal_stride, ++out_grad_i) {</div><div class="line"><a name="l02881"></a><span class="lineno"> 2881</span>&#160;            patch_offsets[2] = i;</div><div class="line"><a name="l02882"></a><span class="lineno"> 2882</span>&#160;            reduced_patch_offsets[2] = out_grad_i;</div><div class="line"><a name="l02883"></a><span class="lineno"> 2883</span>&#160;            std::size_t out_grad_j = 0;</div><div class="line"><a name="l02884"></a><span class="lineno"> 2884</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt;= height_rem; j += vertical_stride, ++out_grad_j) {</div><div class="line"><a name="l02885"></a><span class="lineno"> 2885</span>&#160;                patch_offsets[1] = j;</div><div class="line"><a name="l02886"></a><span class="lineno"> 2886</span>&#160;                reduced_patch_offsets[1] = out_grad_j;</div><div class="line"><a name="l02887"></a><span class="lineno"> 2887</span>&#160;                Tensor&lt;Scalar,4&gt; reduced_patch_grad = out_grad.slice(reduced_patch_offsets, reduced_patch_extents);</div><div class="line"><a name="l02888"></a><span class="lineno"> 2888</span>&#160;                <span class="comment">// Accumulate the gradients where the patches overlap.</span></div><div class="line"><a name="l02889"></a><span class="lineno"> 2889</span>&#160;                prev_out_grad.slice(patch_offsets, patch_extents) += <a class="code" href="classcattle_1_1_pool_layer.html#a88b451faf349bb303657bc6c6d60abf8">_d_reduce</a>(reduced_patch_grad, patch_ind++);</div><div class="line"><a name="l02890"></a><span class="lineno"> 2890</span>&#160;            }</div><div class="line"><a name="l02891"></a><span class="lineno"> 2891</span>&#160;        }</div><div class="line"><a name="l02892"></a><span class="lineno"> 2892</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l02893"></a><span class="lineno"> 2893</span>&#160;    }</div><div class="line"><a name="l02894"></a><span class="lineno"> 2894</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,3&gt; ext_input_dims;</div><div class="line"><a name="l02895"></a><span class="lineno"> 2895</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,3&gt; ext_output_dims;</div><div class="line"><a name="l02896"></a><span class="lineno"> 2896</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt; input_dims;</div><div class="line"><a name="l02897"></a><span class="lineno"> 2897</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt; output_dims;</div><div class="line"><a name="l02898"></a><span class="lineno"> 2898</span>&#160;    <span class="keyword">const</span> std::size_t receptor_height;</div><div class="line"><a name="l02899"></a><span class="lineno"> 2899</span>&#160;    <span class="keyword">const</span> std::size_t receptor_width;</div><div class="line"><a name="l02900"></a><span class="lineno"> 2900</span>&#160;    <span class="keyword">const</span> std::size_t vertical_stride;</div><div class="line"><a name="l02901"></a><span class="lineno"> 2901</span>&#160;    <span class="keyword">const</span> std::size_t horizontal_stride;</div><div class="line"><a name="l02902"></a><span class="lineno"> 2902</span>&#160;    <span class="keyword">const</span> std::size_t height_rem;</div><div class="line"><a name="l02903"></a><span class="lineno"> 2903</span>&#160;    <span class="keyword">const</span> std::size_t width_rem;</div><div class="line"><a name="l02904"></a><span class="lineno"> 2904</span>&#160;    <span class="comment">// Arrays for tensor manipulation.</span></div><div class="line"><a name="l02905"></a><span class="lineno"> 2905</span>&#160;    ReductionRanksArray2D reduction_ranks;</div><div class="line"><a name="l02906"></a><span class="lineno"> 2906</span>&#160;    Array4 broadcast;</div><div class="line"><a name="l02907"></a><span class="lineno"> 2907</span>&#160;    Array4 patch_offsets;</div><div class="line"><a name="l02908"></a><span class="lineno"> 2908</span>&#160;    Array4 patch_extents;</div><div class="line"><a name="l02909"></a><span class="lineno"> 2909</span>&#160;    Array4 reduced_patch_offsets;</div><div class="line"><a name="l02910"></a><span class="lineno"> 2910</span>&#160;    Array4 reduced_patch_extents;</div><div class="line"><a name="l02911"></a><span class="lineno"> 2911</span>&#160;    Array4 dil_strides;</div><div class="line"><a name="l02912"></a><span class="lineno"> 2912</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02913"></a><span class="lineno"> 2913</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> std::size_t calculate_spatial_output_dim(std::size_t input_dim, std::size_t receptor_size, std::size_t stride) {</div><div class="line"><a name="l02914"></a><span class="lineno"> 2914</span>&#160;        <span class="keywordflow">return</span> (input_dim - receptor_size) / stride + 1;</div><div class="line"><a name="l02915"></a><span class="lineno"> 2915</span>&#160;    }</div><div class="line"><a name="l02916"></a><span class="lineno"> 2916</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> Dimensions&lt;std::size_t,3&gt; calculate_output_dims(<span class="keyword">const</span> Dimensions&lt;std::size_t,3&gt;&amp; input_dims,</div><div class="line"><a name="l02917"></a><span class="lineno"> 2917</span>&#160;            std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_stride, std::size_t horizontal_stride) {</div><div class="line"><a name="l02918"></a><span class="lineno"> 2918</span>&#160;        <span class="keywordflow">return</span> { calculate_spatial_output_dim(input_dims(0), receptor_height, vertical_stride),</div><div class="line"><a name="l02919"></a><span class="lineno"> 2919</span>&#160;                calculate_spatial_output_dim(input_dims(1), receptor_width, horizontal_stride),</div><div class="line"><a name="l02920"></a><span class="lineno"> 2920</span>&#160;                input_dims(2) };</div><div class="line"><a name="l02921"></a><span class="lineno"> 2921</span>&#160;    }</div><div class="line"><a name="l02922"></a><span class="lineno"> 2922</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l02923"></a><span class="lineno"> 2923</span>&#160;    <span class="keywordtype">bool</span> frozen;</div><div class="line"><a name="l02924"></a><span class="lineno"> 2924</span>&#160;    <span class="comment">// No actual parameters.</span></div><div class="line"><a name="l02925"></a><span class="lineno"> 2925</span>&#160;    Matrix&lt;Scalar&gt; params;</div><div class="line"><a name="l02926"></a><span class="lineno"> 2926</span>&#160;    Matrix&lt;Scalar&gt; params_grad;</div><div class="line"><a name="l02927"></a><span class="lineno"> 2927</span>&#160;};</div><div class="line"><a name="l02928"></a><span class="lineno"> 2928</span>&#160;</div><div class="line"><a name="l02933"></a><span class="lineno"> 2933</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l02934"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_base.html"> 2934</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolLayerBase</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02935"></a><span class="lineno"> 2935</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l02936"></a><span class="lineno"> 2936</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l02937"></a><span class="lineno"> 2937</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02938"></a><span class="lineno"> 2938</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolLayerBase</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; input_dims, std::size_t receptor_height,</div><div class="line"><a name="l02939"></a><span class="lineno"> 2939</span>&#160;            std::size_t receptor_width, std::size_t vertical_stride, std::size_t horizontal_stride) :</div><div class="line"><a name="l02940"></a><span class="lineno"> 2940</span>&#160;                Base::PoolLayer(input_dims, receptor_height, receptor_width, vertical_stride,</div><div class="line"><a name="l02941"></a><span class="lineno"> 2941</span>&#160;                        horizontal_stride),</div><div class="line"><a name="l02942"></a><span class="lineno"> 2942</span>&#160;                receptor_area(receptor_height * receptor_width) { }</div><div class="line"><a name="l02943"></a><span class="lineno"> 2943</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02944"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_base.html#ae8cc07b8101db1e0ba06bc48ceca3b0e"> 2944</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html#ae8cc07b8101db1e0ba06bc48ceca3b0e">empty_cache</a>() { }</div><div class="line"><a name="l02945"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_base.html#ab7afcbc0dacf7a340d313c521c6a4d87"> 2945</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html#ab7afcbc0dacf7a340d313c521c6a4d87">_init_cache</a>() { }</div><div class="line"><a name="l02946"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_base.html#a0b9a18aa55e2c5e3653f85950980ab74"> 2946</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html#a0b9a18aa55e2c5e3653f85950980ab74">_reduce</a>(<span class="keyword">const</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a>&amp; patch, std::size_t patch_ind) {</div><div class="line"><a name="l02947"></a><span class="lineno"> 2947</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,2&gt;</a> reduced_patch = patch.mean(Base::reduction_ranks);</div><div class="line"><a name="l02948"></a><span class="lineno"> 2948</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(reduced_patch.data(), Base::reduced_patch_extents);</div><div class="line"><a name="l02949"></a><span class="lineno"> 2949</span>&#160;    }</div><div class="line"><a name="l02950"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_base.html#a11d69acda36367bdb1187f7485b90f9e"> 2950</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html#a11d69acda36367bdb1187f7485b90f9e">_d_reduce</a>(<span class="keyword">const</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a>&amp; grad, std::size_t patch_ind) {</div><div class="line"><a name="l02951"></a><span class="lineno"> 2951</span>&#160;        <span class="keywordflow">return</span> (grad / (Scalar) receptor_area).broadcast(Base::broadcast);</div><div class="line"><a name="l02952"></a><span class="lineno"> 2952</span>&#160;    }</div><div class="line"><a name="l02953"></a><span class="lineno"> 2953</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02954"></a><span class="lineno"> 2954</span>&#160;    std::size_t receptor_area;</div><div class="line"><a name="l02955"></a><span class="lineno"> 2955</span>&#160;};</div><div class="line"><a name="l02956"></a><span class="lineno"> 2956</span>&#160;</div><div class="line"><a name="l02960"></a><span class="lineno"> 2960</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank = 3&gt;</div><div class="line"><a name="l02961"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer.html"> 2961</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_mean_pool_layer.html">MeanPoolLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolLayerBase</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l02962"></a><span class="lineno"> 2962</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l02963"></a><span class="lineno"> 2963</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_pool_layer.html">PoolBase</a>;</div><div class="line"><a name="l02964"></a><span class="lineno"> 2964</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolLayerBase&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolBase</a>;</div><div class="line"><a name="l02965"></a><span class="lineno"> 2965</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l02975"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer.html#af51464d25c72c3495f0f39ca43322134"> 2975</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_mean_pool_layer.html#af51464d25c72c3495f0f39ca43322134">MeanPoolLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>&amp; input_dims, std::size_t receptor_height = 2,</div><div class="line"><a name="l02976"></a><span class="lineno"> 2976</span>&#160;            std::size_t receptor_width = 2, std::size_t vertical_stride = 2, std::size_t horizontal_stride = 2) :</div><div class="line"><a name="l02977"></a><span class="lineno"> 2977</span>&#160;                <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolBase</a>::<a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolLayerBase</a>(input_dims, receptor_height, receptor_width, vertical_stride,</div><div class="line"><a name="l02978"></a><span class="lineno"> 2978</span>&#160;                        horizontal_stride) { }</div><div class="line"><a name="l02979"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer.html#a78fe029b0af419a4a04fd0526e444445"> 2979</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_mean_pool_layer.html#a78fe029b0af419a4a04fd0526e444445">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l02980"></a><span class="lineno"> 2980</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_mean_pool_layer.html#af51464d25c72c3495f0f39ca43322134">MeanPoolLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l02981"></a><span class="lineno"> 2981</span>&#160;    }</div><div class="line"><a name="l02982"></a><span class="lineno"> 2982</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l02983"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer.html#a6a011291cc3fc7a494a462f499ea3a8f"> 2983</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_mean_pool_layer.html#a6a011291cc3fc7a494a462f499ea3a8f">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l02984"></a><span class="lineno"> 2984</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,4&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::input_dims);</div><div class="line"><a name="l02985"></a><span class="lineno"> 2985</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l02986"></a><span class="lineno"> 2986</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l02987"></a><span class="lineno"> 2987</span>&#160;        <span class="keywordflow">return</span> PoolBase::_pass_forward(std::move(in), training);</div><div class="line"><a name="l02988"></a><span class="lineno"> 2988</span>&#160;    }</div><div class="line"><a name="l02989"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer.html#aea2085455b95f06f2046085af0275a67"> 2989</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_mean_pool_layer.html#aea2085455b95f06f2046085af0275a67">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l02990"></a><span class="lineno"> 2990</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,4&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::output_dims);</div><div class="line"><a name="l02991"></a><span class="lineno"> 2991</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l02992"></a><span class="lineno"> 2992</span>&#160;        <span class="keywordflow">return</span> PoolBase::_pass_back(std::move(out_grad));</div><div class="line"><a name="l02993"></a><span class="lineno"> 2993</span>&#160;    }</div><div class="line"><a name="l02994"></a><span class="lineno"> 2994</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l02995"></a><span class="lineno"> 2995</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l02996"></a><span class="lineno"> 2996</span>&#160;};</div><div class="line"><a name="l02997"></a><span class="lineno"> 2997</span>&#160;</div><div class="line"><a name="l03001"></a><span class="lineno"> 3001</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l03002"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html"> 3002</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_mean_pool_layer.html">MeanPoolLayer</a>&lt;Scalar,2&gt; : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolLayerBase</a>&lt;Scalar,2&gt; {</div><div class="line"><a name="l03003"></a><span class="lineno"> 3003</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l03004"></a><span class="lineno"> 3004</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_pool_layer.html">PoolBase</a>;</div><div class="line"><a name="l03005"></a><span class="lineno"> 3005</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolLayerBase&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolBase</a>;</div><div class="line"><a name="l03006"></a><span class="lineno"> 3006</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03016"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#adafbcae0285d7acc605260eb738262db"> 3016</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#adafbcae0285d7acc605260eb738262db">MeanPoolLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>&amp; input_dims, std::size_t receptor_height = 2,</div><div class="line"><a name="l03017"></a><span class="lineno"> 3017</span>&#160;            std::size_t receptor_width = 2, std::size_t vertical_stride = 2, std::size_t horizontal_stride = 2) :</div><div class="line"><a name="l03018"></a><span class="lineno"> 3018</span>&#160;                <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolBase</a>::<a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolLayerBase</a>(input_dims, receptor_height, receptor_width, vertical_stride,</div><div class="line"><a name="l03019"></a><span class="lineno"> 3019</span>&#160;                        horizontal_stride) { }</div><div class="line"><a name="l03020"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#a624e7117839125b1c67c1178e381064c"> 3020</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#a624e7117839125b1c67c1178e381064c">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03021"></a><span class="lineno"> 3021</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_mean_pool_layer.html#af51464d25c72c3495f0f39ca43322134">MeanPoolLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l03022"></a><span class="lineno"> 3022</span>&#160;    }</div><div class="line"><a name="l03023"></a><span class="lineno"> 3023</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l03024"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#adf15353dcff3915634b18f3bbd533c6c"> 3024</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#adf15353dcff3915634b18f3bbd533c6c">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l03025"></a><span class="lineno"> 3025</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::input_dims);</div><div class="line"><a name="l03026"></a><span class="lineno"> 3026</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l03027"></a><span class="lineno"> 3027</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l03028"></a><span class="lineno"> 3028</span>&#160;        <span class="keywordflow">return</span> PoolBase::_pass_forward(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(in.data(), { batch_size, in.dimension(1), in.dimension(2), 1u }),</div><div class="line"><a name="l03029"></a><span class="lineno"> 3029</span>&#160;                training).reshape(std::array&lt;std::size_t,3&gt;({ batch_size, PoolBase::output_dims(0), PoolBase::output_dims(1) }));</div><div class="line"><a name="l03030"></a><span class="lineno"> 3030</span>&#160;    }</div><div class="line"><a name="l03031"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#a8f3dcbc5d06b5c461c7df214c2263e54"> 3031</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#a8f3dcbc5d06b5c461c7df214c2263e54">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l03032"></a><span class="lineno"> 3032</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::output_dims);</div><div class="line"><a name="l03033"></a><span class="lineno"> 3033</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l03034"></a><span class="lineno"> 3034</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> prev_out_grad = PoolBase::_pass_back(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(out_grad.data(),</div><div class="line"><a name="l03035"></a><span class="lineno"> 3035</span>&#160;                { batch_size, PoolBase::ext_output_dims(0), PoolBase::ext_output_dims(1), PoolBase::ext_output_dims(2) }));</div><div class="line"><a name="l03036"></a><span class="lineno"> 3036</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_pool_layer.html#a1f08f1fb9ee99afb1a899a38ff12adbf">PoolBase::is_input_layer</a>())</div><div class="line"><a name="l03037"></a><span class="lineno"> 3037</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,3&gt;</a>();</div><div class="line"><a name="l03038"></a><span class="lineno"> 3038</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,3&gt;</a>(prev_out_grad.data(), { batch_size, PoolBase::input_dims(0), PoolBase::input_dims(1) });</div><div class="line"><a name="l03039"></a><span class="lineno"> 3039</span>&#160;    }</div><div class="line"><a name="l03040"></a><span class="lineno"> 3040</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l03041"></a><span class="lineno"> 3041</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l03042"></a><span class="lineno"> 3042</span>&#160;};</div><div class="line"><a name="l03043"></a><span class="lineno"> 3043</span>&#160;</div><div class="line"><a name="l03047"></a><span class="lineno"> 3047</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l03048"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html"> 3048</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_mean_pool_layer.html">MeanPoolLayer</a>&lt;Scalar,1&gt; : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolLayerBase</a>&lt;Scalar,1&gt; {</div><div class="line"><a name="l03049"></a><span class="lineno"> 3049</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l03050"></a><span class="lineno"> 3050</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_pool_layer.html">PoolBase</a>;</div><div class="line"><a name="l03051"></a><span class="lineno"> 3051</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolLayerBase&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolBase</a>;</div><div class="line"><a name="l03052"></a><span class="lineno"> 3052</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03059"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#a4dd7371a50d43f13cc46642296c0a248"> 3059</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#a4dd7371a50d43f13cc46642296c0a248">MeanPoolLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,1&gt;</a>&amp; input_dims, std::size_t receptor_length = 2,</div><div class="line"><a name="l03060"></a><span class="lineno"> 3060</span>&#160;            std::size_t stride = 2) :</div><div class="line"><a name="l03061"></a><span class="lineno"> 3061</span>&#160;                <a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolBase</a>::<a class="code" href="classcattle_1_1_mean_pool_layer_base.html">MeanPoolLayerBase</a>(input_dims, receptor_length, 1, stride, 1) { }</div><div class="line"><a name="l03062"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#acee10ea9184f727d8734038b2f390bee"> 3062</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#acee10ea9184f727d8734038b2f390bee">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03063"></a><span class="lineno"> 3063</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_mean_pool_layer.html#af51464d25c72c3495f0f39ca43322134">MeanPoolLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l03064"></a><span class="lineno"> 3064</span>&#160;    }</div><div class="line"><a name="l03065"></a><span class="lineno"> 3065</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l03066"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#a8bddebf1d3fcfdafbdd1c4e93b3294dd"> 3066</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#a8bddebf1d3fcfdafbdd1c4e93b3294dd">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l03067"></a><span class="lineno"> 3067</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::input_dims);</div><div class="line"><a name="l03068"></a><span class="lineno"> 3068</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l03069"></a><span class="lineno"> 3069</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l03070"></a><span class="lineno"> 3070</span>&#160;        <span class="keywordflow">return</span> PoolBase::_pass_forward(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(in.data(), { batch_size, in.dimension(1), 1u, 1u }), training)</div><div class="line"><a name="l03071"></a><span class="lineno"> 3071</span>&#160;                .reshape(std::array&lt;std::size_t,2&gt;({ batch_size, PoolBase::output_dims(0) }));</div><div class="line"><a name="l03072"></a><span class="lineno"> 3072</span>&#160;    }</div><div class="line"><a name="l03073"></a><span class="lineno"><a class="line" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#ae48c09c01819911fb2ed189b0203beb1"> 3073</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#ae48c09c01819911fb2ed189b0203beb1">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l03074"></a><span class="lineno"> 3074</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::output_dims);</div><div class="line"><a name="l03075"></a><span class="lineno"> 3075</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l03076"></a><span class="lineno"> 3076</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> prev_out_grad = PoolBase::_pass_back(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(out_grad.data(),</div><div class="line"><a name="l03077"></a><span class="lineno"> 3077</span>&#160;                { batch_size, PoolBase::ext_output_dims(0), PoolBase::ext_output_dims(1), PoolBase::ext_output_dims(2) }));</div><div class="line"><a name="l03078"></a><span class="lineno"> 3078</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1_pool_layer.html#a1f08f1fb9ee99afb1a899a38ff12adbf">PoolBase::is_input_layer</a>())</div><div class="line"><a name="l03079"></a><span class="lineno"> 3079</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,2&gt;</a>();</div><div class="line"><a name="l03080"></a><span class="lineno"> 3080</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,2&gt;</a>(prev_out_grad.data(), { batch_size, PoolBase::input_dims(0) });</div><div class="line"><a name="l03081"></a><span class="lineno"> 3081</span>&#160;    }</div><div class="line"><a name="l03082"></a><span class="lineno"> 3082</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l03083"></a><span class="lineno"> 3083</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l03084"></a><span class="lineno"> 3084</span>&#160;};</div><div class="line"><a name="l03085"></a><span class="lineno"> 3085</span>&#160;</div><div class="line"><a name="l03090"></a><span class="lineno"> 3090</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l03091"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_base.html"> 3091</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolLayerBase</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l03092"></a><span class="lineno"> 3092</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l03093"></a><span class="lineno"> 3093</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l03094"></a><span class="lineno"> 3094</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03095"></a><span class="lineno"> 3095</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolLayerBase</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; input_dims, std::size_t receptor_height,</div><div class="line"><a name="l03096"></a><span class="lineno"> 3096</span>&#160;            std::size_t receptor_width, std::size_t vertical_stride, std::size_t horizontal_stride) :</div><div class="line"><a name="l03097"></a><span class="lineno"> 3097</span>&#160;                Base::PoolLayer(input_dims, receptor_height, receptor_width, vertical_stride,</div><div class="line"><a name="l03098"></a><span class="lineno"> 3098</span>&#160;                        horizontal_stride) { }</div><div class="line"><a name="l03099"></a><span class="lineno"> 3099</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l03100"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_base.html#acfe4016482ff9624e21e2856f2209655"> 3100</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_max_pool_layer_base.html#acfe4016482ff9624e21e2856f2209655">empty_cache</a>() {</div><div class="line"><a name="l03101"></a><span class="lineno"> 3101</span>&#160;        max_inds = std::vector&lt;std::vector&lt;unsigned&gt;&gt;(0);</div><div class="line"><a name="l03102"></a><span class="lineno"> 3102</span>&#160;    }</div><div class="line"><a name="l03103"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_base.html#a069f031d5c41d7602bf65f4f21c8fcd2"> 3103</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_max_pool_layer_base.html#a069f031d5c41d7602bf65f4f21c8fcd2">_init_cache</a>() {</div><div class="line"><a name="l03104"></a><span class="lineno"> 3104</span>&#160;        max_inds = std::vector&lt;std::vector&lt;unsigned&gt;&gt;(Base::ext_output_dims(0) * Base::ext_output_dims(1));</div><div class="line"><a name="l03105"></a><span class="lineno"> 3105</span>&#160;    }</div><div class="line"><a name="l03106"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_base.html#adba251e3a789c00b852d896e3742f3b4"> 3106</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> <a class="code" href="classcattle_1_1_max_pool_layer_base.html#adba251e3a789c00b852d896e3742f3b4">_reduce</a>(<span class="keyword">const</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a>&amp; patch, std::size_t patch_ind) {</div><div class="line"><a name="l03107"></a><span class="lineno"> 3107</span>&#160;        std::size_t rows = patch.dimension(0);</div><div class="line"><a name="l03108"></a><span class="lineno"> 3108</span>&#160;        std::size_t depth = patch.dimension(3);</div><div class="line"><a name="l03109"></a><span class="lineno"> 3109</span>&#160;        std::vector&lt;unsigned&gt; inds(rows * depth);</div><div class="line"><a name="l03110"></a><span class="lineno"> 3110</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> reduced_patch(rows, 1u, 1u, depth);</div><div class="line"><a name="l03111"></a><span class="lineno"> 3111</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt; depth; ++i) {</div><div class="line"><a name="l03112"></a><span class="lineno"> 3112</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt; rows; ++j) {</div><div class="line"><a name="l03113"></a><span class="lineno"> 3113</span>&#160;                Scalar max = <a class="code" href="classcattle_1_1internal_1_1_numeric_utils.html">internal::NumericUtils&lt;Scalar&gt;::MIN</a>;</div><div class="line"><a name="l03114"></a><span class="lineno"> 3114</span>&#160;                <span class="keywordtype">unsigned</span> max_height = 0;</div><div class="line"><a name="l03115"></a><span class="lineno"> 3115</span>&#160;                <span class="keywordtype">unsigned</span> max_width = 0;</div><div class="line"><a name="l03116"></a><span class="lineno"> 3116</span>&#160;                <span class="keywordflow">for</span> (std::size_t k = 0; k &lt; Base::receptor_width; ++k) {</div><div class="line"><a name="l03117"></a><span class="lineno"> 3117</span>&#160;                    <span class="keywordflow">for</span> (std::size_t l = 0; l &lt; Base::receptor_height; ++l) {</div><div class="line"><a name="l03118"></a><span class="lineno"> 3118</span>&#160;                        Scalar val = patch(j,l,k,i);</div><div class="line"><a name="l03119"></a><span class="lineno"> 3119</span>&#160;                        <span class="keywordflow">if</span> (val &gt; max) {</div><div class="line"><a name="l03120"></a><span class="lineno"> 3120</span>&#160;                            max = val;</div><div class="line"><a name="l03121"></a><span class="lineno"> 3121</span>&#160;                            max_height = l;</div><div class="line"><a name="l03122"></a><span class="lineno"> 3122</span>&#160;                            max_width = k;</div><div class="line"><a name="l03123"></a><span class="lineno"> 3123</span>&#160;                        }</div><div class="line"><a name="l03124"></a><span class="lineno"> 3124</span>&#160;                    }</div><div class="line"><a name="l03125"></a><span class="lineno"> 3125</span>&#160;                }</div><div class="line"><a name="l03126"></a><span class="lineno"> 3126</span>&#160;                inds[i * rows + j] = max_width * Base::receptor_height + max_height;</div><div class="line"><a name="l03127"></a><span class="lineno"> 3127</span>&#160;                reduced_patch(j,0u,0u,i) = max;</div><div class="line"><a name="l03128"></a><span class="lineno"> 3128</span>&#160;            }</div><div class="line"><a name="l03129"></a><span class="lineno"> 3129</span>&#160;        }</div><div class="line"><a name="l03130"></a><span class="lineno"> 3130</span>&#160;        max_inds[patch_ind] = inds;</div><div class="line"><a name="l03131"></a><span class="lineno"> 3131</span>&#160;        <span class="keywordflow">return</span> reduced_patch;</div><div class="line"><a name="l03132"></a><span class="lineno"> 3132</span>&#160;    }</div><div class="line"><a name="l03133"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_base.html#af34fe1a2706503a74ef87f2ed8364a6f"> 3133</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> <a class="code" href="classcattle_1_1_max_pool_layer_base.html#af34fe1a2706503a74ef87f2ed8364a6f">_d_reduce</a>(<span class="keyword">const</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a>&amp; grad, std::size_t patch_ind) {</div><div class="line"><a name="l03134"></a><span class="lineno"> 3134</span>&#160;        std::size_t rows = grad.dimension(0);</div><div class="line"><a name="l03135"></a><span class="lineno"> 3135</span>&#160;        std::size_t depth = grad.dimension(3);</div><div class="line"><a name="l03136"></a><span class="lineno"> 3136</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> patch(rows, Base::receptor_height, Base::receptor_width, depth);</div><div class="line"><a name="l03137"></a><span class="lineno"> 3137</span>&#160;        patch.setZero();</div><div class="line"><a name="l03138"></a><span class="lineno"> 3138</span>&#160;        std::vector&lt;unsigned&gt;&amp; inds = max_inds[patch_ind];</div><div class="line"><a name="l03139"></a><span class="lineno"> 3139</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt; depth; ++i) {</div><div class="line"><a name="l03140"></a><span class="lineno"> 3140</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt; rows; ++j) {</div><div class="line"><a name="l03141"></a><span class="lineno"> 3141</span>&#160;                <span class="keywordtype">unsigned</span> max_ind = inds[i * rows + j];</div><div class="line"><a name="l03142"></a><span class="lineno"> 3142</span>&#160;                <span class="keywordtype">unsigned</span> max_height = max_ind % Base::receptor_height;</div><div class="line"><a name="l03143"></a><span class="lineno"> 3143</span>&#160;                <span class="keywordtype">unsigned</span> max_width = max_ind / Base::receptor_height;</div><div class="line"><a name="l03144"></a><span class="lineno"> 3144</span>&#160;                patch(j,max_height,max_width,i) = grad(j,0u,0u,i);</div><div class="line"><a name="l03145"></a><span class="lineno"> 3145</span>&#160;            }</div><div class="line"><a name="l03146"></a><span class="lineno"> 3146</span>&#160;        }</div><div class="line"><a name="l03147"></a><span class="lineno"> 3147</span>&#160;        <span class="keywordflow">return</span> patch;</div><div class="line"><a name="l03148"></a><span class="lineno"> 3148</span>&#160;    }</div><div class="line"><a name="l03149"></a><span class="lineno"> 3149</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l03150"></a><span class="lineno"> 3150</span>&#160;    <span class="comment">// Cache</span></div><div class="line"><a name="l03151"></a><span class="lineno"> 3151</span>&#160;    std::vector&lt;std::vector&lt;unsigned&gt;&gt; max_inds;</div><div class="line"><a name="l03152"></a><span class="lineno"> 3152</span>&#160;};</div><div class="line"><a name="l03153"></a><span class="lineno"> 3153</span>&#160;</div><div class="line"><a name="l03159"></a><span class="lineno"> 3159</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank = 3&gt;</div><div class="line"><a name="l03160"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer.html"> 3160</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_max_pool_layer.html">MaxPoolLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolLayerBase</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l03161"></a><span class="lineno"> 3161</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l03162"></a><span class="lineno"> 3162</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_pool_layer.html">PoolBase</a>;</div><div class="line"><a name="l03163"></a><span class="lineno"> 3163</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolLayerBase&lt;Scalar,3&gt;</a> <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolBase</a>;</div><div class="line"><a name="l03164"></a><span class="lineno"> 3164</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03174"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer.html#a91a604342f478507b3337fe85ba1a2bb"> 3174</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_max_pool_layer.html#a91a604342f478507b3337fe85ba1a2bb">MaxPoolLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>&amp; input_dims, std::size_t receptor_height = 2,</div><div class="line"><a name="l03175"></a><span class="lineno"> 3175</span>&#160;            std::size_t receptor_width = 2, std::size_t vertical_stride = 2, std::size_t horizontal_stride = 2) :</div><div class="line"><a name="l03176"></a><span class="lineno"> 3176</span>&#160;                <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolBase</a>::<a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolLayerBase</a>(input_dims, receptor_height, receptor_width, vertical_stride,</div><div class="line"><a name="l03177"></a><span class="lineno"> 3177</span>&#160;                        horizontal_stride) { }</div><div class="line"><a name="l03178"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer.html#a26a24d870ec2b776bc5c229ba01448a7"> 3178</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_max_pool_layer.html#a26a24d870ec2b776bc5c229ba01448a7">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03179"></a><span class="lineno"> 3179</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_max_pool_layer.html">MaxPoolLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l03180"></a><span class="lineno"> 3180</span>&#160;    }</div><div class="line"><a name="l03181"></a><span class="lineno"> 3181</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l03182"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer.html#a735124db085951aad791d44b24485610"> 3182</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_max_pool_layer.html#a735124db085951aad791d44b24485610">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l03183"></a><span class="lineno"> 3183</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,4&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::input_dims);</div><div class="line"><a name="l03184"></a><span class="lineno"> 3184</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l03185"></a><span class="lineno"> 3185</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l03186"></a><span class="lineno"> 3186</span>&#160;        <span class="keywordflow">return</span> PoolBase::_pass_forward(std::move(in), training);</div><div class="line"><a name="l03187"></a><span class="lineno"> 3187</span>&#160;    }</div><div class="line"><a name="l03188"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer.html#a50a2546e78f1e39a9fef5fcc4dbc10ca"> 3188</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_max_pool_layer.html#a50a2546e78f1e39a9fef5fcc4dbc10ca">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l03189"></a><span class="lineno"> 3189</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,4&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::output_dims);</div><div class="line"><a name="l03190"></a><span class="lineno"> 3190</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l03191"></a><span class="lineno"> 3191</span>&#160;        <span class="keywordflow">return</span> PoolBase::_pass_back(std::move(out_grad));</div><div class="line"><a name="l03192"></a><span class="lineno"> 3192</span>&#160;    }</div><div class="line"><a name="l03193"></a><span class="lineno"> 3193</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l03194"></a><span class="lineno"> 3194</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l03195"></a><span class="lineno"> 3195</span>&#160;};</div><div class="line"><a name="l03196"></a><span class="lineno"> 3196</span>&#160;</div><div class="line"><a name="l03202"></a><span class="lineno"> 3202</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l03203"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html"> 3203</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_max_pool_layer.html">MaxPoolLayer</a>&lt;Scalar,2&gt; : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolLayerBase</a>&lt;Scalar,2&gt; {</div><div class="line"><a name="l03204"></a><span class="lineno"> 3204</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l03205"></a><span class="lineno"> 3205</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_pool_layer.html">PoolBase</a>;</div><div class="line"><a name="l03206"></a><span class="lineno"> 3206</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolLayerBase&lt;Scalar,2&gt;</a> <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolBase</a>;</div><div class="line"><a name="l03207"></a><span class="lineno"> 3207</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03217"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#a21edc93d718d45b36cd574ce8b363ec5"> 3217</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#a21edc93d718d45b36cd574ce8b363ec5">MaxPoolLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>&amp; input_dims, std::size_t receptor_height = 2,</div><div class="line"><a name="l03218"></a><span class="lineno"> 3218</span>&#160;            std::size_t receptor_width = 2, std::size_t vertical_stride = 2, std::size_t horizontal_stride = 2) :</div><div class="line"><a name="l03219"></a><span class="lineno"> 3219</span>&#160;                <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolBase</a>::<a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolLayerBase</a>(input_dims, receptor_height, receptor_width, vertical_stride,</div><div class="line"><a name="l03220"></a><span class="lineno"> 3220</span>&#160;                        horizontal_stride) { }</div><div class="line"><a name="l03221"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#abf3096d94719bacc657cca0fcad1afb4"> 3221</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#abf3096d94719bacc657cca0fcad1afb4">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03222"></a><span class="lineno"> 3222</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_max_pool_layer.html">MaxPoolLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l03223"></a><span class="lineno"> 3223</span>&#160;    }</div><div class="line"><a name="l03224"></a><span class="lineno"> 3224</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l03225"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#a230df133932f7c470be5d6c796c3ca87"> 3225</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#a230df133932f7c470be5d6c796c3ca87">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l03226"></a><span class="lineno"> 3226</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::input_dims);</div><div class="line"><a name="l03227"></a><span class="lineno"> 3227</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l03228"></a><span class="lineno"> 3228</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l03229"></a><span class="lineno"> 3229</span>&#160;        <span class="keywordflow">return</span> PoolBase::_pass_forward(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(in.data(), { batch_size, in.dimension(1), in.dimension(2), 1u }), training)</div><div class="line"><a name="l03230"></a><span class="lineno"> 3230</span>&#160;                .reshape(std::array&lt;std::size_t,3&gt;({ batch_size, PoolBase::output_dims(0), PoolBase::output_dims(1) }));</div><div class="line"><a name="l03231"></a><span class="lineno"> 3231</span>&#160;    }</div><div class="line"><a name="l03232"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#a420dc3d7bbed6bfa1c706bc927ca7b25"> 3232</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#a420dc3d7bbed6bfa1c706bc927ca7b25">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l03233"></a><span class="lineno"> 3233</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,3&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::output_dims);</div><div class="line"><a name="l03234"></a><span class="lineno"> 3234</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l03235"></a><span class="lineno"> 3235</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> prev_out_grad = PoolBase::_pass_back(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(out_grad.data(),</div><div class="line"><a name="l03236"></a><span class="lineno"> 3236</span>&#160;                { batch_size, PoolBase::ext_output_dims(0), PoolBase::ext_output_dims(1), PoolBase::ext_output_dims(2) }));</div><div class="line"><a name="l03237"></a><span class="lineno"> 3237</span>&#160;        <span class="keywordflow">if</span> (PoolBase::is_input_layer())</div><div class="line"><a name="l03238"></a><span class="lineno"> 3238</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,3&gt;</a>();</div><div class="line"><a name="l03239"></a><span class="lineno"> 3239</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,3&gt;</a>(prev_out_grad.data(), { batch_size, PoolBase::input_dims(0), PoolBase::input_dims(1) });</div><div class="line"><a name="l03240"></a><span class="lineno"> 3240</span>&#160;    }</div><div class="line"><a name="l03241"></a><span class="lineno"> 3241</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l03242"></a><span class="lineno"> 3242</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l03243"></a><span class="lineno"> 3243</span>&#160;};</div><div class="line"><a name="l03244"></a><span class="lineno"> 3244</span>&#160;</div><div class="line"><a name="l03250"></a><span class="lineno"> 3250</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l03251"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html"> 3251</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_max_pool_layer.html">MaxPoolLayer</a>&lt;Scalar,1&gt; : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolLayerBase</a>&lt;Scalar,1&gt; {</div><div class="line"><a name="l03252"></a><span class="lineno"> 3252</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Root</a>;</div><div class="line"><a name="l03253"></a><span class="lineno"> 3253</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_pool_layer.html">PoolLayer&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_pool_layer.html">PoolBase</a>;</div><div class="line"><a name="l03254"></a><span class="lineno"> 3254</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolLayerBase&lt;Scalar,1&gt;</a> <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolBase</a>;</div><div class="line"><a name="l03255"></a><span class="lineno"> 3255</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03262"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#a01a4b38bcf4efb0af6ef29f63ced044a"> 3262</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#a01a4b38bcf4efb0af6ef29f63ced044a">MaxPoolLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,1&gt;</a>&amp; input_dims, std::size_t receptor_length = 2,</div><div class="line"><a name="l03263"></a><span class="lineno"> 3263</span>&#160;            std::size_t stride = 2) :</div><div class="line"><a name="l03264"></a><span class="lineno"> 3264</span>&#160;                <a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolBase</a>::<a class="code" href="classcattle_1_1_max_pool_layer_base.html">MaxPoolLayerBase</a>(input_dims, receptor_length, 1, stride, 1) { }</div><div class="line"><a name="l03265"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#a3190763e39f851cf28606dc1b7906f4a"> 3265</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Root</a>* <a class="code" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#a3190763e39f851cf28606dc1b7906f4a">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03266"></a><span class="lineno"> 3266</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_max_pool_layer.html">MaxPoolLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l03267"></a><span class="lineno"> 3267</span>&#160;    }</div><div class="line"><a name="l03268"></a><span class="lineno"> 3268</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l03269"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#ae8f4e95932e2d890d7d475198522e0bd"> 3269</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#ae8f4e95932e2d890d7d475198522e0bd">pass_forward</a>(<span class="keyword">typename</span> Root::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l03270"></a><span class="lineno"> 3270</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::input_dims);</div><div class="line"><a name="l03271"></a><span class="lineno"> 3271</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l03272"></a><span class="lineno"> 3272</span>&#160;        batch_size = in.dimension(0);</div><div class="line"><a name="l03273"></a><span class="lineno"> 3273</span>&#160;        <span class="keywordflow">return</span> PoolBase::_pass_forward(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(in.data(), { batch_size, in.dimension(1), 1u, 1u }), training)</div><div class="line"><a name="l03274"></a><span class="lineno"> 3274</span>&#160;                .reshape(std::array&lt;std::size_t,2&gt;({ batch_size, PoolBase::output_dims(0) }));</div><div class="line"><a name="l03275"></a><span class="lineno"> 3275</span>&#160;    }</div><div class="line"><a name="l03276"></a><span class="lineno"><a class="line" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#a4766dca992a2b2255a3bb8800dc00dc2"> 3276</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Root::Data <a class="code" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#a4766dca992a2b2255a3bb8800dc00dc2">pass_back</a>(<span class="keyword">typename</span> Root::Data out_grad) {</div><div class="line"><a name="l03277"></a><span class="lineno"> 3277</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,2&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == PoolBase::output_dims);</div><div class="line"><a name="l03278"></a><span class="lineno"> 3278</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_size == out_grad.dimension(0));</div><div class="line"><a name="l03279"></a><span class="lineno"> 3279</span>&#160;        <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,4&gt;</a> prev_out_grad = PoolBase::_pass_back(<a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,4&gt;</a>(out_grad.data(),</div><div class="line"><a name="l03280"></a><span class="lineno"> 3280</span>&#160;                { batch_size, PoolBase::ext_output_dims(0), PoolBase::ext_output_dims(1), PoolBase::ext_output_dims(2) }));</div><div class="line"><a name="l03281"></a><span class="lineno"> 3281</span>&#160;        <span class="keywordflow">if</span> (PoolBase::is_input_layer())</div><div class="line"><a name="l03282"></a><span class="lineno"> 3282</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">Tensor&lt;Scalar,2&gt;</a>();</div><div class="line"><a name="l03283"></a><span class="lineno"> 3283</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,2&gt;</a>(prev_out_grad.data(), { batch_size, PoolBase::input_dims(0) });</div><div class="line"><a name="l03284"></a><span class="lineno"> 3284</span>&#160;    }</div><div class="line"><a name="l03285"></a><span class="lineno"> 3285</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l03286"></a><span class="lineno"> 3286</span>&#160;    std::size_t batch_size;</div><div class="line"><a name="l03287"></a><span class="lineno"> 3287</span>&#160;};</div><div class="line"><a name="l03288"></a><span class="lineno"> 3288</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l03289"></a><span class="lineno"> 3289</span>&#160;</div><div class="line"><a name="l03292"></a><span class="lineno"> 3292</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l03293"></a><span class="lineno"> 3293</span>&#160;<span class="keyword">class </span>PoolLayer : <span class="keyword">public</span> Layer&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l03294"></a><span class="lineno"> 3294</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,Rank&gt; Base;</div><div class="line"><a name="l03295"></a><span class="lineno"> 3295</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,4&gt; Array4;</div><div class="line"><a name="l03296"></a><span class="lineno"> 3296</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03297"></a><span class="lineno"> 3297</span>&#160;    <span class="keyword">virtual</span> Base* clone() <span class="keyword">const</span> = 0;</div><div class="line"><a name="l03298"></a><span class="lineno"> 3298</span>&#160;    <span class="keyword">inline</span> Base* clone_with_shared_params() {</div><div class="line"><a name="l03299"></a><span class="lineno"> 3299</span>&#160;        <span class="keywordflow">return</span> clone();</div><div class="line"><a name="l03300"></a><span class="lineno"> 3300</span>&#160;    }</div><div class="line"><a name="l03301"></a><span class="lineno"> 3301</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Base&amp; get_params_owner()<span class="keyword"> const </span>{</div><div class="line"><a name="l03302"></a><span class="lineno"> 3302</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l03303"></a><span class="lineno"> 3303</span>&#160;    }</div><div class="line"><a name="l03304"></a><span class="lineno"> 3304</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; get_input_dims()<span class="keyword"> const </span>{</div><div class="line"><a name="l03305"></a><span class="lineno"> 3305</span>&#160;        <span class="keywordflow">return</span> input_dims;</div><div class="line"><a name="l03306"></a><span class="lineno"> 3306</span>&#160;    }</div><div class="line"><a name="l03307"></a><span class="lineno"> 3307</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; get_output_dims()<span class="keyword"> const </span>{</div><div class="line"><a name="l03308"></a><span class="lineno"> 3308</span>&#160;        <span class="keywordflow">return</span> output_dims;</div><div class="line"><a name="l03309"></a><span class="lineno"> 3309</span>&#160;    }</div><div class="line"><a name="l03310"></a><span class="lineno"> 3310</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Matrix&lt;Scalar&gt;&amp; get_params()<span class="keyword"> const </span>{</div><div class="line"><a name="l03311"></a><span class="lineno"> 3311</span>&#160;        <span class="keywordflow">return</span> params;</div><div class="line"><a name="l03312"></a><span class="lineno"> 3312</span>&#160;    }</div><div class="line"><a name="l03313"></a><span class="lineno"> 3313</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Matrix&lt;Scalar&gt;&amp; get_params_grad()<span class="keyword"> const </span>{</div><div class="line"><a name="l03314"></a><span class="lineno"> 3314</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l03315"></a><span class="lineno"> 3315</span>&#160;    }</div><div class="line"><a name="l03316"></a><span class="lineno"> 3316</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> is_frozen()<span class="keyword"> const </span>{</div><div class="line"><a name="l03317"></a><span class="lineno"> 3317</span>&#160;        <span class="keywordflow">return</span> frozen;</div><div class="line"><a name="l03318"></a><span class="lineno"> 3318</span>&#160;    }</div><div class="line"><a name="l03319"></a><span class="lineno"> 3319</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> set_frozen(<span class="keywordtype">bool</span> frozen) {</div><div class="line"><a name="l03320"></a><span class="lineno"> 3320</span>&#160;        this-&gt;frozen = frozen;</div><div class="line"><a name="l03321"></a><span class="lineno"> 3321</span>&#160;    }</div><div class="line"><a name="l03322"></a><span class="lineno"> 3322</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> init() { }</div><div class="line"><a name="l03323"></a><span class="lineno"> 3323</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l03324"></a><span class="lineno"> 3324</span>&#160;    <span class="keyword">inline</span> PoolLayer(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; input_dims, cudnnPoolingMode_t pool_mode,</div><div class="line"><a name="l03325"></a><span class="lineno"> 3325</span>&#160;            std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_stride,</div><div class="line"><a name="l03326"></a><span class="lineno"> 3326</span>&#160;            std::size_t horizontal_stride) :</div><div class="line"><a name="l03327"></a><span class="lineno"> 3327</span>&#160;                input_dims(input_dims),</div><div class="line"><a name="l03328"></a><span class="lineno"> 3328</span>&#160;                output_dims(calculate_adjusted_output_dims(input_dims, pool_mode, receptor_height,</div><div class="line"><a name="l03329"></a><span class="lineno"> 3329</span>&#160;                        receptor_width, vertical_stride, horizontal_stride)),</div><div class="line"><a name="l03330"></a><span class="lineno"> 3330</span>&#160;                receptor_height(receptor_height),</div><div class="line"><a name="l03331"></a><span class="lineno"> 3331</span>&#160;                receptor_width(receptor_width),</div><div class="line"><a name="l03332"></a><span class="lineno"> 3332</span>&#160;                vertical_stride(vertical_stride),</div><div class="line"><a name="l03333"></a><span class="lineno"> 3333</span>&#160;                horizontal_stride(horizontal_stride),</div><div class="line"><a name="l03334"></a><span class="lineno"> 3334</span>&#160;                pool_mode(pool_mode),</div><div class="line"><a name="l03335"></a><span class="lineno"> 3335</span>&#160;                adj_in_batch_dims(input_dims.template promote&lt;&gt;()),</div><div class="line"><a name="l03336"></a><span class="lineno"> 3336</span>&#160;                adj_out_batch_dims(output_dims.template promote&lt;&gt;()),</div><div class="line"><a name="l03337"></a><span class="lineno"> 3337</span>&#160;                in_batch_dims(input_dims.template promote&lt;&gt;().template extend&lt;3 - Rank&gt;()),</div><div class="line"><a name="l03338"></a><span class="lineno"> 3338</span>&#160;                out_batch_dims(output_dims.template promote&lt;&gt;().template extend&lt;3 - Rank&gt;()),</div><div class="line"><a name="l03339"></a><span class="lineno"> 3339</span>&#160;                input_layer(false),</div><div class="line"><a name="l03340"></a><span class="lineno"> 3340</span>&#160;                frozen(false),</div><div class="line"><a name="l03341"></a><span class="lineno"> 3341</span>&#160;                params(0, 0),</div><div class="line"><a name="l03342"></a><span class="lineno"> 3342</span>&#160;                params_grad(0, 0) {</div><div class="line"><a name="l03343"></a><span class="lineno"> 3343</span>&#160;        assert(receptor_height &gt; 0 &amp;&amp; receptor_width &gt; 0);</div><div class="line"><a name="l03344"></a><span class="lineno"> 3344</span>&#160;        assert(vertical_stride &gt; 0 &amp;&amp; horizontal_stride &gt; 0);</div><div class="line"><a name="l03345"></a><span class="lineno"> 3345</span>&#160;        assert(input_dims.template extend&lt;3 - Rank&gt;()(0) &gt;= receptor_height &amp;&amp;</div><div class="line"><a name="l03346"></a><span class="lineno"> 3346</span>&#160;                input_dims.template extend&lt;3 - Rank&gt;()(1) &gt;= receptor_width);</div><div class="line"><a name="l03347"></a><span class="lineno"> 3347</span>&#160;    }</div><div class="line"><a name="l03348"></a><span class="lineno"> 3348</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> is_input_layer()<span class="keyword"> const </span>{</div><div class="line"><a name="l03349"></a><span class="lineno"> 3349</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l03350"></a><span class="lineno"> 3350</span>&#160;    }</div><div class="line"><a name="l03351"></a><span class="lineno"> 3351</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> set_input_layer(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l03352"></a><span class="lineno"> 3352</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l03353"></a><span class="lineno"> 3353</span>&#160;    }</div><div class="line"><a name="l03354"></a><span class="lineno"> 3354</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> empty_cache() {</div><div class="line"><a name="l03355"></a><span class="lineno"> 3355</span>&#160;        input = <span class="keyword">typename</span> Base::Data();</div><div class="line"><a name="l03356"></a><span class="lineno"> 3356</span>&#160;        output = <span class="keyword">typename</span> Base::Data();</div><div class="line"><a name="l03357"></a><span class="lineno"> 3357</span>&#160;    }</div><div class="line"><a name="l03358"></a><span class="lineno"> 3358</span>&#160;    <span class="keyword">inline</span> Matrix&lt;Scalar&gt;&amp; get_params() {</div><div class="line"><a name="l03359"></a><span class="lineno"> 3359</span>&#160;        <span class="keywordflow">return</span> params;</div><div class="line"><a name="l03360"></a><span class="lineno"> 3360</span>&#160;    }</div><div class="line"><a name="l03361"></a><span class="lineno"> 3361</span>&#160;    <span class="keyword">inline</span> Matrix&lt;Scalar&gt;&amp; get_params_grad() {</div><div class="line"><a name="l03362"></a><span class="lineno"> 3362</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l03363"></a><span class="lineno"> 3363</span>&#160;    }</div><div class="line"><a name="l03364"></a><span class="lineno"> 3364</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> regularize() { }</div><div class="line"><a name="l03365"></a><span class="lineno"> 3365</span>&#160;    <span class="keyword">inline</span> Scalar get_regularization_penalty()<span class="keyword"> const </span>{</div><div class="line"><a name="l03366"></a><span class="lineno"> 3366</span>&#160;        <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l03367"></a><span class="lineno"> 3367</span>&#160;    }</div><div class="line"><a name="l03368"></a><span class="lineno"> 3368</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> enforce_constraints() { }</div><div class="line"><a name="l03369"></a><span class="lineno"> 3369</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data pass_forward(<span class="keyword">typename</span> Base::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l03370"></a><span class="lineno"> 3370</span>&#160;        assert((Dimensions&lt;std::size_t,Rank + 1&gt;(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == input_dims);</div><div class="line"><a name="l03371"></a><span class="lineno"> 3371</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l03372"></a><span class="lineno"> 3372</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l03373"></a><span class="lineno"> 3373</span>&#160;        in_batch_dims[0] = rows;</div><div class="line"><a name="l03374"></a><span class="lineno"> 3374</span>&#160;        out_batch_dims[0] = rows;</div><div class="line"><a name="l03375"></a><span class="lineno"> 3375</span>&#160;        adj_in_batch_dims[0] = rows;</div><div class="line"><a name="l03376"></a><span class="lineno"> 3376</span>&#160;        adj_out_batch_dims[0] = rows;</div><div class="line"><a name="l03377"></a><span class="lineno"> 3377</span>&#160;        <span class="keyword">typename</span> Base::Data out(adj_out_batch_dims);</div><div class="line"><a name="l03378"></a><span class="lineno"> 3378</span>&#160;        internal::CuDNNHandle&lt;Scalar&gt;::get_instance().pooling2d_fwd(in.data(), in_batch_dims,</div><div class="line"><a name="l03379"></a><span class="lineno"> 3379</span>&#160;                out_batch_dims, pool_mode, receptor_height, receptor_width, 0, 0, vertical_stride,</div><div class="line"><a name="l03380"></a><span class="lineno"> 3380</span>&#160;                horizontal_stride, out.data());</div><div class="line"><a name="l03381"></a><span class="lineno"> 3381</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l03382"></a><span class="lineno"> 3382</span>&#160;            input = std::move(in);</div><div class="line"><a name="l03383"></a><span class="lineno"> 3383</span>&#160;            output = out;</div><div class="line"><a name="l03384"></a><span class="lineno"> 3384</span>&#160;        }</div><div class="line"><a name="l03385"></a><span class="lineno"> 3385</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l03386"></a><span class="lineno"> 3386</span>&#160;    }</div><div class="line"><a name="l03387"></a><span class="lineno"> 3387</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data pass_back(<span class="keyword">typename</span> Base::Data out_grad) {</div><div class="line"><a name="l03388"></a><span class="lineno"> 3388</span>&#160;        assert((Dimensions&lt;std::size_t,Rank + 1&gt;(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == output_dims);</div><div class="line"><a name="l03389"></a><span class="lineno"> 3389</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; out_batch_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l03390"></a><span class="lineno"> 3390</span>&#160;        <span class="keyword">typename</span> Base::Data prev_out_grad(adj_in_batch_dims);</div><div class="line"><a name="l03391"></a><span class="lineno"> 3391</span>&#160;        internal::CuDNNHandle&lt;Scalar&gt;::get_instance().pooling2d_bwd(input.data(), output.data(), out_grad.data(),</div><div class="line"><a name="l03392"></a><span class="lineno"> 3392</span>&#160;                in_batch_dims, out_batch_dims, pool_mode, receptor_height, receptor_width, 0, 0, vertical_stride,</div><div class="line"><a name="l03393"></a><span class="lineno"> 3393</span>&#160;                horizontal_stride, prev_out_grad.data());</div><div class="line"><a name="l03394"></a><span class="lineno"> 3394</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l03395"></a><span class="lineno"> 3395</span>&#160;    }</div><div class="line"><a name="l03396"></a><span class="lineno"> 3396</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt; input_dims;</div><div class="line"><a name="l03397"></a><span class="lineno"> 3397</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt; output_dims;</div><div class="line"><a name="l03398"></a><span class="lineno"> 3398</span>&#160;    <span class="keyword">const</span> std::size_t receptor_height;</div><div class="line"><a name="l03399"></a><span class="lineno"> 3399</span>&#160;    <span class="keyword">const</span> std::size_t receptor_width;</div><div class="line"><a name="l03400"></a><span class="lineno"> 3400</span>&#160;    <span class="keyword">const</span> std::size_t vertical_stride;</div><div class="line"><a name="l03401"></a><span class="lineno"> 3401</span>&#160;    <span class="keyword">const</span> std::size_t horizontal_stride;</div><div class="line"><a name="l03402"></a><span class="lineno"> 3402</span>&#160;    <span class="keyword">const</span> cudnnPoolingMode_t pool_mode;</div><div class="line"><a name="l03403"></a><span class="lineno"> 3403</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l03404"></a><span class="lineno"> 3404</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> Array4 calculate_output_dims(<span class="keyword">const</span> Array4&amp; input_dims, cudnnPoolingMode_t pool_mode,</div><div class="line"><a name="l03405"></a><span class="lineno"> 3405</span>&#160;            std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_stride,</div><div class="line"><a name="l03406"></a><span class="lineno"> 3406</span>&#160;            std::size_t horizontal_stride) {</div><div class="line"><a name="l03407"></a><span class="lineno"> 3407</span>&#160;        <span class="keywordflow">return</span> internal::CuDNNHandle&lt;Scalar&gt;::get_instance().pooling2d_output_dims(input_dims, pool_mode, receptor_height,</div><div class="line"><a name="l03408"></a><span class="lineno"> 3408</span>&#160;                receptor_width, 0, 0, vertical_stride, horizontal_stride);</div><div class="line"><a name="l03409"></a><span class="lineno"> 3409</span>&#160;    }</div><div class="line"><a name="l03410"></a><span class="lineno"> 3410</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> Dimensions&lt;std::size_t,Rank&gt; calculate_adjusted_output_dims(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; input_dims,</div><div class="line"><a name="l03411"></a><span class="lineno"> 3411</span>&#160;            cudnnPoolingMode_t pool_mode, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_stride,</div><div class="line"><a name="l03412"></a><span class="lineno"> 3412</span>&#160;            std::size_t horizontal_stride) {</div><div class="line"><a name="l03413"></a><span class="lineno"> 3413</span>&#160;        <span class="keyword">auto</span> output_dims = calculate_output_dims(input_dims.template extend&lt;3 - Rank&gt;().template promote&lt;&gt;(), pool_mode,</div><div class="line"><a name="l03414"></a><span class="lineno"> 3414</span>&#160;                receptor_height, receptor_width, vertical_stride, horizontal_stride);</div><div class="line"><a name="l03415"></a><span class="lineno"> 3415</span>&#160;        <span class="keywordflow">return</span> Dimensions&lt;std::size_t,4&gt;(output_dims).<span class="keyword">template</span> demote&lt;&gt;().template contract&lt;3 - Rank&gt;();</div><div class="line"><a name="l03416"></a><span class="lineno"> 3416</span>&#160;    }</div><div class="line"><a name="l03417"></a><span class="lineno"> 3417</span>&#160;    std::array&lt;std::size_t,Rank + 1&gt; adj_in_batch_dims;</div><div class="line"><a name="l03418"></a><span class="lineno"> 3418</span>&#160;    std::array&lt;std::size_t,Rank + 1&gt; adj_out_batch_dims;</div><div class="line"><a name="l03419"></a><span class="lineno"> 3419</span>&#160;    std::array&lt;std::size_t,4&gt; in_batch_dims;</div><div class="line"><a name="l03420"></a><span class="lineno"> 3420</span>&#160;    std::array&lt;std::size_t,4&gt; out_batch_dims;</div><div class="line"><a name="l03421"></a><span class="lineno"> 3421</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l03422"></a><span class="lineno"> 3422</span>&#160;    <span class="keywordtype">bool</span> frozen;</div><div class="line"><a name="l03423"></a><span class="lineno"> 3423</span>&#160;    Matrix&lt;Scalar&gt; params;</div><div class="line"><a name="l03424"></a><span class="lineno"> 3424</span>&#160;    Matrix&lt;Scalar&gt; params_grad;</div><div class="line"><a name="l03425"></a><span class="lineno"> 3425</span>&#160;    <span class="keyword">typename</span> Base::Data input;</div><div class="line"><a name="l03426"></a><span class="lineno"> 3426</span>&#160;    <span class="keyword">typename</span> Base::Data output;</div><div class="line"><a name="l03427"></a><span class="lineno"> 3427</span>&#160;};</div><div class="line"><a name="l03428"></a><span class="lineno"> 3428</span>&#160;</div><div class="line"><a name="l03432"></a><span class="lineno"> 3432</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank = 3&gt;</div><div class="line"><a name="l03433"></a><span class="lineno"> 3433</span>&#160;<span class="keyword">class </span>MeanPoolLayer : <span class="keyword">public</span> PoolLayer&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l03434"></a><span class="lineno"> 3434</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,Rank&gt; Root;</div><div class="line"><a name="l03435"></a><span class="lineno"> 3435</span>&#160;    <span class="keyword">typedef</span> PoolLayer&lt;Scalar,Rank&gt; Base;</div><div class="line"><a name="l03436"></a><span class="lineno"> 3436</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03446"></a><span class="lineno"> 3446</span>&#160;    <span class="keyword">inline</span> MeanPoolLayer(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; input_dims, std::size_t receptor_height = 2,</div><div class="line"><a name="l03447"></a><span class="lineno"> 3447</span>&#160;            std::size_t receptor_width = 2, std::size_t vertical_stride = 2, std::size_t horizontal_stride = 2) :</div><div class="line"><a name="l03448"></a><span class="lineno"> 3448</span>&#160;                Base::PoolLayer(input_dims, CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING, receptor_height,</div><div class="line"><a name="l03449"></a><span class="lineno"> 3449</span>&#160;                        receptor_width, vertical_stride, horizontal_stride) { }</div><div class="line"><a name="l03450"></a><span class="lineno"> 3450</span>&#160;    <span class="keyword">inline</span> Root* clone()<span class="keyword"> const </span>{</div><div class="line"><a name="l03451"></a><span class="lineno"> 3451</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> MeanPoolLayer(*<span class="keyword">this</span>);</div><div class="line"><a name="l03452"></a><span class="lineno"> 3452</span>&#160;    }</div><div class="line"><a name="l03453"></a><span class="lineno"> 3453</span>&#160;};</div><div class="line"><a name="l03454"></a><span class="lineno"> 3454</span>&#160;</div><div class="line"><a name="l03458"></a><span class="lineno"> 3458</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l03459"></a><span class="lineno"> 3459</span>&#160;<span class="keyword">class </span>MeanPoolLayer&lt;Scalar,1&gt; : <span class="keyword">public</span> PoolLayer&lt;Scalar,1&gt; {</div><div class="line"><a name="l03460"></a><span class="lineno"> 3460</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,1&gt; Root;</div><div class="line"><a name="l03461"></a><span class="lineno"> 3461</span>&#160;    <span class="keyword">typedef</span> PoolLayer&lt;Scalar,1&gt; Base;</div><div class="line"><a name="l03462"></a><span class="lineno"> 3462</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03469"></a><span class="lineno"> 3469</span>&#160;    <span class="keyword">inline</span> MeanPoolLayer(<span class="keyword">const</span> Dimensions&lt;std::size_t,1&gt;&amp; input_dims, std::size_t receptor_length = 2,</div><div class="line"><a name="l03470"></a><span class="lineno"> 3470</span>&#160;            std::size_t stride = 2) :</div><div class="line"><a name="l03471"></a><span class="lineno"> 3471</span>&#160;                Base::PoolLayer(input_dims, CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING, receptor_length, 1,</div><div class="line"><a name="l03472"></a><span class="lineno"> 3472</span>&#160;                        stride, 1) { }</div><div class="line"><a name="l03473"></a><span class="lineno"> 3473</span>&#160;    <span class="keyword">inline</span> Root* clone()<span class="keyword"> const </span>{</div><div class="line"><a name="l03474"></a><span class="lineno"> 3474</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> MeanPoolLayer(*<span class="keyword">this</span>);</div><div class="line"><a name="l03475"></a><span class="lineno"> 3475</span>&#160;    }</div><div class="line"><a name="l03476"></a><span class="lineno"> 3476</span>&#160;};</div><div class="line"><a name="l03477"></a><span class="lineno"> 3477</span>&#160;</div><div class="line"><a name="l03483"></a><span class="lineno"> 3483</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank = 3&gt;</div><div class="line"><a name="l03484"></a><span class="lineno"> 3484</span>&#160;<span class="keyword">class </span>MaxPoolLayer : <span class="keyword">public</span> PoolLayer&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l03485"></a><span class="lineno"> 3485</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,Rank&gt; Root;</div><div class="line"><a name="l03486"></a><span class="lineno"> 3486</span>&#160;    <span class="keyword">typedef</span> PoolLayer&lt;Scalar,Rank&gt; Base;</div><div class="line"><a name="l03487"></a><span class="lineno"> 3487</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03497"></a><span class="lineno"> 3497</span>&#160;    <span class="keyword">inline</span> MaxPoolLayer(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; input_dims, std::size_t receptor_height = 2,</div><div class="line"><a name="l03498"></a><span class="lineno"> 3498</span>&#160;            std::size_t receptor_width = 2, std::size_t vertical_stride = 2, std::size_t horizontal_stride = 2) :</div><div class="line"><a name="l03499"></a><span class="lineno"> 3499</span>&#160;                Base::PoolLayer(input_dims, CUDNN_POOLING_MAX, receptor_height, receptor_width, vertical_stride,</div><div class="line"><a name="l03500"></a><span class="lineno"> 3500</span>&#160;                        horizontal_stride) { }</div><div class="line"><a name="l03501"></a><span class="lineno"> 3501</span>&#160;    <span class="keyword">inline</span> Root* clone()<span class="keyword"> const </span>{</div><div class="line"><a name="l03502"></a><span class="lineno"> 3502</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> MaxPoolLayer(*<span class="keyword">this</span>);</div><div class="line"><a name="l03503"></a><span class="lineno"> 3503</span>&#160;    }</div><div class="line"><a name="l03504"></a><span class="lineno"> 3504</span>&#160;};</div><div class="line"><a name="l03505"></a><span class="lineno"> 3505</span>&#160;</div><div class="line"><a name="l03511"></a><span class="lineno"> 3511</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l03512"></a><span class="lineno"> 3512</span>&#160;<span class="keyword">class </span>MaxPoolLayer&lt;Scalar,1&gt; : <span class="keyword">public</span> PoolLayer&lt;Scalar,1&gt; {</div><div class="line"><a name="l03513"></a><span class="lineno"> 3513</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,1&gt; Root;</div><div class="line"><a name="l03514"></a><span class="lineno"> 3514</span>&#160;    <span class="keyword">typedef</span> PoolLayer&lt;Scalar,1&gt; Base;</div><div class="line"><a name="l03515"></a><span class="lineno"> 3515</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03522"></a><span class="lineno"> 3522</span>&#160;    <span class="keyword">inline</span> MaxPoolLayer(<span class="keyword">const</span> Dimensions&lt;std::size_t,1&gt;&amp; input_dims, std::size_t receptor_length = 2,</div><div class="line"><a name="l03523"></a><span class="lineno"> 3523</span>&#160;            std::size_t stride = 2) :</div><div class="line"><a name="l03524"></a><span class="lineno"> 3524</span>&#160;                Base::PoolLayer(input_dims, CUDNN_POOLING_MAX, receptor_length, 1, stride, 1) { }</div><div class="line"><a name="l03525"></a><span class="lineno"> 3525</span>&#160;    <span class="keyword">inline</span> Root* clone()<span class="keyword"> const </span>{</div><div class="line"><a name="l03526"></a><span class="lineno"> 3526</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> MaxPoolLayer(*<span class="keyword">this</span>);</div><div class="line"><a name="l03527"></a><span class="lineno"> 3527</span>&#160;    }</div><div class="line"><a name="l03528"></a><span class="lineno"> 3528</span>&#160;};</div><div class="line"><a name="l03529"></a><span class="lineno"> 3529</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l03530"></a><span class="lineno"> 3530</span>&#160;</div><div class="line"><a name="l03535"></a><span class="lineno"> 3535</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l03536"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html"> 3536</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_broadcast_layer.html">BroadcastLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l03537"></a><span class="lineno"> 3537</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l03538"></a><span class="lineno"> 3538</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,Rank + 1&gt; RankwiseArray;</div><div class="line"><a name="l03539"></a><span class="lineno"> 3539</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03545"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a18b7c3f932b25b84f2bbfc80cdb6c011"> 3545</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_broadcast_layer.html#a18b7c3f932b25b84f2bbfc80cdb6c011">BroadcastLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; input_dims,</div><div class="line"><a name="l03546"></a><span class="lineno"> 3546</span>&#160;            <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; broadcast) :</div><div class="line"><a name="l03547"></a><span class="lineno"> 3547</span>&#160;                input_dims(input_dims),</div><div class="line"><a name="l03548"></a><span class="lineno"> 3548</span>&#160;                output_dims(input_dims * broadcast),</div><div class="line"><a name="l03549"></a><span class="lineno"> 3549</span>&#160;                input_layer(false),</div><div class="line"><a name="l03550"></a><span class="lineno"> 3550</span>&#160;                frozen(false),</div><div class="line"><a name="l03551"></a><span class="lineno"> 3551</span>&#160;                broadcast(broadcast.template promote&lt;&gt;()),</div><div class="line"><a name="l03552"></a><span class="lineno"> 3552</span>&#160;                params(0, 0),</div><div class="line"><a name="l03553"></a><span class="lineno"> 3553</span>&#160;                params_grad(0, 0) {</div><div class="line"><a name="l03554"></a><span class="lineno"> 3554</span>&#160;        slice_offsets.fill(0);</div><div class="line"><a name="l03555"></a><span class="lineno"> 3555</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt; Rank; ++i)</div><div class="line"><a name="l03556"></a><span class="lineno"> 3556</span>&#160;            assert(broadcast(i) &gt; 0);</div><div class="line"><a name="l03557"></a><span class="lineno"> 3557</span>&#160;    }</div><div class="line"><a name="l03558"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a44310d6481f10b0ff302979a51b38a1e"> 3558</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_broadcast_layer.html#a44310d6481f10b0ff302979a51b38a1e">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03559"></a><span class="lineno"> 3559</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_broadcast_layer.html">BroadcastLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l03560"></a><span class="lineno"> 3560</span>&#160;    }</div><div class="line"><a name="l03561"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a9996f83ed27ef7abcb9df3f8f64fc14e"> 3561</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_broadcast_layer.html#a9996f83ed27ef7abcb9df3f8f64fc14e">clone_with_shared_params</a>() {</div><div class="line"><a name="l03562"></a><span class="lineno"> 3562</span>&#160;        <span class="keywordflow">return</span> clone();</div><div class="line"><a name="l03563"></a><span class="lineno"> 3563</span>&#160;    }</div><div class="line"><a name="l03564"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a02660b1012003ef67a1f98730de09489"> 3564</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>&amp; <a class="code" href="classcattle_1_1_broadcast_layer.html#a02660b1012003ef67a1f98730de09489">get_params_owner</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03565"></a><span class="lineno"> 3565</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l03566"></a><span class="lineno"> 3566</span>&#160;    }</div><div class="line"><a name="l03567"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#aa1113a0964adeb6c688489dfc51221ee"> 3567</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_broadcast_layer.html#aa1113a0964adeb6c688489dfc51221ee">get_input_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03568"></a><span class="lineno"> 3568</span>&#160;        <span class="keywordflow">return</span> input_dims;</div><div class="line"><a name="l03569"></a><span class="lineno"> 3569</span>&#160;    }</div><div class="line"><a name="l03570"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a96c2d546cf321f1532e4efde7fc44419"> 3570</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_broadcast_layer.html#a96c2d546cf321f1532e4efde7fc44419">get_output_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03571"></a><span class="lineno"> 3571</span>&#160;        <span class="keywordflow">return</span> output_dims;</div><div class="line"><a name="l03572"></a><span class="lineno"> 3572</span>&#160;    }</div><div class="line"><a name="l03573"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a025e9d6f4267555ffd115a76397298d8"> 3573</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_broadcast_layer.html#a025e9d6f4267555ffd115a76397298d8">get_params</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03574"></a><span class="lineno"> 3574</span>&#160;        <span class="keywordflow">return</span> params;</div><div class="line"><a name="l03575"></a><span class="lineno"> 3575</span>&#160;    }</div><div class="line"><a name="l03576"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#acdf570a1b89a163d411fdbb2efcf3851"> 3576</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_broadcast_layer.html#acdf570a1b89a163d411fdbb2efcf3851">get_params_grad</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03577"></a><span class="lineno"> 3577</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l03578"></a><span class="lineno"> 3578</span>&#160;    }</div><div class="line"><a name="l03579"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#aa69b5903eb6b03f700cbde298718f695"> 3579</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_broadcast_layer.html#aa69b5903eb6b03f700cbde298718f695">is_frozen</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03580"></a><span class="lineno"> 3580</span>&#160;        <span class="keywordflow">return</span> frozen;</div><div class="line"><a name="l03581"></a><span class="lineno"> 3581</span>&#160;    }</div><div class="line"><a name="l03582"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a1c430298492efebd89502cd1af32ab32"> 3582</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_broadcast_layer.html#a1c430298492efebd89502cd1af32ab32">set_frozen</a>(<span class="keywordtype">bool</span> frozen) {</div><div class="line"><a name="l03583"></a><span class="lineno"> 3583</span>&#160;        this-&gt;frozen = frozen;</div><div class="line"><a name="l03584"></a><span class="lineno"> 3584</span>&#160;    }</div><div class="line"><a name="l03585"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#afc538c1dccf3c50e090356562456fb23"> 3585</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_broadcast_layer.html#afc538c1dccf3c50e090356562456fb23">init</a>() { }</div><div class="line"><a name="l03586"></a><span class="lineno"> 3586</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l03587"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#ab3321ebfcbeeaf3c97a8a3ed4c3d48fc"> 3587</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_broadcast_layer.html#ab3321ebfcbeeaf3c97a8a3ed4c3d48fc">is_input_layer</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03588"></a><span class="lineno"> 3588</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l03589"></a><span class="lineno"> 3589</span>&#160;    }</div><div class="line"><a name="l03590"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#ac454d37d09cc063531c2e750f45cf511"> 3590</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_broadcast_layer.html#ac454d37d09cc063531c2e750f45cf511">set_input_layer</a>(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l03591"></a><span class="lineno"> 3591</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l03592"></a><span class="lineno"> 3592</span>&#160;    }</div><div class="line"><a name="l03593"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a003e6d570d2775a86b018e7676dde67a"> 3593</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_broadcast_layer.html#a003e6d570d2775a86b018e7676dde67a">empty_cache</a>() { }</div><div class="line"><a name="l03594"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#ab6c060e14a2e7d70c2b9e10e41117c6b"> 3594</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_broadcast_layer.html#ab6c060e14a2e7d70c2b9e10e41117c6b">get_params</a>() {</div><div class="line"><a name="l03595"></a><span class="lineno"> 3595</span>&#160;        <span class="keywordflow">return</span> params;</div><div class="line"><a name="l03596"></a><span class="lineno"> 3596</span>&#160;    }</div><div class="line"><a name="l03597"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a3e97c445cb968e46fa032db7639f0177"> 3597</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_broadcast_layer.html#a3e97c445cb968e46fa032db7639f0177">get_params_grad</a>() {</div><div class="line"><a name="l03598"></a><span class="lineno"> 3598</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l03599"></a><span class="lineno"> 3599</span>&#160;    }</div><div class="line"><a name="l03600"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a41035543a76d576abdc5c0b1e8e5487f"> 3600</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_broadcast_layer.html#a41035543a76d576abdc5c0b1e8e5487f">regularize</a>() { }</div><div class="line"><a name="l03601"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a86e85013180c35664a142a1e0e6acae5"> 3601</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1_broadcast_layer.html#a86e85013180c35664a142a1e0e6acae5">get_regularization_penalty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03602"></a><span class="lineno"> 3602</span>&#160;        <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l03603"></a><span class="lineno"> 3603</span>&#160;    }</div><div class="line"><a name="l03604"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a97b185d4e3ccda64313d234d7cc38a86"> 3604</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_broadcast_layer.html#a97b185d4e3ccda64313d234d7cc38a86">enforce_constraints</a>() { }</div><div class="line"><a name="l03605"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a47b9545f9324f4a039e7cd94a0f590d3"> 3605</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_broadcast_layer.html#a47b9545f9324f4a039e7cd94a0f590d3">pass_forward</a>(<span class="keyword">typename</span> Base::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l03606"></a><span class="lineno"> 3606</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == input_dims);</div><div class="line"><a name="l03607"></a><span class="lineno"> 3607</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l03608"></a><span class="lineno"> 3608</span>&#160;        rows = in.dimension(0);</div><div class="line"><a name="l03609"></a><span class="lineno"> 3609</span>&#160;        <span class="keywordflow">return</span> in.broadcast(broadcast);</div><div class="line"><a name="l03610"></a><span class="lineno"> 3610</span>&#160;    }</div><div class="line"><a name="l03611"></a><span class="lineno"><a class="line" href="classcattle_1_1_broadcast_layer.html#a1f24f60a80843b341131b87270f02ec5"> 3611</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_broadcast_layer.html#a1f24f60a80843b341131b87270f02ec5">pass_back</a>(<span class="keyword">typename</span> Base::Data out_grad) {</div><div class="line"><a name="l03612"></a><span class="lineno"> 3612</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == output_dims);</div><div class="line"><a name="l03613"></a><span class="lineno"> 3613</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; rows == out_grad.dimension(0));</div><div class="line"><a name="l03614"></a><span class="lineno"> 3614</span>&#160;        <span class="keyword">typename</span> Base::Data prev_out_grad = std::move(out_grad);</div><div class="line"><a name="l03615"></a><span class="lineno"> 3615</span>&#160;        slice_offsets.fill(0);</div><div class="line"><a name="l03616"></a><span class="lineno"> 3616</span>&#160;        slice_extents = output_dims.template promote&lt;&gt;();</div><div class="line"><a name="l03617"></a><span class="lineno"> 3617</span>&#160;        slice_extents[0] = rows;</div><div class="line"><a name="l03618"></a><span class="lineno"> 3618</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt; Rank; ++i) {</div><div class="line"><a name="l03619"></a><span class="lineno"> 3619</span>&#160;            <span class="keywordflow">if</span> (broadcast[i + 1] &lt;= 1)</div><div class="line"><a name="l03620"></a><span class="lineno"> 3620</span>&#160;                <span class="keywordflow">continue</span>;</div><div class="line"><a name="l03621"></a><span class="lineno"> 3621</span>&#160;            slice_extents[i + 1] = input_dims(i);</div><div class="line"><a name="l03622"></a><span class="lineno"> 3622</span>&#160;            <span class="keyword">typename</span> Base::Data work_tensor(slice_extents);</div><div class="line"><a name="l03623"></a><span class="lineno"> 3623</span>&#160;            work_tensor.setZero();</div><div class="line"><a name="l03624"></a><span class="lineno"> 3624</span>&#160;            <span class="keywordflow">for</span> (std::size_t j = 0; j &lt; broadcast[i + 1]; ++j) {</div><div class="line"><a name="l03625"></a><span class="lineno"> 3625</span>&#160;                work_tensor += prev_out_grad.slice(slice_offsets, slice_extents);</div><div class="line"><a name="l03626"></a><span class="lineno"> 3626</span>&#160;                slice_offsets[i + 1] += input_dims(i);</div><div class="line"><a name="l03627"></a><span class="lineno"> 3627</span>&#160;            }</div><div class="line"><a name="l03628"></a><span class="lineno"> 3628</span>&#160;            slice_offsets[i + 1] = 0;</div><div class="line"><a name="l03629"></a><span class="lineno"> 3629</span>&#160;            prev_out_grad = std::move(work_tensor);</div><div class="line"><a name="l03630"></a><span class="lineno"> 3630</span>&#160;        }</div><div class="line"><a name="l03631"></a><span class="lineno"> 3631</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l03632"></a><span class="lineno"> 3632</span>&#160;    }</div><div class="line"><a name="l03633"></a><span class="lineno"> 3633</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l03634"></a><span class="lineno"> 3634</span>&#160;    <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a> input_dims;</div><div class="line"><a name="l03635"></a><span class="lineno"> 3635</span>&#160;    <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a> output_dims;</div><div class="line"><a name="l03636"></a><span class="lineno"> 3636</span>&#160;    RankwiseArray broadcast;</div><div class="line"><a name="l03637"></a><span class="lineno"> 3637</span>&#160;    RankwiseArray slice_offsets;</div><div class="line"><a name="l03638"></a><span class="lineno"> 3638</span>&#160;    RankwiseArray slice_extents;</div><div class="line"><a name="l03639"></a><span class="lineno"> 3639</span>&#160;    std::size_t rows;</div><div class="line"><a name="l03640"></a><span class="lineno"> 3640</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l03641"></a><span class="lineno"> 3641</span>&#160;    <span class="keywordtype">bool</span> frozen;</div><div class="line"><a name="l03642"></a><span class="lineno"> 3642</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> params;</div><div class="line"><a name="l03643"></a><span class="lineno"> 3643</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> params_grad;</div><div class="line"><a name="l03644"></a><span class="lineno"> 3644</span>&#160;};</div><div class="line"><a name="l03645"></a><span class="lineno"> 3645</span>&#160;</div><div class="line"><a name="l03646"></a><span class="lineno"> 3646</span>&#160;<span class="preprocessor">#ifndef CATTLE_USE_CUDNN</span></div><div class="line"><a name="l03647"></a><span class="lineno"> 3647</span>&#160;</div><div class="line"><a name="l03652"></a><span class="lineno"> 3652</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank, <span class="keywordtype">bool</span> PerLastRank = (Rank == 3)&gt;</div><div class="line"><a name="l03653"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html"> 3653</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l03654"></a><span class="lineno"> 3654</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l03655"></a><span class="lineno"> 3655</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer&lt;Scalar,Rank,PerLastRank&gt;</a> <a class="code" href="classcattle_1_1_batch_norm_layer.html">Self</a>;</div><div class="line"><a name="l03656"></a><span class="lineno"> 3656</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03668"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a9fcfa190cdb86ee669c5809296ee2229"> 3668</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a9fcfa190cdb86ee669c5809296ee2229">BatchNormLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims, <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> gamma_reg = Base::NO_PARAM_REG,</div><div class="line"><a name="l03669"></a><span class="lineno"> 3669</span>&#160;            <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> beta_reg = Base::NO_PARAM_REG, Scalar gamma_max_norm_constraint = 0,</div><div class="line"><a name="l03670"></a><span class="lineno"> 3670</span>&#160;            Scalar beta_max_norm_constraint = 0, Scalar norm_avg_decay = .1, Scalar epsilon = <a class="code" href="classcattle_1_1internal_1_1_numeric_utils.html">internal::NumericUtils&lt;Scalar&gt;::EPSILON2</a>) :</div><div class="line"><a name="l03671"></a><span class="lineno"> 3671</span>&#160;                dims(dims),</div><div class="line"><a name="l03672"></a><span class="lineno"> 3672</span>&#160;                gamma_reg(gamma_reg),</div><div class="line"><a name="l03673"></a><span class="lineno"> 3673</span>&#160;                beta_reg(beta_reg),</div><div class="line"><a name="l03674"></a><span class="lineno"> 3674</span>&#160;                gamma_max_norm_constraint(gamma_max_norm_constraint),</div><div class="line"><a name="l03675"></a><span class="lineno"> 3675</span>&#160;                beta_max_norm_constraint(beta_max_norm_constraint),</div><div class="line"><a name="l03676"></a><span class="lineno"> 3676</span>&#160;                gamma_max_norm(internal::NumericUtils&lt;Scalar&gt;::decidedly_greater(gamma_max_norm_constraint, (Scalar) 0)),</div><div class="line"><a name="l03677"></a><span class="lineno"> 3677</span>&#160;                beta_max_norm(internal::NumericUtils&lt;Scalar&gt;::decidedly_greater(beta_max_norm_constraint, (Scalar) 0)),</div><div class="line"><a name="l03678"></a><span class="lineno"> 3678</span>&#160;                norm_avg_decay(norm_avg_decay),</div><div class="line"><a name="l03679"></a><span class="lineno"> 3679</span>&#160;                epsilon(epsilon),</div><div class="line"><a name="l03680"></a><span class="lineno"> 3680</span>&#160;                channels(dims(Rank - 1)),</div><div class="line"><a name="l03681"></a><span class="lineno"> 3681</span>&#160;                input_layer(false),</div><div class="line"><a name="l03682"></a><span class="lineno"> 3682</span>&#160;                frozen(false),</div><div class="line"><a name="l03683"></a><span class="lineno"> 3683</span>&#160;                offsets(),</div><div class="line"><a name="l03684"></a><span class="lineno"> 3684</span>&#160;                extents(dims.template promote&lt;&gt;()),</div><div class="line"><a name="l03685"></a><span class="lineno"> 3685</span>&#160;                avg_means(channels),</div><div class="line"><a name="l03686"></a><span class="lineno"> 3686</span>&#160;                avg_inv_sds(channels),</div><div class="line"><a name="l03687"></a><span class="lineno"> 3687</span>&#160;                avgs_init(false),</div><div class="line"><a name="l03688"></a><span class="lineno"> 3688</span>&#160;                params(channels, 2),</div><div class="line"><a name="l03689"></a><span class="lineno"> 3689</span>&#160;                params_grad(params.rows(), params.cols()),</div><div class="line"><a name="l03690"></a><span class="lineno"> 3690</span>&#160;                params_ref(params),</div><div class="line"><a name="l03691"></a><span class="lineno"> 3691</span>&#160;                owner(*this),</div><div class="line"><a name="l03692"></a><span class="lineno"> 3692</span>&#160;                cache_vec(channels) {</div><div class="line"><a name="l03693"></a><span class="lineno"> 3693</span>&#160;        assert(gamma_reg != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l03694"></a><span class="lineno"> 3694</span>&#160;        assert(beta_reg != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l03695"></a><span class="lineno"> 3695</span>&#160;        assert(norm_avg_decay &gt;= 0 &amp;&amp; norm_avg_decay &lt;= 1 &amp;&amp;</div><div class="line"><a name="l03696"></a><span class="lineno"> 3696</span>&#160;                <span class="stringliteral">&quot;norm avg decay must not be less than 0 or greater than 1&quot;</span>);</div><div class="line"><a name="l03697"></a><span class="lineno"> 3697</span>&#160;        assert(epsilon &gt; 0 &amp;&amp; <span class="stringliteral">&quot;epsilon must be greater than 0&quot;</span>);</div><div class="line"><a name="l03698"></a><span class="lineno"> 3698</span>&#160;        offsets.fill(0);</div><div class="line"><a name="l03699"></a><span class="lineno"> 3699</span>&#160;        extents[Rank] = 1;</div><div class="line"><a name="l03700"></a><span class="lineno"> 3700</span>&#160;    }</div><div class="line"><a name="l03701"></a><span class="lineno"> 3701</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a>(<span class="keyword">const</span> Self&amp; layer) :</div><div class="line"><a name="l03702"></a><span class="lineno"> 3702</span>&#160;            dims(layer.dims),</div><div class="line"><a name="l03703"></a><span class="lineno"> 3703</span>&#160;            gamma_reg(layer.gamma_reg),</div><div class="line"><a name="l03704"></a><span class="lineno"> 3704</span>&#160;            beta_reg(layer.beta_reg),</div><div class="line"><a name="l03705"></a><span class="lineno"> 3705</span>&#160;            gamma_max_norm_constraint(layer.gamma_max_norm_constraint),</div><div class="line"><a name="l03706"></a><span class="lineno"> 3706</span>&#160;            beta_max_norm_constraint(layer.beta_max_norm_constraint),</div><div class="line"><a name="l03707"></a><span class="lineno"> 3707</span>&#160;            gamma_max_norm(layer.gamma_max_norm),</div><div class="line"><a name="l03708"></a><span class="lineno"> 3708</span>&#160;            beta_max_norm(layer.beta_max_norm),</div><div class="line"><a name="l03709"></a><span class="lineno"> 3709</span>&#160;            norm_avg_decay(layer.norm_avg_decay),</div><div class="line"><a name="l03710"></a><span class="lineno"> 3710</span>&#160;            epsilon(layer.epsilon),</div><div class="line"><a name="l03711"></a><span class="lineno"> 3711</span>&#160;            channels(layer.channels),</div><div class="line"><a name="l03712"></a><span class="lineno"> 3712</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l03713"></a><span class="lineno"> 3713</span>&#160;            frozen(layer.frozen),</div><div class="line"><a name="l03714"></a><span class="lineno"> 3714</span>&#160;            offsets(layer.offsets),</div><div class="line"><a name="l03715"></a><span class="lineno"> 3715</span>&#160;            extents(layer.extents),</div><div class="line"><a name="l03716"></a><span class="lineno"> 3716</span>&#160;            avg_means(layer.avg_means),</div><div class="line"><a name="l03717"></a><span class="lineno"> 3717</span>&#160;            avg_inv_sds(layer.avg_inv_sds),</div><div class="line"><a name="l03718"></a><span class="lineno"> 3718</span>&#160;            avgs_init(layer.avgs_init),</div><div class="line"><a name="l03719"></a><span class="lineno"> 3719</span>&#160;            params(layer.params),</div><div class="line"><a name="l03720"></a><span class="lineno"> 3720</span>&#160;            params_grad(layer.params_grad),</div><div class="line"><a name="l03721"></a><span class="lineno"> 3721</span>&#160;            params_ref(layer.is_shared_params_clone() ? layer.params_ref : params),</div><div class="line"><a name="l03722"></a><span class="lineno"> 3722</span>&#160;            owner(layer.is_shared_params_clone() ? layer.owner : *this),</div><div class="line"><a name="l03723"></a><span class="lineno"> 3723</span>&#160;            cache_vec(layer.cache_vec) { }</div><div class="line"><a name="l03724"></a><span class="lineno"> 3724</span>&#160;    <span class="keyword">inline</span> Self&amp; operator=(<span class="keyword">const</span> Self&amp; layer) {</div><div class="line"><a name="l03725"></a><span class="lineno"> 3725</span>&#160;        dims = layer.dims;</div><div class="line"><a name="l03726"></a><span class="lineno"> 3726</span>&#160;        gamma_reg = layer.gamma_reg;</div><div class="line"><a name="l03727"></a><span class="lineno"> 3727</span>&#160;        beta_reg = layer.beta_reg;</div><div class="line"><a name="l03728"></a><span class="lineno"> 3728</span>&#160;        gamma_max_norm_constraint = layer.gamma_max_norm_constraint;</div><div class="line"><a name="l03729"></a><span class="lineno"> 3729</span>&#160;        beta_max_norm_constraint = layer.beta_max_norm_constraint;</div><div class="line"><a name="l03730"></a><span class="lineno"> 3730</span>&#160;        gamma_max_norm = layer.gamma_max_norm;</div><div class="line"><a name="l03731"></a><span class="lineno"> 3731</span>&#160;        beta_max_norm = layer.beta_max_norm;</div><div class="line"><a name="l03732"></a><span class="lineno"> 3732</span>&#160;        norm_avg_decay = layer.norm_avg_decay;</div><div class="line"><a name="l03733"></a><span class="lineno"> 3733</span>&#160;        epsilon = layer.epsilon;</div><div class="line"><a name="l03734"></a><span class="lineno"> 3734</span>&#160;        channels = layer.channels;</div><div class="line"><a name="l03735"></a><span class="lineno"> 3735</span>&#160;        input_layer = layer.input_layer;</div><div class="line"><a name="l03736"></a><span class="lineno"> 3736</span>&#160;        frozen = layer.frozen;</div><div class="line"><a name="l03737"></a><span class="lineno"> 3737</span>&#160;        offsets = layer.offsets;</div><div class="line"><a name="l03738"></a><span class="lineno"> 3738</span>&#160;        extents = layer.extents;</div><div class="line"><a name="l03739"></a><span class="lineno"> 3739</span>&#160;        avg_means = layer.avg_means;</div><div class="line"><a name="l03740"></a><span class="lineno"> 3740</span>&#160;        avg_inv_sds = layer.avg_inv_sds;</div><div class="line"><a name="l03741"></a><span class="lineno"> 3741</span>&#160;        avgs_init = layer.avgs_init;</div><div class="line"><a name="l03742"></a><span class="lineno"> 3742</span>&#160;        params = layer.params;</div><div class="line"><a name="l03743"></a><span class="lineno"> 3743</span>&#160;        params_grad = layer.params_grad;</div><div class="line"><a name="l03744"></a><span class="lineno"> 3744</span>&#160;        params_ref = (layer.is_shared_params_clone() ? layer.params_ref : params);</div><div class="line"><a name="l03745"></a><span class="lineno"> 3745</span>&#160;        owner = (layer.is_shared_params_clone() ? layer.owner : *<span class="keyword">this</span>);</div><div class="line"><a name="l03746"></a><span class="lineno"> 3746</span>&#160;        cache_vec = layer.cache_vec;</div><div class="line"><a name="l03747"></a><span class="lineno"> 3747</span>&#160;    }</div><div class="line"><a name="l03748"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a7e23442f814d994e2989724901001202"> 3748</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_batch_norm_layer.html#a7e23442f814d994e2989724901001202">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03749"></a><span class="lineno"> 3749</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l03750"></a><span class="lineno"> 3750</span>&#160;    }</div><div class="line"><a name="l03751"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#ab40438ea8902e5bbba29ff6d23b4f187"> 3751</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_batch_norm_layer.html#ab40438ea8902e5bbba29ff6d23b4f187">clone_with_shared_params</a>() {</div><div class="line"><a name="l03752"></a><span class="lineno"> 3752</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l03753"></a><span class="lineno"> 3753</span>&#160;    }</div><div class="line"><a name="l03754"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#ad64fb5495e73699d97714883a77056e8"> 3754</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer.html#ad64fb5495e73699d97714883a77056e8">get_params_owner</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03755"></a><span class="lineno"> 3755</span>&#160;        <span class="keywordflow">return</span> owner;</div><div class="line"><a name="l03756"></a><span class="lineno"> 3756</span>&#160;    }</div><div class="line"><a name="l03757"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a6007fc5ae0a98b5995526ae4df222193"> 3757</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer.html#a6007fc5ae0a98b5995526ae4df222193">get_input_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03758"></a><span class="lineno"> 3758</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l03759"></a><span class="lineno"> 3759</span>&#160;    }</div><div class="line"><a name="l03760"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a64e546b9acecda042790ba1a19527d5d"> 3760</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer.html#a64e546b9acecda042790ba1a19527d5d">get_output_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03761"></a><span class="lineno"> 3761</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l03762"></a><span class="lineno"> 3762</span>&#160;    }</div><div class="line"><a name="l03763"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a3910d423bb77d5cdfc4ef6bc2c432a2e"> 3763</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer.html#a3910d423bb77d5cdfc4ef6bc2c432a2e">get_params</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03764"></a><span class="lineno"> 3764</span>&#160;        <span class="keywordflow">return</span> params_ref;</div><div class="line"><a name="l03765"></a><span class="lineno"> 3765</span>&#160;    }</div><div class="line"><a name="l03766"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#acc3ea38bc71f210553babfe66e48e370"> 3766</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer.html#acc3ea38bc71f210553babfe66e48e370">get_params_grad</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03767"></a><span class="lineno"> 3767</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l03768"></a><span class="lineno"> 3768</span>&#160;    }</div><div class="line"><a name="l03769"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a440a12c44f35ff5cd1953efa1be1cb6c"> 3769</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a440a12c44f35ff5cd1953efa1be1cb6c">is_frozen</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03770"></a><span class="lineno"> 3770</span>&#160;        <span class="keywordflow">return</span> frozen;</div><div class="line"><a name="l03771"></a><span class="lineno"> 3771</span>&#160;    }</div><div class="line"><a name="l03772"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a519e32659a2065563e8ab91289e1f8f3"> 3772</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a519e32659a2065563e8ab91289e1f8f3">set_frozen</a>(<span class="keywordtype">bool</span> frozen) {</div><div class="line"><a name="l03773"></a><span class="lineno"> 3773</span>&#160;        this-&gt;frozen = frozen;</div><div class="line"><a name="l03774"></a><span class="lineno"> 3774</span>&#160;    }</div><div class="line"><a name="l03775"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a9995e383fd1ce20a832172ee4d6c37c0"> 3775</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a9995e383fd1ce20a832172ee4d6c37c0">init</a>() {</div><div class="line"><a name="l03776"></a><span class="lineno"> 3776</span>&#160;        <span class="comment">// Gamma.</span></div><div class="line"><a name="l03777"></a><span class="lineno"> 3777</span>&#160;        params_ref.col(0).setOnes();</div><div class="line"><a name="l03778"></a><span class="lineno"> 3778</span>&#160;        <span class="comment">// Beta.</span></div><div class="line"><a name="l03779"></a><span class="lineno"> 3779</span>&#160;        params_ref.col(1).setZero();</div><div class="line"><a name="l03780"></a><span class="lineno"> 3780</span>&#160;        params_grad.setZero(params_ref.rows(), params_ref.cols());</div><div class="line"><a name="l03781"></a><span class="lineno"> 3781</span>&#160;        avg_means.setZero(avg_means.rows(), avg_means.cols());</div><div class="line"><a name="l03782"></a><span class="lineno"> 3782</span>&#160;        avg_inv_sds.setZero(avg_inv_sds.rows(), avg_inv_sds.cols());</div><div class="line"><a name="l03783"></a><span class="lineno"> 3783</span>&#160;        avgs_init = <span class="keyword">false</span>;</div><div class="line"><a name="l03784"></a><span class="lineno"> 3784</span>&#160;    }</div><div class="line"><a name="l03785"></a><span class="lineno"> 3785</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l03786"></a><span class="lineno"> 3786</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a>(Self&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l03787"></a><span class="lineno"> 3787</span>&#160;            dims(layer.dims),</div><div class="line"><a name="l03788"></a><span class="lineno"> 3788</span>&#160;            gamma_reg(layer.gamma_reg),</div><div class="line"><a name="l03789"></a><span class="lineno"> 3789</span>&#160;            beta_reg(layer.beta_reg),</div><div class="line"><a name="l03790"></a><span class="lineno"> 3790</span>&#160;            gamma_max_norm_constraint(layer.gamma_max_norm_constraint),</div><div class="line"><a name="l03791"></a><span class="lineno"> 3791</span>&#160;            beta_max_norm_constraint(layer.beta_max_norm_constraint),</div><div class="line"><a name="l03792"></a><span class="lineno"> 3792</span>&#160;            gamma_max_norm(layer.gamma_max_norm),</div><div class="line"><a name="l03793"></a><span class="lineno"> 3793</span>&#160;            beta_max_norm(layer.beta_max_norm),</div><div class="line"><a name="l03794"></a><span class="lineno"> 3794</span>&#160;            norm_avg_decay(layer.norm_avg_decay),</div><div class="line"><a name="l03795"></a><span class="lineno"> 3795</span>&#160;            epsilon(layer.epsilon),</div><div class="line"><a name="l03796"></a><span class="lineno"> 3796</span>&#160;            channels(layer.channels),</div><div class="line"><a name="l03797"></a><span class="lineno"> 3797</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l03798"></a><span class="lineno"> 3798</span>&#160;            frozen(layer.frozen),</div><div class="line"><a name="l03799"></a><span class="lineno"> 3799</span>&#160;            offsets(layer.offsets),</div><div class="line"><a name="l03800"></a><span class="lineno"> 3800</span>&#160;            extents(layer.extents),</div><div class="line"><a name="l03801"></a><span class="lineno"> 3801</span>&#160;            avg_means(layer.avg_means),</div><div class="line"><a name="l03802"></a><span class="lineno"> 3802</span>&#160;            avg_inv_sds(layer.avg_inv_sds),</div><div class="line"><a name="l03803"></a><span class="lineno"> 3803</span>&#160;            avgs_init(layer.avgs_init),</div><div class="line"><a name="l03804"></a><span class="lineno"> 3804</span>&#160;            params(share_params ? <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt;Scalar&gt;(0, 0) : layer.params),</div><div class="line"><a name="l03805"></a><span class="lineno"> 3805</span>&#160;            params_grad(layer.params_grad),</div><div class="line"><a name="l03806"></a><span class="lineno"> 3806</span>&#160;            params_ref(share_params ? layer.params_ref : params),</div><div class="line"><a name="l03807"></a><span class="lineno"> 3807</span>&#160;            owner(share_params ? layer.owner : *this),</div><div class="line"><a name="l03808"></a><span class="lineno"> 3808</span>&#160;            cache_vec(layer.cache_vec) { }</div><div class="line"><a name="l03809"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a617e18072bd65f87b90072d9d1288d95"> 3809</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a617e18072bd65f87b90072d9d1288d95">is_input_layer</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03810"></a><span class="lineno"> 3810</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l03811"></a><span class="lineno"> 3811</span>&#160;    }</div><div class="line"><a name="l03812"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a66300725f60f30bd773d47f2dea19f46"> 3812</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a66300725f60f30bd773d47f2dea19f46">set_input_layer</a>(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l03813"></a><span class="lineno"> 3813</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l03814"></a><span class="lineno"> 3814</span>&#160;    }</div><div class="line"><a name="l03815"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#ae82d6c00d3f84d865324c51bcb5ab90c"> 3815</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#ae82d6c00d3f84d865324c51bcb5ab90c">empty_cache</a>() {</div><div class="line"><a name="l03816"></a><span class="lineno"> 3816</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; cache_vec.size(); ++i)</div><div class="line"><a name="l03817"></a><span class="lineno"> 3817</span>&#160;            cache_vec[i].std_in = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(0, 0);</div><div class="line"><a name="l03818"></a><span class="lineno"> 3818</span>&#160;    }</div><div class="line"><a name="l03819"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a71cd5d5e591d7646fb01a029f12cd685"> 3819</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer.html#a71cd5d5e591d7646fb01a029f12cd685">get_params</a>() {</div><div class="line"><a name="l03820"></a><span class="lineno"> 3820</span>&#160;        <span class="keywordflow">return</span> params_ref;</div><div class="line"><a name="l03821"></a><span class="lineno"> 3821</span>&#160;    }</div><div class="line"><a name="l03822"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#afea25117f93e8ca72fd4538251dd7f01"> 3822</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer.html#afea25117f93e8ca72fd4538251dd7f01">get_params_grad</a>() {</div><div class="line"><a name="l03823"></a><span class="lineno"> 3823</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l03824"></a><span class="lineno"> 3824</span>&#160;    }</div><div class="line"><a name="l03825"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a412548cbdf36c15ed8c96f095884e656"> 3825</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a412548cbdf36c15ed8c96f095884e656">regularize</a>() {</div><div class="line"><a name="l03826"></a><span class="lineno"> 3826</span>&#160;        params_grad.col(0) += gamma_reg-&gt;d_function(params_ref.col(0));</div><div class="line"><a name="l03827"></a><span class="lineno"> 3827</span>&#160;        params_grad.col(1) += beta_reg-&gt;d_function(params_ref.col(1));</div><div class="line"><a name="l03828"></a><span class="lineno"> 3828</span>&#160;    }</div><div class="line"><a name="l03829"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a11af8181b2494e2644ebda1016b4062c"> 3829</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1_batch_norm_layer.html#a11af8181b2494e2644ebda1016b4062c">get_regularization_penalty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l03830"></a><span class="lineno"> 3830</span>&#160;        <span class="keywordflow">return</span> gamma_reg-&gt;function(params_ref.col(0)) + beta_reg-&gt;function(params_ref.col(1));</div><div class="line"><a name="l03831"></a><span class="lineno"> 3831</span>&#160;    }</div><div class="line"><a name="l03832"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a958aacf0e9f1267e7e007ba8f2822021"> 3832</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a958aacf0e9f1267e7e007ba8f2822021">enforce_constraints</a>() {</div><div class="line"><a name="l03833"></a><span class="lineno"> 3833</span>&#160;        Scalar l2_norm;</div><div class="line"><a name="l03834"></a><span class="lineno"> 3834</span>&#160;        <span class="keywordflow">if</span> (gamma_max_norm) {</div><div class="line"><a name="l03835"></a><span class="lineno"> 3835</span>&#160;            l2_norm = params_ref.col(0).squaredNorm();</div><div class="line"><a name="l03836"></a><span class="lineno"> 3836</span>&#160;            <span class="keywordflow">if</span> (l2_norm &gt; gamma_max_norm_constraint)</div><div class="line"><a name="l03837"></a><span class="lineno"> 3837</span>&#160;                params_ref.col(0) *= (gamma_max_norm_constraint / l2_norm);</div><div class="line"><a name="l03838"></a><span class="lineno"> 3838</span>&#160;        }</div><div class="line"><a name="l03839"></a><span class="lineno"> 3839</span>&#160;        <span class="keywordflow">if</span> (beta_max_norm) {</div><div class="line"><a name="l03840"></a><span class="lineno"> 3840</span>&#160;            l2_norm = params_ref.col(1).squaredNorm();</div><div class="line"><a name="l03841"></a><span class="lineno"> 3841</span>&#160;            <span class="keywordflow">if</span> (l2_norm &gt; beta_max_norm_constraint)</div><div class="line"><a name="l03842"></a><span class="lineno"> 3842</span>&#160;                params_ref.col(1) *= (beta_max_norm_constraint / l2_norm);</div><div class="line"><a name="l03843"></a><span class="lineno"> 3843</span>&#160;        }</div><div class="line"><a name="l03844"></a><span class="lineno"> 3844</span>&#160;    }</div><div class="line"><a name="l03845"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a220d347e28e8456fbaa42e8b37ff565d"> 3845</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_batch_norm_layer.html#a220d347e28e8456fbaa42e8b37ff565d">pass_forward</a>(<span class="keyword">typename</span> Base::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l03846"></a><span class="lineno"> 3846</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l03847"></a><span class="lineno"> 3847</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l03848"></a><span class="lineno"> 3848</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l03849"></a><span class="lineno"> 3849</span>&#160;        extents[0] = rows;</div><div class="line"><a name="l03850"></a><span class="lineno"> 3850</span>&#160;        <span class="keyword">typename</span> Base::Data out;</div><div class="line"><a name="l03851"></a><span class="lineno"> 3851</span>&#160;        <span class="keywordflow">if</span> (channels == 1) {</div><div class="line"><a name="l03852"></a><span class="lineno"> 3852</span>&#160;            <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> in_mat(in.data(), rows, in.size() / rows);</div><div class="line"><a name="l03853"></a><span class="lineno"> 3853</span>&#160;            <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out_mat = _pass_forward(in_mat, 0, training);</div><div class="line"><a name="l03854"></a><span class="lineno"> 3854</span>&#160;            out = <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(out_mat.data(), extents);</div><div class="line"><a name="l03855"></a><span class="lineno"> 3855</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l03856"></a><span class="lineno"> 3856</span>&#160;            out = <span class="keyword">typename</span> Base::Data(in.dimensions());</div><div class="line"><a name="l03857"></a><span class="lineno"> 3857</span>&#160;            <span class="keywordflow">for</span> (std::size_t i = 0; i &lt; channels; ++i) {</div><div class="line"><a name="l03858"></a><span class="lineno"> 3858</span>&#160;                offsets[Rank] = i;</div><div class="line"><a name="l03859"></a><span class="lineno"> 3859</span>&#160;                <span class="keyword">typename</span> Base::Data in_slice = in.slice(offsets, extents);</div><div class="line"><a name="l03860"></a><span class="lineno"> 3860</span>&#160;                <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> in_slice_mat(in_slice.data(), rows, in_slice.size() / rows);</div><div class="line"><a name="l03861"></a><span class="lineno"> 3861</span>&#160;                <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out_slice_mat = _pass_forward(in_slice_mat, i, training);</div><div class="line"><a name="l03862"></a><span class="lineno"> 3862</span>&#160;                out.slice(offsets, extents) = <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(out_slice_mat.data(), extents);</div><div class="line"><a name="l03863"></a><span class="lineno"> 3863</span>&#160;            }</div><div class="line"><a name="l03864"></a><span class="lineno"> 3864</span>&#160;        }</div><div class="line"><a name="l03865"></a><span class="lineno"> 3865</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l03866"></a><span class="lineno"> 3866</span>&#160;    }</div><div class="line"><a name="l03867"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a1cc2a6f67e5d6b8e7f7996a9267b7401"> 3867</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_batch_norm_layer.html#a1cc2a6f67e5d6b8e7f7996a9267b7401">pass_back</a>(<span class="keyword">typename</span> Base::Data out_grad) {</div><div class="line"><a name="l03868"></a><span class="lineno"> 3868</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l03869"></a><span class="lineno"> 3869</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; extents[0] == out_grad.dimension(0));</div><div class="line"><a name="l03870"></a><span class="lineno"> 3870</span>&#160;        std::size_t rows = out_grad.dimension(0);</div><div class="line"><a name="l03871"></a><span class="lineno"> 3871</span>&#160;        <span class="keyword">typename</span> Base::Data prev_out_grad;</div><div class="line"><a name="l03872"></a><span class="lineno"> 3872</span>&#160;        <span class="keywordflow">if</span> (channels == 1) {</div><div class="line"><a name="l03873"></a><span class="lineno"> 3873</span>&#160;            <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> out_grad_mat(out_grad.data(), rows, out_grad.size() / rows);</div><div class="line"><a name="l03874"></a><span class="lineno"> 3874</span>&#160;            <span class="keywordflow">if</span> (input_layer) {</div><div class="line"><a name="l03875"></a><span class="lineno"> 3875</span>&#160;                _pass_back(out_grad_mat, 0);</div><div class="line"><a name="l03876"></a><span class="lineno"> 3876</span>&#160;                <span class="keywordflow">return</span> <span class="keyword">typename</span> Base::Data();</div><div class="line"><a name="l03877"></a><span class="lineno"> 3877</span>&#160;            } <span class="keywordflow">else</span> {</div><div class="line"><a name="l03878"></a><span class="lineno"> 3878</span>&#160;                <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> prev_out_grad_mat = _pass_back(out_grad_mat, 0);</div><div class="line"><a name="l03879"></a><span class="lineno"> 3879</span>&#160;                prev_out_grad = <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(prev_out_grad_mat.data(), extents);</div><div class="line"><a name="l03880"></a><span class="lineno"> 3880</span>&#160;            }</div><div class="line"><a name="l03881"></a><span class="lineno"> 3881</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l03882"></a><span class="lineno"> 3882</span>&#160;            prev_out_grad = input_layer ? <span class="keyword">typename</span> Base::Data() : <span class="keyword">typename</span> Base::Data(out_grad.dimensions());</div><div class="line"><a name="l03883"></a><span class="lineno"> 3883</span>&#160;            <span class="keywordflow">for</span> (std::size_t i = 0; i &lt; channels; ++i) {</div><div class="line"><a name="l03884"></a><span class="lineno"> 3884</span>&#160;                offsets[Rank] = i;</div><div class="line"><a name="l03885"></a><span class="lineno"> 3885</span>&#160;                <span class="keyword">typename</span> Base::Data out_grad_slice = out_grad.slice(offsets, extents);</div><div class="line"><a name="l03886"></a><span class="lineno"> 3886</span>&#160;                <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> out_grad_slice_mat(out_grad_slice.data(), rows, out_grad_slice.size() / rows);</div><div class="line"><a name="l03887"></a><span class="lineno"> 3887</span>&#160;                <span class="keywordflow">if</span> (input_layer) {</div><div class="line"><a name="l03888"></a><span class="lineno"> 3888</span>&#160;                    _pass_back(out_grad_slice_mat, i);</div><div class="line"><a name="l03889"></a><span class="lineno"> 3889</span>&#160;                    <span class="keywordflow">continue</span>;</div><div class="line"><a name="l03890"></a><span class="lineno"> 3890</span>&#160;                } <span class="keywordflow">else</span> {</div><div class="line"><a name="l03891"></a><span class="lineno"> 3891</span>&#160;                    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> prev_out_grad_slice_mat = _pass_back(out_grad_slice_mat, i);</div><div class="line"><a name="l03892"></a><span class="lineno"> 3892</span>&#160;                    prev_out_grad.slice(offsets, extents) =</div><div class="line"><a name="l03893"></a><span class="lineno"> 3893</span>&#160;                            <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(prev_out_grad_slice_mat.data(), extents);</div><div class="line"><a name="l03894"></a><span class="lineno"> 3894</span>&#160;                }</div><div class="line"><a name="l03895"></a><span class="lineno"> 3895</span>&#160;            }</div><div class="line"><a name="l03896"></a><span class="lineno"> 3896</span>&#160;        }</div><div class="line"><a name="l03897"></a><span class="lineno"> 3897</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l03898"></a><span class="lineno"> 3898</span>&#160;    }</div><div class="line"><a name="l03899"></a><span class="lineno"> 3899</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l03900"></a><span class="lineno"> 3900</span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> _pass_forward(<a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a>&amp; in, std::size_t i, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l03901"></a><span class="lineno"> 3901</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out;</div><div class="line"><a name="l03902"></a><span class="lineno"> 3902</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l03903"></a><span class="lineno"> 3903</span>&#160;            Cache&amp; cache = cache_vec[i];</div><div class="line"><a name="l03904"></a><span class="lineno"> 3904</span>&#160;            Scalar mean = in.mean();</div><div class="line"><a name="l03905"></a><span class="lineno"> 3905</span>&#160;            <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> norm_in = in.array() - mean;</div><div class="line"><a name="l03906"></a><span class="lineno"> 3906</span>&#160;            cache.inv_in_sd = 1 / sqrt(norm_in.array().square().mean() + epsilon);</div><div class="line"><a name="l03907"></a><span class="lineno"> 3907</span>&#160;            cache.std_in = norm_in * cache.inv_in_sd;</div><div class="line"><a name="l03908"></a><span class="lineno"> 3908</span>&#160;            out = cache.std_in;</div><div class="line"><a name="l03909"></a><span class="lineno"> 3909</span>&#160;            <span class="keywordflow">if</span> (avgs_init) {</div><div class="line"><a name="l03910"></a><span class="lineno"> 3910</span>&#160;                avg_means(i) = (1.0 - norm_avg_decay) * avg_means(i) + norm_avg_decay * mean;</div><div class="line"><a name="l03911"></a><span class="lineno"> 3911</span>&#160;                avg_inv_sds(i) = (1.0 - norm_avg_decay) * avg_inv_sds(i) + norm_avg_decay * cache.inv_in_sd;</div><div class="line"><a name="l03912"></a><span class="lineno"> 3912</span>&#160;            } <span class="keywordflow">else</span> {</div><div class="line"><a name="l03913"></a><span class="lineno"> 3913</span>&#160;                avg_means(i) = mean;</div><div class="line"><a name="l03914"></a><span class="lineno"> 3914</span>&#160;                avg_inv_sds(i) = cache.inv_in_sd;</div><div class="line"><a name="l03915"></a><span class="lineno"> 3915</span>&#160;                avgs_init = <span class="keyword">true</span>;</div><div class="line"><a name="l03916"></a><span class="lineno"> 3916</span>&#160;            }</div><div class="line"><a name="l03917"></a><span class="lineno"> 3917</span>&#160;        } <span class="keywordflow">else</span></div><div class="line"><a name="l03918"></a><span class="lineno"> 3918</span>&#160;            out = (in.array() - avg_means(i)) * avg_inv_sds(i);</div><div class="line"><a name="l03919"></a><span class="lineno"> 3919</span>&#160;        <span class="keywordflow">return</span> (out * params_ref(i, 0)).array() + params_ref(i, 1);</div><div class="line"><a name="l03920"></a><span class="lineno"> 3920</span>&#160;    }</div><div class="line"><a name="l03921"></a><span class="lineno"> 3921</span>&#160;    <span class="keyword">inline</span> Matrix&lt;Scalar&gt; _pass_back(MatrixMap&lt;Scalar&gt;&amp; out_grad, std::size_t i) {</div><div class="line"><a name="l03922"></a><span class="lineno"> 3922</span>&#160;        Cache&amp; cache = cache_vec[i];</div><div class="line"><a name="l03923"></a><span class="lineno"> 3923</span>&#160;        params_grad(i, 0) = out_grad.cwiseProduct(cache.std_in).sum();</div><div class="line"><a name="l03924"></a><span class="lineno"> 3924</span>&#160;        params_grad(i, 1) = out_grad.sum();</div><div class="line"><a name="l03925"></a><span class="lineno"> 3925</span>&#160;        <span class="keywordflow">if</span> (input_layer)</div><div class="line"><a name="l03926"></a><span class="lineno"> 3926</span>&#160;            <span class="keywordflow">return</span> Matrix&lt;Scalar&gt;();</div><div class="line"><a name="l03927"></a><span class="lineno"> 3927</span>&#160;        std::size_t locations = out_grad.size();</div><div class="line"><a name="l03928"></a><span class="lineno"> 3928</span>&#160;        Matrix&lt;Scalar&gt; std_in_grad = out_grad * params_ref(i, 0);</div><div class="line"><a name="l03929"></a><span class="lineno"> 3929</span>&#160;        <span class="keywordflow">return</span> (((locations * std_in_grad).array() - std_in_grad.sum()).matrix() -</div><div class="line"><a name="l03930"></a><span class="lineno"> 3930</span>&#160;                cache.std_in * cache.std_in.cwiseProduct(std_in_grad).sum()) *</div><div class="line"><a name="l03931"></a><span class="lineno"> 3931</span>&#160;                (((Scalar) 1 / locations) * cache.inv_in_sd);</div><div class="line"><a name="l03932"></a><span class="lineno"> 3932</span>&#160;    }</div><div class="line"><a name="l03933"></a><span class="lineno"> 3933</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt; dims;</div><div class="line"><a name="l03934"></a><span class="lineno"> 3934</span>&#160;    <span class="keyword">const</span> ParamRegSharedPtr&lt;Scalar&gt; gamma_reg;</div><div class="line"><a name="l03935"></a><span class="lineno"> 3935</span>&#160;    <span class="keyword">const</span> ParamRegSharedPtr&lt;Scalar&gt; beta_reg;</div><div class="line"><a name="l03936"></a><span class="lineno"> 3936</span>&#160;    <span class="keyword">const</span> Scalar gamma_max_norm_constraint;</div><div class="line"><a name="l03937"></a><span class="lineno"> 3937</span>&#160;    <span class="keyword">const</span> Scalar beta_max_norm_constraint;</div><div class="line"><a name="l03938"></a><span class="lineno"> 3938</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> gamma_max_norm;</div><div class="line"><a name="l03939"></a><span class="lineno"> 3939</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> beta_max_norm;</div><div class="line"><a name="l03940"></a><span class="lineno"> 3940</span>&#160;    <span class="keyword">const</span> Scalar norm_avg_decay;</div><div class="line"><a name="l03941"></a><span class="lineno"> 3941</span>&#160;    <span class="keyword">const</span> Scalar epsilon;</div><div class="line"><a name="l03942"></a><span class="lineno"> 3942</span>&#160;    <span class="keyword">const</span> std::size_t channels;</div><div class="line"><a name="l03943"></a><span class="lineno"> 3943</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l03944"></a><span class="lineno"> 3944</span>&#160;    <span class="keywordtype">bool</span> frozen;</div><div class="line"><a name="l03945"></a><span class="lineno"> 3945</span>&#160;    std::array&lt;std::size_t,Rank + 1&gt; offsets;</div><div class="line"><a name="l03946"></a><span class="lineno"> 3946</span>&#160;    std::array&lt;std::size_t,Rank + 1&gt; extents;</div><div class="line"><a name="l03947"></a><span class="lineno"> 3947</span>&#160;    <span class="comment">// Dynamic batch normalization parameters.</span></div><div class="line"><a name="l03948"></a><span class="lineno"> 3948</span>&#160;    RowVector&lt;Scalar&gt; avg_means;</div><div class="line"><a name="l03949"></a><span class="lineno"> 3949</span>&#160;    RowVector&lt;Scalar&gt; avg_inv_sds;</div><div class="line"><a name="l03950"></a><span class="lineno"> 3950</span>&#160;    <span class="keywordtype">bool</span> avgs_init;</div><div class="line"><a name="l03951"></a><span class="lineno"> 3951</span>&#160;    <span class="comment">// Betas and gammas</span></div><div class="line"><a name="l03952"></a><span class="lineno"> 3952</span>&#160;    Matrix&lt;Scalar&gt; params;</div><div class="line"><a name="l03953"></a><span class="lineno"> 3953</span>&#160;    Matrix&lt;Scalar&gt;&amp; params_ref;</div><div class="line"><a name="l03954"></a><span class="lineno"> 3954</span>&#160;    Matrix&lt;Scalar&gt; params_grad;</div><div class="line"><a name="l03955"></a><span class="lineno"> 3955</span>&#160;    <span class="keyword">const</span> Base&amp; owner;</div><div class="line"><a name="l03956"></a><span class="lineno"> 3956</span>&#160;    <span class="comment">// Staged computation cache vector.</span></div><div class="line"><a name="l03957"></a><span class="lineno"> 3957</span>&#160;    <span class="keyword">struct </span>Cache {</div><div class="line"><a name="l03958"></a><span class="lineno"> 3958</span>&#160;        Scalar inv_in_sd;</div><div class="line"><a name="l03959"></a><span class="lineno"> 3959</span>&#160;        Matrix&lt;Scalar&gt; std_in;</div><div class="line"><a name="l03960"></a><span class="lineno"> 3960</span>&#160;    };</div><div class="line"><a name="l03961"></a><span class="lineno"> 3961</span>&#160;    std::vector&lt;Cache&gt; cache_vec;</div><div class="line"><a name="l03962"></a><span class="lineno"> 3962</span>&#160;};</div><div class="line"><a name="l03963"></a><span class="lineno"> 3963</span>&#160;</div><div class="line"><a name="l03969"></a><span class="lineno"> 3969</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l03970"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html"> 3970</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a>&lt;Scalar,Rank,false&gt; : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l03971"></a><span class="lineno"> 3971</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l03972"></a><span class="lineno"> 3972</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html">BatchNormLayer&lt;Scalar,Rank,false&gt;</a> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html">Self</a>;</div><div class="line"><a name="l03973"></a><span class="lineno"> 3973</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l03985"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a865ffd7d7961901c5d08cb64e33b111b"> 3985</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a865ffd7d7961901c5d08cb64e33b111b">BatchNormLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims, <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> gamma_reg = Base::NO_PARAM_REG,</div><div class="line"><a name="l03986"></a><span class="lineno"> 3986</span>&#160;            <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> beta_reg = Base::NO_PARAM_REG, Scalar gamma_max_norm_constraint = 0,</div><div class="line"><a name="l03987"></a><span class="lineno"> 3987</span>&#160;            Scalar beta_max_norm_constraint = 0, Scalar norm_avg_decay = .1, Scalar epsilon = <a class="code" href="classcattle_1_1internal_1_1_numeric_utils.html">internal::NumericUtils&lt;Scalar&gt;::EPSILON2</a>) :</div><div class="line"><a name="l03988"></a><span class="lineno"> 3988</span>&#160;                dims(dims),</div><div class="line"><a name="l03989"></a><span class="lineno"> 3989</span>&#160;                gamma_reg(gamma_reg),</div><div class="line"><a name="l03990"></a><span class="lineno"> 3990</span>&#160;                beta_reg(beta_reg),</div><div class="line"><a name="l03991"></a><span class="lineno"> 3991</span>&#160;                gamma_max_norm_constraint(gamma_max_norm_constraint),</div><div class="line"><a name="l03992"></a><span class="lineno"> 3992</span>&#160;                beta_max_norm_constraint(beta_max_norm_constraint),</div><div class="line"><a name="l03993"></a><span class="lineno"> 3993</span>&#160;                gamma_max_norm(internal::NumericUtils&lt;Scalar&gt;::decidedly_greater(gamma_max_norm_constraint, (Scalar) 0)),</div><div class="line"><a name="l03994"></a><span class="lineno"> 3994</span>&#160;                beta_max_norm(internal::NumericUtils&lt;Scalar&gt;::decidedly_greater(beta_max_norm_constraint, (Scalar) 0)),</div><div class="line"><a name="l03995"></a><span class="lineno"> 3995</span>&#160;                norm_avg_decay(norm_avg_decay),</div><div class="line"><a name="l03996"></a><span class="lineno"> 3996</span>&#160;                epsilon(epsilon),</div><div class="line"><a name="l03997"></a><span class="lineno"> 3997</span>&#160;                input_layer(false),</div><div class="line"><a name="l03998"></a><span class="lineno"> 3998</span>&#160;                frozen(false),</div><div class="line"><a name="l03999"></a><span class="lineno"> 3999</span>&#160;                avg_means(dims.get_volume()),</div><div class="line"><a name="l04000"></a><span class="lineno"> 4000</span>&#160;                avg_inv_sds(avg_means.size()),</div><div class="line"><a name="l04001"></a><span class="lineno"> 4001</span>&#160;                avgs_init(false),</div><div class="line"><a name="l04002"></a><span class="lineno"> 4002</span>&#160;                params(avg_means.size(), 2),</div><div class="line"><a name="l04003"></a><span class="lineno"> 4003</span>&#160;                params_grad(params.rows(), params.cols()),</div><div class="line"><a name="l04004"></a><span class="lineno"> 4004</span>&#160;                params_ref(params),</div><div class="line"><a name="l04005"></a><span class="lineno"> 4005</span>&#160;                owner(*this) {</div><div class="line"><a name="l04006"></a><span class="lineno"> 4006</span>&#160;        assert(gamma_reg != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l04007"></a><span class="lineno"> 4007</span>&#160;        assert(beta_reg != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l04008"></a><span class="lineno"> 4008</span>&#160;        assert(norm_avg_decay &gt;= 0 &amp;&amp; norm_avg_decay &lt;= 1 &amp;&amp;</div><div class="line"><a name="l04009"></a><span class="lineno"> 4009</span>&#160;                <span class="stringliteral">&quot;norm avg decay must not be less than 0 or greater than 1&quot;</span>);</div><div class="line"><a name="l04010"></a><span class="lineno"> 4010</span>&#160;        assert(epsilon &gt; 0 &amp;&amp; <span class="stringliteral">&quot;epsilon must be greater than 0&quot;</span>);</div><div class="line"><a name="l04011"></a><span class="lineno"> 4011</span>&#160;    }</div><div class="line"><a name="l04012"></a><span class="lineno"> 4012</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a>(<span class="keyword">const</span> Self&amp; layer) :</div><div class="line"><a name="l04013"></a><span class="lineno"> 4013</span>&#160;            dims(layer.dims),</div><div class="line"><a name="l04014"></a><span class="lineno"> 4014</span>&#160;            gamma_reg(layer.gamma_reg),</div><div class="line"><a name="l04015"></a><span class="lineno"> 4015</span>&#160;            beta_reg(layer.beta_reg),</div><div class="line"><a name="l04016"></a><span class="lineno"> 4016</span>&#160;            gamma_max_norm_constraint(layer.gamma_max_norm_constraint),</div><div class="line"><a name="l04017"></a><span class="lineno"> 4017</span>&#160;            beta_max_norm_constraint(layer.beta_max_norm_constraint),</div><div class="line"><a name="l04018"></a><span class="lineno"> 4018</span>&#160;            gamma_max_norm(layer.gamma_max_norm),</div><div class="line"><a name="l04019"></a><span class="lineno"> 4019</span>&#160;            beta_max_norm(layer.beta_max_norm),</div><div class="line"><a name="l04020"></a><span class="lineno"> 4020</span>&#160;            norm_avg_decay(layer.norm_avg_decay),</div><div class="line"><a name="l04021"></a><span class="lineno"> 4021</span>&#160;            epsilon(layer.epsilon),</div><div class="line"><a name="l04022"></a><span class="lineno"> 4022</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l04023"></a><span class="lineno"> 4023</span>&#160;            frozen(layer.frozen),</div><div class="line"><a name="l04024"></a><span class="lineno"> 4024</span>&#160;            avg_means(layer.avg_means),</div><div class="line"><a name="l04025"></a><span class="lineno"> 4025</span>&#160;            avg_inv_sds(layer.avg_inv_sds),</div><div class="line"><a name="l04026"></a><span class="lineno"> 4026</span>&#160;            avgs_init(layer.avgs_init),</div><div class="line"><a name="l04027"></a><span class="lineno"> 4027</span>&#160;            params(layer.params),</div><div class="line"><a name="l04028"></a><span class="lineno"> 4028</span>&#160;            params_grad(layer.params_grad),</div><div class="line"><a name="l04029"></a><span class="lineno"> 4029</span>&#160;            params_ref(layer.is_shared_params_clone() ? layer.params_ref : params),</div><div class="line"><a name="l04030"></a><span class="lineno"> 4030</span>&#160;            owner(layer.is_shared_params_clone() ? layer.owner : *this),</div><div class="line"><a name="l04031"></a><span class="lineno"> 4031</span>&#160;            inv_in_sd(layer.inv_in_sd),</div><div class="line"><a name="l04032"></a><span class="lineno"> 4032</span>&#160;            std_in(layer.std_in) { }</div><div class="line"><a name="l04033"></a><span class="lineno"> 4033</span>&#160;    <span class="keyword">inline</span> Self&amp; operator=(<span class="keyword">const</span> Self&amp; layer) {</div><div class="line"><a name="l04034"></a><span class="lineno"> 4034</span>&#160;        dims = layer.dims;</div><div class="line"><a name="l04035"></a><span class="lineno"> 4035</span>&#160;        gamma_reg = layer.gamma_reg;</div><div class="line"><a name="l04036"></a><span class="lineno"> 4036</span>&#160;        beta_reg = layer.beta_reg;</div><div class="line"><a name="l04037"></a><span class="lineno"> 4037</span>&#160;        gamma_max_norm_constraint = layer.gamma_max_norm_constraint;</div><div class="line"><a name="l04038"></a><span class="lineno"> 4038</span>&#160;        beta_max_norm_constraint = layer.beta_max_norm_constraint;</div><div class="line"><a name="l04039"></a><span class="lineno"> 4039</span>&#160;        gamma_max_norm = layer.gamma_max_norm;</div><div class="line"><a name="l04040"></a><span class="lineno"> 4040</span>&#160;        beta_max_norm = layer.beta_max_norm;</div><div class="line"><a name="l04041"></a><span class="lineno"> 4041</span>&#160;        norm_avg_decay = layer.norm_avg_decay;</div><div class="line"><a name="l04042"></a><span class="lineno"> 4042</span>&#160;        epsilon = layer.epsilon;</div><div class="line"><a name="l04043"></a><span class="lineno"> 4043</span>&#160;        input_layer = layer.input_layer;</div><div class="line"><a name="l04044"></a><span class="lineno"> 4044</span>&#160;        frozen = layer.frozen;</div><div class="line"><a name="l04045"></a><span class="lineno"> 4045</span>&#160;        avg_means = layer.avg_means;</div><div class="line"><a name="l04046"></a><span class="lineno"> 4046</span>&#160;        avg_inv_sds = layer.avg_inv_sds;</div><div class="line"><a name="l04047"></a><span class="lineno"> 4047</span>&#160;        avgs_init = layer.avgs_init;</div><div class="line"><a name="l04048"></a><span class="lineno"> 4048</span>&#160;        params = layer.params;</div><div class="line"><a name="l04049"></a><span class="lineno"> 4049</span>&#160;        params_grad = layer.params_grad;</div><div class="line"><a name="l04050"></a><span class="lineno"> 4050</span>&#160;        params_ref = (layer.is_shared_params_clone() ? layer.params_ref : params);</div><div class="line"><a name="l04051"></a><span class="lineno"> 4051</span>&#160;        owner = (layer.is_shared_params_clone() ? layer.owner : *<span class="keyword">this</span>);</div><div class="line"><a name="l04052"></a><span class="lineno"> 4052</span>&#160;        inv_in_sd = layer.inv_in_sd;</div><div class="line"><a name="l04053"></a><span class="lineno"> 4053</span>&#160;        std_in = layer.std_in;</div><div class="line"><a name="l04054"></a><span class="lineno"> 4054</span>&#160;    }</div><div class="line"><a name="l04055"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a18bd4016f07bfc33c27bb518066ff67b"> 4055</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a18bd4016f07bfc33c27bb518066ff67b">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04056"></a><span class="lineno"> 4056</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l04057"></a><span class="lineno"> 4057</span>&#160;    }</div><div class="line"><a name="l04058"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ab952d37eca54ad52ec43c632ea6a7856"> 4058</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ab952d37eca54ad52ec43c632ea6a7856">clone_with_shared_params</a>() {</div><div class="line"><a name="l04059"></a><span class="lineno"> 4059</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l04060"></a><span class="lineno"> 4060</span>&#160;    }</div><div class="line"><a name="l04061"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae91b49e8b4eaf586faf27c2147b3e684"> 4061</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae91b49e8b4eaf586faf27c2147b3e684">get_params_owner</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04062"></a><span class="lineno"> 4062</span>&#160;        <span class="keywordflow">return</span> owner;</div><div class="line"><a name="l04063"></a><span class="lineno"> 4063</span>&#160;    }</div><div class="line"><a name="l04064"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a3de931b84f08ff85ecaa75c3c6ffcbf0"> 4064</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a3de931b84f08ff85ecaa75c3c6ffcbf0">get_input_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04065"></a><span class="lineno"> 4065</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l04066"></a><span class="lineno"> 4066</span>&#160;    }</div><div class="line"><a name="l04067"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#acc0f9ba4bf27c0dec2da75196252137e"> 4067</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#acc0f9ba4bf27c0dec2da75196252137e">get_output_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04068"></a><span class="lineno"> 4068</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l04069"></a><span class="lineno"> 4069</span>&#160;    }</div><div class="line"><a name="l04070"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7cdb31857371b739af38aa184ac1bebe"> 4070</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7cdb31857371b739af38aa184ac1bebe">get_params</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04071"></a><span class="lineno"> 4071</span>&#160;        <span class="keywordflow">return</span> params_ref;</div><div class="line"><a name="l04072"></a><span class="lineno"> 4072</span>&#160;    }</div><div class="line"><a name="l04073"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7db2cae21bd26cc571114fe817e72577"> 4073</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7db2cae21bd26cc571114fe817e72577">get_params_grad</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04074"></a><span class="lineno"> 4074</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l04075"></a><span class="lineno"> 4075</span>&#160;    }</div><div class="line"><a name="l04076"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#aafc6601f084c42c5b1d759b305066261"> 4076</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#aafc6601f084c42c5b1d759b305066261">is_frozen</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04077"></a><span class="lineno"> 4077</span>&#160;        <span class="keywordflow">return</span> frozen;</div><div class="line"><a name="l04078"></a><span class="lineno"> 4078</span>&#160;    }</div><div class="line"><a name="l04079"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ad7b183d5305bfb0303d9284c0c9b833e"> 4079</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ad7b183d5305bfb0303d9284c0c9b833e">set_frozen</a>(<span class="keywordtype">bool</span> frozen) {</div><div class="line"><a name="l04080"></a><span class="lineno"> 4080</span>&#160;        this-&gt;frozen = frozen;</div><div class="line"><a name="l04081"></a><span class="lineno"> 4081</span>&#160;    }</div><div class="line"><a name="l04082"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a96eed3e8027413d21b26ac2f48d71a88"> 4082</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a96eed3e8027413d21b26ac2f48d71a88">init</a>() {</div><div class="line"><a name="l04083"></a><span class="lineno"> 4083</span>&#160;        <span class="comment">// Gamma.</span></div><div class="line"><a name="l04084"></a><span class="lineno"> 4084</span>&#160;        params_ref.col(0).setOnes();</div><div class="line"><a name="l04085"></a><span class="lineno"> 4085</span>&#160;        <span class="comment">// Beta.</span></div><div class="line"><a name="l04086"></a><span class="lineno"> 4086</span>&#160;        params_ref.col(1).setZero();</div><div class="line"><a name="l04087"></a><span class="lineno"> 4087</span>&#160;        params_grad.setZero(params_ref.rows(), params_ref.cols());</div><div class="line"><a name="l04088"></a><span class="lineno"> 4088</span>&#160;        avg_means.setZero(avg_means.rows(), avg_means.cols());</div><div class="line"><a name="l04089"></a><span class="lineno"> 4089</span>&#160;        avg_inv_sds.setZero(avg_means.rows(), avg_inv_sds.cols());</div><div class="line"><a name="l04090"></a><span class="lineno"> 4090</span>&#160;        avgs_init = <span class="keyword">false</span>;</div><div class="line"><a name="l04091"></a><span class="lineno"> 4091</span>&#160;    }</div><div class="line"><a name="l04092"></a><span class="lineno"> 4092</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l04093"></a><span class="lineno"> 4093</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a>(Self&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l04094"></a><span class="lineno"> 4094</span>&#160;            dims(layer.dims),</div><div class="line"><a name="l04095"></a><span class="lineno"> 4095</span>&#160;            gamma_reg(layer.gamma_reg),</div><div class="line"><a name="l04096"></a><span class="lineno"> 4096</span>&#160;            beta_reg(layer.beta_reg),</div><div class="line"><a name="l04097"></a><span class="lineno"> 4097</span>&#160;            gamma_max_norm_constraint(layer.gamma_max_norm_constraint),</div><div class="line"><a name="l04098"></a><span class="lineno"> 4098</span>&#160;            beta_max_norm_constraint(layer.beta_max_norm_constraint),</div><div class="line"><a name="l04099"></a><span class="lineno"> 4099</span>&#160;            gamma_max_norm(layer.gamma_max_norm),</div><div class="line"><a name="l04100"></a><span class="lineno"> 4100</span>&#160;            beta_max_norm(layer.beta_max_norm),</div><div class="line"><a name="l04101"></a><span class="lineno"> 4101</span>&#160;            norm_avg_decay(layer.norm_avg_decay),</div><div class="line"><a name="l04102"></a><span class="lineno"> 4102</span>&#160;            epsilon(layer.epsilon),</div><div class="line"><a name="l04103"></a><span class="lineno"> 4103</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l04104"></a><span class="lineno"> 4104</span>&#160;            frozen(layer.frozen),</div><div class="line"><a name="l04105"></a><span class="lineno"> 4105</span>&#160;            avg_means(layer.avg_means),</div><div class="line"><a name="l04106"></a><span class="lineno"> 4106</span>&#160;            avg_inv_sds(layer.avg_inv_sds),</div><div class="line"><a name="l04107"></a><span class="lineno"> 4107</span>&#160;            avgs_init(layer.avgs_init),</div><div class="line"><a name="l04108"></a><span class="lineno"> 4108</span>&#160;            params(share_params ? <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt;Scalar&gt;(0, 0) : layer.params),</div><div class="line"><a name="l04109"></a><span class="lineno"> 4109</span>&#160;            params_grad(layer.params_grad),</div><div class="line"><a name="l04110"></a><span class="lineno"> 4110</span>&#160;            params_ref(share_params ? layer.params : params),</div><div class="line"><a name="l04111"></a><span class="lineno"> 4111</span>&#160;            owner(share_params ? layer.owner : *this),</div><div class="line"><a name="l04112"></a><span class="lineno"> 4112</span>&#160;            inv_in_sd(layer.inv_in_sd),</div><div class="line"><a name="l04113"></a><span class="lineno"> 4113</span>&#160;            std_in(layer.std_in) { }</div><div class="line"><a name="l04114"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7f46a6d30c7004193fef2b4b75835f28"> 4114</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7f46a6d30c7004193fef2b4b75835f28">is_input_layer</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04115"></a><span class="lineno"> 4115</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l04116"></a><span class="lineno"> 4116</span>&#160;    }</div><div class="line"><a name="l04117"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a6aebaf7cd158c35983c27f691c80a5bd"> 4117</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a6aebaf7cd158c35983c27f691c80a5bd">set_input_layer</a>(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l04118"></a><span class="lineno"> 4118</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l04119"></a><span class="lineno"> 4119</span>&#160;    }</div><div class="line"><a name="l04120"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7b62f3a8bab743a0714ec3d1c7e87506"> 4120</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7b62f3a8bab743a0714ec3d1c7e87506">empty_cache</a>() {</div><div class="line"><a name="l04121"></a><span class="lineno"> 4121</span>&#160;        inv_in_sd = <a class="code" href="namespacecattle.html#a23ebf4fefd4f6b9dc0cd34afb1ce1b65">RowVector&lt;Scalar&gt;</a>(0);</div><div class="line"><a name="l04122"></a><span class="lineno"> 4122</span>&#160;        std_in = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>(0, 0);</div><div class="line"><a name="l04123"></a><span class="lineno"> 4123</span>&#160;    }</div><div class="line"><a name="l04124"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#adca55b556a6ecf4f087b84abd5752f9f"> 4124</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#adca55b556a6ecf4f087b84abd5752f9f">get_params</a>() {</div><div class="line"><a name="l04125"></a><span class="lineno"> 4125</span>&#160;        <span class="keywordflow">return</span> params_ref;</div><div class="line"><a name="l04126"></a><span class="lineno"> 4126</span>&#160;    }</div><div class="line"><a name="l04127"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a3d9cb8a20f6fd062aa52b41f8534f5af"> 4127</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a3d9cb8a20f6fd062aa52b41f8534f5af">get_params_grad</a>() {</div><div class="line"><a name="l04128"></a><span class="lineno"> 4128</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l04129"></a><span class="lineno"> 4129</span>&#160;    }</div><div class="line"><a name="l04130"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#aa8a04f59b19fa5eb664ca14fc9222a96"> 4130</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#aa8a04f59b19fa5eb664ca14fc9222a96">regularize</a>() {</div><div class="line"><a name="l04131"></a><span class="lineno"> 4131</span>&#160;        params_grad.col(0) += gamma_reg-&gt;d_function(params_ref.col(0));</div><div class="line"><a name="l04132"></a><span class="lineno"> 4132</span>&#160;        params_grad.col(1) += beta_reg-&gt;d_function(params_ref.col(1));</div><div class="line"><a name="l04133"></a><span class="lineno"> 4133</span>&#160;    }</div><div class="line"><a name="l04134"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ab185ef41a45b7a7cd8dc0371885e1ce1"> 4134</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ab185ef41a45b7a7cd8dc0371885e1ce1">get_regularization_penalty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04135"></a><span class="lineno"> 4135</span>&#160;        <span class="keywordflow">return</span> gamma_reg-&gt;function(params_ref.col(0)) + beta_reg-&gt;function(params_ref.col(1));</div><div class="line"><a name="l04136"></a><span class="lineno"> 4136</span>&#160;    }</div><div class="line"><a name="l04137"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a71f24afcc944fab3b3243850af0b6972"> 4137</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a71f24afcc944fab3b3243850af0b6972">enforce_constraints</a>() {</div><div class="line"><a name="l04138"></a><span class="lineno"> 4138</span>&#160;        Scalar l2_norm;</div><div class="line"><a name="l04139"></a><span class="lineno"> 4139</span>&#160;        <span class="keywordflow">if</span> (gamma_max_norm) {</div><div class="line"><a name="l04140"></a><span class="lineno"> 4140</span>&#160;            l2_norm = params_ref.col(0).squaredNorm();</div><div class="line"><a name="l04141"></a><span class="lineno"> 4141</span>&#160;            <span class="keywordflow">if</span> (l2_norm &gt; gamma_max_norm_constraint)</div><div class="line"><a name="l04142"></a><span class="lineno"> 4142</span>&#160;                params_ref.col(0) *= (gamma_max_norm_constraint / l2_norm);</div><div class="line"><a name="l04143"></a><span class="lineno"> 4143</span>&#160;        }</div><div class="line"><a name="l04144"></a><span class="lineno"> 4144</span>&#160;        <span class="keywordflow">if</span> (beta_max_norm) {</div><div class="line"><a name="l04145"></a><span class="lineno"> 4145</span>&#160;            l2_norm = params_ref.col(1).squaredNorm();</div><div class="line"><a name="l04146"></a><span class="lineno"> 4146</span>&#160;            <span class="keywordflow">if</span> (l2_norm &gt; beta_max_norm_constraint)</div><div class="line"><a name="l04147"></a><span class="lineno"> 4147</span>&#160;                params_ref.col(1) *= (beta_max_norm_constraint / l2_norm);</div><div class="line"><a name="l04148"></a><span class="lineno"> 4148</span>&#160;        }</div><div class="line"><a name="l04149"></a><span class="lineno"> 4149</span>&#160;    }</div><div class="line"><a name="l04150"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae01fe5aa00615cab21ac81babf2756b2"> 4150</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae01fe5aa00615cab21ac81babf2756b2">pass_forward</a>(<span class="keyword">typename</span> Base::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l04151"></a><span class="lineno"> 4151</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l04152"></a><span class="lineno"> 4152</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l04153"></a><span class="lineno"> 4153</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l04154"></a><span class="lineno"> 4154</span>&#160;        <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> in_mat(in.data(), rows, in.size() / rows);</div><div class="line"><a name="l04155"></a><span class="lineno"> 4155</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l04156"></a><span class="lineno"> 4156</span>&#160;            <a class="code" href="namespacecattle.html#a23ebf4fefd4f6b9dc0cd34afb1ce1b65">RowVector&lt;Scalar&gt;</a> means = in_mat.colwise().mean();</div><div class="line"><a name="l04157"></a><span class="lineno"> 4157</span>&#160;            <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> norm_in = in_mat.rowwise() - means;</div><div class="line"><a name="l04158"></a><span class="lineno"> 4158</span>&#160;            inv_in_sd = (norm_in.array().square().colwise().mean() + epsilon).sqrt().inverse();</div><div class="line"><a name="l04159"></a><span class="lineno"> 4159</span>&#160;            std_in = norm_in * inv_in_sd.asDiagonal();</div><div class="line"><a name="l04160"></a><span class="lineno"> 4160</span>&#160;            in_mat = std_in;</div><div class="line"><a name="l04161"></a><span class="lineno"> 4161</span>&#160;            <span class="comment">// Maintain a moving average of means and variances for testing.</span></div><div class="line"><a name="l04162"></a><span class="lineno"> 4162</span>&#160;            <span class="keywordflow">if</span> (avgs_init) {</div><div class="line"><a name="l04163"></a><span class="lineno"> 4163</span>&#160;                avg_means = (1.0 - norm_avg_decay) * avg_means + norm_avg_decay * means;</div><div class="line"><a name="l04164"></a><span class="lineno"> 4164</span>&#160;                avg_inv_sds = (1.0 - norm_avg_decay) * avg_inv_sds + norm_avg_decay * inv_in_sd;</div><div class="line"><a name="l04165"></a><span class="lineno"> 4165</span>&#160;            } <span class="keywordflow">else</span> {</div><div class="line"><a name="l04166"></a><span class="lineno"> 4166</span>&#160;                avg_means = means;</div><div class="line"><a name="l04167"></a><span class="lineno"> 4167</span>&#160;                avg_inv_sds = inv_in_sd;</div><div class="line"><a name="l04168"></a><span class="lineno"> 4168</span>&#160;                avgs_init = <span class="keyword">true</span>;</div><div class="line"><a name="l04169"></a><span class="lineno"> 4169</span>&#160;            }</div><div class="line"><a name="l04170"></a><span class="lineno"> 4170</span>&#160;        } <span class="keywordflow">else</span> <span class="comment">// For testing, use the moving averages.</span></div><div class="line"><a name="l04171"></a><span class="lineno"> 4171</span>&#160;            in_mat = (in_mat.rowwise() - avg_means) * avg_inv_sds.asDiagonal();</div><div class="line"><a name="l04172"></a><span class="lineno"> 4172</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out = (in_mat * params_ref.col(0).asDiagonal()).rowwise() + params_ref.col(1).transpose();</div><div class="line"><a name="l04173"></a><span class="lineno"> 4173</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(out.data(), in.dimensions());</div><div class="line"><a name="l04174"></a><span class="lineno"> 4174</span>&#160;    }</div><div class="line"><a name="l04175"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ad1b665c616770249569c831b9bef076c"> 4175</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ad1b665c616770249569c831b9bef076c">pass_back</a>(<span class="keyword">typename</span> Base::Data out_grad) {</div><div class="line"><a name="l04176"></a><span class="lineno"> 4176</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l04177"></a><span class="lineno"> 4177</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; std_in.rows() == out_grad.dimension(0));</div><div class="line"><a name="l04178"></a><span class="lineno"> 4178</span>&#160;        std::size_t rows = out_grad.dimension(0);</div><div class="line"><a name="l04179"></a><span class="lineno"> 4179</span>&#160;        <span class="comment">/* Back-propagate the gradient through the batch normalization function and also calculate the</span></div><div class="line"><a name="l04180"></a><span class="lineno"> 4180</span>&#160;<span class="comment">         * gradients of the betas and gammas. */</span></div><div class="line"><a name="l04181"></a><span class="lineno"> 4181</span>&#160;        <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> out_grad_mat(out_grad.data(), rows, out_grad.size() / rows);</div><div class="line"><a name="l04182"></a><span class="lineno"> 4182</span>&#160;        params_grad.col(0) = out_grad_mat.cwiseProduct(std_in).colwise().sum().transpose();</div><div class="line"><a name="l04183"></a><span class="lineno"> 4183</span>&#160;        params_grad.col(1) = out_grad_mat.colwise().sum().transpose();</div><div class="line"><a name="l04184"></a><span class="lineno"> 4184</span>&#160;        <span class="keywordflow">if</span> (input_layer)</div><div class="line"><a name="l04185"></a><span class="lineno"> 4185</span>&#160;            <span class="keywordflow">return</span> <span class="keyword">typename</span> Base::Data();</div><div class="line"><a name="l04186"></a><span class="lineno"> 4186</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> std_in_grad = out_grad_mat * params_ref.col(0).asDiagonal();</div><div class="line"><a name="l04187"></a><span class="lineno"> 4187</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> prev_out_grad = (((rows * std_in_grad).rowwise() - std_in_grad.colwise().sum()) -</div><div class="line"><a name="l04188"></a><span class="lineno"> 4188</span>&#160;                std_in * (std_in.cwiseProduct(std_in_grad).colwise().sum().asDiagonal())) *</div><div class="line"><a name="l04189"></a><span class="lineno"> 4189</span>&#160;                (((Scalar) 1 / rows) * inv_in_sd).asDiagonal();</div><div class="line"><a name="l04190"></a><span class="lineno"> 4190</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(prev_out_grad.data(), out_grad.dimensions());</div><div class="line"><a name="l04191"></a><span class="lineno"> 4191</span>&#160;    }</div><div class="line"><a name="l04192"></a><span class="lineno"> 4192</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l04193"></a><span class="lineno"> 4193</span>&#160;    <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a> dims;</div><div class="line"><a name="l04194"></a><span class="lineno"> 4194</span>&#160;    <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> gamma_reg;</div><div class="line"><a name="l04195"></a><span class="lineno"> 4195</span>&#160;    <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">ParamRegSharedPtr&lt;Scalar&gt;</a> beta_reg;</div><div class="line"><a name="l04196"></a><span class="lineno"> 4196</span>&#160;    <span class="keyword">const</span> Scalar gamma_max_norm_constraint;</div><div class="line"><a name="l04197"></a><span class="lineno"> 4197</span>&#160;    <span class="keyword">const</span> Scalar beta_max_norm_constraint;</div><div class="line"><a name="l04198"></a><span class="lineno"> 4198</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> gamma_max_norm;</div><div class="line"><a name="l04199"></a><span class="lineno"> 4199</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> beta_max_norm;</div><div class="line"><a name="l04200"></a><span class="lineno"> 4200</span>&#160;    <span class="keyword">const</span> Scalar norm_avg_decay;</div><div class="line"><a name="l04201"></a><span class="lineno"> 4201</span>&#160;    <span class="keyword">const</span> Scalar epsilon;</div><div class="line"><a name="l04202"></a><span class="lineno"> 4202</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l04203"></a><span class="lineno"> 4203</span>&#160;    <span class="keywordtype">bool</span> frozen;</div><div class="line"><a name="l04204"></a><span class="lineno"> 4204</span>&#160;    <span class="comment">// Dynamic batch normalization parameters.</span></div><div class="line"><a name="l04205"></a><span class="lineno"> 4205</span>&#160;    <a class="code" href="namespacecattle.html#a23ebf4fefd4f6b9dc0cd34afb1ce1b65">RowVector&lt;Scalar&gt;</a> avg_means;</div><div class="line"><a name="l04206"></a><span class="lineno"> 4206</span>&#160;    <a class="code" href="namespacecattle.html#a23ebf4fefd4f6b9dc0cd34afb1ce1b65">RowVector&lt;Scalar&gt;</a> avg_inv_sds;</div><div class="line"><a name="l04207"></a><span class="lineno"> 4207</span>&#160;    <span class="keywordtype">bool</span> avgs_init;</div><div class="line"><a name="l04208"></a><span class="lineno"> 4208</span>&#160;    <span class="comment">// Betas and gammas</span></div><div class="line"><a name="l04209"></a><span class="lineno"> 4209</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> params;</div><div class="line"><a name="l04210"></a><span class="lineno"> 4210</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; params_ref;</div><div class="line"><a name="l04211"></a><span class="lineno"> 4211</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> params_grad;</div><div class="line"><a name="l04212"></a><span class="lineno"> 4212</span>&#160;    <span class="keyword">const</span> Base&amp; owner;</div><div class="line"><a name="l04213"></a><span class="lineno"> 4213</span>&#160;    <span class="comment">// Staged computation caches.</span></div><div class="line"><a name="l04214"></a><span class="lineno"> 4214</span>&#160;    <a class="code" href="namespacecattle.html#a23ebf4fefd4f6b9dc0cd34afb1ce1b65">RowVector&lt;Scalar&gt;</a> inv_in_sd;</div><div class="line"><a name="l04215"></a><span class="lineno"> 4215</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> std_in;</div><div class="line"><a name="l04216"></a><span class="lineno"> 4216</span>&#160;};</div><div class="line"><a name="l04217"></a><span class="lineno"> 4217</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l04218"></a><span class="lineno"> 4218</span>&#160;</div><div class="line"><a name="l04223"></a><span class="lineno"> 4223</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank, <span class="keywordtype">bool</span> PerLastRank = (Rank == 3)&gt;</div><div class="line"><a name="l04224"></a><span class="lineno"> 4224</span>&#160;<span class="keyword">class </span>BatchNormLayer : <span class="keyword">public</span> Layer&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l04225"></a><span class="lineno"> 4225</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,Rank&gt; Base;</div><div class="line"><a name="l04226"></a><span class="lineno"> 4226</span>&#160;    <span class="keyword">typedef</span> BatchNormLayer&lt;Scalar,Rank,PerLastRank&gt; Self;</div><div class="line"><a name="l04227"></a><span class="lineno"> 4227</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l04239"></a><span class="lineno"> 4239</span>&#160;    <span class="keyword">inline</span> BatchNormLayer(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; dims, ParamRegSharedPtr&lt;Scalar&gt; gamma_reg = Base::NO_PARAM_REG,</div><div class="line"><a name="l04240"></a><span class="lineno"> 4240</span>&#160;            ParamRegSharedPtr&lt;Scalar&gt; beta_reg = Base::NO_PARAM_REG, Scalar gamma_max_norm_constraint = 0,</div><div class="line"><a name="l04241"></a><span class="lineno"> 4241</span>&#160;            Scalar beta_max_norm_constraint = 0, Scalar norm_avg_decay = .1, Scalar epsilon = internal::NumericUtils&lt;Scalar&gt;::EPSILON2) :</div><div class="line"><a name="l04242"></a><span class="lineno"> 4242</span>&#160;                dims(dims),</div><div class="line"><a name="l04243"></a><span class="lineno"> 4243</span>&#160;                gamma_reg(gamma_reg),</div><div class="line"><a name="l04244"></a><span class="lineno"> 4244</span>&#160;                beta_reg(beta_reg),</div><div class="line"><a name="l04245"></a><span class="lineno"> 4245</span>&#160;                gamma_max_norm_constraint(gamma_max_norm_constraint),</div><div class="line"><a name="l04246"></a><span class="lineno"> 4246</span>&#160;                beta_max_norm_constraint(beta_max_norm_constraint),</div><div class="line"><a name="l04247"></a><span class="lineno"> 4247</span>&#160;                gamma_max_norm(internal::NumericUtils&lt;Scalar&gt;::decidedly_greater(gamma_max_norm_constraint, (Scalar) 0)),</div><div class="line"><a name="l04248"></a><span class="lineno"> 4248</span>&#160;                beta_max_norm(internal::NumericUtils&lt;Scalar&gt;::decidedly_greater(beta_max_norm_constraint, (Scalar) 0)),</div><div class="line"><a name="l04249"></a><span class="lineno"> 4249</span>&#160;                norm_avg_decay(norm_avg_decay),</div><div class="line"><a name="l04250"></a><span class="lineno"> 4250</span>&#160;                epsilon(epsilon),</div><div class="line"><a name="l04251"></a><span class="lineno"> 4251</span>&#160;                params_vol(PerLastRank ? dims(Rank - 1) : dims.get_volume()),</div><div class="line"><a name="l04252"></a><span class="lineno"> 4252</span>&#160;                input_layer(false),</div><div class="line"><a name="l04253"></a><span class="lineno"> 4253</span>&#160;                frozen(false),</div><div class="line"><a name="l04254"></a><span class="lineno"> 4254</span>&#160;                batch_dims(calculate_extended_batch_dims(dims)),</div><div class="line"><a name="l04255"></a><span class="lineno"> 4255</span>&#160;                means(params_vol),</div><div class="line"><a name="l04256"></a><span class="lineno"> 4256</span>&#160;                vars(params_vol),</div><div class="line"><a name="l04257"></a><span class="lineno"> 4257</span>&#160;                params(params_vol, 2),</div><div class="line"><a name="l04258"></a><span class="lineno"> 4258</span>&#160;                params_grad(params.rows(), params.cols()),</div><div class="line"><a name="l04259"></a><span class="lineno"> 4259</span>&#160;                params_ref(params),</div><div class="line"><a name="l04260"></a><span class="lineno"> 4260</span>&#160;                owner(*this) {</div><div class="line"><a name="l04261"></a><span class="lineno"> 4261</span>&#160;        assert(gamma_reg != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l04262"></a><span class="lineno"> 4262</span>&#160;        assert(beta_reg != <span class="keyword">nullptr</span>);</div><div class="line"><a name="l04263"></a><span class="lineno"> 4263</span>&#160;        assert(norm_avg_decay &gt;= 0 &amp;&amp; norm_avg_decay &lt;= 1 &amp;&amp;</div><div class="line"><a name="l04264"></a><span class="lineno"> 4264</span>&#160;                <span class="stringliteral">&quot;norm avg decay must not be less than 0 or greater than 1&quot;</span>);</div><div class="line"><a name="l04265"></a><span class="lineno"> 4265</span>&#160;        assert(epsilon &gt; 0 &amp;&amp; <span class="stringliteral">&quot;epsilon must be greater than 0&quot;</span>);</div><div class="line"><a name="l04266"></a><span class="lineno"> 4266</span>&#160;    }</div><div class="line"><a name="l04267"></a><span class="lineno"> 4267</span>&#160;    <span class="keyword">inline</span> BatchNormLayer(<span class="keyword">const</span> Self&amp; layer) :</div><div class="line"><a name="l04268"></a><span class="lineno"> 4268</span>&#160;            dims(layer.dims),</div><div class="line"><a name="l04269"></a><span class="lineno"> 4269</span>&#160;            gamma_reg(layer.gamma_reg),</div><div class="line"><a name="l04270"></a><span class="lineno"> 4270</span>&#160;            beta_reg(layer.beta_reg),</div><div class="line"><a name="l04271"></a><span class="lineno"> 4271</span>&#160;            gamma_max_norm_constraint(layer.gamma_max_norm_constraint),</div><div class="line"><a name="l04272"></a><span class="lineno"> 4272</span>&#160;            beta_max_norm_constraint(layer.beta_max_norm_constraint),</div><div class="line"><a name="l04273"></a><span class="lineno"> 4273</span>&#160;            gamma_max_norm(layer.gamma_max_norm),</div><div class="line"><a name="l04274"></a><span class="lineno"> 4274</span>&#160;            beta_max_norm(layer.beta_max_norm),</div><div class="line"><a name="l04275"></a><span class="lineno"> 4275</span>&#160;            norm_avg_decay(layer.norm_avg_decay),</div><div class="line"><a name="l04276"></a><span class="lineno"> 4276</span>&#160;            epsilon(layer.epsilon),</div><div class="line"><a name="l04277"></a><span class="lineno"> 4277</span>&#160;            params_vol(layer.params_vol),</div><div class="line"><a name="l04278"></a><span class="lineno"> 4278</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l04279"></a><span class="lineno"> 4279</span>&#160;            frozen(layer.frozen),</div><div class="line"><a name="l04280"></a><span class="lineno"> 4280</span>&#160;            batch_dims(layer.batch_dims),</div><div class="line"><a name="l04281"></a><span class="lineno"> 4281</span>&#160;            means(layer.means),</div><div class="line"><a name="l04282"></a><span class="lineno"> 4282</span>&#160;            vars(layer.vars),</div><div class="line"><a name="l04283"></a><span class="lineno"> 4283</span>&#160;            params(layer.params),</div><div class="line"><a name="l04284"></a><span class="lineno"> 4284</span>&#160;            params_grad(layer.params_grad),</div><div class="line"><a name="l04285"></a><span class="lineno"> 4285</span>&#160;            params_ref(layer.is_shared_params_clone() ? layer.params_ref : params),</div><div class="line"><a name="l04286"></a><span class="lineno"> 4286</span>&#160;            owner(layer.is_shared_params_clone() ? layer.owner : *this),</div><div class="line"><a name="l04287"></a><span class="lineno"> 4287</span>&#160;            input(layer.input),</div><div class="line"><a name="l04288"></a><span class="lineno"> 4288</span>&#160;            mean_cache(layer.mean_cache),</div><div class="line"><a name="l04289"></a><span class="lineno"> 4289</span>&#160;            inv_var_cache(layer.inv_var_cache) { }</div><div class="line"><a name="l04290"></a><span class="lineno"> 4290</span>&#160;    <span class="keyword">inline</span> Self&amp; operator=(<span class="keyword">const</span> Self&amp; layer) {</div><div class="line"><a name="l04291"></a><span class="lineno"> 4291</span>&#160;        dims = layer.dims;</div><div class="line"><a name="l04292"></a><span class="lineno"> 4292</span>&#160;        gamma_reg = layer.gamma_reg;</div><div class="line"><a name="l04293"></a><span class="lineno"> 4293</span>&#160;        beta_reg = layer.beta_reg;</div><div class="line"><a name="l04294"></a><span class="lineno"> 4294</span>&#160;        gamma_max_norm_constraint = layer.gamma_max_norm_constraint;</div><div class="line"><a name="l04295"></a><span class="lineno"> 4295</span>&#160;        beta_max_norm_constraint = layer.beta_max_norm_constraint;</div><div class="line"><a name="l04296"></a><span class="lineno"> 4296</span>&#160;        gamma_max_norm = layer.gamma_max_norm;</div><div class="line"><a name="l04297"></a><span class="lineno"> 4297</span>&#160;        beta_max_norm = layer.beta_max_norm;</div><div class="line"><a name="l04298"></a><span class="lineno"> 4298</span>&#160;        norm_avg_decay = layer.norm_avg_decay;</div><div class="line"><a name="l04299"></a><span class="lineno"> 4299</span>&#160;        epsilon = layer.epsilon;</div><div class="line"><a name="l04300"></a><span class="lineno"> 4300</span>&#160;        params_vol = layer.params_vol;</div><div class="line"><a name="l04301"></a><span class="lineno"> 4301</span>&#160;        input_layer = layer.input_layer;</div><div class="line"><a name="l04302"></a><span class="lineno"> 4302</span>&#160;        frozen = layer.frozen;</div><div class="line"><a name="l04303"></a><span class="lineno"> 4303</span>&#160;        batch_dims = layer.batch_dims;</div><div class="line"><a name="l04304"></a><span class="lineno"> 4304</span>&#160;        means = layer.means;</div><div class="line"><a name="l04305"></a><span class="lineno"> 4305</span>&#160;        vars = layer.vars;</div><div class="line"><a name="l04306"></a><span class="lineno"> 4306</span>&#160;        params = layer.params;</div><div class="line"><a name="l04307"></a><span class="lineno"> 4307</span>&#160;        params_grad = layer.params_grad;</div><div class="line"><a name="l04308"></a><span class="lineno"> 4308</span>&#160;        params_ref = (layer.is_shared_params_clone() ? layer.params_ref : params);</div><div class="line"><a name="l04309"></a><span class="lineno"> 4309</span>&#160;        owner = (layer.is_shared_params_clone() ? layer.owner : *<span class="keyword">this</span>);</div><div class="line"><a name="l04310"></a><span class="lineno"> 4310</span>&#160;        input = layer.input;</div><div class="line"><a name="l04311"></a><span class="lineno"> 4311</span>&#160;        mean_cache = layer.mean_cache;</div><div class="line"><a name="l04312"></a><span class="lineno"> 4312</span>&#160;        inv_var_cache = layer.inv_var_cache;</div><div class="line"><a name="l04313"></a><span class="lineno"> 4313</span>&#160;    }</div><div class="line"><a name="l04314"></a><span class="lineno"> 4314</span>&#160;    <span class="keyword">inline</span> Base* clone()<span class="keyword"> const </span>{</div><div class="line"><a name="l04315"></a><span class="lineno"> 4315</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> BatchNormLayer(*<span class="keyword">this</span>);</div><div class="line"><a name="l04316"></a><span class="lineno"> 4316</span>&#160;    }</div><div class="line"><a name="l04317"></a><span class="lineno"> 4317</span>&#160;    <span class="keyword">inline</span> Base* clone_with_shared_params() {</div><div class="line"><a name="l04318"></a><span class="lineno"> 4318</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> BatchNormLayer(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l04319"></a><span class="lineno"> 4319</span>&#160;    }</div><div class="line"><a name="l04320"></a><span class="lineno"> 4320</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Base&amp; get_params_owner()<span class="keyword"> const </span>{</div><div class="line"><a name="l04321"></a><span class="lineno"> 4321</span>&#160;        <span class="keywordflow">return</span> owner;</div><div class="line"><a name="l04322"></a><span class="lineno"> 4322</span>&#160;    }</div><div class="line"><a name="l04323"></a><span class="lineno"> 4323</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; get_input_dims()<span class="keyword"> const </span>{</div><div class="line"><a name="l04324"></a><span class="lineno"> 4324</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l04325"></a><span class="lineno"> 4325</span>&#160;    }</div><div class="line"><a name="l04326"></a><span class="lineno"> 4326</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; get_output_dims()<span class="keyword"> const </span>{</div><div class="line"><a name="l04327"></a><span class="lineno"> 4327</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l04328"></a><span class="lineno"> 4328</span>&#160;    }</div><div class="line"><a name="l04329"></a><span class="lineno"> 4329</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Matrix&lt;Scalar&gt;&amp; get_params()<span class="keyword"> const </span>{</div><div class="line"><a name="l04330"></a><span class="lineno"> 4330</span>&#160;        <span class="keywordflow">return</span> params_ref;</div><div class="line"><a name="l04331"></a><span class="lineno"> 4331</span>&#160;    }</div><div class="line"><a name="l04332"></a><span class="lineno"> 4332</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Matrix&lt;Scalar&gt;&amp; get_params_grad()<span class="keyword"> const </span>{</div><div class="line"><a name="l04333"></a><span class="lineno"> 4333</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l04334"></a><span class="lineno"> 4334</span>&#160;    }</div><div class="line"><a name="l04335"></a><span class="lineno"> 4335</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> is_frozen()<span class="keyword"> const </span>{</div><div class="line"><a name="l04336"></a><span class="lineno"> 4336</span>&#160;        <span class="keywordflow">return</span> frozen;</div><div class="line"><a name="l04337"></a><span class="lineno"> 4337</span>&#160;    }</div><div class="line"><a name="l04338"></a><span class="lineno"> 4338</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> set_frozen(<span class="keywordtype">bool</span> frozen) {</div><div class="line"><a name="l04339"></a><span class="lineno"> 4339</span>&#160;        this-&gt;frozen = frozen;</div><div class="line"><a name="l04340"></a><span class="lineno"> 4340</span>&#160;    }</div><div class="line"><a name="l04341"></a><span class="lineno"> 4341</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> init() {</div><div class="line"><a name="l04342"></a><span class="lineno"> 4342</span>&#160;        params_ref.col(0).setOnes();</div><div class="line"><a name="l04343"></a><span class="lineno"> 4343</span>&#160;        params_ref.col(1).setZero();</div><div class="line"><a name="l04344"></a><span class="lineno"> 4344</span>&#160;        params_grad.setZero(params_ref.rows(), params_ref.cols());</div><div class="line"><a name="l04345"></a><span class="lineno"> 4345</span>&#160;        means.setZero(means.rows(), means.cols());</div><div class="line"><a name="l04346"></a><span class="lineno"> 4346</span>&#160;        vars.setZero(vars.rows(), vars.cols());</div><div class="line"><a name="l04347"></a><span class="lineno"> 4347</span>&#160;    }</div><div class="line"><a name="l04348"></a><span class="lineno"> 4348</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l04349"></a><span class="lineno"> 4349</span>&#160;    <span class="keyword">inline</span> BatchNormLayer(Self&amp; layer, <span class="keywordtype">bool</span> share_params) :</div><div class="line"><a name="l04350"></a><span class="lineno"> 4350</span>&#160;            dims(layer.dims),</div><div class="line"><a name="l04351"></a><span class="lineno"> 4351</span>&#160;            gamma_reg(layer.gamma_reg),</div><div class="line"><a name="l04352"></a><span class="lineno"> 4352</span>&#160;            beta_reg(layer.beta_reg),</div><div class="line"><a name="l04353"></a><span class="lineno"> 4353</span>&#160;            gamma_max_norm_constraint(layer.gamma_max_norm_constraint),</div><div class="line"><a name="l04354"></a><span class="lineno"> 4354</span>&#160;            beta_max_norm_constraint(layer.beta_max_norm_constraint),</div><div class="line"><a name="l04355"></a><span class="lineno"> 4355</span>&#160;            gamma_max_norm(layer.gamma_max_norm),</div><div class="line"><a name="l04356"></a><span class="lineno"> 4356</span>&#160;            beta_max_norm(layer.beta_max_norm),</div><div class="line"><a name="l04357"></a><span class="lineno"> 4357</span>&#160;            norm_avg_decay(layer.norm_avg_decay),</div><div class="line"><a name="l04358"></a><span class="lineno"> 4358</span>&#160;            epsilon(layer.epsilon),</div><div class="line"><a name="l04359"></a><span class="lineno"> 4359</span>&#160;            params_vol(layer.params_vol),</div><div class="line"><a name="l04360"></a><span class="lineno"> 4360</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l04361"></a><span class="lineno"> 4361</span>&#160;            frozen(layer.frozen),</div><div class="line"><a name="l04362"></a><span class="lineno"> 4362</span>&#160;            batch_dims(layer.batch_dims),</div><div class="line"><a name="l04363"></a><span class="lineno"> 4363</span>&#160;            means(layer.means),</div><div class="line"><a name="l04364"></a><span class="lineno"> 4364</span>&#160;            vars(layer.vars),</div><div class="line"><a name="l04365"></a><span class="lineno"> 4365</span>&#160;            params(share_params ? <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix</a>&lt;Scalar&gt;(0, 0) : layer.params),</div><div class="line"><a name="l04366"></a><span class="lineno"> 4366</span>&#160;            params_grad(layer.params_grad),</div><div class="line"><a name="l04367"></a><span class="lineno"> 4367</span>&#160;            params_ref(share_params ? layer.params_ref : params),</div><div class="line"><a name="l04368"></a><span class="lineno"> 4368</span>&#160;            owner(share_params ? layer.owner : params),</div><div class="line"><a name="l04369"></a><span class="lineno"> 4369</span>&#160;            input(layer.input),</div><div class="line"><a name="l04370"></a><span class="lineno"> 4370</span>&#160;            mean_cache(layer.mean_cache),</div><div class="line"><a name="l04371"></a><span class="lineno"> 4371</span>&#160;            inv_var_cache(layer.inv_var_cache) { }</div><div class="line"><a name="l04372"></a><span class="lineno"> 4372</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> is_input_layer()<span class="keyword"> const </span>{</div><div class="line"><a name="l04373"></a><span class="lineno"> 4373</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l04374"></a><span class="lineno"> 4374</span>&#160;    }</div><div class="line"><a name="l04375"></a><span class="lineno"> 4375</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> set_input_layer(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l04376"></a><span class="lineno"> 4376</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l04377"></a><span class="lineno"> 4377</span>&#160;    }</div><div class="line"><a name="l04378"></a><span class="lineno"> 4378</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> empty_cache() {</div><div class="line"><a name="l04379"></a><span class="lineno"> 4379</span>&#160;        input = <span class="keyword">typename</span> Base::Data();</div><div class="line"><a name="l04380"></a><span class="lineno"> 4380</span>&#160;        mean_cache = Matrix&lt;Scalar&gt;(0, 0);</div><div class="line"><a name="l04381"></a><span class="lineno"> 4381</span>&#160;        inv_var_cache = Matrix&lt;Scalar&gt;(0, 0);</div><div class="line"><a name="l04382"></a><span class="lineno"> 4382</span>&#160;    }</div><div class="line"><a name="l04383"></a><span class="lineno"> 4383</span>&#160;    <span class="keyword">inline</span> Matrix&lt;Scalar&gt;&amp; get_params() {</div><div class="line"><a name="l04384"></a><span class="lineno"> 4384</span>&#160;        <span class="keywordflow">return</span> params_ref;</div><div class="line"><a name="l04385"></a><span class="lineno"> 4385</span>&#160;    }</div><div class="line"><a name="l04386"></a><span class="lineno"> 4386</span>&#160;    <span class="keyword">inline</span> Matrix&lt;Scalar&gt;&amp; get_params_grad() {</div><div class="line"><a name="l04387"></a><span class="lineno"> 4387</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l04388"></a><span class="lineno"> 4388</span>&#160;    }</div><div class="line"><a name="l04389"></a><span class="lineno"> 4389</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> regularize() {</div><div class="line"><a name="l04390"></a><span class="lineno"> 4390</span>&#160;        params_grad.col(0) += gamma_reg-&gt;d_function(params_ref.col(0));</div><div class="line"><a name="l04391"></a><span class="lineno"> 4391</span>&#160;        params_grad.col(1) += beta_reg-&gt;d_function(params_ref.col(1));</div><div class="line"><a name="l04392"></a><span class="lineno"> 4392</span>&#160;    }</div><div class="line"><a name="l04393"></a><span class="lineno"> 4393</span>&#160;    <span class="keyword">inline</span> Scalar get_regularization_penalty()<span class="keyword"> const </span>{</div><div class="line"><a name="l04394"></a><span class="lineno"> 4394</span>&#160;        <span class="keywordflow">return</span> gamma_reg-&gt;function(params_ref.col(0)) + beta_reg-&gt;function(params_ref.col(1));</div><div class="line"><a name="l04395"></a><span class="lineno"> 4395</span>&#160;    }</div><div class="line"><a name="l04396"></a><span class="lineno"> 4396</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> enforce_constraints() {</div><div class="line"><a name="l04397"></a><span class="lineno"> 4397</span>&#160;        Scalar l2_norm;</div><div class="line"><a name="l04398"></a><span class="lineno"> 4398</span>&#160;        <span class="keywordflow">if</span> (gamma_max_norm) {</div><div class="line"><a name="l04399"></a><span class="lineno"> 4399</span>&#160;            l2_norm = params_ref.col(0).squaredNorm();</div><div class="line"><a name="l04400"></a><span class="lineno"> 4400</span>&#160;            <span class="keywordflow">if</span> (l2_norm &gt; gamma_max_norm_constraint)</div><div class="line"><a name="l04401"></a><span class="lineno"> 4401</span>&#160;                params_ref.col(0) *= (gamma_max_norm_constraint / l2_norm);</div><div class="line"><a name="l04402"></a><span class="lineno"> 4402</span>&#160;        }</div><div class="line"><a name="l04403"></a><span class="lineno"> 4403</span>&#160;        <span class="keywordflow">if</span> (beta_max_norm) {</div><div class="line"><a name="l04404"></a><span class="lineno"> 4404</span>&#160;            l2_norm = params_ref.col(1).squaredNorm();</div><div class="line"><a name="l04405"></a><span class="lineno"> 4405</span>&#160;            <span class="keywordflow">if</span> (l2_norm &gt; beta_max_norm_constraint)</div><div class="line"><a name="l04406"></a><span class="lineno"> 4406</span>&#160;                params_ref.col(1) *= (beta_max_norm_constraint / l2_norm);</div><div class="line"><a name="l04407"></a><span class="lineno"> 4407</span>&#160;        }</div><div class="line"><a name="l04408"></a><span class="lineno"> 4408</span>&#160;    }</div><div class="line"><a name="l04409"></a><span class="lineno"> 4409</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data pass_forward(<span class="keyword">typename</span> Base::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l04410"></a><span class="lineno"> 4410</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l04411"></a><span class="lineno"> 4411</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l04412"></a><span class="lineno"> 4412</span>&#160;        batch_dims[0] = in.dimension(0);</div><div class="line"><a name="l04413"></a><span class="lineno"> 4413</span>&#160;        Matrix&lt;Scalar&gt; gamma = params_ref.col(0);</div><div class="line"><a name="l04414"></a><span class="lineno"> 4414</span>&#160;        Matrix&lt;Scalar&gt; beta = params_ref.col(1);</div><div class="line"><a name="l04415"></a><span class="lineno"> 4415</span>&#160;        <span class="keyword">typename</span> Base::Data out(in.dimensions());</div><div class="line"><a name="l04416"></a><span class="lineno"> 4416</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l04417"></a><span class="lineno"> 4417</span>&#160;            input = std::move(in);</div><div class="line"><a name="l04418"></a><span class="lineno"> 4418</span>&#160;            mean_cache = RowVector&lt;Scalar&gt;(params_vol);</div><div class="line"><a name="l04419"></a><span class="lineno"> 4419</span>&#160;            inv_var_cache = RowVector&lt;Scalar&gt;(params_vol);</div><div class="line"><a name="l04420"></a><span class="lineno"> 4420</span>&#160;            batch_norm_fwd_training(input.data(), gamma.data(), beta.data(), batch_dims, PerLastRank,</div><div class="line"><a name="l04421"></a><span class="lineno"> 4421</span>&#160;                    1 - norm_avg_decay, epsilon, means.data(), vars.data(), out.data(), mean_cache.data(),</div><div class="line"><a name="l04422"></a><span class="lineno"> 4422</span>&#160;                    inv_var_cache.data());</div><div class="line"><a name="l04423"></a><span class="lineno"> 4423</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l04424"></a><span class="lineno"> 4424</span>&#160;            batch_norm_fwd_inference(in.data(), gamma.data(), beta.data(), means.data(), vars.data(),</div><div class="line"><a name="l04425"></a><span class="lineno"> 4425</span>&#160;                    batch_dims, PerLastRank, epsilon. out.data());</div><div class="line"><a name="l04426"></a><span class="lineno"> 4426</span>&#160;        }</div><div class="line"><a name="l04427"></a><span class="lineno"> 4427</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l04428"></a><span class="lineno"> 4428</span>&#160;    }</div><div class="line"><a name="l04429"></a><span class="lineno"> 4429</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data pass_back(<span class="keyword">typename</span> Base::Data out_grad) {</div><div class="line"><a name="l04430"></a><span class="lineno"> 4430</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l04431"></a><span class="lineno"> 4431</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; batch_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l04432"></a><span class="lineno"> 4432</span>&#160;        Matrix&lt;Scalar&gt; gamma = params_ref.col(0);</div><div class="line"><a name="l04433"></a><span class="lineno"> 4433</span>&#160;        Matrix&lt;Scalar&gt; gamma_grad(params_vol, 1);</div><div class="line"><a name="l04434"></a><span class="lineno"> 4434</span>&#160;        Matrix&lt;Scalar&gt; beta_grad(params_vol, 1);</div><div class="line"><a name="l04435"></a><span class="lineno"> 4435</span>&#160;        <span class="keyword">typename</span> Base::Data prev_out_grad(out_grad.dimensions());</div><div class="line"><a name="l04436"></a><span class="lineno"> 4436</span>&#160;        batch_norm_bwd(input.data(), out_grad.data(), gamma.data(), mean_cache.data(), inv_var_cache.data(),</div><div class="line"><a name="l04437"></a><span class="lineno"> 4437</span>&#160;                batch_dims, PerLastRank, epsilon, prev_out_grad.data(), gamma_grad.data(), beta_grad.data());</div><div class="line"><a name="l04438"></a><span class="lineno"> 4438</span>&#160;        params_grad.col(0) = gamma_grad;</div><div class="line"><a name="l04439"></a><span class="lineno"> 4439</span>&#160;        params_grad.col(1) = beta_grad;</div><div class="line"><a name="l04440"></a><span class="lineno"> 4440</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l04441"></a><span class="lineno"> 4441</span>&#160;    }</div><div class="line"><a name="l04442"></a><span class="lineno"> 4442</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l04443"></a><span class="lineno"> 4443</span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> std::array&lt;std::size_t,4&gt; calculate_extended_batch_dims(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; dims) {</div><div class="line"><a name="l04444"></a><span class="lineno"> 4444</span>&#160;        std::size_t params_vol = dims(Rank - 1);</div><div class="line"><a name="l04445"></a><span class="lineno"> 4445</span>&#160;        Dimensions&lt;std::size_t,3&gt; adjusted_dims = dims.template extend&lt;3 - Rank&gt;();</div><div class="line"><a name="l04446"></a><span class="lineno"> 4446</span>&#160;        adjusted_dims(Rank - 1) = 1;</div><div class="line"><a name="l04447"></a><span class="lineno"> 4447</span>&#160;        adjusted_dims(2) = params_vol;</div><div class="line"><a name="l04448"></a><span class="lineno"> 4448</span>&#160;        <span class="keywordflow">return</span> adjusted_dims.template promote&lt;&gt;();</div><div class="line"><a name="l04449"></a><span class="lineno"> 4449</span>&#160;    }</div><div class="line"><a name="l04450"></a><span class="lineno"> 4450</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt; dims;</div><div class="line"><a name="l04451"></a><span class="lineno"> 4451</span>&#160;    <span class="keyword">const</span> ParamRegSharedPtr&lt;Scalar&gt; gamma_reg;</div><div class="line"><a name="l04452"></a><span class="lineno"> 4452</span>&#160;    <span class="keyword">const</span> ParamRegSharedPtr&lt;Scalar&gt; beta_reg;</div><div class="line"><a name="l04453"></a><span class="lineno"> 4453</span>&#160;    <span class="keyword">const</span> Scalar gamma_max_norm_constraint;</div><div class="line"><a name="l04454"></a><span class="lineno"> 4454</span>&#160;    <span class="keyword">const</span> Scalar beta_max_norm_constraint;</div><div class="line"><a name="l04455"></a><span class="lineno"> 4455</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> gamma_max_norm;</div><div class="line"><a name="l04456"></a><span class="lineno"> 4456</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> beta_max_norm;</div><div class="line"><a name="l04457"></a><span class="lineno"> 4457</span>&#160;    <span class="keyword">const</span> Scalar norm_avg_decay;</div><div class="line"><a name="l04458"></a><span class="lineno"> 4458</span>&#160;    <span class="keyword">const</span> Scalar epsilon;</div><div class="line"><a name="l04459"></a><span class="lineno"> 4459</span>&#160;    <span class="keyword">const</span> std::size_t params_vol;</div><div class="line"><a name="l04460"></a><span class="lineno"> 4460</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l04461"></a><span class="lineno"> 4461</span>&#160;    <span class="keywordtype">bool</span> frozen;</div><div class="line"><a name="l04462"></a><span class="lineno"> 4462</span>&#160;    std::array&lt;std::size_t,4&gt; batch_dims;</div><div class="line"><a name="l04463"></a><span class="lineno"> 4463</span>&#160;    RowVector&lt;Scalar&gt; means;</div><div class="line"><a name="l04464"></a><span class="lineno"> 4464</span>&#160;    RowVector&lt;Scalar&gt; vars;</div><div class="line"><a name="l04465"></a><span class="lineno"> 4465</span>&#160;    Matrix&lt;Scalar&gt; params;</div><div class="line"><a name="l04466"></a><span class="lineno"> 4466</span>&#160;    Matrix&lt;Scalar&gt; params_grad;</div><div class="line"><a name="l04467"></a><span class="lineno"> 4467</span>&#160;    Matrix&lt;Scalar&gt;&amp; params_ref;</div><div class="line"><a name="l04468"></a><span class="lineno"> 4468</span>&#160;    <span class="keyword">const</span> Base&amp; owner;</div><div class="line"><a name="l04469"></a><span class="lineno"> 4469</span>&#160;    <span class="keyword">typename</span> Base::Data input;</div><div class="line"><a name="l04470"></a><span class="lineno"> 4470</span>&#160;    RowVector&lt;Scalar&gt; mean_cache;</div><div class="line"><a name="l04471"></a><span class="lineno"> 4471</span>&#160;    RowVector&lt;Scalar&gt; inv_var_cache;</div><div class="line"><a name="l04472"></a><span class="lineno"> 4472</span>&#160;};</div><div class="line"><a name="l04473"></a><span class="lineno"> 4473</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l04474"></a><span class="lineno"> 4474</span>&#160;</div><div class="line"><a name="l04475"></a><span class="lineno"> 4475</span>&#160;<span class="preprocessor">#ifndef CATTL3_USE_CUDNN</span></div><div class="line"><a name="l04476"></a><span class="lineno"> 4476</span>&#160;</div><div class="line"><a name="l04482"></a><span class="lineno"> 4482</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l04483"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html"> 4483</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_dropout_layer.html">DropoutLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l04484"></a><span class="lineno"> 4484</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l04485"></a><span class="lineno"> 4485</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l04491"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#aaa346c955d02369927de664087a32999"> 4491</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_dropout_layer.html#aaa346c955d02369927de664087a32999">DropoutLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; dims, Scalar dropout_prob,</div><div class="line"><a name="l04492"></a><span class="lineno"> 4492</span>&#160;            Scalar epsilon = <a class="code" href="classcattle_1_1internal_1_1_numeric_utils.html">internal::NumericUtils&lt;Scalar&gt;::EPSILON2</a>) :</div><div class="line"><a name="l04493"></a><span class="lineno"> 4493</span>&#160;                dims(dims),</div><div class="line"><a name="l04494"></a><span class="lineno"> 4494</span>&#160;                dropout_prob(dropout_prob),</div><div class="line"><a name="l04495"></a><span class="lineno"> 4495</span>&#160;                epsilon(epsilon),</div><div class="line"><a name="l04496"></a><span class="lineno"> 4496</span>&#160;                input_layer(false),</div><div class="line"><a name="l04497"></a><span class="lineno"> 4497</span>&#160;                frozen(false),</div><div class="line"><a name="l04498"></a><span class="lineno"> 4498</span>&#160;                params(0, 0),</div><div class="line"><a name="l04499"></a><span class="lineno"> 4499</span>&#160;                params_grad(0, 0) {</div><div class="line"><a name="l04500"></a><span class="lineno"> 4500</span>&#160;        assert(dropout_prob &gt; 0 &amp;&amp; dropout_prob &lt;= 1 &amp;&amp;</div><div class="line"><a name="l04501"></a><span class="lineno"> 4501</span>&#160;                <span class="stringliteral">&quot;dropout probability must be greater than 0 and no greater than 1&quot;</span>);</div><div class="line"><a name="l04502"></a><span class="lineno"> 4502</span>&#160;        assert(epsilon &gt; 0 &amp;&amp; <span class="stringliteral">&quot;epsilon must be greater than 0&quot;</span>);</div><div class="line"><a name="l04503"></a><span class="lineno"> 4503</span>&#160;    }</div><div class="line"><a name="l04504"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a0206c8917c45b9ac3f4388fa29ab9a26"> 4504</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_dropout_layer.html#a0206c8917c45b9ac3f4388fa29ab9a26">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04505"></a><span class="lineno"> 4505</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_dropout_layer.html">DropoutLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l04506"></a><span class="lineno"> 4506</span>&#160;    }</div><div class="line"><a name="l04507"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a14cbbb352c679482e3fe4ce2b970f06a"> 4507</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_dropout_layer.html#a14cbbb352c679482e3fe4ce2b970f06a">clone_with_shared_params</a>() {</div><div class="line"><a name="l04508"></a><span class="lineno"> 4508</span>&#160;        <span class="keywordflow">return</span> clone();</div><div class="line"><a name="l04509"></a><span class="lineno"> 4509</span>&#160;    }</div><div class="line"><a name="l04510"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a8fb4d7ea9030d99c74a04902bea3d477"> 4510</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>&amp; <a class="code" href="classcattle_1_1_dropout_layer.html#a8fb4d7ea9030d99c74a04902bea3d477">get_params_owner</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04511"></a><span class="lineno"> 4511</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l04512"></a><span class="lineno"> 4512</span>&#160;    }</div><div class="line"><a name="l04513"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a24cc229aaaa68fe8889c4c05f5a1529a"> 4513</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_dropout_layer.html#a24cc229aaaa68fe8889c4c05f5a1529a">get_input_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04514"></a><span class="lineno"> 4514</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l04515"></a><span class="lineno"> 4515</span>&#160;    }</div><div class="line"><a name="l04516"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a4eaac782e31cae389237b843ce7569e5"> 4516</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_dropout_layer.html#a4eaac782e31cae389237b843ce7569e5">get_output_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04517"></a><span class="lineno"> 4517</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l04518"></a><span class="lineno"> 4518</span>&#160;    }</div><div class="line"><a name="l04519"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a60266bc0cc76f7639bca2541890e870b"> 4519</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_dropout_layer.html#a60266bc0cc76f7639bca2541890e870b">get_params</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04520"></a><span class="lineno"> 4520</span>&#160;        <span class="keywordflow">return</span> params;</div><div class="line"><a name="l04521"></a><span class="lineno"> 4521</span>&#160;    }</div><div class="line"><a name="l04522"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a046463edd1e0b4b335cefeae6bf5b614"> 4522</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_dropout_layer.html#a046463edd1e0b4b335cefeae6bf5b614">get_params_grad</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04523"></a><span class="lineno"> 4523</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l04524"></a><span class="lineno"> 4524</span>&#160;    }</div><div class="line"><a name="l04525"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a506589d195f7cf7440ce005b85c4be8e"> 4525</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_dropout_layer.html#a506589d195f7cf7440ce005b85c4be8e">is_frozen</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04526"></a><span class="lineno"> 4526</span>&#160;        <span class="keywordflow">return</span> frozen;</div><div class="line"><a name="l04527"></a><span class="lineno"> 4527</span>&#160;    }</div><div class="line"><a name="l04528"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a0da23b87533c9f9825948d31538a5e06"> 4528</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_dropout_layer.html#a0da23b87533c9f9825948d31538a5e06">set_frozen</a>(<span class="keywordtype">bool</span> frozen) {</div><div class="line"><a name="l04529"></a><span class="lineno"> 4529</span>&#160;        this-&gt;frozen = frozen;</div><div class="line"><a name="l04530"></a><span class="lineno"> 4530</span>&#160;    }</div><div class="line"><a name="l04531"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a89ad20c1cdf2ec2de893665aa417e0f1"> 4531</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_dropout_layer.html#a89ad20c1cdf2ec2de893665aa417e0f1">init</a>() { }</div><div class="line"><a name="l04532"></a><span class="lineno"> 4532</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l04533"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a601eec2c307fd047dd390e2e4347cc58"> 4533</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_dropout_layer.html#a601eec2c307fd047dd390e2e4347cc58">is_input_layer</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04534"></a><span class="lineno"> 4534</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l04535"></a><span class="lineno"> 4535</span>&#160;    }</div><div class="line"><a name="l04536"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#ae1d090be4a0c212daaf625f5acbd9f22"> 4536</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_dropout_layer.html#ae1d090be4a0c212daaf625f5acbd9f22">set_input_layer</a>(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l04537"></a><span class="lineno"> 4537</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l04538"></a><span class="lineno"> 4538</span>&#160;    }</div><div class="line"><a name="l04539"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#af82f4022e6bbd0c328729342d18432cd"> 4539</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_dropout_layer.html#af82f4022e6bbd0c328729342d18432cd">empty_cache</a>() {</div><div class="line"><a name="l04540"></a><span class="lineno"> 4540</span>&#160;        dropout_mask = <span class="keyword">typename</span> Base::Data();</div><div class="line"><a name="l04541"></a><span class="lineno"> 4541</span>&#160;    }</div><div class="line"><a name="l04542"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#afdf7ed4bac91e56664c0f5ed6a9dafda"> 4542</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_dropout_layer.html#afdf7ed4bac91e56664c0f5ed6a9dafda">get_params</a>() {</div><div class="line"><a name="l04543"></a><span class="lineno"> 4543</span>&#160;        <span class="keywordflow">return</span> params;</div><div class="line"><a name="l04544"></a><span class="lineno"> 4544</span>&#160;    }</div><div class="line"><a name="l04545"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#ac72ed377cf408274f15e280de3266044"> 4545</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_dropout_layer.html#ac72ed377cf408274f15e280de3266044">get_params_grad</a>() {</div><div class="line"><a name="l04546"></a><span class="lineno"> 4546</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l04547"></a><span class="lineno"> 4547</span>&#160;    }</div><div class="line"><a name="l04548"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a970a990edc47ed017ae845ed9fe1a430"> 4548</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_dropout_layer.html#a970a990edc47ed017ae845ed9fe1a430">regularize</a>() { }</div><div class="line"><a name="l04549"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#ac19d7798baf005d3729f620d1eb9a58b"> 4549</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1_dropout_layer.html#ac19d7798baf005d3729f620d1eb9a58b">get_regularization_penalty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04550"></a><span class="lineno"> 4550</span>&#160;        <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l04551"></a><span class="lineno"> 4551</span>&#160;    }</div><div class="line"><a name="l04552"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a21cafbb1c42e3fd63551e4056eaa9d8a"> 4552</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_dropout_layer.html#a21cafbb1c42e3fd63551e4056eaa9d8a">enforce_constraints</a>() { }</div><div class="line"><a name="l04553"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a0c833b2176304d5f975e7f66ac203d15"> 4553</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_dropout_layer.html#a0c833b2176304d5f975e7f66ac203d15">pass_forward</a>(<span class="keyword">typename</span> Base::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l04554"></a><span class="lineno"> 4554</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l04555"></a><span class="lineno"> 4555</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l04556"></a><span class="lineno"> 4556</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l04557"></a><span class="lineno"> 4557</span>&#160;            <span class="comment">// Inverted dropout.</span></div><div class="line"><a name="l04558"></a><span class="lineno"> 4558</span>&#160;            Scalar scaling_factor = (Scalar) 1 / (1 - dropout_prob + epsilon);</div><div class="line"><a name="l04559"></a><span class="lineno"> 4559</span>&#160;            dropout_mask = ((in.random() + in.constant(1)) / (Scalar) 2).unaryExpr([<span class="keyword">this</span>,scaling_factor](Scalar i) {</div><div class="line"><a name="l04560"></a><span class="lineno"> 4560</span>&#160;                <span class="keywordflow">return</span> (Scalar) (i &lt;= dropout_prob ? 0 : scaling_factor);</div><div class="line"><a name="l04561"></a><span class="lineno"> 4561</span>&#160;            });</div><div class="line"><a name="l04562"></a><span class="lineno"> 4562</span>&#160;            <span class="keywordflow">return</span> in * dropout_mask;</div><div class="line"><a name="l04563"></a><span class="lineno"> 4563</span>&#160;        }</div><div class="line"><a name="l04564"></a><span class="lineno"> 4564</span>&#160;        <span class="keywordflow">return</span> in;</div><div class="line"><a name="l04565"></a><span class="lineno"> 4565</span>&#160;    }</div><div class="line"><a name="l04566"></a><span class="lineno"><a class="line" href="classcattle_1_1_dropout_layer.html#a7d71b25a0789d9b8b852f9fdfd86f183"> 4566</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_dropout_layer.html#a7d71b25a0789d9b8b852f9fdfd86f183">pass_back</a>(<span class="keyword">typename</span> Base::Data out_grad) {</div><div class="line"><a name="l04567"></a><span class="lineno"> 4567</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l04568"></a><span class="lineno"> 4568</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; dropout_mask.dimension(0) == out_grad.dimension(0));</div><div class="line"><a name="l04569"></a><span class="lineno"> 4569</span>&#160;        <span class="keywordflow">if</span> (input_layer)</div><div class="line"><a name="l04570"></a><span class="lineno"> 4570</span>&#160;            <span class="keywordflow">return</span> <span class="keyword">typename</span> Base::Data();</div><div class="line"><a name="l04571"></a><span class="lineno"> 4571</span>&#160;        <span class="comment">// The derivative of the dropout function.</span></div><div class="line"><a name="l04572"></a><span class="lineno"> 4572</span>&#160;        <span class="keywordflow">return</span> out_grad * dropout_mask;</div><div class="line"><a name="l04573"></a><span class="lineno"> 4573</span>&#160;    }</div><div class="line"><a name="l04574"></a><span class="lineno"> 4574</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l04575"></a><span class="lineno"> 4575</span>&#160;    <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a> dims;</div><div class="line"><a name="l04576"></a><span class="lineno"> 4576</span>&#160;    <span class="keyword">const</span> Scalar dropout_prob;</div><div class="line"><a name="l04577"></a><span class="lineno"> 4577</span>&#160;    <span class="keyword">const</span> Scalar epsilon;</div><div class="line"><a name="l04578"></a><span class="lineno"> 4578</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l04579"></a><span class="lineno"> 4579</span>&#160;    <span class="keywordtype">bool</span> frozen;</div><div class="line"><a name="l04580"></a><span class="lineno"> 4580</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> params;</div><div class="line"><a name="l04581"></a><span class="lineno"> 4581</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> params_grad;</div><div class="line"><a name="l04582"></a><span class="lineno"> 4582</span>&#160;    <span class="comment">// Staged computation cache.</span></div><div class="line"><a name="l04583"></a><span class="lineno"> 4583</span>&#160;    <span class="keyword">typename</span> Base::Data dropout_mask;</div><div class="line"><a name="l04584"></a><span class="lineno"> 4584</span>&#160;};</div><div class="line"><a name="l04585"></a><span class="lineno"> 4585</span>&#160;<span class="preprocessor">#else</span></div><div class="line"><a name="l04586"></a><span class="lineno"> 4586</span>&#160;</div><div class="line"><a name="l04592"></a><span class="lineno"> 4592</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l04593"></a><span class="lineno"> 4593</span>&#160;<span class="keyword">class </span>DropoutLayer : <span class="keyword">public</span> Layer&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l04594"></a><span class="lineno"> 4594</span>&#160;    <span class="keyword">typedef</span> Layer&lt;Scalar,Rank&gt; Base;</div><div class="line"><a name="l04595"></a><span class="lineno"> 4595</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l04601"></a><span class="lineno"> 4601</span>&#160;    <span class="keyword">inline</span> DropoutLayer(<span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; dims, Scalar dropout_prob) :</div><div class="line"><a name="l04602"></a><span class="lineno"> 4602</span>&#160;                dims(dims),</div><div class="line"><a name="l04603"></a><span class="lineno"> 4603</span>&#160;                dropout_prob(dropout_prob),</div><div class="line"><a name="l04604"></a><span class="lineno"> 4604</span>&#160;                input_layer(false),</div><div class="line"><a name="l04605"></a><span class="lineno"> 4605</span>&#160;                frozen(false),</div><div class="line"><a name="l04606"></a><span class="lineno"> 4606</span>&#160;                ext_batch_dims(dims.template extend&lt;3 - Rank&gt;().template promote&lt;&gt;()),</div><div class="line"><a name="l04607"></a><span class="lineno"> 4607</span>&#160;                params(0, 0),</div><div class="line"><a name="l04608"></a><span class="lineno"> 4608</span>&#160;                params_grad(0, 0),</div><div class="line"><a name="l04609"></a><span class="lineno"> 4609</span>&#160;                reserve() {</div><div class="line"><a name="l04610"></a><span class="lineno"> 4610</span>&#160;        assert(dropout_prob &gt; 0 &amp;&amp; dropout_prob &lt;= 1 &amp;&amp;</div><div class="line"><a name="l04611"></a><span class="lineno"> 4611</span>&#160;                <span class="stringliteral">&quot;dropout probability must be greater than 0 and no greater than 1&quot;</span>);</div><div class="line"><a name="l04612"></a><span class="lineno"> 4612</span>&#160;    }</div><div class="line"><a name="l04613"></a><span class="lineno"> 4613</span>&#160;    <span class="keyword">inline</span> Base* clone()<span class="keyword"> const </span>{</div><div class="line"><a name="l04614"></a><span class="lineno"> 4614</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> DropoutLayer(*<span class="keyword">this</span>);</div><div class="line"><a name="l04615"></a><span class="lineno"> 4615</span>&#160;    }</div><div class="line"><a name="l04616"></a><span class="lineno"> 4616</span>&#160;    <span class="keyword">inline</span> Base* clone_with_shared_params() {</div><div class="line"><a name="l04617"></a><span class="lineno"> 4617</span>&#160;        <span class="keywordflow">return</span> clone();</div><div class="line"><a name="l04618"></a><span class="lineno"> 4618</span>&#160;    }</div><div class="line"><a name="l04619"></a><span class="lineno"> 4619</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Base&amp; get_params_owner()<span class="keyword"> const </span>{</div><div class="line"><a name="l04620"></a><span class="lineno"> 4620</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l04621"></a><span class="lineno"> 4621</span>&#160;    }</div><div class="line"><a name="l04622"></a><span class="lineno"> 4622</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; get_input_dims()<span class="keyword"> const </span>{</div><div class="line"><a name="l04623"></a><span class="lineno"> 4623</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l04624"></a><span class="lineno"> 4624</span>&#160;    }</div><div class="line"><a name="l04625"></a><span class="lineno"> 4625</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt;&amp; get_output_dims()<span class="keyword"> const </span>{</div><div class="line"><a name="l04626"></a><span class="lineno"> 4626</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l04627"></a><span class="lineno"> 4627</span>&#160;    }</div><div class="line"><a name="l04628"></a><span class="lineno"> 4628</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Matrix&lt;Scalar&gt;&amp; get_params()<span class="keyword"> const </span>{</div><div class="line"><a name="l04629"></a><span class="lineno"> 4629</span>&#160;        <span class="keywordflow">return</span> params_ref;</div><div class="line"><a name="l04630"></a><span class="lineno"> 4630</span>&#160;    }</div><div class="line"><a name="l04631"></a><span class="lineno"> 4631</span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> Matrix&lt;Scalar&gt;&amp; get_params_grad()<span class="keyword"> const </span>{</div><div class="line"><a name="l04632"></a><span class="lineno"> 4632</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l04633"></a><span class="lineno"> 4633</span>&#160;    }</div><div class="line"><a name="l04634"></a><span class="lineno"> 4634</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> is_frozen()<span class="keyword"> const </span>{</div><div class="line"><a name="l04635"></a><span class="lineno"> 4635</span>&#160;        <span class="keywordflow">return</span> frozen;</div><div class="line"><a name="l04636"></a><span class="lineno"> 4636</span>&#160;    }</div><div class="line"><a name="l04637"></a><span class="lineno"> 4637</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> set_frozen(<span class="keywordtype">bool</span> frozen) {</div><div class="line"><a name="l04638"></a><span class="lineno"> 4638</span>&#160;        this-&gt;frozen = frozen;</div><div class="line"><a name="l04639"></a><span class="lineno"> 4639</span>&#160;    }</div><div class="line"><a name="l04640"></a><span class="lineno"> 4640</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> init() { }</div><div class="line"><a name="l04641"></a><span class="lineno"> 4641</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l04642"></a><span class="lineno"> 4642</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> is_input_layer()<span class="keyword"> const </span>{</div><div class="line"><a name="l04643"></a><span class="lineno"> 4643</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l04644"></a><span class="lineno"> 4644</span>&#160;    }</div><div class="line"><a name="l04645"></a><span class="lineno"> 4645</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> set_input_layer(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l04646"></a><span class="lineno"> 4646</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l04647"></a><span class="lineno"> 4647</span>&#160;    }</div><div class="line"><a name="l04648"></a><span class="lineno"> 4648</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> empty_cache() {</div><div class="line"><a name="l04649"></a><span class="lineno"> 4649</span>&#160;        reserve = std::vector&lt;Scalar&gt;(0);</div><div class="line"><a name="l04650"></a><span class="lineno"> 4650</span>&#160;    }</div><div class="line"><a name="l04651"></a><span class="lineno"> 4651</span>&#160;    <span class="keyword">inline</span> Matrix&lt;Scalar&gt;&amp; get_params() {</div><div class="line"><a name="l04652"></a><span class="lineno"> 4652</span>&#160;        <span class="keywordflow">return</span> params;</div><div class="line"><a name="l04653"></a><span class="lineno"> 4653</span>&#160;    }</div><div class="line"><a name="l04654"></a><span class="lineno"> 4654</span>&#160;    <span class="keyword">inline</span> Matrix&lt;Scalar&gt;&amp; get_params_grad() {</div><div class="line"><a name="l04655"></a><span class="lineno"> 4655</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l04656"></a><span class="lineno"> 4656</span>&#160;    }</div><div class="line"><a name="l04657"></a><span class="lineno"> 4657</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> regularize() { }</div><div class="line"><a name="l04658"></a><span class="lineno"> 4658</span>&#160;    <span class="keyword">inline</span> Scalar get_regularization_penalty()<span class="keyword"> const </span>{</div><div class="line"><a name="l04659"></a><span class="lineno"> 4659</span>&#160;        <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l04660"></a><span class="lineno"> 4660</span>&#160;    }</div><div class="line"><a name="l04661"></a><span class="lineno"> 4661</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> enforce_constraints() { }</div><div class="line"><a name="l04662"></a><span class="lineno"> 4662</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data pass_forward(<span class="keyword">typename</span> Base::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l04663"></a><span class="lineno"> 4663</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l04664"></a><span class="lineno"> 4664</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l04665"></a><span class="lineno"> 4665</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l04666"></a><span class="lineno"> 4666</span>&#160;            ext_batch_dims[0] = in.dimension(0);</div><div class="line"><a name="l04667"></a><span class="lineno"> 4667</span>&#160;            <span class="keyword">typename</span> Base::Data out(in.dimensions());</div><div class="line"><a name="l04668"></a><span class="lineno"> 4668</span>&#160;            internal::CuDNNHandle&lt;Scalar&gt;::get_instance().dropout_fwd(in.data(), ext_batch_dims, dropout_prob,</div><div class="line"><a name="l04669"></a><span class="lineno"> 4669</span>&#160;                    out.data(), reserve);</div><div class="line"><a name="l04670"></a><span class="lineno"> 4670</span>&#160;            <span class="keywordflow">return</span> out;</div><div class="line"><a name="l04671"></a><span class="lineno"> 4671</span>&#160;        }</div><div class="line"><a name="l04672"></a><span class="lineno"> 4672</span>&#160;        <span class="keywordflow">return</span> in;</div><div class="line"><a name="l04673"></a><span class="lineno"> 4673</span>&#160;    }</div><div class="line"><a name="l04674"></a><span class="lineno"> 4674</span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data pass_back(<span class="keyword">typename</span> Base::Data out_grad) {</div><div class="line"><a name="l04675"></a><span class="lineno"> 4675</span>&#160;        assert((Dimensions&lt;std::size_t,Base::DATA_RANK&gt;(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l04676"></a><span class="lineno"> 4676</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; ext_batch_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l04677"></a><span class="lineno"> 4677</span>&#160;        <span class="keywordflow">if</span> (input_layer)</div><div class="line"><a name="l04678"></a><span class="lineno"> 4678</span>&#160;            <span class="keywordflow">return</span> <span class="keyword">typename</span> Base::Data();</div><div class="line"><a name="l04679"></a><span class="lineno"> 4679</span>&#160;        <span class="keyword">typename</span> Base::Data prev_out_grad(out_grad.dimensions());</div><div class="line"><a name="l04680"></a><span class="lineno"> 4680</span>&#160;        internal::CuDNNHandle&lt;Scalar&gt;::get_instance().dropout_bwd(out_grad.data(), reserve, ext_batch_dims,</div><div class="line"><a name="l04681"></a><span class="lineno"> 4681</span>&#160;                dropout_prob, prev_out_grad.data());</div><div class="line"><a name="l04682"></a><span class="lineno"> 4682</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l04683"></a><span class="lineno"> 4683</span>&#160;    }</div><div class="line"><a name="l04684"></a><span class="lineno"> 4684</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l04685"></a><span class="lineno"> 4685</span>&#160;    <span class="keyword">const</span> Dimensions&lt;std::size_t,Rank&gt; dims;</div><div class="line"><a name="l04686"></a><span class="lineno"> 4686</span>&#160;    <span class="keyword">const</span> Scalar dropout_prob;</div><div class="line"><a name="l04687"></a><span class="lineno"> 4687</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l04688"></a><span class="lineno"> 4688</span>&#160;    <span class="keywordtype">bool</span> frozen;</div><div class="line"><a name="l04689"></a><span class="lineno"> 4689</span>&#160;    Matrix&lt;Scalar&gt; params;</div><div class="line"><a name="l04690"></a><span class="lineno"> 4690</span>&#160;    Matrix&lt;Scalar&gt; params_grad;</div><div class="line"><a name="l04691"></a><span class="lineno"> 4691</span>&#160;    std::array&lt;std::size_t,4&gt; ext_batch_dims;</div><div class="line"><a name="l04692"></a><span class="lineno"> 4692</span>&#160;    std::vector&lt;Scalar&gt; reserve;</div><div class="line"><a name="l04693"></a><span class="lineno"> 4693</span>&#160;};</div><div class="line"><a name="l04694"></a><span class="lineno"> 4694</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l04695"></a><span class="lineno"> 4695</span>&#160;</div><div class="line"><a name="l04700"></a><span class="lineno"> 4700</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l04701"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html"> 4701</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_reshape_layer.html">ReshapeLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l04702"></a><span class="lineno"> 4702</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l04703"></a><span class="lineno"> 4703</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,Rank + 1&gt; RankwiseArray;</div><div class="line"><a name="l04704"></a><span class="lineno"> 4704</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l04710"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a81a8592dbe5a4d75a3ba4575780b0ac2"> 4710</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_reshape_layer.html#a81a8592dbe5a4d75a3ba4575780b0ac2">ReshapeLayer</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; input_dims,</div><div class="line"><a name="l04711"></a><span class="lineno"> 4711</span>&#160;            <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; output_dims) :</div><div class="line"><a name="l04712"></a><span class="lineno"> 4712</span>&#160;                input_dims(input_dims),</div><div class="line"><a name="l04713"></a><span class="lineno"> 4713</span>&#160;                output_dims(output_dims),</div><div class="line"><a name="l04714"></a><span class="lineno"> 4714</span>&#160;                input_layer(false),</div><div class="line"><a name="l04715"></a><span class="lineno"> 4715</span>&#160;                frozen(false),</div><div class="line"><a name="l04716"></a><span class="lineno"> 4716</span>&#160;                input_conversion_dims(output_dims.template promote&lt;&gt;()),</div><div class="line"><a name="l04717"></a><span class="lineno"> 4717</span>&#160;                output_conversion_dims(input_dims.template promote&lt;&gt;()),</div><div class="line"><a name="l04718"></a><span class="lineno"> 4718</span>&#160;                params(0, 0),</div><div class="line"><a name="l04719"></a><span class="lineno"> 4719</span>&#160;                params_grad(0, 0) {</div><div class="line"><a name="l04720"></a><span class="lineno"> 4720</span>&#160;        assert(input_dims.<a class="code" href="classcattle_1_1_dim_expression.html#adae8f2ea4e6a29d65b85ea0aa2d48bd1">get_volume</a>() == output_dims.<a class="code" href="classcattle_1_1_dim_expression.html#adae8f2ea4e6a29d65b85ea0aa2d48bd1">get_volume</a>());</div><div class="line"><a name="l04721"></a><span class="lineno"> 4721</span>&#160;    }</div><div class="line"><a name="l04722"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#ac07e30bf427e0fdf40265ac8ae66cdc3"> 4722</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_reshape_layer.html#ac07e30bf427e0fdf40265ac8ae66cdc3">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04723"></a><span class="lineno"> 4723</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_reshape_layer.html">ReshapeLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l04724"></a><span class="lineno"> 4724</span>&#160;    }</div><div class="line"><a name="l04725"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a1ffb24e855f633d0f5e8cc14e108d9fc"> 4725</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_reshape_layer.html#a1ffb24e855f633d0f5e8cc14e108d9fc">clone_with_shared_params</a>() {</div><div class="line"><a name="l04726"></a><span class="lineno"> 4726</span>&#160;        <span class="keywordflow">return</span> clone();</div><div class="line"><a name="l04727"></a><span class="lineno"> 4727</span>&#160;    }</div><div class="line"><a name="l04728"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#ac348f24763e65ede1ae53f024b000c18"> 4728</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>&amp; <a class="code" href="classcattle_1_1_reshape_layer.html#ac348f24763e65ede1ae53f024b000c18">get_params_owner</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04729"></a><span class="lineno"> 4729</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l04730"></a><span class="lineno"> 4730</span>&#160;    }</div><div class="line"><a name="l04731"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a9816572e8dcfafa764bbad24e7dba8f4"> 4731</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_reshape_layer.html#a9816572e8dcfafa764bbad24e7dba8f4">get_input_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04732"></a><span class="lineno"> 4732</span>&#160;        <span class="keywordflow">return</span> input_dims;</div><div class="line"><a name="l04733"></a><span class="lineno"> 4733</span>&#160;    }</div><div class="line"><a name="l04734"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a2817da84a7102af5c1f538f4a1a60664"> 4734</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a>&amp; <a class="code" href="classcattle_1_1_reshape_layer.html#a2817da84a7102af5c1f538f4a1a60664">get_output_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04735"></a><span class="lineno"> 4735</span>&#160;        <span class="keywordflow">return</span> output_dims;</div><div class="line"><a name="l04736"></a><span class="lineno"> 4736</span>&#160;    }</div><div class="line"><a name="l04737"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#af7d261c1deedb980914a51c20070af32"> 4737</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_reshape_layer.html#af7d261c1deedb980914a51c20070af32">get_params</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04738"></a><span class="lineno"> 4738</span>&#160;        <span class="keywordflow">return</span> params;</div><div class="line"><a name="l04739"></a><span class="lineno"> 4739</span>&#160;    }</div><div class="line"><a name="l04740"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a26863f25c7ee95558db07defb108e672"> 4740</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_reshape_layer.html#a26863f25c7ee95558db07defb108e672">get_params_grad</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04741"></a><span class="lineno"> 4741</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l04742"></a><span class="lineno"> 4742</span>&#160;    }</div><div class="line"><a name="l04743"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a7f63fcaa9fa3a39fae777d3e7a513b4a"> 4743</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_reshape_layer.html#a7f63fcaa9fa3a39fae777d3e7a513b4a">is_frozen</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04744"></a><span class="lineno"> 4744</span>&#160;        <span class="keywordflow">return</span> frozen;</div><div class="line"><a name="l04745"></a><span class="lineno"> 4745</span>&#160;    }</div><div class="line"><a name="l04746"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#ab5d5a62101f9dfc7402d7b4b1c216f65"> 4746</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_reshape_layer.html#ab5d5a62101f9dfc7402d7b4b1c216f65">set_frozen</a>(<span class="keywordtype">bool</span> frozen) {</div><div class="line"><a name="l04747"></a><span class="lineno"> 4747</span>&#160;        this-&gt;frozen = frozen;</div><div class="line"><a name="l04748"></a><span class="lineno"> 4748</span>&#160;    }</div><div class="line"><a name="l04749"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a496cc9b192875d633554b44b9866fd6b"> 4749</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_reshape_layer.html#a496cc9b192875d633554b44b9866fd6b">init</a>() { }</div><div class="line"><a name="l04750"></a><span class="lineno"> 4750</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l04751"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#af25577fd157dbd6a8ddd05d3abdf65ed"> 4751</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_reshape_layer.html#af25577fd157dbd6a8ddd05d3abdf65ed">is_input_layer</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04752"></a><span class="lineno"> 4752</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l04753"></a><span class="lineno"> 4753</span>&#160;    }</div><div class="line"><a name="l04754"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a57c06bd60a7784adde787012e2b78178"> 4754</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_reshape_layer.html#a57c06bd60a7784adde787012e2b78178">set_input_layer</a>(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l04755"></a><span class="lineno"> 4755</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l04756"></a><span class="lineno"> 4756</span>&#160;    }</div><div class="line"><a name="l04757"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#aa2e932dd174e1511ae1b57cc63c7e8ca"> 4757</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_reshape_layer.html#aa2e932dd174e1511ae1b57cc63c7e8ca">empty_cache</a>() { }</div><div class="line"><a name="l04758"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a464493846ede7742da92224914855d24"> 4758</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_reshape_layer.html#a464493846ede7742da92224914855d24">get_params</a>() {</div><div class="line"><a name="l04759"></a><span class="lineno"> 4759</span>&#160;        <span class="keywordflow">return</span> params;</div><div class="line"><a name="l04760"></a><span class="lineno"> 4760</span>&#160;    }</div><div class="line"><a name="l04761"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a75bbccc82caf137479054b0bd926602a"> 4761</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; <a class="code" href="classcattle_1_1_reshape_layer.html#a75bbccc82caf137479054b0bd926602a">get_params_grad</a>() {</div><div class="line"><a name="l04762"></a><span class="lineno"> 4762</span>&#160;        <span class="keywordflow">return</span> params_grad;</div><div class="line"><a name="l04763"></a><span class="lineno"> 4763</span>&#160;    }</div><div class="line"><a name="l04764"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#acfcf2228f1c0ce3292692f8eb48b7444"> 4764</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_reshape_layer.html#acfcf2228f1c0ce3292692f8eb48b7444">regularize</a>() { }</div><div class="line"><a name="l04765"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#ac7e767125736b077d6d225cfb3ab1c5d"> 4765</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1_reshape_layer.html#ac7e767125736b077d6d225cfb3ab1c5d">get_regularization_penalty</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l04766"></a><span class="lineno"> 4766</span>&#160;        <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l04767"></a><span class="lineno"> 4767</span>&#160;    }</div><div class="line"><a name="l04768"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a023390583dcb27e6d839384a2c67b70a"> 4768</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_reshape_layer.html#a023390583dcb27e6d839384a2c67b70a">enforce_constraints</a>() { }</div><div class="line"><a name="l04769"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#ad90d03809c1a76aee78463a25c7724a3"> 4769</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_reshape_layer.html#ad90d03809c1a76aee78463a25c7724a3">pass_forward</a>(<span class="keyword">typename</span> Base::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l04770"></a><span class="lineno"> 4770</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == input_dims);</div><div class="line"><a name="l04771"></a><span class="lineno"> 4771</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l04772"></a><span class="lineno"> 4772</span>&#160;        input_conversion_dims[0] = in.dimension(0);</div><div class="line"><a name="l04773"></a><span class="lineno"> 4773</span>&#160;        <span class="keywordflow">return</span> in.reshape(input_conversion_dims);</div><div class="line"><a name="l04774"></a><span class="lineno"> 4774</span>&#160;    }</div><div class="line"><a name="l04775"></a><span class="lineno"><a class="line" href="classcattle_1_1_reshape_layer.html#a9ce0f661d35ef7efa79885e76dec673a"> 4775</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_reshape_layer.html#a9ce0f661d35ef7efa79885e76dec673a">pass_back</a>(<span class="keyword">typename</span> Base::Data out_grad) {</div><div class="line"><a name="l04776"></a><span class="lineno"> 4776</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == output_dims);</div><div class="line"><a name="l04777"></a><span class="lineno"> 4777</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; input_conversion_dims[0] == out_grad.dimension(0));</div><div class="line"><a name="l04778"></a><span class="lineno"> 4778</span>&#160;        output_conversion_dims[0] = input_conversion_dims[0];</div><div class="line"><a name="l04779"></a><span class="lineno"> 4779</span>&#160;        <span class="keywordflow">return</span> out_grad.reshape(output_conversion_dims);</div><div class="line"><a name="l04780"></a><span class="lineno"> 4780</span>&#160;    }</div><div class="line"><a name="l04781"></a><span class="lineno"> 4781</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l04782"></a><span class="lineno"> 4782</span>&#160;    <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a> input_dims;</div><div class="line"><a name="l04783"></a><span class="lineno"> 4783</span>&#160;    <span class="keyword">const</span> <a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Rank&gt;</a> output_dims;</div><div class="line"><a name="l04784"></a><span class="lineno"> 4784</span>&#160;    RankwiseArray input_conversion_dims;</div><div class="line"><a name="l04785"></a><span class="lineno"> 4785</span>&#160;    RankwiseArray output_conversion_dims;</div><div class="line"><a name="l04786"></a><span class="lineno"> 4786</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l04787"></a><span class="lineno"> 4787</span>&#160;    <span class="keywordtype">bool</span> frozen;</div><div class="line"><a name="l04788"></a><span class="lineno"> 4788</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> params;</div><div class="line"><a name="l04789"></a><span class="lineno"> 4789</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> params_grad;</div><div class="line"><a name="l04790"></a><span class="lineno"> 4790</span>&#160;};</div><div class="line"><a name="l04791"></a><span class="lineno"> 4791</span>&#160;</div><div class="line"><a name="l04792"></a><span class="lineno"> 4792</span>&#160;} <span class="comment">/* namespace cattle */</span></div><div class="line"><a name="l04793"></a><span class="lineno"> 4793</span>&#160;</div><div class="line"><a name="l04794"></a><span class="lineno"> 4794</span>&#160;<span class="preprocessor">#endif </span><span class="comment">/* CATTL3_LAYER_H_ */</span><span class="preprocessor"></span></div><div class="ttc" id="classcattle_1_1_mean_pool_layer_base_html"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_base.html">cattle::MeanPoolLayerBase</a></div><div class="ttdoc">An abstract class template representing a pooling layer that reduces patches of the input by taking t...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2934</div></div>
<div class="ttc" id="classcattle_1_1_p_re_l_u_activation_layer_html_a22b686f15e500942fb894063ae65bda8"><div class="ttname"><a href="classcattle_1_1_p_re_l_u_activation_layer.html#a22b686f15e500942fb894063ae65bda8">cattle::PReLUActivationLayer::enforce_constraints</a></div><div class="ttdeci">void enforce_constraints()</div><div class="ttdoc">It applies constraints such as max-norm to the parameters of the layer (if applicable). </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2550</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_a245b781c1e5ae253816389c2091565a1"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#a245b781c1e5ae253816389c2091565a1">cattle::ActivationLayer::get_regularization_penalty</a></div><div class="ttdeci">Scalar get_regularization_penalty() const</div><div class="ttdoc">It calculates the regularization penalty of the layer&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1695</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_base_html_afd721c979e18de71d6b2a7dd6a3d5030"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_base.html#afd721c979e18de71d6b2a7dd6a3d5030">cattle::ConvKernelLayerBase::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:607</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a7f63fcaa9fa3a39fae777d3e7a513b4a"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a7f63fcaa9fa3a39fae777d3e7a513b4a">cattle::ReshapeLayer::is_frozen</a></div><div class="ttdeci">bool is_frozen() const</div><div class="ttdoc">It determines whether the parameters of the layer, if there are any, are to be updated during optimiz...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4743</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a6aebaf7cd158c35983c27f691c80a5bd"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a6aebaf7cd158c35983c27f691c80a5bd">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::set_input_layer</a></div><div class="ttdeci">void set_input_layer(bool input_layer)</div><div class="ttdoc">Sets this instance&amp;#39;s input layer status to the given value. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4117</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_a30f2215af291a00e008fa09de8a32cf7"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#a30f2215af291a00e008fa09de8a32cf7">cattle::ActivationLayer::get_output_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_output_dims() const</div><div class="ttdoc">A simple constant getter method for the output dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1631</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_aafc6601f084c42c5b1d759b305066261"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#aafc6601f084c42c5b1d759b305066261">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::is_frozen</a></div><div class="ttdeci">bool is_frozen() const</div><div class="ttdoc">It determines whether the parameters of the layer, if there are any, are to be updated during optimiz...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4076</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_aae8baf56035b9c2130eec90881e27bad"><div class="ttname"><a href="classcattle_1_1_layer.html#aae8baf56035b9c2130eec90881e27bad">cattle::Layer::init</a></div><div class="ttdeci">virtual void init()=0</div><div class="ttdoc">It initializes the layer and its parameters. </div></div>
<div class="ttc" id="classcattle_1_1_tanh_activation_layer_html_a67d44e760962f78b74c182b1b1cf528d"><div class="ttname"><a href="classcattle_1_1_tanh_activation_layer.html#a67d44e760962f78b74c182b1b1cf528d">cattle::TanhActivationLayer::TanhActivationLayer</a></div><div class="ttdeci">TanhActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1928</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_ae1d090be4a0c212daaf625f5acbd9f22"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#ae1d090be4a0c212daaf625f5acbd9f22">cattle::DropoutLayer::set_input_layer</a></div><div class="ttdeci">void set_input_layer(bool input_layer)</div><div class="ttdoc">Sets this instance&amp;#39;s input layer status to the given value. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4536</div></div>
<div class="ttc" id="classcattle_1_1internal_1_1_cu_b_l_a_s_handle_html_aeed972c3e81eab21836a014787d8baf6"><div class="ttname"><a href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#aeed972c3e81eab21836a014787d8baf6">cattle::internal::CuBLASHandle::get_instance</a></div><div class="ttdeci">static CuBLASHandle &amp; get_instance()</div><div class="ttdef"><b>Definition:</b> CuBLASHandle.hpp:59</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4_html_adf15353dcff3915634b18f3bbd533c6c"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#adf15353dcff3915634b18f3bbd533c6c">cattle::MeanPoolLayer&lt; Scalar, 2 &gt;::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3024</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a71f24afcc944fab3b3243850af0b6972"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a71f24afcc944fab3b3243850af0b6972">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::enforce_constraints</a></div><div class="ttdeci">void enforce_constraints()</div><div class="ttdoc">It applies constraints such as max-norm to the parameters of the layer (if applicable). </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4137</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a683f9b67748863329938da07e86ecd8c"><div class="ttname"><a href="classcattle_1_1_layer.html#a683f9b67748863329938da07e86ecd8c">cattle::Layer::get_params_owner</a></div><div class="ttdeci">virtual const Layer&lt; Scalar, Rank &gt; &amp; get_params_owner() const =0</div><div class="ttdoc">It returns a reference to the layer owning the parameters used. </div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a970a990edc47ed017ae845ed9fe1a430"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a970a990edc47ed017ae845ed9fe1a430">cattle::DropoutLayer::regularize</a></div><div class="ttdeci">void regularize()</div><div class="ttdoc">It computes the derivative of the regularization function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4548</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4_html_a307c7269d977540fcfb070f1b9376cf6"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#a307c7269d977540fcfb070f1b9376cf6">cattle::DeconvKernelLayer&lt; Scalar, 1 &gt;::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1593</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_ad64fb5495e73699d97714883a77056e8"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#ad64fb5495e73699d97714883a77056e8">cattle::BatchNormLayer::get_params_owner</a></div><div class="ttdeci">const Base &amp; get_params_owner() const</div><div class="ttdoc">It returns a reference to the layer owning the parameters used. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3754</div></div>
<div class="ttc" id="classcattle_1_1_p_re_l_u_activation_layer_html_a822da21b34e644180efda947c185e13e"><div class="ttname"><a href="classcattle_1_1_p_re_l_u_activation_layer.html#a822da21b34e644180efda947c185e13e">cattle::PReLUActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2523</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4_html"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html">cattle::DeconvKernelLayer&lt; Scalar, 2 &gt;</a></div><div class="ttdoc">A class template for a transposed 2D convolutional layer operating on rank-2 data batches (rank-3 ten...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1485</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a86e85013180c35664a142a1e0e6acae5"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a86e85013180c35664a142a1e0e6acae5">cattle::BroadcastLayer::get_regularization_penalty</a></div><div class="ttdeci">Scalar get_regularization_penalty() const</div><div class="ttdoc">It calculates the regularization penalty of the layer&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3601</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a5920113d2477183eb7f64a5e92fa2ab6"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a5920113d2477183eb7f64a5e92fa2ab6">cattle::PoolLayer::get_params_owner</a></div><div class="ttdeci">const Base &amp; get_params_owner() const</div><div class="ttdoc">It returns a reference to the layer owning the parameters used. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2762</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a023390583dcb27e6d839384a2c67b70a"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a023390583dcb27e6d839384a2c67b70a">cattle::ReshapeLayer::enforce_constraints</a></div><div class="ttdeci">void enforce_constraints()</div><div class="ttdoc">It applies constraints such as max-norm to the parameters of the layer (if applicable). </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4768</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_html_a781eb0a003bcd29b85ad6a98a1bdfb46"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer.html#a781eb0a003bcd29b85ad6a98a1bdfb46">cattle::DeconvKernelLayer::clone_with_shared_params</a></div><div class="ttdeci">Root * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1455</div></div>
<div class="ttc" id="classcattle_1_1_tanh_activation_layer_html_a8376f4a0a7162753dafa16f5c10bb220"><div class="ttname"><a href="classcattle_1_1_tanh_activation_layer.html#a8376f4a0a7162753dafa16f5c10bb220">cattle::TanhActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1937</div></div>
<div class="ttc" id="classcattle_1_1_p_re_l_u_activation_layer_html_a2c4c775a8f711ecce2636d71b4d31c77"><div class="ttname"><a href="classcattle_1_1_p_re_l_u_activation_layer.html#a2c4c775a8f711ecce2636d71b4d31c77">cattle::PReLUActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2557</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4_html_a01a4b38bcf4efb0af6ef29f63ced044a"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#a01a4b38bcf4efb0af6ef29f63ced044a">cattle::MaxPoolLayer&lt; Scalar, 1 &gt;::MaxPoolLayer</a></div><div class="ttdeci">MaxPoolLayer(const Dimensions&lt; std::size_t, 1 &gt; &amp;input_dims, std::size_t receptor_length=2, std::size_t stride=2)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3262</div></div>
<div class="ttc" id="classcattle_1_1_swish_activation_layer_html_af2792078dedd9be1de647c1998f9c75e"><div class="ttname"><a href="classcattle_1_1_swish_activation_layer.html#af2792078dedd9be1de647c1998f9c75e">cattle::SwishActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2620</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_html"><div class="ttname"><a href="classcattle_1_1_max_pool_layer.html">cattle::MaxPoolLayer</a></div><div class="ttdoc">A class template representing a 2D max pooling layer operating on rank-3 data. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3160</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_ab38d6acf3933fb2ac0c3e33bb15405ab"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#ab38d6acf3933fb2ac0c3e33bb15405ab">cattle::ActivationLayer::get_params</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params() const</div><div class="ttdoc">It returns a constant reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1634</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4_html_a062ba6c4dafdaf89f81fbfbdeeb42a39"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a062ba6c4dafdaf89f81fbfbdeeb42a39">cattle::ConvKernelLayer&lt; Scalar, 2 &gt;::ConvKernelLayer</a></div><div class="ttdeci">ConvKernelLayer(const Dimensions&lt; std::size_t, 2 &gt; &amp;input_dims, std::size_t filters, WeightInitSharedPtr&lt; Scalar &gt; weight_init, ParamRegSharedPtr&lt; Scalar &gt; weight_reg=Root::NO_PARAM_REG, std::size_t receptor_height=3, std::size_t receptor_width=3, std::size_t vertical_padding=1, std::size_t horizontal_padding=1, std::size_t vertical_stride=1, std::size_t horizontal_stride=1, std::size_t vertical_dilation=0, std::size_t horizontal_dilation=0, Scalar max_norm_constraint=0)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1027</div></div>
<div class="ttc" id="classcattle_1_1_dense_kernel_layer_html_ac70aa473ee0b2cd7c18a4575dcadaa0e"><div class="ttname"><a href="classcattle_1_1_dense_kernel_layer.html#ac70aa473ee0b2cd7c18a4575dcadaa0e">cattle::DenseKernelLayer::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:443</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_ac99f3186190c5d1d61e26e05427eb5df"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#ac99f3186190c5d1d61e26e05427eb5df">cattle::PoolLayer::set_frozen</a></div><div class="ttdeci">void set_frozen(bool frozen)</div><div class="ttdoc">It sets whether the parameters of the layer should not be updated during optimization. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2780</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_html_af51464d25c72c3495f0f39ca43322134"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer.html#af51464d25c72c3495f0f39ca43322134">cattle::MeanPoolLayer::MeanPoolLayer</a></div><div class="ttdeci">MeanPoolLayer(const Dimensions&lt; std::size_t, 3 &gt; &amp;input_dims, std::size_t receptor_height=2, std::size_t receptor_width=2, std::size_t vertical_stride=2, std::size_t horizontal_stride=2)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2975</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4_html"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html">cattle::ConvKernelLayer&lt; Scalar, 1 &gt;</a></div><div class="ttdoc">A class template for a 1D convolutional layer operating on rank-1 data batches (rank-2 tensors)...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1072</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a60fbc161deece174499e4be12b730255"><div class="ttname"><a href="classcattle_1_1_layer.html#a60fbc161deece174499e4be12b730255">cattle::Layer::get_params_grad</a></div><div class="ttdeci">virtual const Matrix&lt; Scalar &gt; &amp; get_params_grad() const =0</div><div class="ttdoc">It returns a constant reference to the gradient of the learnable parameters of the layer...</div></div>
<div class="ttc" id="classcattle_1_1_softplus_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_softplus_activation_layer.html">cattle::SoftplusActivationLayer</a></div><div class="ttdoc">A class template representing a softplus activation function layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2055</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a44310d6481f10b0ff302979a51b38a1e"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a44310d6481f10b0ff302979a51b38a1e">cattle::BroadcastLayer::clone</a></div><div class="ttdeci">Base * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3558</div></div>
<div class="ttc" id="classcattle_1_1_p_swish_activation_layer_html_a5fb5bc049a3bbb788ad362ae790c4134"><div class="ttname"><a href="classcattle_1_1_p_swish_activation_layer.html#a5fb5bc049a3bbb788ad362ae790c4134">cattle::PSwishActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2697</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_aee201eb78f434c69319f42a7645081c8"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#aee201eb78f434c69319f42a7645081c8">cattle::ActivationLayer::set_frozen</a></div><div class="ttdeci">void set_frozen(bool frozen)</div><div class="ttdoc">It sets whether the parameters of the layer should not be updated during optimization. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1643</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_ac554223ce79c3d18511c5ad9c3c95101"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#ac554223ce79c3d18511c5ad9c3c95101">cattle::PoolLayer::get_params_grad</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params_grad()</div><div class="ttdoc">It returns a reference to the gradient of the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2844</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_a08d25e205022e91c9d13db75fe1babe1"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#a08d25e205022e91c9d13db75fe1babe1">cattle::KernelLayer::get_params_owner</a></div><div class="ttdeci">const Base &amp; get_params_owner() const</div><div class="ttdoc">It returns a reference to the layer owning the parameters used. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:291</div></div>
<div class="ttc" id="classcattle_1_1_dense_kernel_layer_html_a89706a4d8b43b46dd3df65f2c0340969"><div class="ttname"><a href="classcattle_1_1_dense_kernel_layer.html#a89706a4d8b43b46dd3df65f2c0340969">cattle::DenseKernelLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:459</div></div>
<div class="ttc" id="classcattle_1_1_tanh_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_tanh_activation_layer.html">cattle::TanhActivationLayer</a></div><div class="ttdoc">A class template representing a hyperbolic tangent activation function layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1921</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_a08946304d56287db036990d9d890f18e"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#a08946304d56287db036990d9d890f18e">cattle::ActivationLayer::get_params_grad</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params_grad() const</div><div class="ttdoc">It returns a constant reference to the gradient of the learnable parameters of the layer...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1637</div></div>
<div class="ttc" id="classcattle_1_1_e_l_u_activation_layer_html_aa8542434a8430319aaa149363151e777"><div class="ttname"><a href="classcattle_1_1_e_l_u_activation_layer.html#aa8542434a8430319aaa149363151e777">cattle::ELUActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2385</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_html_a50a2546e78f1e39a9fef5fcc4dbc10ca"><div class="ttname"><a href="classcattle_1_1_max_pool_layer.html#a50a2546e78f1e39a9fef5fcc4dbc10ca">cattle::MaxPoolLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3188</div></div>
<div class="ttc" id="classcattle_1_1_dense_kernel_layer_html_a38cac34fd04b0cde05f4f803d5aac5c1"><div class="ttname"><a href="classcattle_1_1_dense_kernel_layer.html#a38cac34fd04b0cde05f4f803d5aac5c1">cattle::DenseKernelLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:471</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_ac454d37d09cc063531c2e750f45cf511"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#ac454d37d09cc063531c2e750f45cf511">cattle::BroadcastLayer::set_input_layer</a></div><div class="ttdeci">void set_input_layer(bool input_layer)</div><div class="ttdoc">Sets this instance&amp;#39;s input layer status to the given value. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3590</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a7e23442f814d994e2989724901001202"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a7e23442f814d994e2989724901001202">cattle::BatchNormLayer::clone</a></div><div class="ttdeci">Base * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3748</div></div>
<div class="ttc" id="namespacecattle_html_a96574a467e593e2c62c432b0c8ec8349"><div class="ttname"><a href="namespacecattle.html#a96574a467e593e2c62c432b0c8ec8349">cattle::WeightInitSharedPtr</a></div><div class="ttdeci">std::shared_ptr&lt; WeightInitialization&lt; Scalar &gt; &gt; WeightInitSharedPtr</div><div class="ttdoc">An alias for a shared pointer to a WeightInitialization implementation instance of an arbitrary scala...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:50</div></div>
<div class="ttc" id="classcattle_1_1_leaky_re_l_u_activation_layer_html_ab2363872da292de34c35c3983d5b97ee"><div class="ttname"><a href="classcattle_1_1_leaky_re_l_u_activation_layer.html#ab2363872da292de34c35c3983d5b97ee">cattle::LeakyReLUActivationLayer::LeakyReLUActivationLayer</a></div><div class="ttdeci">LeakyReLUActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims, Scalar alpha=1e-1)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2329</div></div>
<div class="ttc" id="namespacecattle_html_a23ebf4fefd4f6b9dc0cd34afb1ce1b65"><div class="ttname"><a href="namespacecattle.html#a23ebf4fefd4f6b9dc0cd34afb1ce1b65">cattle::RowVector</a></div><div class="ttdeci">Eigen::Matrix&lt; Scalar, 1, Eigen::Dynamic, Eigen::RowMajor, 1, Eigen::Dynamic &gt; RowVector</div><div class="ttdoc">An alias for a single row matrix of an arbitrary scalar type. </div><div class="ttdef"><b>Definition:</b> EigenProxy.hpp:28</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a3ba02f76506a7f8a72f44be78693209e"><div class="ttname"><a href="classcattle_1_1_layer.html#a3ba02f76506a7f8a72f44be78693209e">cattle::Layer::is_parametric</a></div><div class="ttdeci">bool is_parametric() const</div><div class="ttdoc">A method that returns whether the layer has parameters that can be learned. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:162</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_html_a91a604342f478507b3337fe85ba1a2bb"><div class="ttname"><a href="classcattle_1_1_max_pool_layer.html#a91a604342f478507b3337fe85ba1a2bb">cattle::MaxPoolLayer::MaxPoolLayer</a></div><div class="ttdeci">MaxPoolLayer(const Dimensions&lt; std::size_t, 3 &gt; &amp;input_dims, std::size_t receptor_height=2, std::size_t receptor_width=2, std::size_t vertical_stride=2, std::size_t horizontal_stride=2)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3174</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a3de931b84f08ff85ecaa75c3c6ffcbf0"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a3de931b84f08ff85ecaa75c3c6ffcbf0">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_input_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_input_dims() const</div><div class="ttdoc">A simple constant getter method for the input dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4064</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a26f50624ba25185ae1c9a7c855ffc0d6"><div class="ttname"><a href="classcattle_1_1_layer.html#a26f50624ba25185ae1c9a7c855ffc0d6">cattle::Layer::get_output_dims</a></div><div class="ttdeci">virtual const Dimensions&lt; std::size_t, Rank &gt; &amp; get_output_dims() const =0</div><div class="ttdoc">A simple constant getter method for the output dimensionality of the layer. </div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_af9822a94073cb72e2db4de62c2126d54"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#af9822a94073cb72e2db4de62c2126d54">cattle::ActivationLayer::get_params_grad</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params_grad()</div><div class="ttdoc">It returns a reference to the gradient of the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1691</div></div>
<div class="ttc" id="classcattle_1_1_p_re_l_u_activation_layer_html_aea1064a99c89f7c06a7deaf0b87cb8a9"><div class="ttname"><a href="classcattle_1_1_p_re_l_u_activation_layer.html#aea1064a99c89f7c06a7deaf0b87cb8a9">cattle::PReLUActivationLayer::get_regularization_penalty</a></div><div class="ttdeci">Scalar get_regularization_penalty() const</div><div class="ttdoc">It calculates the regularization penalty of the layer&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2547</div></div>
<div class="ttc" id="classcattle_1_1_softmax_activation_layer_html_a8ccc8f03783ec2791aabf328ebcc855e"><div class="ttname"><a href="classcattle_1_1_softmax_activation_layer.html#a8ccc8f03783ec2791aabf328ebcc855e">cattle::SoftmaxActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2136</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4_html_abf3096d94719bacc657cca0fcad1afb4"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#abf3096d94719bacc657cca0fcad1afb4">cattle::MaxPoolLayer&lt; Scalar, 2 &gt;::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3221</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html"><div class="ttname"><a href="classcattle_1_1_pool_layer.html">cattle::PoolLayer</a></div><div class="ttdoc">An abstract base class template representing a pooling layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2755</div></div>
<div class="ttc" id="classcattle_1_1_binary_step_activation_layer_html_af7dcd32d6982b8405bae6f25a2859e62"><div class="ttname"><a href="classcattle_1_1_binary_step_activation_layer.html#af7dcd32d6982b8405bae6f25a2859e62">cattle::BinaryStepActivationLayer::BinaryStepActivationLayer</a></div><div class="ttdeci">BinaryStepActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1801</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_a2722517029fa18cb0ee1b9038a643da9"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#a2722517029fa18cb0ee1b9038a643da9">cattle::ActivationLayer::enforce_constraints</a></div><div class="ttdeci">void enforce_constraints()</div><div class="ttdoc">It applies constraints such as max-norm to the parameters of the layer (if applicable). </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1698</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4_html_adafbcae0285d7acc605260eb738262db"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#adafbcae0285d7acc605260eb738262db">cattle::MeanPoolLayer&lt; Scalar, 2 &gt;::MeanPoolLayer</a></div><div class="ttdeci">MeanPoolLayer(const Dimensions&lt; std::size_t, 2 &gt; &amp;input_dims, std::size_t receptor_height=2, std::size_t receptor_width=2, std::size_t vertical_stride=2, std::size_t horizontal_stride=2)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3016</div></div>
<div class="ttc" id="classcattle_1_1_scaled_activation_layer_html_ab734027e0de3a17a15e4cb3f0fac4da2"><div class="ttname"><a href="classcattle_1_1_scaled_activation_layer.html#ab734027e0de3a17a15e4cb3f0fac4da2">cattle::ScaledActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1772</div></div>
<div class="ttc" id="classcattle_1_1internal_1_1_cu_d_n_n_handle_html_acd5781e6e3acdcb1a6d888cddf616843"><div class="ttname"><a href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#acd5781e6e3acdcb1a6d888cddf616843">cattle::internal::CuDNNHandle::conv2d_output_dims</a></div><div class="ttdeci">Array4 conv2d_output_dims(const Array4 &amp;input_dims, std::size_t filters, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation) const</div><div class="ttdoc">Computes the dimensions of the output of the convolution. </div><div class="ttdef"><b>Definition:</b> CuDNNHandle.hpp:70</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_adca55b556a6ecf4f087b84abd5752f9f"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#adca55b556a6ecf4f087b84abd5752f9f">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_params</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params()</div><div class="ttdoc">It returns a reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4124</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_base_html_ae8cc07b8101db1e0ba06bc48ceca3b0e"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_base.html#ae8cc07b8101db1e0ba06bc48ceca3b0e">cattle::MeanPoolLayerBase::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2944</div></div>
<div class="ttc" id="classcattle_1_1_softsign_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_softsign_activation_layer.html">cattle::SoftsignActivationLayer</a></div><div class="ttdoc">A class template representing a softsign activation function layer, an alternative to the tanh layer...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2012</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_ab6c060e14a2e7d70c2b9e10e41117c6b"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#ab6c060e14a2e7d70c2b9e10e41117c6b">cattle::BroadcastLayer::get_params</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params()</div><div class="ttdoc">It returns a reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3594</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a6007fc5ae0a98b5995526ae4df222193"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a6007fc5ae0a98b5995526ae4df222193">cattle::BatchNormLayer::get_input_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_input_dims() const</div><div class="ttdoc">A simple constant getter method for the input dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3757</div></div>
<div class="ttc" id="classcattle_1_1_re_l_u_activation_layer_html_a3f50854f7aaf891eccf373b8f70cb3d7"><div class="ttname"><a href="classcattle_1_1_re_l_u_activation_layer.html#a3f50854f7aaf891eccf373b8f70cb3d7">cattle::ReLUActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2242</div></div>
<div class="ttc" id="classcattle_1_1_p_swish_activation_layer_html_a1d5a8b953b4d2533e4d8e2baf2b24860"><div class="ttname"><a href="classcattle_1_1_p_swish_activation_layer.html#a1d5a8b953b4d2533e4d8e2baf2b24860">cattle::PSwishActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2728</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4_html_a5d9a6e54673186b9686410b1d9e11047"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a5d9a6e54673186b9686410b1d9e11047">cattle::DeconvKernelLayer&lt; Scalar, 2 &gt;::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1530</div></div>
<div class="ttc" id="classcattle_1_1_dense_kernel_layer_html_a849b12085e90cba66e75f6011f0274a9"><div class="ttname"><a href="classcattle_1_1_dense_kernel_layer.html#a849b12085e90cba66e75f6011f0274a9">cattle::DenseKernelLayer::clone_with_shared_params</a></div><div class="ttdeci">Root * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:446</div></div>
<div class="ttc" id="classcattle_1_1_optimizer_html"><div class="ttname"><a href="classcattle_1_1_optimizer.html">cattle::Optimizer</a></div><div class="ttdoc">An abstract class template for neural network optimizer algorithm implementations. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:60</div></div>
<div class="ttc" id="classcattle_1_1_p_re_l_u_activation_layer_html_a7ac09416efe5d2cd6cc73df9890e9725"><div class="ttname"><a href="classcattle_1_1_p_re_l_u_activation_layer.html#a7ac09416efe5d2cd6cc73df9890e9725">cattle::PReLUActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2541</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_ac07e30bf427e0fdf40265ac8ae66cdc3"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#ac07e30bf427e0fdf40265ac8ae66cdc3">cattle::ReshapeLayer::clone</a></div><div class="ttdeci">Base * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4722</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4_html_a3190763e39f851cf28606dc1b7906f4a"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#a3190763e39f851cf28606dc1b7906f4a">cattle::MaxPoolLayer&lt; Scalar, 1 &gt;::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3265</div></div>
<div class="ttc" id="classcattle_1_1internal_1_1_cu_d_n_n_handle_html_a39f10a0e8df9b93dd041d23100d49c57"><div class="ttname"><a href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a39f10a0e8df9b93dd041d23100d49c57">cattle::internal::CuDNNHandle::convolution2d_bwd</a></div><div class="ttdeci">void convolution2d_bwd(Scalar *input, Scalar *out_grad, Scalar *filter, Scalar *bias, const Array4 &amp;input_dims, const Array4 &amp;output_dims, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation, Scalar *prev_out_grad, Scalar *filter_grad, Scalar *bias_grad) const</div><div class="ttdoc">Performs a backward 2D convolution on a rank 4 tensor to compute the gradients of the output of the p...</div><div class="ttdef"><b>Definition:</b> CuDNNHandle.hpp:210</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_html_abb6ecb02b8f801f151e345a2735efd2a"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer.html#abb6ecb02b8f801f151e345a2735efd2a">cattle::ConvKernelLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:979</div></div>
<div class="ttc" id="classcattle_1_1_re_l_u_activation_layer_html_ae53d86eece7966ace131af941bb6e095"><div class="ttname"><a href="classcattle_1_1_re_l_u_activation_layer.html#ae53d86eece7966ace131af941bb6e095">cattle::ReLUActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2235</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a7b62f3a8bab743a0714ec3d1c7e87506"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7b62f3a8bab743a0714ec3d1c7e87506">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4120</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_ac348f24763e65ede1ae53f024b000c18"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#ac348f24763e65ede1ae53f024b000c18">cattle::ReshapeLayer::get_params_owner</a></div><div class="ttdeci">const Base &amp; get_params_owner() const</div><div class="ttdoc">It returns a reference to the layer owning the parameters used. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4728</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a0da23b87533c9f9825948d31538a5e06"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a0da23b87533c9f9825948d31538a5e06">cattle::DropoutLayer::set_frozen</a></div><div class="ttdeci">void set_frozen(bool frozen)</div><div class="ttdoc">It sets whether the parameters of the layer should not be updated during optimization. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4528</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_a08ee9d5c6877d2ca969be895be1bafb3"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#a08ee9d5c6877d2ca969be895be1bafb3">cattle::KernelLayer::get_output_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_output_dims() const</div><div class="ttdoc">A simple constant getter method for the output dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:297</div></div>
<div class="ttc" id="classcattle_1_1_identity_activation_layer_html_ab6e4a91524b3a535c74b7804e8c0097f"><div class="ttname"><a href="classcattle_1_1_identity_activation_layer.html#ab6e4a91524b3a535c74b7804e8c0097f">cattle::IdentityActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1736</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4_html_ae8f4e95932e2d890d7d475198522e0bd"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#ae8f4e95932e2d890d7d475198522e0bd">cattle::MaxPoolLayer&lt; Scalar, 1 &gt;::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3269</div></div>
<div class="ttc" id="classcattle_1_1_scaled_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_scaled_activation_layer.html">cattle::ScaledActivationLayer</a></div><div class="ttdoc">A class template that represents a linearly scaling activation layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1751</div></div>
<div class="ttc" id="classcattle_1_1_scaled_activation_layer_html_a42aa507a420c05fb92231beb2771384e"><div class="ttname"><a href="classcattle_1_1_scaled_activation_layer.html#a42aa507a420c05fb92231beb2771384e">cattle::ScaledActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1766</div></div>
<div class="ttc" id="classcattle_1_1_softsign_activation_layer_html_a212ef821664165b0f1e5656bb48b40ee"><div class="ttname"><a href="classcattle_1_1_softsign_activation_layer.html#a212ef821664165b0f1e5656bb48b40ee">cattle::SoftsignActivationLayer::SoftsignActivationLayer</a></div><div class="ttdeci">SoftsignActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2019</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a003e6d570d2775a86b018e7676dde67a"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a003e6d570d2775a86b018e7676dde67a">cattle::BroadcastLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3593</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a9557e077d940b2ff0c280e9a78c4b52e"><div class="ttname"><a href="classcattle_1_1_layer.html#a9557e077d940b2ff0c280e9a78c4b52e">cattle::Layer::set_input_layer</a></div><div class="ttdeci">virtual void set_input_layer(bool input_layer)=0</div><div class="ttdoc">Sets this instance&amp;#39;s input layer status to the given value. </div></div>
<div class="ttc" id="classcattle_1_1_softplus_activation_layer_html_ac1533119d3423aa2130d01eb95b12431"><div class="ttname"><a href="classcattle_1_1_softplus_activation_layer.html#ac1533119d3423aa2130d01eb95b12431">cattle::SoftplusActivationLayer::SoftplusActivationLayer</a></div><div class="ttdeci">SoftplusActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2062</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a5f6dcc02c8ac98701607ab697951b25f"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a5f6dcc02c8ac98701607ab697951b25f">cattle::PoolLayer::get_input_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_input_dims() const</div><div class="ttdoc">A simple constant getter method for the input dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2765</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a96c2d546cf321f1532e4efde7fc44419"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a96c2d546cf321f1532e4efde7fc44419">cattle::BroadcastLayer::get_output_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_output_dims() const</div><div class="ttdoc">A simple constant getter method for the output dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3570</div></div>
<div class="ttc" id="classcattle_1_1_p_swish_activation_layer_html_ad9ddf16a25f9a6708f1569e1b9d48bff"><div class="ttname"><a href="classcattle_1_1_p_swish_activation_layer.html#ad9ddf16a25f9a6708f1569e1b9d48bff">cattle::PSwishActivationLayer::init</a></div><div class="ttdeci">void init()</div><div class="ttdoc">It initializes the layer and its parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2685</div></div>
<div class="ttc" id="namespacecattle_html_a8b9323ad928764340e46f0802bf27fbb"><div class="ttname"><a href="namespacecattle.html#a8b9323ad928764340e46f0802bf27fbb">cattle::Tensor</a></div><div class="ttdeci">Eigen::Tensor&lt; Scalar, Rank, Eigen::ColMajor, std::size_t &gt; Tensor</div><div class="ttdoc">An alias for a tensor of arbitrary rank and scalar type with dynamic dimensionality. </div><div class="ttdef"><b>Definition:</b> EigenProxy.hpp:54</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_html_a8385135d797538bc8fe694e6e8248ecc"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer.html#a8385135d797538bc8fe694e6e8248ecc">cattle::DeconvKernelLayer::DeconvKernelLayer</a></div><div class="ttdeci">DeconvKernelLayer(const Dimensions&lt; std::size_t, 3 &gt; &amp;input_dims, std::size_t filters, WeightInitSharedPtr&lt; Scalar &gt; weight_init, ParamRegSharedPtr&lt; Scalar &gt; weight_reg=Root::NO_PARAM_REG, std::size_t receptor_height=3, std::size_t receptor_width=3, std::size_t vertical_padding=1, std::size_t horizontal_padding=1, std::size_t vertical_stride=1, std::size_t horizontal_stride=1, std::size_t vertical_dilation=0, std::size_t horizontal_dilation=0, Scalar max_norm_constraint=0)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1444</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a75260941d25afbe9d8c47b495c998ad3"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a75260941d25afbe9d8c47b495c998ad3">cattle::PoolLayer::get_output_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_output_dims() const</div><div class="ttdoc">A simple constant getter method for the output dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2768</div></div>
<div class="ttc" id="classcattle_1_1_e_l_u_activation_layer_html_a67800526be3ccda15d3b5c6f8c2d4f2e"><div class="ttname"><a href="classcattle_1_1_e_l_u_activation_layer.html#a67800526be3ccda15d3b5c6f8c2d4f2e">cattle::ELUActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2393</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4_html_a230df133932f7c470be5d6c796c3ca87"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#a230df133932f7c470be5d6c796c3ca87">cattle::MaxPoolLayer&lt; Scalar, 2 &gt;::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3225</div></div>
<div class="ttc" id="classcattle_1_1_dense_kernel_layer_html"><div class="ttname"><a href="classcattle_1_1_dense_kernel_layer.html">cattle::DenseKernelLayer</a></div><div class="ttdoc">A class template representing a fully connected layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:422</div></div>
<div class="ttc" id="classcattle_1_1_p_swish_activation_layer_html_a55177f124396da9ed5d9a6356cd676f5"><div class="ttname"><a href="classcattle_1_1_p_swish_activation_layer.html#a55177f124396da9ed5d9a6356cd676f5">cattle::PSwishActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2714</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a519e32659a2065563e8ab91289e1f8f3"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a519e32659a2065563e8ab91289e1f8f3">cattle::BatchNormLayer::set_frozen</a></div><div class="ttdeci">void set_frozen(bool frozen)</div><div class="ttdoc">It sets whether the parameters of the layer should not be updated during optimization. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3772</div></div>
<div class="ttc" id="classcattle_1_1_softmax_activation_layer_html_a7c642043ac4d852b0a6b7373c57a2206"><div class="ttname"><a href="classcattle_1_1_softmax_activation_layer.html#a7c642043ac4d852b0a6b7373c57a2206">cattle::SoftmaxActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2117</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a02660b1012003ef67a1f98730de09489"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a02660b1012003ef67a1f98730de09489">cattle::BroadcastLayer::get_params_owner</a></div><div class="ttdeci">const Base &amp; get_params_owner() const</div><div class="ttdoc">It returns a reference to the layer owning the parameters used. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3564</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a9fcfa190cdb86ee669c5809296ee2229"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a9fcfa190cdb86ee669c5809296ee2229">cattle::BatchNormLayer::BatchNormLayer</a></div><div class="ttdeci">BatchNormLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims, ParamRegSharedPtr&lt; Scalar &gt; gamma_reg=Base::NO_PARAM_REG, ParamRegSharedPtr&lt; Scalar &gt; beta_reg=Base::NO_PARAM_REG, Scalar gamma_max_norm_constraint=0, Scalar beta_max_norm_constraint=0, Scalar norm_avg_decay=.1, Scalar epsilon=internal::NumericUtils&lt; Scalar &gt;::EPSILON2)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3668</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_ae5c4d2b057b9f7edc6eb3ca4c1b9ade8"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#ae5c4d2b057b9f7edc6eb3ca4c1b9ade8">cattle::PoolLayer::_init_cache</a></div><div class="ttdeci">virtual void _init_cache()=0</div><div class="ttdoc">Initializes the cache required for back-propagation. </div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4_html_a21edc93d718d45b36cd574ce8b363ec5"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#a21edc93d718d45b36cd574ce8b363ec5">cattle::MaxPoolLayer&lt; Scalar, 2 &gt;::MaxPoolLayer</a></div><div class="ttdeci">MaxPoolLayer(const Dimensions&lt; std::size_t, 2 &gt; &amp;input_dims, std::size_t receptor_height=2, std::size_t receptor_width=2, std::size_t vertical_stride=2, std::size_t horizontal_stride=2)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3217</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_ac19d7798baf005d3729f620d1eb9a58b"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#ac19d7798baf005d3729f620d1eb9a58b">cattle::DropoutLayer::get_regularization_penalty</a></div><div class="ttdeci">Scalar get_regularization_penalty() const</div><div class="ttdoc">It calculates the regularization penalty of the layer&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4549</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_a3733446d064f63f86f8a48bd30c0dbcb"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#a3733446d064f63f86f8a48bd30c0dbcb">cattle::ActivationLayer::is_input_layer</a></div><div class="ttdeci">bool is_input_layer() const</div><div class="ttdoc">A constant method that returns whether this layer functions as an input layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1682</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_aa1113a0964adeb6c688489dfc51221ee"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#aa1113a0964adeb6c688489dfc51221ee">cattle::BroadcastLayer::get_input_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_input_dims() const</div><div class="ttdoc">A simple constant getter method for the input dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3567</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a7f46a6d30c7004193fef2b4b75835f28"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7f46a6d30c7004193fef2b4b75835f28">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::is_input_layer</a></div><div class="ttdeci">bool is_input_layer() const</div><div class="ttdoc">A constant method that returns whether this layer functions as an input layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4114</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_html_a735124db085951aad791d44b24485610"><div class="ttname"><a href="classcattle_1_1_max_pool_layer.html#a735124db085951aad791d44b24485610">cattle::MaxPoolLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3182</div></div>
<div class="ttc" id="namespacecattle_html_a1d78623a47279d516750a44dbad6090b"><div class="ttname"><a href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">cattle::Matrix</a></div><div class="ttdeci">Eigen::Matrix&lt; Scalar, Eigen::Dynamic, Eigen::Dynamic, Eigen::ColMajor, Eigen::Dynamic, Eigen::Dynamic &gt; Matrix</div><div class="ttdoc">An alias for a dynamically sized matrix of an arbitrary scalar type. </div><div class="ttdef"><b>Definition:</b> EigenProxy.hpp:41</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a7cb51862ef9b87632b5abb8e3ab36dd9"><div class="ttname"><a href="classcattle_1_1_layer.html#a7cb51862ef9b87632b5abb8e3ab36dd9">cattle::Layer::pass_back</a></div><div class="ttdeci">virtual Data pass_back(Data out_grad)=0</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div></div>
<div class="ttc" id="classcattle_1_1_p_re_l_u_activation_layer_html_a7bb2f7bd02261af5aae033d9727c00c8"><div class="ttname"><a href="classcattle_1_1_p_re_l_u_activation_layer.html#a7bb2f7bd02261af5aae033d9727c00c8">cattle::PReLUActivationLayer::regularize</a></div><div class="ttdeci">void regularize()</div><div class="ttdoc">It computes the derivative of the regularization function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2544</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_ac72ed377cf408274f15e280de3266044"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#ac72ed377cf408274f15e280de3266044">cattle::DropoutLayer::get_params_grad</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params_grad()</div><div class="ttdoc">It returns a reference to the gradient of the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4545</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a3d9cb8a20f6fd062aa52b41f8534f5af"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a3d9cb8a20f6fd062aa52b41f8534f5af">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_params_grad</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params_grad()</div><div class="ttdoc">It returns a reference to the gradient of the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4127</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4_html_adcc32375c88da7cb099f1aa02cfbaf6c"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#adcc32375c88da7cb099f1aa02cfbaf6c">cattle::DeconvKernelLayer&lt; Scalar, 1 &gt;::DeconvKernelLayer</a></div><div class="ttdeci">DeconvKernelLayer(const Dimensions&lt; std::size_t, 1 &gt; &amp;input_dims, std::size_t filters, WeightInitSharedPtr&lt; Scalar &gt; weight_init, ParamRegSharedPtr&lt; Scalar &gt; weight_reg=Root::NO_PARAM_REG, std::size_t receptor_length=3, std::size_t padding=1, std::size_t stride=1, std::size_t dilation=0, Scalar max_norm_constraint=0)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1578</div></div>
<div class="ttc" id="classcattle_1_1_p_re_l_u_activation_layer_html_a26107800b142f95b0d34a9519b801e9c"><div class="ttname"><a href="classcattle_1_1_p_re_l_u_activation_layer.html#a26107800b142f95b0d34a9519b801e9c">cattle::PReLUActivationLayer::init</a></div><div class="ttdeci">void init()</div><div class="ttdoc">It initializes the layer and its parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2529</div></div>
<div class="ttc" id="classcattle_1_1_e_l_u_activation_layer_html_a04933fe8b46478f608062e88ac549ed9"><div class="ttname"><a href="classcattle_1_1_e_l_u_activation_layer.html#a04933fe8b46478f608062e88ac549ed9">cattle::ELUActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2389</div></div>
<div class="ttc" id="classcattle_1_1internal_1_1_cu_d_n_n_handle_html_ae958103fd306a6ad9c1e0d50d9e13d57"><div class="ttname"><a href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#ae958103fd306a6ad9c1e0d50d9e13d57">cattle::internal::CuDNNHandle::activation_bwd</a></div><div class="ttdeci">void activation_bwd(Scalar *input, Scalar *output, Scalar *out_grad, const Array4 &amp;dims, cudnnActivationMode_t act_mode, Scalar coeff, Scalar *prev_out_grad) const</div><div class="ttdoc">It computes the gradient of the input of the activation function. </div><div class="ttdef"><b>Definition:</b> CuDNNHandle.hpp:346</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_ac92d606818b5a240d0ce898e35afe63d"><div class="ttname"><a href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">cattle::Layer::is_shared_params_clone</a></div><div class="ttdeci">bool is_shared_params_clone() const</div><div class="ttdoc">It determines whether the layer instance is a clone using the shared parameters of another instance...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:154</div></div>
<div class="ttc" id="classcattle_1_1_re_l_u_activation_layer_html_a413bba29e917c3de534cf9fcf7f85d11"><div class="ttname"><a href="classcattle_1_1_re_l_u_activation_layer.html#a413bba29e917c3de534cf9fcf7f85d11">cattle::ReLUActivationLayer::ReLUActivationLayer</a></div><div class="ttdeci">ReLUActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2226</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4_html_a8bddebf1d3fcfdafbdd1c4e93b3294dd"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#a8bddebf1d3fcfdafbdd1c4e93b3294dd">cattle::MeanPoolLayer&lt; Scalar, 1 &gt;::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3066</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4_html_aeaa3fa2d91460475a2e9b970deed5ad2"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aeaa3fa2d91460475a2e9b970deed5ad2">cattle::ConvKernelLayer&lt; Scalar, 1 &gt;::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1097</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_ac74dd19ed2f3a253cfbb1d1785f56197"><div class="ttname"><a href="classcattle_1_1_layer.html#ac74dd19ed2f3a253cfbb1d1785f56197">cattle::Layer::enforce_constraints</a></div><div class="ttdeci">virtual void enforce_constraints()=0</div><div class="ttdoc">It applies constraints such as max-norm to the parameters of the layer (if applicable). </div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a81a8592dbe5a4d75a3ba4575780b0ac2"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a81a8592dbe5a4d75a3ba4575780b0ac2">cattle::ReshapeLayer::ReshapeLayer</a></div><div class="ttdeci">ReshapeLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;input_dims, const Dimensions&lt; std::size_t, Rank &gt; &amp;output_dims)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4710</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4_html_a93619900866409b99543510a099855b3"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a93619900866409b99543510a099855b3">cattle::ConvKernelLayer&lt; Scalar, 1 &gt;::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1114</div></div>
<div class="ttc" id="classcattle_1_1_softsign_activation_layer_html_a22932a2f01f7b000cf8e7f58bf81b0ec"><div class="ttname"><a href="classcattle_1_1_softsign_activation_layer.html#a22932a2f01f7b000cf8e7f58bf81b0ec">cattle::SoftsignActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2025</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_acfcf2228f1c0ce3292692f8eb48b7444"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#acfcf2228f1c0ce3292692f8eb48b7444">cattle::ReshapeLayer::regularize</a></div><div class="ttdeci">void regularize()</div><div class="ttdoc">It computes the derivative of the regularization function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4764</div></div>
<div class="ttc" id="classcattle_1_1_softsign_activation_layer_html_a10ece7c1af4ebfdfaf03f2c64b05c2b5"><div class="ttname"><a href="classcattle_1_1_softsign_activation_layer.html#a10ece7c1af4ebfdfaf03f2c64b05c2b5">cattle::SoftsignActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2038</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_ab40438ea8902e5bbba29ff6d23b4f187"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#ab40438ea8902e5bbba29ff6d23b4f187">cattle::BatchNormLayer::clone_with_shared_params</a></div><div class="ttdeci">Base * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3751</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_aa2e932dd174e1511ae1b57cc63c7e8ca"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#aa2e932dd174e1511ae1b57cc63c7e8ca">cattle::ReshapeLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4757</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_acdf570a1b89a163d411fdbb2efcf3851"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#acdf570a1b89a163d411fdbb2efcf3851">cattle::BroadcastLayer::get_params_grad</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params_grad() const</div><div class="ttdoc">It returns a constant reference to the gradient of the learnable parameters of the layer...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3576</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_base_html_acfe4016482ff9624e21e2856f2209655"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_base.html#acfe4016482ff9624e21e2856f2209655">cattle::MaxPoolLayerBase::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3100</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_a9b9896f4bd8461df9021f9ae0c03c5b8"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#a9b9896f4bd8461df9021f9ae0c03c5b8">cattle::KernelLayer::get_params</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params()</div><div class="ttdoc">It returns a reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:381</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_a2cfd231e456e1f828dc3638b3a5eb0c7"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#a2cfd231e456e1f828dc3638b3a5eb0c7">cattle::KernelLayer::set_input_layer</a></div><div class="ttdeci">void set_input_layer(bool input_layer)</div><div class="ttdoc">Sets this instance&amp;#39;s input layer status to the given value. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:378</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4_html_a420dc3d7bbed6bfa1c706bc927ca7b25"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#a420dc3d7bbed6bfa1c706bc927ca7b25">cattle::MaxPoolLayer&lt; Scalar, 2 &gt;::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3232</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a96eed3e8027413d21b26ac2f48d71a88"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a96eed3e8027413d21b26ac2f48d71a88">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::init</a></div><div class="ttdeci">void init()</div><div class="ttdoc">It initializes the layer and its parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4082</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_html"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer.html">cattle::MeanPoolLayer</a></div><div class="ttdoc">A class template representing a 2D mean pooling layer operating on rank-3 data. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2961</div></div>
<div class="ttc" id="classcattle_1_1_sigmoid_activation_layer_html_a1b3bf686340f3b716d11425fc93431d4"><div class="ttname"><a href="classcattle_1_1_sigmoid_activation_layer.html#a1b3bf686340f3b716d11425fc93431d4">cattle::SigmoidActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1855</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_a60063073706819b0625db87b01b6fc5c"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#a60063073706819b0625db87b01b6fc5c">cattle::KernelLayer::get_params_grad</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params_grad() const</div><div class="ttdoc">It returns a constant reference to the gradient of the learnable parameters of the layer...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:303</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a9995e383fd1ce20a832172ee4d6c37c0"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a9995e383fd1ce20a832172ee4d6c37c0">cattle::BatchNormLayer::init</a></div><div class="ttdeci">void init()</div><div class="ttdoc">It initializes the layer and its parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3775</div></div>
<div class="ttc" id="namespacecattle_html"><div class="ttname"><a href="namespacecattle.html">cattle</a></div><div class="ttdoc">The namespace containing all classes and typedefs of the C-ATTL3 library. </div><div class="ttdef"><b>Definition:</b> Codec.hpp:21</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a9ce0f661d35ef7efa79885e76dec673a"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a9ce0f661d35ef7efa79885e76dec673a">cattle::ReshapeLayer::pass_back</a></div><div class="ttdeci">Base::Data pass_back(typename Base::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4775</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_base_html_a0b9a18aa55e2c5e3653f85950980ab74"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_base.html#a0b9a18aa55e2c5e3653f85950980ab74">cattle::MeanPoolLayerBase::_reduce</a></div><div class="ttdeci">Tensor&lt; Scalar, 4 &gt; _reduce(const Tensor&lt; Scalar, 4 &gt; &amp;patch, std::size_t patch_ind)</div><div class="ttdoc">Reduces the input tensor patch along the specified ranks. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2946</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html">cattle::KernelLayer</a></div><div class="ttdoc">An abstract base class template for layers representing linear kernel-based operations such as matrix...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:287</div></div>
<div class="ttc" id="classcattle_1_1_e_l_u_activation_layer_html_a4f95c5a7dab61b50bf2c55304a253f14"><div class="ttname"><a href="classcattle_1_1_e_l_u_activation_layer.html#a4f95c5a7dab61b50bf2c55304a253f14">cattle::ELUActivationLayer::ELUActivationLayer</a></div><div class="ttdeci">ELUActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims, Scalar alpha=1e-1)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2381</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_afea25117f93e8ca72fd4538251dd7f01"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#afea25117f93e8ca72fd4538251dd7f01">cattle::BatchNormLayer::get_params_grad</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params_grad()</div><div class="ttdoc">It returns a reference to the gradient of the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3822</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_html_a34b6db12d2d0aa7d29434be0878f632a"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer.html#a34b6db12d2d0aa7d29434be0878f632a">cattle::DeconvKernelLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1462</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a601eec2c307fd047dd390e2e4347cc58"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a601eec2c307fd047dd390e2e4347cc58">cattle::DropoutLayer::is_input_layer</a></div><div class="ttdeci">bool is_input_layer() const</div><div class="ttdoc">A constant method that returns whether this layer functions as an input layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4533</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a1f24f60a80843b341131b87270f02ec5"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a1f24f60a80843b341131b87270f02ec5">cattle::BroadcastLayer::pass_back</a></div><div class="ttdeci">Base::Data pass_back(typename Base::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3611</div></div>
<div class="ttc" id="classcattle_1_1_scaled_activation_layer_html_ab0915b571e2ac239d0b0aec7cee2374b"><div class="ttname"><a href="classcattle_1_1_scaled_activation_layer.html#ab0915b571e2ac239d0b0aec7cee2374b">cattle::ScaledActivationLayer::ScaledActivationLayer</a></div><div class="ttdeci">ScaledActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims, Scalar scale)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1759</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_base_html_a069f031d5c41d7602bf65f4f21c8fcd2"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_base.html#a069f031d5c41d7602bf65f4f21c8fcd2">cattle::MaxPoolLayerBase::_init_cache</a></div><div class="ttdeci">void _init_cache()</div><div class="ttdoc">Initializes the cache required for back-propagation. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3103</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_ab3719ffa784c45277252f2fb16b209d5"><div class="ttname"><a href="classcattle_1_1_layer.html#ab3719ffa784c45277252f2fb16b209d5">cattle::Layer::get_regularization_penalty</a></div><div class="ttdeci">virtual Scalar get_regularization_penalty() const =0</div><div class="ttdoc">It calculates the regularization penalty of the layer&amp;#39;s parameters. </div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_ad90d03809c1a76aee78463a25c7724a3"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#ad90d03809c1a76aee78463a25c7724a3">cattle::ReshapeLayer::pass_forward</a></div><div class="ttdeci">Base::Data pass_forward(typename Base::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4769</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a14cbbb352c679482e3fe4ce2b970f06a"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a14cbbb352c679482e3fe4ce2b970f06a">cattle::DropoutLayer::clone_with_shared_params</a></div><div class="ttdeci">Base * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4507</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_af25577fd157dbd6a8ddd05d3abdf65ed"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#af25577fd157dbd6a8ddd05d3abdf65ed">cattle::ReshapeLayer::is_input_layer</a></div><div class="ttdeci">bool is_input_layer() const</div><div class="ttdoc">A constant method that returns whether this layer functions as an input layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4751</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_aa69b5903eb6b03f700cbde298718f695"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#aa69b5903eb6b03f700cbde298718f695">cattle::BroadcastLayer::is_frozen</a></div><div class="ttdeci">bool is_frozen() const</div><div class="ttdoc">It determines whether the parameters of the layer, if there are any, are to be updated during optimiz...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3579</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_ab3321ebfcbeeaf3c97a8a3ed4c3d48fc"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#ab3321ebfcbeeaf3c97a8a3ed4c3d48fc">cattle::BroadcastLayer::is_input_layer</a></div><div class="ttdeci">bool is_input_layer() const</div><div class="ttdoc">A constant method that returns whether this layer functions as an input layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3587</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4_html"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html">cattle::DeconvKernelLayer&lt; Scalar, 1 &gt;</a></div><div class="ttdoc">A class template for a transposed 2D convolutional layer operating on rank-1 data batches (rank-2 ten...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1558</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4_html_aae11392cc9350c8ac87a0fe0db278a19"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#aae11392cc9350c8ac87a0fe0db278a19">cattle::ConvKernelLayer&lt; Scalar, 2 &gt;::clone_with_shared_params</a></div><div class="ttdeci">Root * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1038</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a57c06bd60a7784adde787012e2b78178"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a57c06bd60a7784adde787012e2b78178">cattle::ReshapeLayer::set_input_layer</a></div><div class="ttdeci">void set_input_layer(bool input_layer)</div><div class="ttdoc">Sets this instance&amp;#39;s input layer status to the given value. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4754</div></div>
<div class="ttc" id="classcattle_1_1internal_1_1_cu_d_n_n_handle_html_a2da9235cdf411aa8c37c6a5554bc415d"><div class="ttname"><a href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a2da9235cdf411aa8c37c6a5554bc415d">cattle::internal::CuDNNHandle::softmax_bwd</a></div><div class="ttdeci">void softmax_bwd(Scalar *output, Scalar *out_grad, const Array4 &amp;dims, Scalar *prev_out_grad) const</div><div class="ttdoc">It computes the gradient of the input of the softmax activation function. </div><div class="ttdef"><b>Definition:</b> CuDNNHandle.hpp:408</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4_html_ac391887510fae8472b7ea92b7f4d6114"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#ac391887510fae8472b7ea92b7f4d6114">cattle::ConvKernelLayer&lt; Scalar, 2 &gt;::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1045</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a18bd4016f07bfc33c27bb518066ff67b"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a18bd4016f07bfc33c27bb518066ff67b">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::clone</a></div><div class="ttdeci">Base * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4055</div></div>
<div class="ttc" id="classcattle_1_1_softmax_activation_layer_html_a970361710856c4497c4bb8fd6f1e9ac9"><div class="ttname"><a href="classcattle_1_1_softmax_activation_layer.html#a970361710856c4497c4bb8fd6f1e9ac9">cattle::SoftmaxActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2113</div></div>
<div class="ttc" id="classcattle_1_1_softplus_activation_layer_html_ad3a362dd884f047371f20981cb50dcdd"><div class="ttname"><a href="classcattle_1_1_softplus_activation_layer.html#ad3a362dd884f047371f20981cb50dcdd">cattle::SoftplusActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2064</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a865ffd7d7961901c5d08cb64e33b111b"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a865ffd7d7961901c5d08cb64e33b111b">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::BatchNormLayer</a></div><div class="ttdeci">BatchNormLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims, ParamRegSharedPtr&lt; Scalar &gt; gamma_reg=Base::NO_PARAM_REG, ParamRegSharedPtr&lt; Scalar &gt; beta_reg=Base::NO_PARAM_REG, Scalar gamma_max_norm_constraint=0, Scalar beta_max_norm_constraint=0, Scalar norm_avg_decay=.1, Scalar epsilon=internal::NumericUtils&lt; Scalar &gt;::EPSILON2)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3985</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a3910d423bb77d5cdfc4ef6bc2c432a2e"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a3910d423bb77d5cdfc4ef6bc2c432a2e">cattle::BatchNormLayer::get_params</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params() const</div><div class="ttdoc">It returns a constant reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3763</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_ad324ff93b576e8e542962a4d2d5d18f4"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#ad324ff93b576e8e542962a4d2d5d18f4">cattle::KernelLayer::enforce_constraints</a></div><div class="ttdeci">void enforce_constraints()</div><div class="ttdoc">It applies constraints such as max-norm to the parameters of the layer (if applicable). </div><div class="ttdef"><b>Definition:</b> Layer.hpp:394</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_ab185ef41a45b7a7cd8dc0371885e1ce1"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ab185ef41a45b7a7cd8dc0371885e1ce1">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_regularization_penalty</a></div><div class="ttdeci">Scalar get_regularization_penalty() const</div><div class="ttdoc">It calculates the regularization penalty of the layer&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4134</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_base_html_ab7afcbc0dacf7a340d313c521c6a4d87"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_base.html#ab7afcbc0dacf7a340d313c521c6a4d87">cattle::MeanPoolLayerBase::_init_cache</a></div><div class="ttdeci">void _init_cache()</div><div class="ttdoc">Initializes the cache required for back-propagation. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2945</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4_html"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html">cattle::ConvKernelLayer&lt; Scalar, 2 &gt;</a></div><div class="ttdoc">A class template for a 2D convolutional layer operating on rank-2 data batches (rank-3 tensors)...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1000</div></div>
<div class="ttc" id="classcattle_1_1_softsign_activation_layer_html_ac1c1cf2b0fdcd49fd896c12147995ca1"><div class="ttname"><a href="classcattle_1_1_softsign_activation_layer.html#ac1c1cf2b0fdcd49fd896c12147995ca1">cattle::SoftsignActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2028</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_base_html_adba251e3a789c00b852d896e3742f3b4"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_base.html#adba251e3a789c00b852d896e3742f3b4">cattle::MaxPoolLayerBase::_reduce</a></div><div class="ttdeci">Tensor&lt; Scalar, 4 &gt; _reduce(const Tensor&lt; Scalar, 4 &gt; &amp;patch, std::size_t patch_ind)</div><div class="ttdoc">Reduces the input tensor patch along the specified ranks. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3106</div></div>
<div class="ttc" id="classcattle_1_1_re_l_u_activation_layer_html_ad9fecbc7c7a552e89eae61034ad89cf9"><div class="ttname"><a href="classcattle_1_1_re_l_u_activation_layer.html#ad9fecbc7c7a552e89eae61034ad89cf9">cattle::ReLUActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2232</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_ae3d00e9fb6079e4b4990b3a14625a93d"><div class="ttname"><a href="classcattle_1_1_layer.html#ae3d00e9fb6079e4b4990b3a14625a93d">cattle::Layer::empty_cache</a></div><div class="ttdeci">virtual void empty_cache()=0</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_aa4fbd5c1c230270282c2501348e3f446"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#aa4fbd5c1c230270282c2501348e3f446">cattle::KernelLayer::is_frozen</a></div><div class="ttdeci">bool is_frozen() const</div><div class="ttdoc">It determines whether the parameters of the layer, if there are any, are to be updated during optimiz...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:306</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a41035543a76d576abdc5c0b1e8e5487f"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a41035543a76d576abdc5c0b1e8e5487f">cattle::BroadcastLayer::regularize</a></div><div class="ttdeci">void regularize()</div><div class="ttdoc">It computes the derivative of the regularization function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3600</div></div>
<div class="ttc" id="classcattle_1_1_leaky_re_l_u_activation_layer_html_a3ca83e1f497e8d9e07dd043fecf9cd10"><div class="ttname"><a href="classcattle_1_1_leaky_re_l_u_activation_layer.html#a3ca83e1f497e8d9e07dd043fecf9cd10">cattle::LeakyReLUActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2336</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a8fb4d7ea9030d99c74a04902bea3d477"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a8fb4d7ea9030d99c74a04902bea3d477">cattle::DropoutLayer::get_params_owner</a></div><div class="ttdeci">const Base &amp; get_params_owner() const</div><div class="ttdoc">It returns a reference to the layer owning the parameters used. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4510</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a26863f25c7ee95558db07defb108e672"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a26863f25c7ee95558db07defb108e672">cattle::ReshapeLayer::get_params_grad</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params_grad() const</div><div class="ttdoc">It returns a constant reference to the gradient of the learnable parameters of the layer...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4740</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_html_aef2dbd6e8dfa79738619355583fb4f30"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer.html#aef2dbd6e8dfa79738619355583fb4f30">cattle::ConvKernelLayer::ConvKernelLayer</a></div><div class="ttdeci">ConvKernelLayer(const Dimensions&lt; std::size_t, 3 &gt; &amp;input_dims, std::size_t filters, WeightInitSharedPtr&lt; Scalar &gt; weight_init, ParamRegSharedPtr&lt; Scalar &gt; weight_reg=Root::NO_PARAM_REG, std::size_t receptor_height=3, std::size_t receptor_width=3, std::size_t vertical_padding=1, std::size_t horizontal_padding=1, std::size_t vertical_stride=1, std::size_t horizontal_stride=1, std::size_t vertical_dilation=0, std::size_t horizontal_dilation=0, Scalar max_norm_constraint=0)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:961</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_af7d261c1deedb980914a51c20070af32"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#af7d261c1deedb980914a51c20070af32">cattle::ReshapeLayer::get_params</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params() const</div><div class="ttdoc">It returns a constant reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4737</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_afdf7ed4bac91e56664c0f5ed6a9dafda"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#afdf7ed4bac91e56664c0f5ed6a9dafda">cattle::DropoutLayer::get_params</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params()</div><div class="ttdoc">It returns a reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4542</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a464493846ede7742da92224914855d24"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a464493846ede7742da92224914855d24">cattle::ReshapeLayer::get_params</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params()</div><div class="ttdoc">It returns a reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4758</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_a261c832c58e43392cdede3257e666dec"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#a261c832c58e43392cdede3257e666dec">cattle::ActivationLayer::get_params_owner</a></div><div class="ttdeci">const Base &amp; get_params_owner() const</div><div class="ttdoc">It returns a reference to the layer owning the parameters used. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1625</div></div>
<div class="ttc" id="classcattle_1_1_p_swish_activation_layer_html_a647a6edc649ca0713cb448546635175b"><div class="ttname"><a href="classcattle_1_1_p_swish_activation_layer.html#a647a6edc649ca0713cb448546635175b">cattle::PSwishActivationLayer::enforce_constraints</a></div><div class="ttdeci">void enforce_constraints()</div><div class="ttdoc">It applies constraints such as max-norm to the parameters of the layer (if applicable). </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2707</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a4eaac782e31cae389237b843ce7569e5"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a4eaac782e31cae389237b843ce7569e5">cattle::DropoutLayer::get_output_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_output_dims() const</div><div class="ttdoc">A simple constant getter method for the output dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4516</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a></div><div class="ttdoc">A class template for a per-activation batch normalization layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3970</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_ab67312e1fc860a8a246f6f9aeadffbb4"><div class="ttname"><a href="classcattle_1_1_layer.html#ab67312e1fc860a8a246f6f9aeadffbb4">cattle::Layer::get_params</a></div><div class="ttdeci">virtual const Matrix&lt; Scalar &gt; &amp; get_params() const =0</div><div class="ttdoc">It returns a constant reference to the learnable parameters of the layer. </div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a2efa46d4b10ec998cb7b09a3c430e025"><div class="ttname"><a href="classcattle_1_1_layer.html#a2efa46d4b10ec998cb7b09a3c430e025">cattle::Layer::set_frozen</a></div><div class="ttdeci">virtual void set_frozen(bool frozen)=0</div><div class="ttdoc">It sets whether the parameters of the layer should not be updated during optimization. </div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a71cd5d5e591d7646fb01a029f12cd685"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a71cd5d5e591d7646fb01a029f12cd685">cattle::BatchNormLayer::get_params</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params()</div><div class="ttdoc">It returns a reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3819</div></div>
<div class="ttc" id="classcattle_1_1_softplus_activation_layer_html_a93b157a4de8aad27a722f9acb5e6aaff"><div class="ttname"><a href="classcattle_1_1_softplus_activation_layer.html#a93b157a4de8aad27a722f9acb5e6aaff">cattle::SoftplusActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2080</div></div>
<div class="ttc" id="classcattle_1_1_softmax_activation_layer_html_a627e9ccac859cacac5e7ade52be93142"><div class="ttname"><a href="classcattle_1_1_softmax_activation_layer.html#a627e9ccac859cacac5e7ade52be93142">cattle::SoftmaxActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2120</div></div>
<div class="ttc" id="classcattle_1_1_p_re_l_u_activation_layer_html_a30914840f4fc20d25805b8a3ac0c6e51"><div class="ttname"><a href="classcattle_1_1_p_re_l_u_activation_layer.html#a30914840f4fc20d25805b8a3ac0c6e51">cattle::PReLUActivationLayer::PReLUActivationLayer</a></div><div class="ttdeci">PReLUActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims, ParamRegSharedPtr&lt; Scalar &gt; param_reg=Root::NO_PARAM_REG, Scalar init_alpha=1e-1, Scalar max_norm_constraint=0)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2513</div></div>
<div class="ttc" id="classcattle_1_1_swish_activation_layer_html_a87b1c9e1f24d354b6e3bf92e411afa16"><div class="ttname"><a href="classcattle_1_1_swish_activation_layer.html#a87b1c9e1f24d354b6e3bf92e411afa16">cattle::SwishActivationLayer::SwishActivationLayer</a></div><div class="ttdeci">SwishActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims, Scalar beta=1)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2613</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a7d71b25a0789d9b8b852f9fdfd86f183"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a7d71b25a0789d9b8b852f9fdfd86f183">cattle::DropoutLayer::pass_back</a></div><div class="ttdeci">Base::Data pass_back(typename Base::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4566</div></div>
<div class="ttc" id="classcattle_1_1internal_1_1_cu_b_l_a_s_handle_html_a608acc1a5e1f61d2d86eebf0d62ff948"><div class="ttname"><a href="classcattle_1_1internal_1_1_cu_b_l_a_s_handle.html#a608acc1a5e1f61d2d86eebf0d62ff948">cattle::internal::CuBLASHandle::matrix_mul</a></div><div class="ttdeci">void matrix_mul(Scalar *a, std::size_t a_orig_rows, std::size_t a_orig_cols, bool transpose_a, Scalar *b, std::size_t b_orig_rows, std::size_t b_orig_cols, bool transpose_b, Scalar *c) const</div><div class="ttdoc">It computes the product of the matrix multiplication. </div><div class="ttdef"><b>Definition:</b> CuBLASHandle.hpp:78</div></div>
<div class="ttc" id="classcattle_1_1_dimensions_html"><div class="ttname"><a href="classcattle_1_1_dimensions.html">cattle::Dimensions&lt; std::size_t, Rank &gt;</a></div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4_html_a482fdde9c3f36efcdd4ea8ae4cd8100a"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a482fdde9c3f36efcdd4ea8ae4cd8100a">cattle::DeconvKernelLayer&lt; Scalar, 2 &gt;::clone_with_shared_params</a></div><div class="ttdeci">Root * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1523</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_ab97e38ad519af40007f659120f3f7fe1"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#ab97e38ad519af40007f659120f3f7fe1">cattle::ActivationLayer::get_params</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params()</div><div class="ttdoc">It returns a reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1688</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4_html_a9dcaad150e53f16071543ad8d19079a1"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a9dcaad150e53f16071543ad8d19079a1">cattle::ConvKernelLayer&lt; Scalar, 1 &gt;::clone_with_shared_params</a></div><div class="ttdeci">Root * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1100</div></div>
<div class="ttc" id="classcattle_1_1_softplus_activation_layer_html_a751103bc7ec61c943727e81e60a495c1"><div class="ttname"><a href="classcattle_1_1_softplus_activation_layer.html#a751103bc7ec61c943727e81e60a495c1">cattle::SoftplusActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2068</div></div>
<div class="ttc" id="classcattle_1_1_binary_step_activation_layer_html_a934bfb1068ace14920a2ccc0277668e2"><div class="ttname"><a href="classcattle_1_1_binary_step_activation_layer.html#a934bfb1068ace14920a2ccc0277668e2">cattle::BinaryStepActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1813</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html">cattle::DropoutLayer</a></div><div class="ttdoc">A class template representing a drop-out layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4483</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a0c833b2176304d5f975e7f66ac203d15"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a0c833b2176304d5f975e7f66ac203d15">cattle::DropoutLayer::pass_forward</a></div><div class="ttdeci">Base::Data pass_forward(typename Base::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4553</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_html_ac89d36d1e61efb112f241ed8e2966337"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer.html#ac89d36d1e61efb112f241ed8e2966337">cattle::DeconvKernelLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1468</div></div>
<div class="ttc" id="classcattle_1_1_leaky_re_l_u_activation_layer_html_aea6e407de7b9a8c3dd366e6f89823bc4"><div class="ttname"><a href="classcattle_1_1_leaky_re_l_u_activation_layer.html#aea6e407de7b9a8c3dd366e6f89823bc4">cattle::LeakyReLUActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2346</div></div>
<div class="ttc" id="classcattle_1_1_layer_html"><div class="ttname"><a href="classcattle_1_1_layer.html">cattle::Layer</a></div><div class="ttdoc">An abstract class template representing layers in a neural network. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:66</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a46db46c62f3d46c6bbef5a482d7fcb00"><div class="ttname"><a href="classcattle_1_1_layer.html#a46db46c62f3d46c6bbef5a482d7fcb00">cattle::Layer::clone</a></div><div class="ttdeci">virtual Layer&lt; Scalar, Rank &gt; * clone() const =0</div><div class="ttdoc">It returns a clone of the layer instance. </div></div>
<div class="ttc" id="classcattle_1_1_p_swish_activation_layer_html_a8908ccf599442daa45682028d79a0871"><div class="ttname"><a href="classcattle_1_1_p_swish_activation_layer.html#a8908ccf599442daa45682028d79a0871">cattle::PSwishActivationLayer::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2679</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a025e9d6f4267555ffd115a76397298d8"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a025e9d6f4267555ffd115a76397298d8">cattle::BroadcastLayer::get_params</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params() const</div><div class="ttdoc">It returns a constant reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3573</div></div>
<div class="ttc" id="classcattle_1_1internal_1_1_cu_d_n_n_handle_html_a66ff49f3b34f05a1043f22d5d0275575"><div class="ttname"><a href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a66ff49f3b34f05a1043f22d5d0275575">cattle::internal::CuDNNHandle::get_instance</a></div><div class="ttdeci">static CuDNNHandle &amp; get_instance()</div><div class="ttdef"><b>Definition:</b> CuDNNHandle.hpp:49</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4_html_acee10ea9184f727d8734038b2f390bee"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#acee10ea9184f727d8734038b2f390bee">cattle::MeanPoolLayer&lt; Scalar, 1 &gt;::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3062</div></div>
<div class="ttc" id="classcattle_1_1_leaky_re_l_u_activation_layer_html_a82d876e1484fd0e695ad72eb20ccadc4"><div class="ttname"><a href="classcattle_1_1_leaky_re_l_u_activation_layer.html#a82d876e1484fd0e695ad72eb20ccadc4">cattle::LeakyReLUActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2332</div></div>
<div class="ttc" id="classcattle_1_1_p_swish_activation_layer_html_af217f7a8a67fa7cff16930a071616ec6"><div class="ttname"><a href="classcattle_1_1_p_swish_activation_layer.html#af217f7a8a67fa7cff16930a071616ec6">cattle::PSwishActivationLayer::regularize</a></div><div class="ttdeci">void regularize()</div><div class="ttdoc">It computes the derivative of the regularization function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2701</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a66300725f60f30bd773d47f2dea19f46"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a66300725f60f30bd773d47f2dea19f46">cattle::BatchNormLayer::set_input_layer</a></div><div class="ttdeci">void set_input_layer(bool input_layer)</div><div class="ttdoc">Sets this instance&amp;#39;s input layer status to the given value. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3812</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a24cc229aaaa68fe8889c4c05f5a1529a"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a24cc229aaaa68fe8889c4c05f5a1529a">cattle::DropoutLayer::get_input_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_input_dims() const</div><div class="ttdoc">A simple constant getter method for the input dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4513</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4_html_aaf1ed54777882941a705fdd94595fc5c"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aaf1ed54777882941a705fdd94595fc5c">cattle::ConvKernelLayer&lt; Scalar, 1 &gt;::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1107</div></div>
<div class="ttc" id="namespacecattle_html_a083ab63c64a5c935b2d2cd3f03c4e27a"><div class="ttname"><a href="namespacecattle.html#a083ab63c64a5c935b2d2cd3f03c4e27a">cattle::ParamRegSharedPtr</a></div><div class="ttdeci">std::shared_ptr&lt; ParamaterRegularization&lt; Scalar &gt; &gt; ParamRegSharedPtr</div><div class="ttdoc">An alias for a shared pointer to a regularization penalty of an arbitrary scalar type. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:56</div></div>
<div class="ttc" id="classcattle_1_1_softmax_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_softmax_activation_layer.html">cattle::SoftmaxActivationLayer</a></div><div class="ttdoc">A class template for a softmax activation function layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2100</div></div>
<div class="ttc" id="classcattle_1_1_sigmoid_activation_layer_html_a9b6f4ebb210c70b972e9831831bac6fd"><div class="ttname"><a href="classcattle_1_1_sigmoid_activation_layer.html#a9b6f4ebb210c70b972e9831831bac6fd">cattle::SigmoidActivationLayer::SigmoidActivationLayer</a></div><div class="ttdeci">SigmoidActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1836</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_acfbb6290f425e0f5d94dbc14d9aabfae"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#acfbb6290f425e0f5d94dbc14d9aabfae">cattle::ActivationLayer::clone</a></div><div class="ttdeci">virtual Base * clone() const =0</div><div class="ttdoc">It returns a clone of the layer instance. </div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html">cattle::ReshapeLayer</a></div><div class="ttdoc">A class template representing a reshaping layer that outputs a reshaped copy of the input tensor with...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4701</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_acc3ea38bc71f210553babfe66e48e370"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#acc3ea38bc71f210553babfe66e48e370">cattle::BatchNormLayer::get_params_grad</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params_grad() const</div><div class="ttdoc">It returns a constant reference to the gradient of the learnable parameters of the layer...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3766</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a2197c18cdbc8c8e80bc059d8f36a4d5c"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a2197c18cdbc8c8e80bc059d8f36a4d5c">cattle::PoolLayer::clone_with_shared_params</a></div><div class="ttdeci">Base * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2759</div></div>
<div class="ttc" id="classcattle_1_1_identity_activation_layer_html_a76d0cd6edb8434e33a845b171b305967"><div class="ttname"><a href="classcattle_1_1_identity_activation_layer.html#a76d0cd6edb8434e33a845b171b305967">cattle::IdentityActivationLayer::IdentityActivationLayer</a></div><div class="ttdeci">IdentityActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1724</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a2817da84a7102af5c1f538f4a1a60664"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a2817da84a7102af5c1f538f4a1a60664">cattle::ReshapeLayer::get_output_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_output_dims() const</div><div class="ttdoc">A simple constant getter method for the output dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4734</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_ab952d37eca54ad52ec43c632ea6a7856"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ab952d37eca54ad52ec43c632ea6a7856">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::clone_with_shared_params</a></div><div class="ttdeci">Base * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4058</div></div>
<div class="ttc" id="classcattle_1_1_identity_activation_layer_html_aa66b095d8084fecdddaaeade76728bb6"><div class="ttname"><a href="classcattle_1_1_identity_activation_layer.html#aa66b095d8084fecdddaaeade76728bb6">cattle::IdentityActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1730</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4_html_a8f3dcbc5d06b5c461c7df214c2263e54"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#a8f3dcbc5d06b5c461c7df214c2263e54">cattle::MeanPoolLayer&lt; Scalar, 2 &gt;::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3031</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_aeb164eb34a28a3109b1713f50980286e"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#aeb164eb34a28a3109b1713f50980286e">cattle::PoolLayer::get_params</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params()</div><div class="ttdoc">It returns a reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2841</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_ac7e767125736b077d6d225cfb3ab1c5d"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#ac7e767125736b077d6d225cfb3ab1c5d">cattle::ReshapeLayer::get_regularization_penalty</a></div><div class="ttdeci">Scalar get_regularization_penalty() const</div><div class="ttdoc">It calculates the regularization penalty of the layer&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4765</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a6c1ea7b25d9f882364b7f2288f02d8da"><div class="ttname"><a href="classcattle_1_1_layer.html#a6c1ea7b25d9f882364b7f2288f02d8da">cattle::Layer::pass_forward</a></div><div class="ttdeci">virtual Data pass_forward(Data in, bool training)=0</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4_html_a2379f9e643bf7e47a33f4e0a5e7bc2c1"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a2379f9e643bf7e47a33f4e0a5e7bc2c1">cattle::ConvKernelLayer&lt; Scalar, 2 &gt;::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1052</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a506589d195f7cf7440ce005b85c4be8e"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a506589d195f7cf7440ce005b85c4be8e">cattle::DropoutLayer::is_frozen</a></div><div class="ttdeci">bool is_frozen() const</div><div class="ttdoc">It determines whether the parameters of the layer, if there are any, are to be updated during optimiz...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4525</div></div>
<div class="ttc" id="classcattle_1_1_p_re_l_u_activation_layer_html_a03db64ab6a9f91966257269af1662373"><div class="ttname"><a href="classcattle_1_1_p_re_l_u_activation_layer.html#a03db64ab6a9f91966257269af1662373">cattle::PReLUActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2566</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_base_html_a8806cde9facfcb881881758bf5801c2b"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_base.html#a8806cde9facfcb881881758bf5801c2b">cattle::DeconvKernelLayerBase::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1206</div></div>
<div class="ttc" id="classcattle_1_1_swish_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_swish_activation_layer.html">cattle::SwishActivationLayer</a></div><div class="ttdoc">A class template representing the Swish activation function. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2604</div></div>
<div class="ttc" id="classcattle_1_1_tanh_activation_layer_html_ad0164a3bcb90574df7b5865e6a3c4a33"><div class="ttname"><a href="classcattle_1_1_tanh_activation_layer.html#ad0164a3bcb90574df7b5865e6a3c4a33">cattle::TanhActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1934</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4_html_adbc814d4f313739c0bf5c34d195507a5"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#adbc814d4f313739c0bf5c34d195507a5">cattle::DeconvKernelLayer&lt; Scalar, 1 &gt;::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1600</div></div>
<div class="ttc" id="classcattle_1_1_swish_activation_layer_html_aeeacccc1907003c77578d71b38d1f481"><div class="ttname"><a href="classcattle_1_1_swish_activation_layer.html#aeeacccc1907003c77578d71b38d1f481">cattle::SwishActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2616</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4_html_aabc6223fac8bd0c8bd8a3093fd3e333c"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aabc6223fac8bd0c8bd8a3093fd3e333c">cattle::ConvKernelLayer&lt; Scalar, 1 &gt;::ConvKernelLayer</a></div><div class="ttdeci">ConvKernelLayer(const Dimensions&lt; std::size_t, 1 &gt; &amp;input_dims, std::size_t filters, WeightInitSharedPtr&lt; Scalar &gt; weight_init, ParamRegSharedPtr&lt; Scalar &gt; weight_reg=Root::NO_PARAM_REG, std::size_t receptor_length=3, std::size_t padding=1, std::size_t stride=1, std::size_t dilation=0, Scalar max_norm_constraint=0)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1092</div></div>
<div class="ttc" id="classcattle_1_1internal_1_1_numeric_utils_html"><div class="ttname"><a href="classcattle_1_1internal_1_1_numeric_utils.html">cattle::internal::NumericUtils</a></div><div class="ttdoc">A utility class template containing static methods and variables to help with numerical issues...</div><div class="ttdef"><b>Definition:</b> NumericUtils.hpp:23</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a074a197df04250449a059d97a4e6e120"><div class="ttname"><a href="classcattle_1_1_layer.html#a074a197df04250449a059d97a4e6e120">cattle::Layer::clone_with_shared_params</a></div><div class="ttdeci">virtual Layer&lt; Scalar, Rank &gt; * clone_with_shared_params()=0</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a11af8181b2494e2644ebda1016b4062c"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a11af8181b2494e2644ebda1016b4062c">cattle::BatchNormLayer::get_regularization_penalty</a></div><div class="ttdeci">Scalar get_regularization_penalty() const</div><div class="ttdoc">It calculates the regularization penalty of the layer&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3829</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_base_html_a11d69acda36367bdb1187f7485b90f9e"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_base.html#a11d69acda36367bdb1187f7485b90f9e">cattle::MeanPoolLayerBase::_d_reduce</a></div><div class="ttdeci">Tensor&lt; Scalar, 4 &gt; _d_reduce(const Tensor&lt; Scalar, 4 &gt; &amp;grad, std::size_t patch_ind)</div><div class="ttdoc">Differentiates the reduction function and returns the derivative of the loss function w...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2950</div></div>
<div class="ttc" id="classcattle_1_1_p_re_l_u_activation_layer_html_a01e678cea84bc7f952303bc5747e7c3f"><div class="ttname"><a href="classcattle_1_1_p_re_l_u_activation_layer.html#a01e678cea84bc7f952303bc5747e7c3f">cattle::PReLUActivationLayer::clone_with_shared_params</a></div><div class="ttdeci">Root * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2526</div></div>
<div class="ttc" id="classcattle_1_1_e_l_u_activation_layer_html_a712f1ee68d924b13db82dce302ba2b20"><div class="ttname"><a href="classcattle_1_1_e_l_u_activation_layer.html#a712f1ee68d924b13db82dce302ba2b20">cattle::ELUActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2406</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_ae82d6c00d3f84d865324c51bcb5ab90c"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#ae82d6c00d3f84d865324c51bcb5ab90c">cattle::BatchNormLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3815</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a7cdb31857371b739af38aa184ac1bebe"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7cdb31857371b739af38aa184ac1bebe">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_params</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params() const</div><div class="ttdoc">It returns a constant reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4070</div></div>
<div class="ttc" id="classcattle_1_1_identity_activation_layer_html_a90c6d2eca9a8d5913d5186b96df2f82e"><div class="ttname"><a href="classcattle_1_1_identity_activation_layer.html#a90c6d2eca9a8d5913d5186b96df2f82e">cattle::IdentityActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1726</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_html_af1423e99f6cbf2fe5ea5780aa46945a2"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer.html#af1423e99f6cbf2fe5ea5780aa46945a2">cattle::ConvKernelLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:985</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a584687e28d220062f36ec67d0cf90054"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a584687e28d220062f36ec67d0cf90054">cattle::PoolLayer::set_input_layer</a></div><div class="ttdeci">void set_input_layer(bool input_layer)</div><div class="ttdoc">Sets this instance&amp;#39;s input layer status to the given value. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2838</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a872d8b4156c8a7e719e4ae1dafd763f1"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a872d8b4156c8a7e719e4ae1dafd763f1">cattle::PoolLayer::get_params</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params() const</div><div class="ttdoc">It returns a constant reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2771</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a9996f83ed27ef7abcb9df3f8f64fc14e"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a9996f83ed27ef7abcb9df3f8f64fc14e">cattle::BroadcastLayer::clone_with_shared_params</a></div><div class="ttdeci">Base * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3561</div></div>
<div class="ttc" id="classcattle_1_1internal_1_1_cu_d_n_n_handle_html_a11d9ff0d2bf96e04b13e142fd57fb99e"><div class="ttname"><a href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a11d9ff0d2bf96e04b13e142fd57fb99e">cattle::internal::CuDNNHandle::convolution2d_fwd</a></div><div class="ttdeci">void convolution2d_fwd(Scalar *input, Scalar *filter, Scalar *bias, const Array4 &amp;input_dims, const Array4 &amp;output_dims, std::size_t receptor_height, std::size_t receptor_width, std::size_t vertical_padding, std::size_t horizontal_padding, std::size_t vertical_stride, std::size_t horizontal_stride, std::size_t vertical_dilation, std::size_t horizontal_dilation, Scalar *output) const</div><div class="ttdoc">Performs a GPU accelerated 2D convolution on a rank 4 tensor of [N,H,W,C] orientation. </div><div class="ttdef"><b>Definition:</b> CuDNNHandle.hpp:115</div></div>
<div class="ttc" id="classcattle_1_1_re_l_u_activation_layer_html_a9f15affc9a835583ed6745496b1dd0c7"><div class="ttname"><a href="classcattle_1_1_re_l_u_activation_layer.html#a9f15affc9a835583ed6745496b1dd0c7">cattle::ReLUActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2228</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a883b154da497fcf7ca074f0aa2b46e9d"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a883b154da497fcf7ca074f0aa2b46e9d">cattle::PoolLayer::is_frozen</a></div><div class="ttdeci">bool is_frozen() const</div><div class="ttdoc">It determines whether the parameters of the layer, if there are any, are to be updated during optimiz...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2777</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4_html_a301dadf7765a2ac52a592207fa6db5d9"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a301dadf7765a2ac52a592207fa6db5d9">cattle::DeconvKernelLayer&lt; Scalar, 2 &gt;::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1537</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4_html_a5bc6b37c61ab96080ff9615915871212"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a5bc6b37c61ab96080ff9615915871212">cattle::ConvKernelLayer&lt; Scalar, 2 &gt;::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1035</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a0206c8917c45b9ac3f4388fa29ab9a26"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a0206c8917c45b9ac3f4388fa29ab9a26">cattle::DropoutLayer::clone</a></div><div class="ttdeci">Base * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4504</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_a93f48e39e3e9af884acc8ddd518c45e4"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">cattle::KernelLayer::is_input_layer</a></div><div class="ttdeci">bool is_input_layer() const</div><div class="ttdoc">A constant method that returns whether this layer functions as an input layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:375</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4_html_a44c8abc3fc0c11875969a0586fbb2f95"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#a44c8abc3fc0c11875969a0586fbb2f95">cattle::DeconvKernelLayer&lt; Scalar, 2 &gt;::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1520</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4_html_ab151ba52fa5ab583252c75af73555274"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_012_01_4.html#ab151ba52fa5ab583252c75af73555274">cattle::DeconvKernelLayer&lt; Scalar, 2 &gt;::DeconvKernelLayer</a></div><div class="ttdeci">DeconvKernelLayer(const Dimensions&lt; std::size_t, 2 &gt; &amp;input_dims, std::size_t filters, WeightInitSharedPtr&lt; Scalar &gt; weight_init, ParamRegSharedPtr&lt; Scalar &gt; weight_reg=Root::NO_PARAM_REG, std::size_t receptor_height=3, std::size_t receptor_width=3, std::size_t vertical_padding=1, std::size_t horizontal_padding=1, std::size_t vertical_stride=1, std::size_t horizontal_stride=1, std::size_t vertical_dilation=0, std::size_t horizontal_dilation=0, Scalar max_norm_constraint=0)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1512</div></div>
<div class="ttc" id="classcattle_1_1_dense_kernel_layer_html_a131a2e0c7b6ae0faf070555bda0d39a6"><div class="ttname"><a href="classcattle_1_1_dense_kernel_layer.html#a131a2e0c7b6ae0faf070555bda0d39a6">cattle::DenseKernelLayer::DenseKernelLayer</a></div><div class="ttdeci">DenseKernelLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;input_dims, std::size_t output_size, WeightInitSharedPtr&lt; Scalar &gt; weight_init, ParamRegSharedPtr&lt; Scalar &gt; weight_reg=Root::NO_PARAM_REG, Scalar max_norm_constraint=0)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:436</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_base_html"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_base.html">cattle::MaxPoolLayerBase</a></div><div class="ttdoc">An abstract class template representing a pooling layer that reduces patches of the input by taking t...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3091</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_aaa346c955d02369927de664087a32999"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#aaa346c955d02369927de664087a32999">cattle::DropoutLayer::DropoutLayer</a></div><div class="ttdeci">DropoutLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims, Scalar dropout_prob, Scalar epsilon=internal::NumericUtils&lt; Scalar &gt;::EPSILON2)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4491</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a40d43922450a2d28e36057256905403e"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a40d43922450a2d28e36057256905403e">cattle::PoolLayer::clone</a></div><div class="ttdeci">virtual Base * clone() const =0</div><div class="ttdoc">It returns a clone of the layer instance. </div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4_html_a4766dca992a2b2255a3bb8800dc00dc2"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#a4766dca992a2b2255a3bb8800dc00dc2">cattle::MaxPoolLayer&lt; Scalar, 1 &gt;::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3276</div></div>
<div class="ttc" id="classcattle_1_1_binary_step_activation_layer_html_ac4ea89bab72ee953cb38dcd31b89041e"><div class="ttname"><a href="classcattle_1_1_binary_step_activation_layer.html#ac4ea89bab72ee953cb38dcd31b89041e">cattle::BinaryStepActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1807</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_a9120bb46be48a022463aa07a35801074"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#a9120bb46be48a022463aa07a35801074">cattle::KernelLayer::get_params</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params() const</div><div class="ttdoc">It returns a constant reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:300</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_html_a12ec3c5520108283dabf16f90dc9c850"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer.html#a12ec3c5520108283dabf16f90dc9c850">cattle::ConvKernelLayer::clone_with_shared_params</a></div><div class="ttdeci">Root * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:972</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a984f124ef5a2de9b2466ccb5a591eca2"><div class="ttname"><a href="classcattle_1_1_layer.html#a984f124ef5a2de9b2466ccb5a591eca2">cattle::Layer::to_string</a></div><div class="ttdeci">virtual std::string to_string() const</div><div class="ttdef"><b>Definition:</b> Layer.hpp:168</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_ad1b665c616770249569c831b9bef076c"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ad1b665c616770249569c831b9bef076c">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::pass_back</a></div><div class="ttdeci">Base::Data pass_back(typename Base::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4175</div></div>
<div class="ttc" id="namespacecattle_html_a7dfcb4d57e2c5da3170ebd8d13fd0431"><div class="ttname"><a href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">cattle::TensorMap</a></div><div class="ttdeci">Eigen::TensorMap&lt; Tensor&lt; Scalar, Rank &gt; &gt; TensorMap</div><div class="ttdoc">An for a class that can be used to map raw pointer data to a tensor of arbitrary rank and scalar type...</div><div class="ttdef"><b>Definition:</b> EigenProxy.hpp:61</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a18b7c3f932b25b84f2bbfc80cdb6c011"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a18b7c3f932b25b84f2bbfc80cdb6c011">cattle::BroadcastLayer::BroadcastLayer</a></div><div class="ttdeci">BroadcastLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;input_dims, const Dimensions&lt; std::size_t, Rank &gt; &amp;broadcast)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3545</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a046463edd1e0b4b335cefeae6bf5b614"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a046463edd1e0b4b335cefeae6bf5b614">cattle::DropoutLayer::get_params_grad</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params_grad() const</div><div class="ttdoc">It returns a constant reference to the gradient of the learnable parameters of the layer...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4522</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_ab5d5a62101f9dfc7402d7b4b1c216f65"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#ab5d5a62101f9dfc7402d7b4b1c216f65">cattle::ReshapeLayer::set_frozen</a></div><div class="ttdeci">void set_frozen(bool frozen)</div><div class="ttdoc">It sets whether the parameters of the layer should not be updated during optimization. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4746</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a9816572e8dcfafa764bbad24e7dba8f4"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a9816572e8dcfafa764bbad24e7dba8f4">cattle::ReshapeLayer::get_input_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_input_dims() const</div><div class="ttdoc">A simple constant getter method for the input dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4731</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_ae91b49e8b4eaf586faf27c2147b3e684"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae91b49e8b4eaf586faf27c2147b3e684">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_params_owner</a></div><div class="ttdeci">const Base &amp; get_params_owner() const</div><div class="ttdoc">It returns a reference to the layer owning the parameters used. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4061</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_a403029b832ce6534577e87dbe4163ccb"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#a403029b832ce6534577e87dbe4163ccb">cattle::KernelLayer::regularize</a></div><div class="ttdeci">void regularize()</div><div class="ttdoc">It computes the derivative of the regularization function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:387</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a89ad20c1cdf2ec2de893665aa417e0f1"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a89ad20c1cdf2ec2de893665aa417e0f1">cattle::DropoutLayer::init</a></div><div class="ttdeci">void init()</div><div class="ttdoc">It initializes the layer and its parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4531</div></div>
<div class="ttc" id="classcattle_1_1_sigmoid_activation_layer_html_a6093c9a63f0a3d4a368eb9bb13aa707f"><div class="ttname"><a href="classcattle_1_1_sigmoid_activation_layer.html#a6093c9a63f0a3d4a368eb9bb13aa707f">cattle::SigmoidActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1838</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a440a12c44f35ff5cd1953efa1be1cb6c"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a440a12c44f35ff5cd1953efa1be1cb6c">cattle::BatchNormLayer::is_frozen</a></div><div class="ttdeci">bool is_frozen() const</div><div class="ttdoc">It determines whether the parameters of the layer, if there are any, are to be updated during optimiz...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3769</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_a4550c77e6341cd77a62a751eb129e44e"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#a4550c77e6341cd77a62a751eb129e44e">cattle::ActivationLayer::get_input_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_input_dims() const</div><div class="ttdoc">A simple constant getter method for the input dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1628</div></div>
<div class="ttc" id="classcattle_1_1_sigmoid_activation_layer_html_af39afa34fcfd33a14a95fc2518be1c19"><div class="ttname"><a href="classcattle_1_1_sigmoid_activation_layer.html#af39afa34fcfd33a14a95fc2518be1c19">cattle::SigmoidActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1842</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a1ffb24e855f633d0f5e8cc14e108d9fc"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a1ffb24e855f633d0f5e8cc14e108d9fc">cattle::ReshapeLayer::clone_with_shared_params</a></div><div class="ttdeci">Base * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4725</div></div>
<div class="ttc" id="classcattle_1_1_tanh_activation_layer_html_ab22a9baac0d6e0285f837b8c8c8f2e07"><div class="ttname"><a href="classcattle_1_1_tanh_activation_layer.html#ab22a9baac0d6e0285f837b8c8c8f2e07">cattle::TanhActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1947</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a616670d011b739c619fe2c8f6d14baa4"><div class="ttname"><a href="classcattle_1_1_layer.html#a616670d011b739c619fe2c8f6d14baa4">cattle::Layer::get_input_dims</a></div><div class="ttdeci">virtual const Dimensions&lt; std::size_t, Rank &gt; &amp; get_input_dims() const =0</div><div class="ttdoc">A simple constant getter method for the input dimensionality of the layer. </div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_acc0f9ba4bf27c0dec2da75196252137e"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#acc0f9ba4bf27c0dec2da75196252137e">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_output_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_output_dims() const</div><div class="ttdoc">A simple constant getter method for the output dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4067</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_a5633fa5220ac376441846002ff8ff22d"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#a5633fa5220ac376441846002ff8ff22d">cattle::KernelLayer::get_input_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_input_dims() const</div><div class="ttdoc">A simple constant getter method for the input dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:294</div></div>
<div class="ttc" id="classcattle_1_1_p_swish_activation_layer_html_a0d6f194ac78749343dbf7eb0e378cc55"><div class="ttname"><a href="classcattle_1_1_p_swish_activation_layer.html#a0d6f194ac78749343dbf7eb0e378cc55">cattle::PSwishActivationLayer::clone_with_shared_params</a></div><div class="ttdeci">Root * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2682</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_a3ea3acc95aef44eac905481020f3f946"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#a3ea3acc95aef44eac905481020f3f946">cattle::ActivationLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1699</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_a34972577a520dc5e4d34d40c448f127b"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#a34972577a520dc5e4d34d40c448f127b">cattle::ActivationLayer::set_input_layer</a></div><div class="ttdeci">void set_input_layer(bool input_layer)</div><div class="ttdoc">Sets this instance&amp;#39;s input layer status to the given value. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1685</div></div>
<div class="ttc" id="classcattle_1_1_dense_kernel_layer_html_a937d64c683eb3415c6eedfd1855c4ae0"><div class="ttname"><a href="classcattle_1_1_dense_kernel_layer.html#a937d64c683eb3415c6eedfd1855c4ae0">cattle::DenseKernelLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:455</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_activation_layer.html">cattle::ActivationLayer</a></div><div class="ttdoc">An abstract class template that represents an activation function layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1617</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4_html_a6a34796d715b879c89b3721b4cec4f7f"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#a6a34796d715b879c89b3721b4cec4f7f">cattle::DeconvKernelLayer&lt; Scalar, 1 &gt;::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1583</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_aff288c69e4af006db23d2e998d84e847"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#aff288c69e4af006db23d2e998d84e847">cattle::ActivationLayer::regularize</a></div><div class="ttdeci">void regularize()</div><div class="ttdoc">It computes the derivative of the regularization function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1694</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a496cc9b192875d633554b44b9866fd6b"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a496cc9b192875d633554b44b9866fd6b">cattle::ReshapeLayer::init</a></div><div class="ttdeci">void init()</div><div class="ttdoc">It initializes the layer and its parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4749</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4_html_a624e7117839125b1c67c1178e381064c"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#a624e7117839125b1c67c1178e381064c">cattle::MeanPoolLayer&lt; Scalar, 2 &gt;::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3020</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_html_a26a24d870ec2b776bc5c229ba01448a7"><div class="ttname"><a href="classcattle_1_1_max_pool_layer.html#a26a24d870ec2b776bc5c229ba01448a7">cattle::MaxPoolLayer::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3178</div></div>
<div class="ttc" id="classcattle_1_1_swish_activation_layer_html_ad2d918f28cb80019cde160152d85650e"><div class="ttname"><a href="classcattle_1_1_swish_activation_layer.html#ad2d918f28cb80019cde160152d85650e">cattle::SwishActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2624</div></div>
<div class="ttc" id="classcattle_1_1_binary_step_activation_layer_html_a7be1597139f721c9b5f259adadc30a8a"><div class="ttname"><a href="classcattle_1_1_binary_step_activation_layer.html#a7be1597139f721c9b5f259adadc30a8a">cattle::BinaryStepActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1803</div></div>
<div class="ttc" id="classcattle_1_1internal_1_1_cu_d_n_n_handle_html_a46b5ef9ed5403f8e934dc35038c377c9"><div class="ttname"><a href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#a46b5ef9ed5403f8e934dc35038c377c9">cattle::internal::CuDNNHandle::activation_fwd</a></div><div class="ttdeci">void activation_fwd(Scalar *input, const Array4 &amp;dims, cudnnActivationMode_t act_mode, Scalar coeff, Scalar *output) const</div><div class="ttdoc">It applies the specified activation function the the input tensor. </div><div class="ttdef"><b>Definition:</b> CuDNNHandle.hpp:313</div></div>
<div class="ttc" id="classcattle_1_1_leaky_re_l_u_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_leaky_re_l_u_activation_layer.html">cattle::LeakyReLUActivationLayer</a></div><div class="ttdoc">A class template representing a leaky rectified linear unit activation function. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2321</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html">cattle::BroadcastLayer</a></div><div class="ttdoc">A class template representing a broadcasting layer that repeats the contents of its input tensors alo...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3536</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_html"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer.html">cattle::ConvKernelLayer</a></div><div class="ttdoc">A class template for a 2D convolutional layer operating on rank-3 data batches (rank-4 tensors)...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:934</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a560c5f9614ad83cbc4429cc99a36d9b6"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a560c5f9614ad83cbc4429cc99a36d9b6">cattle::PoolLayer::get_params_grad</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params_grad() const</div><div class="ttdoc">It returns a constant reference to the gradient of the learnable parameters of the layer...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2774</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_aa2956ff7c87760f05d4e0d906ed16b10"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#aa2956ff7c87760f05d4e0d906ed16b10">cattle::KernelLayer::get_params_grad</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params_grad()</div><div class="ttdoc">It returns a reference to the gradient of the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:384</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_html_a6a011291cc3fc7a494a462f499ea3a8f"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer.html#a6a011291cc3fc7a494a462f499ea3a8f">cattle::MeanPoolLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2983</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a1f08f1fb9ee99afb1a899a38ff12adbf"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a1f08f1fb9ee99afb1a899a38ff12adbf">cattle::PoolLayer::is_input_layer</a></div><div class="ttdeci">bool is_input_layer() const</div><div class="ttdoc">A constant method that returns whether this layer functions as an input layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2835</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_html_a205e894a1bd2a0c8c0a210813c232c21"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer.html#a205e894a1bd2a0c8c0a210813c232c21">cattle::ConvKernelLayer::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:969</div></div>
<div class="ttc" id="classcattle_1_1_p_re_l_u_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_p_re_l_u_activation_layer.html">cattle::PReLUActivationLayer</a></div><div class="ttdoc">A class template representing a parametric rectified linear unit (PReLU) activation function...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2501</div></div>
<div class="ttc" id="classcattle_1_1_dim_expression_html_ae51ed9575f019bc86402615cf08e97d8"><div class="ttname"><a href="classcattle_1_1_dim_expression.html#ae51ed9575f019bc86402615cf08e97d8">cattle::DimExpression::to_string</a></div><div class="ttdeci">std::string to_string() const</div><div class="ttdoc">It evaluates the expression and returns a string containing the results. </div><div class="ttdef"><b>Definition:</b> Dimensions.hpp:293</div></div>
<div class="ttc" id="classcattle_1_1_softmax_activation_layer_html_a2a8be6bee1fb6cf884f4f2d3f613257a"><div class="ttname"><a href="classcattle_1_1_softmax_activation_layer.html#a2a8be6bee1fb6cf884f4f2d3f613257a">cattle::SoftmaxActivationLayer::SoftmaxActivationLayer</a></div><div class="ttdeci">SoftmaxActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims, Scalar epsilon=internal::NumericUtils&lt; Scalar &gt;::EPSILON2)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2109</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a64e546b9acecda042790ba1a19527d5d"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a64e546b9acecda042790ba1a19527d5d">cattle::BatchNormLayer::get_output_dims</a></div><div class="ttdeci">const Dimensions&lt; std::size_t, Rank &gt; &amp; get_output_dims() const</div><div class="ttdoc">A simple constant getter method for the output dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3760</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_ae01fe5aa00615cab21ac81babf2756b2"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae01fe5aa00615cab21ac81babf2756b2">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::pass_forward</a></div><div class="ttdeci">Base::Data pass_forward(typename Base::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4150</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a971e2f47a2e4f46e859b17dc60e07910"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a971e2f47a2e4f46e859b17dc60e07910">cattle::PoolLayer::get_regularization_penalty</a></div><div class="ttdeci">Scalar get_regularization_penalty() const</div><div class="ttdoc">It calculates the regularization penalty of the layer&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2848</div></div>
<div class="ttc" id="classcattle_1_1_softplus_activation_layer_html_a4cff59f6b0eab448d9ca41ba99261c31"><div class="ttname"><a href="classcattle_1_1_softplus_activation_layer.html#a4cff59f6b0eab448d9ca41ba99261c31">cattle::SoftplusActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2071</div></div>
<div class="ttc" id="classcattle_1_1_re_l_u_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_re_l_u_activation_layer.html">cattle::ReLUActivationLayer</a></div><div class="ttdoc">A class template representing a rectified linear unit (ReLU) activation function. ...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2219</div></div>
<div class="ttc" id="classcattle_1_1_sigmoid_activation_layer_html_aa5501e54efa3a5ec8bc7e1dc7025d102"><div class="ttname"><a href="classcattle_1_1_sigmoid_activation_layer.html#aa5501e54efa3a5ec8bc7e1dc7025d102">cattle::SigmoidActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1845</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4_html_ae48c09c01819911fb2ed189b0203beb1"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#ae48c09c01819911fb2ed189b0203beb1">cattle::MeanPoolLayer&lt; Scalar, 1 &gt;::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3073</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_aae685cf7e708e0c4f32ddc4c10254046"><div class="ttname"><a href="classcattle_1_1_layer.html#aae685cf7e708e0c4f32ddc4c10254046">cattle::Layer::regularize</a></div><div class="ttdeci">virtual void regularize()=0</div><div class="ttdoc">It computes the derivative of the regularization function w.r.t. </div></div>
<div class="ttc" id="classcattle_1_1_softsign_activation_layer_html_a02f3977bb217af6dd52f0dcb63120bcd"><div class="ttname"><a href="classcattle_1_1_softsign_activation_layer.html#a02f3977bb217af6dd52f0dcb63120bcd">cattle::SoftsignActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2021</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_html_aea2085455b95f06f2046085af0275a67"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer.html#aea2085455b95f06f2046085af0275a67">cattle::MeanPoolLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2989</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_af82f4022e6bbd0c328729342d18432cd"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#af82f4022e6bbd0c328729342d18432cd">cattle::DropoutLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4539</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4_html_a56ae483bf59bf85c8e01416f79f4b13c"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_3_01_scalar_00_011_01_4.html#a56ae483bf59bf85c8e01416f79f4b13c">cattle::DeconvKernelLayer&lt; Scalar, 1 &gt;::clone_with_shared_params</a></div><div class="ttdeci">Root * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1586</div></div>
<div class="ttc" id="classcattle_1_1_swish_activation_layer_html_a5434963c7955b090aed37844ab47441b"><div class="ttname"><a href="classcattle_1_1_swish_activation_layer.html#a5434963c7955b090aed37844ab47441b">cattle::SwishActivationLayer::pass_back</a></div><div class="ttdeci">Root::Data pass_back(typename Root::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2635</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4_html_a4dd7371a50d43f13cc46642296c0a248"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#a4dd7371a50d43f13cc46642296c0a248">cattle::MeanPoolLayer&lt; Scalar, 1 &gt;::MeanPoolLayer</a></div><div class="ttdeci">MeanPoolLayer(const Dimensions&lt; std::size_t, 1 &gt; &amp;input_dims, std::size_t receptor_length=2, std::size_t stride=2)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3059</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_ae46130f5336ab1271537f28458d7a162"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#ae46130f5336ab1271537f28458d7a162">cattle::ActivationLayer::is_frozen</a></div><div class="ttdeci">bool is_frozen() const</div><div class="ttdoc">It determines whether the parameters of the layer, if there are any, are to be updated during optimiz...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1640</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_a2ff3acc579905c6a26c219caaa018993"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#a2ff3acc579905c6a26c219caaa018993">cattle::ActivationLayer::clone_with_shared_params</a></div><div class="ttdeci">Base * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1622</div></div>
<div class="ttc" id="classcattle_1_1_dim_expression_html_adae8f2ea4e6a29d65b85ea0aa2d48bd1"><div class="ttname"><a href="classcattle_1_1_dim_expression.html#adae8f2ea4e6a29d65b85ea0aa2d48bd1">cattle::DimExpression::get_volume</a></div><div class="ttdeci">IndexType get_volume() const</div><div class="ttdoc">A constant method the returns the volume of the expression. </div><div class="ttdef"><b>Definition:</b> Dimensions.hpp:273</div></div>
<div class="ttc" id="classcattle_1_1_e_l_u_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_e_l_u_activation_layer.html">cattle::ELUActivationLayer</a></div><div class="ttdoc">A class template representing an exponential linear unit (ELU) activation function. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2372</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html">cattle::BatchNormLayer</a></div><div class="ttdoc">A class template for a per-channel batch normalization layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3653</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_ab12e754d7fa7dd9cbeb77ebe50286bdd"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#ab12e754d7fa7dd9cbeb77ebe50286bdd">cattle::KernelLayer::set_frozen</a></div><div class="ttdeci">void set_frozen(bool frozen)</div><div class="ttdoc">It sets whether the parameters of the layer should not be updated during optimization. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:309</div></div>
<div class="ttc" id="classcattle_1_1_activation_layer_html_a03f8dc5fe0d781b983e4494ab8413f5f"><div class="ttname"><a href="classcattle_1_1_activation_layer.html#a03f8dc5fe0d781b983e4494ab8413f5f">cattle::ActivationLayer::init</a></div><div class="ttdeci">void init()</div><div class="ttdoc">It initializes the layer and its parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1646</div></div>
<div class="ttc" id="classcattle_1_1_scaled_activation_layer_html_ab329b830fef5bd4df9ebd9efda83b879"><div class="ttname"><a href="classcattle_1_1_scaled_activation_layer.html#ab329b830fef5bd4df9ebd9efda83b879">cattle::ScaledActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1762</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_af208065ae34cbebcdc932c84383ea159"><div class="ttname"><a href="classcattle_1_1_layer.html#af208065ae34cbebcdc932c84383ea159">cattle::Layer::is_input_layer</a></div><div class="ttdeci">virtual bool is_input_layer() const =0</div><div class="ttdoc">A constant method that returns whether this layer functions as an input layer. </div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a412548cbdf36c15ed8c96f095884e656"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a412548cbdf36c15ed8c96f095884e656">cattle::BatchNormLayer::regularize</a></div><div class="ttdeci">void regularize()</div><div class="ttdoc">It computes the derivative of the regularization function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3825</div></div>
<div class="ttc" id="classcattle_1_1_sigmoid_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_sigmoid_activation_layer.html">cattle::SigmoidActivationLayer</a></div><div class="ttdoc">A class template representing a sigmoid activation function layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1829</div></div>
<div class="ttc" id="classcattle_1_1_tanh_activation_layer_html_a7896bd20f2379a0b2e84390510219482"><div class="ttname"><a href="classcattle_1_1_tanh_activation_layer.html#a7896bd20f2379a0b2e84390510219482">cattle::TanhActivationLayer::clone</a></div><div class="ttdeci">Layer&lt; Scalar, Rank &gt; * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1930</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_html"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer.html">cattle::DeconvKernelLayer</a></div><div class="ttdoc">A class template for a transposed 2D convolutional layer operating on rank-3 data batches (rank-4 ten...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1419</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a7db2cae21bd26cc571114fe817e72577"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7db2cae21bd26cc571114fe817e72577">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_params_grad</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params_grad() const</div><div class="ttdoc">It returns a constant reference to the gradient of the learnable parameters of the layer...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:4073</div></div>
<div class="ttc" id="classcattle_1_1_layer_html_a9b9374ca0299ed3b599c0403174a79af"><div class="ttname"><a href="classcattle_1_1_layer.html#a9b9374ca0299ed3b599c0403174a79af">cattle::Layer::is_frozen</a></div><div class="ttdeci">virtual bool is_frozen() const =0</div><div class="ttdoc">It determines whether the parameters of the layer, if there are any, are to be updated during optimiz...</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a1cc2a6f67e5d6b8e7f7996a9267b7401"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a1cc2a6f67e5d6b8e7f7996a9267b7401">cattle::BatchNormLayer::pass_back</a></div><div class="ttdeci">Base::Data pass_back(typename Base::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3867</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_aa0dcd228d7973b19201ea507146d8b67"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#aa0dcd228d7973b19201ea507146d8b67">cattle::PoolLayer::regularize</a></div><div class="ttdeci">void regularize()</div><div class="ttdoc">It computes the derivative of the regularization function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2847</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a958aacf0e9f1267e7e007ba8f2822021"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a958aacf0e9f1267e7e007ba8f2822021">cattle::BatchNormLayer::enforce_constraints</a></div><div class="ttdeci">void enforce_constraints()</div><div class="ttdoc">It applies constraints such as max-norm to the parameters of the layer (if applicable). </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3832</div></div>
<div class="ttc" id="classcattle_1_1_binary_step_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_binary_step_activation_layer.html">cattle::BinaryStepActivationLayer</a></div><div class="ttdoc">A class template that represents a binary step activation function that outputs either 1 or 0 based o...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1794</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a60266bc0cc76f7639bca2541890e870b"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a60266bc0cc76f7639bca2541890e870b">cattle::DropoutLayer::get_params</a></div><div class="ttdeci">const Matrix&lt; Scalar &gt; &amp; get_params() const</div><div class="ttdoc">It returns a constant reference to the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4519</div></div>
<div class="ttc" id="classcattle_1_1_max_pool_layer_base_html_af34fe1a2706503a74ef87f2ed8364a6f"><div class="ttname"><a href="classcattle_1_1_max_pool_layer_base.html#af34fe1a2706503a74ef87f2ed8364a6f">cattle::MaxPoolLayerBase::_d_reduce</a></div><div class="ttdeci">Tensor&lt; Scalar, 4 &gt; _d_reduce(const Tensor&lt; Scalar, 4 &gt; &amp;grad, std::size_t patch_ind)</div><div class="ttdoc">Differentiates the reduction function and returns the derivative of the loss function w...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:3133</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a7837c89a4d3ac765c78507da09c35f8b"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a7837c89a4d3ac765c78507da09c35f8b">cattle::PoolLayer::init</a></div><div class="ttdeci">void init()</div><div class="ttdoc">It initializes the layer and its parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2783</div></div>
<div class="ttc" id="classcattle_1_1_p_swish_activation_layer_html_a8b8ff178771ca116934695127ed9ade8"><div class="ttname"><a href="classcattle_1_1_p_swish_activation_layer.html#a8b8ff178771ca116934695127ed9ade8">cattle::PSwishActivationLayer::get_regularization_penalty</a></div><div class="ttdeci">Scalar get_regularization_penalty() const</div><div class="ttdoc">It calculates the regularization penalty of the layer&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2704</div></div>
<div class="ttc" id="classcattle_1_1_leaky_re_l_u_activation_layer_html_aa9ac55adebb9725a86db28ed148d22f0"><div class="ttname"><a href="classcattle_1_1_leaky_re_l_u_activation_layer.html#aa9ac55adebb9725a86db28ed148d22f0">cattle::LeakyReLUActivationLayer::pass_forward</a></div><div class="ttdeci">Root::Data pass_forward(typename Root::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2339</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a1c430298492efebd89502cd1af32ab32"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a1c430298492efebd89502cd1af32ab32">cattle::BroadcastLayer::set_frozen</a></div><div class="ttdeci">void set_frozen(bool frozen)</div><div class="ttdoc">It sets whether the parameters of the layer should not be updated during optimization. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3582</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a47b9545f9324f4a039e7cd94a0f590d3"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a47b9545f9324f4a039e7cd94a0f590d3">cattle::BroadcastLayer::pass_forward</a></div><div class="ttdeci">Base::Data pass_forward(typename Base::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3605</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_html_aa7f0a5c55c5e7dc0f37b4a4fb7368551"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer.html#aa7f0a5c55c5e7dc0f37b4a4fb7368551">cattle::DeconvKernelLayer::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1452</div></div>
<div class="ttc" id="classcattle_1_1_p_swish_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_p_swish_activation_layer.html">cattle::PSwishActivationLayer</a></div><div class="ttdoc">A class template representing the parametric Swish activation function with learnable beta values...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2656</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_ae3d67e9ff5577d153ef7ce8ffc7c7e9c"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#ae3d67e9ff5577d153ef7ce8ffc7c7e9c">cattle::PoolLayer::enforce_constraints</a></div><div class="ttdeci">void enforce_constraints()</div><div class="ttdoc">It applies constraints such as max-norm to the parameters of the layer (if applicable). </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2851</div></div>
<div class="ttc" id="classcattle_1_1_deconv_kernel_layer_base_html"><div class="ttname"><a href="classcattle_1_1_deconv_kernel_layer_base.html">cattle::DeconvKernelLayerBase</a></div><div class="ttdoc">An abstract base class template for a transposed 2D convolutional layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:1131</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a220d347e28e8456fbaa42e8b37ff565d"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a220d347e28e8456fbaa42e8b37ff565d">cattle::BatchNormLayer::pass_forward</a></div><div class="ttdeci">Base::Data pass_forward(typename Base::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3845</div></div>
<div class="ttc" id="namespacecattle_html_afe8803bdb57fb149be7d7b7916f30ca9"><div class="ttname"><a href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">cattle::MatrixMap</a></div><div class="ttdeci">Eigen::Map&lt; Matrix&lt; Scalar &gt; &gt; MatrixMap</div><div class="ttdoc">An alias for a class that can be used to map raw pointer data to a dynamically sized Matrix of an arb...</div><div class="ttdef"><b>Definition:</b> EigenProxy.hpp:48</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a97b185d4e3ccda64313d234d7cc38a86"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a97b185d4e3ccda64313d234d7cc38a86">cattle::BroadcastLayer::enforce_constraints</a></div><div class="ttdeci">void enforce_constraints()</div><div class="ttdoc">It applies constraints such as max-norm to the parameters of the layer (if applicable). </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3604</div></div>
<div class="ttc" id="classcattle_1_1_neural_network_html"><div class="ttname"><a href="classcattle_1_1_neural_network.html">cattle::NeuralNetwork</a></div><div class="ttdoc">An abstract neural network class template. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:59</div></div>
<div class="ttc" id="classcattle_1_1_mean_pool_layer_html_a78fe029b0af419a4a04fd0526e444445"><div class="ttname"><a href="classcattle_1_1_mean_pool_layer.html#a78fe029b0af419a4a04fd0526e444445">cattle::MeanPoolLayer::clone</a></div><div class="ttdeci">Root * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:2979</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_a197971b8fe62e3c29177e5c28ff6f5f2"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#a197971b8fe62e3c29177e5c28ff6f5f2">cattle::KernelLayer::get_regularization_penalty</a></div><div class="ttdeci">Scalar get_regularization_penalty() const</div><div class="ttdoc">It calculates the regularization penalty of the layer&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:391</div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_a3e97c445cb968e46fa032db7639f0177"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#a3e97c445cb968e46fa032db7639f0177">cattle::BroadcastLayer::get_params_grad</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params_grad()</div><div class="ttdoc">It returns a reference to the gradient of the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3597</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_a88b451faf349bb303657bc6c6d60abf8"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#a88b451faf349bb303657bc6c6d60abf8">cattle::PoolLayer::_d_reduce</a></div><div class="ttdeci">virtual Tensor&lt; Scalar, 4 &gt; _d_reduce(const Tensor&lt; Scalar, 4 &gt; &amp;grad, std::size_t patch_ind)=0</div><div class="ttdoc">Differentiates the reduction function and returns the derivative of the loss function w...</div></div>
<div class="ttc" id="classcattle_1_1_dropout_layer_html_a21cafbb1c42e3fd63551e4056eaa9d8a"><div class="ttname"><a href="classcattle_1_1_dropout_layer.html#a21cafbb1c42e3fd63551e4056eaa9d8a">cattle::DropoutLayer::enforce_constraints</a></div><div class="ttdeci">void enforce_constraints()</div><div class="ttdoc">It applies constraints such as max-norm to the parameters of the layer (if applicable). </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4552</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a617e18072bd65f87b90072d9d1288d95"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a617e18072bd65f87b90072d9d1288d95">cattle::BatchNormLayer::is_input_layer</a></div><div class="ttdeci">bool is_input_layer() const</div><div class="ttdoc">A constant method that returns whether this layer functions as an input layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3809</div></div>
<div class="ttc" id="classcattle_1_1_kernel_layer_html_af6cb82a9e05d72dc92d8a36274e71a63"><div class="ttname"><a href="classcattle_1_1_kernel_layer.html#af6cb82a9e05d72dc92d8a36274e71a63">cattle::KernelLayer::init</a></div><div class="ttdeci">void init()</div><div class="ttdoc">It initializes the layer and its parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:312</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_aa8a04f59b19fa5eb664ca14fc9222a96"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#aa8a04f59b19fa5eb664ca14fc9222a96">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::regularize</a></div><div class="ttdeci">void regularize()</div><div class="ttdoc">It computes the derivative of the regularization function w.r.t. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4130</div></div>
<div class="ttc" id="classcattle_1_1_p_swish_activation_layer_html_ac760278b4e9f632d4bfea91bd22b1ccf"><div class="ttname"><a href="classcattle_1_1_p_swish_activation_layer.html#ac760278b4e9f632d4bfea91bd22b1ccf">cattle::PSwishActivationLayer::PSwishActivationLayer</a></div><div class="ttdeci">PSwishActivationLayer(const Dimensions&lt; std::size_t, Rank &gt; &amp;dims, ParamRegSharedPtr&lt; Scalar &gt; param_reg=Root::NO_PARAM_REG, Scalar init_beta=1e-1, Scalar max_norm_constraint=0)</div><div class="ttdef"><b>Definition:</b> Layer.hpp:2669</div></div>
<div class="ttc" id="classcattle_1_1_identity_activation_layer_html"><div class="ttname"><a href="classcattle_1_1_identity_activation_layer.html">cattle::IdentityActivationLayer</a></div><div class="ttdoc">A class template representing an identity activation layer that merely outputs its input...</div><div class="ttdef"><b>Definition:</b> Layer.hpp:1717</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_ad7b183d5305bfb0303d9284c0c9b833e"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ad7b183d5305bfb0303d9284c0c9b833e">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::set_frozen</a></div><div class="ttdeci">void set_frozen(bool frozen)</div><div class="ttdoc">It sets whether the parameters of the layer should not be updated during optimization. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4079</div></div>
<div class="ttc" id="classcattle_1_1_pool_layer_html_af4ba868123db71633f79628f5112fa06"><div class="ttname"><a href="classcattle_1_1_pool_layer.html#af4ba868123db71633f79628f5112fa06">cattle::PoolLayer::_reduce</a></div><div class="ttdeci">virtual Tensor&lt; Scalar, 4 &gt; _reduce(const Tensor&lt; Scalar, 4 &gt; &amp;patch, std::size_t patch_ind)=0</div><div class="ttdoc">Reduces the input tensor patch along the specified ranks. </div></div>
<div class="ttc" id="classcattle_1_1_broadcast_layer_html_afc538c1dccf3c50e090356562456fb23"><div class="ttname"><a href="classcattle_1_1_broadcast_layer.html#afc538c1dccf3c50e090356562456fb23">cattle::BroadcastLayer::init</a></div><div class="ttdeci">void init()</div><div class="ttdoc">It initializes the layer and its parameters. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:3585</div></div>
<div class="ttc" id="classcattle_1_1_conv_kernel_layer_base_html"><div class="ttname"><a href="classcattle_1_1_conv_kernel_layer_base.html">cattle::ConvKernelLayerBase</a></div><div class="ttdoc">An abstract base class template for a 2D convolutional layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:529</div></div>
<div class="ttc" id="classcattle_1_1_reshape_layer_html_a75bbccc82caf137479054b0bd926602a"><div class="ttname"><a href="classcattle_1_1_reshape_layer.html#a75bbccc82caf137479054b0bd926602a">cattle::ReshapeLayer::get_params_grad</a></div><div class="ttdeci">Matrix&lt; Scalar &gt; &amp; get_params_grad()</div><div class="ttdoc">It returns a reference to the gradient of the learnable parameters of the layer. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:4761</div></div>
<div class="ttc" id="classcattle_1_1internal_1_1_cu_d_n_n_handle_html_ae6ca224fc2b1b651fa8076e95b477cad"><div class="ttname"><a href="classcattle_1_1internal_1_1_cu_d_n_n_handle.html#ae6ca224fc2b1b651fa8076e95b477cad">cattle::internal::CuDNNHandle::softmax_fwd</a></div><div class="ttdeci">void softmax_fwd(Scalar *input, const Array4 &amp;dims, Scalar *output) const</div><div class="ttdoc">It applies the softmax activation function the the input tensor. </div><div class="ttdef"><b>Definition:</b> CuDNNHandle.hpp:383</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
