<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: C:/Users/Viktor/git/C-ATTL3/C-ATTL3/layer/BatchNormLayer.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_b8183163ce8e0490cf11c57c211e66be.html">C-ATTL3</a></li><li class="navelem"><a class="el" href="dir_ab7907026134b3eebf54833ae6eb8947.html">layer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">BatchNormLayer.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/*</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"> * BatchNormLayer.hpp</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> *  Created on: 24 Jul 2018</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> *      Author: Viktor Csomor</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#ifndef C_ATTL3_LAYER_BATCHNORMLAYER_H_</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#define C_ATTL3_LAYER_BATCHNORMLAYER_H_</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &lt;array&gt;</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &lt;cassert&gt;</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &lt;utility&gt;</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &quot;core/Layer.hpp&quot;</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &quot;core/NumericUtils.hpp&quot;</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &quot;parameter_initialization/OneParameterInitialization.hpp&quot;</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include &quot;parameter_initialization/ZeroParameterInitialization.hpp&quot;</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#include &quot;parameters/HostParameters.hpp&quot;</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacecattle.html">cattle</a> {</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank, <span class="keywordtype">bool</span> PerLastRank = (Rank == 3)&gt;</div><div class="line"><a name="l00029"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html">   29</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer&lt;Scalar,Rank,PerLastRank&gt;</a> <a class="code" href="classcattle_1_1_batch_norm_layer.html">Self</a>;</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;    <span class="keyword">typedef</span> std::array&lt;std::size_t,Base::DATA_RANK&gt; RankwiseArray;</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;    <span class="keyword">typedef</span> std::shared_ptr&lt;HostParameters&lt;Scalar&gt;&gt; HostParamsSharedPtr;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00066"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a8d219fcba0da06256568e4fa61a6ade7">   66</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a8d219fcba0da06256568e4fa61a6ade7">BatchNormLayer</a>(<span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classcattle_1_1_dimensions.html">Base::Dims</a>&amp; dims, Scalar norm_avg_decay = .1,</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;            Scalar epsilon = <a class="code" href="classcattle_1_1_numeric_utils.html">NumericUtils&lt;Scalar&gt;::EPSILON2</a>, <a class="code" href="namespacecattle.html#a8ea9ee634a3a9e87dbc4635d9f14320a">ParamRegSharedPtr&lt;Scalar&gt;</a> gamma_reg = <span class="keyword">nullptr</span>,</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;            Scalar gamma_clip = 0, Scalar gamma_max_l1_norm = 0, Scalar gamma_max_l2_norm = 0,</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;            Scalar gamma_grad_clip = 0, Scalar gamma_grad_max_l1_norm = 0, Scalar gamma_grad_max_l2_norm = 0,</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;            <a class="code" href="namespacecattle.html#a8ea9ee634a3a9e87dbc4635d9f14320a">ParamRegSharedPtr&lt;Scalar&gt;</a> beta_reg = <span class="keyword">nullptr</span>, Scalar beta_clip = 0, Scalar beta_max_l1_norm = 0,</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;            Scalar beta_max_l2_norm = 0, Scalar beta_grad_clip = 0, Scalar beta_grad_max_l1_norm = 0,</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;            Scalar beta_grad_max_l2_norm = 0) :</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;                owner(*this),</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;                dims(dims),</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;                norm_avg_decay(norm_avg_decay),</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;                epsilon(epsilon),</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;                channels(dims(Rank - 1)),</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;                input_layer(false),</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;                offsets(),</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;                extents(dims.template promote&lt;&gt;()),</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;                memb_vec(channels) {</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;        assert(norm_avg_decay &gt;= 0 &amp;&amp; norm_avg_decay &lt;= 1 &amp;&amp;</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;                <span class="stringliteral">&quot;norm avg decay must not be less than 0 or greater than 1&quot;</span>);</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;        assert(epsilon &gt; 0 &amp;&amp; <span class="stringliteral">&quot;epsilon must be greater than 0&quot;</span>);</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;        offsets.fill(0);</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;        extents[Rank] = 1;</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;        <span class="keyword">auto</span> gamma_init = std::make_shared&lt;OneParameterInitialization&lt;Scalar&gt;&gt;();</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;        <span class="keyword">auto</span> beta_init = std::make_shared&lt;ZeroParameterInitialization&lt;Scalar&gt;&gt;();</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt; channels; ++i) {</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;            ChannelSpecificMembers&amp; memb = memb_vec[i];</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;            memb.avg_means = std::make_shared&lt;HostParameters&lt;Scalar&gt;&gt;(1, 1, <span class="keyword">false</span>);</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;            memb.avg_inv_sds = std::make_shared&lt;HostParameters&lt;Scalar&gt;&gt;(1, 1, <span class="keyword">false</span>);</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;            memb.gammas = std::make_shared&lt;HostParameters&lt;Scalar&gt;&gt;(1, 1, <span class="keyword">true</span>, gamma_init, gamma_reg,</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;                    gamma_clip, gamma_max_l1_norm, gamma_max_l2_norm, gamma_grad_clip, gamma_grad_max_l1_norm,</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;                    gamma_grad_max_l2_norm);</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;            memb.betas = std::make_shared&lt;HostParameters&lt;Scalar&gt;&gt;(1, 1, <span class="keyword">true</span>, beta_init, beta_reg, beta_clip,</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;                    beta_max_l1_norm, beta_max_l2_norm, beta_grad_clip, beta_grad_max_l1_norm,</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;                    beta_grad_max_l2_norm);</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;            memb.avgs_init = <span class="keyword">false</span>;</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;        }</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;    }</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a8d219fcba0da06256568e4fa61a6ade7">BatchNormLayer</a>(<span class="keyword">const</span> Self&amp; layer, <span class="keywordtype">bool</span> share_params = <span class="keyword">false</span>) :</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;            owner(share_params ? layer.owner : *this),</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;            dims(layer.dims),</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;            norm_avg_decay(layer.norm_avg_decay),</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;            epsilon(layer.epsilon),</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;            channels(layer.channels),</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;            offsets(layer.offsets),</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;            extents(layer.extents),</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;            memb_vec(channels) {</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt; channels; ++i) {</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;            ChannelSpecificMembers&amp; memb1 = memb_vec[i];</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;            <span class="keyword">const</span> ChannelSpecificMembers&amp; memb2 = layer.memb_vec[i];</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;            <span class="keywordflow">if</span> (share_params) {</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;                memb1.avg_means = memb2.avg_means;</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;                memb1.avg_inv_sds = memb2.avg_inv_sds;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;                memb1.gammas = memb2.gammas;</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;                memb1.betas = memb2.betas;</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;            } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;                memb1.avg_means = HostParamsSharedPtr(<span class="keyword">static_cast&lt;</span>HostParameters&lt;Scalar&gt;*<span class="keyword">&gt;</span>(</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;                        memb2.avg_means-&gt;clone()));</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;                memb1.avg_inv_sds = HostParamsSharedPtr(<span class="keyword">static_cast&lt;</span>HostParameters&lt;Scalar&gt;*<span class="keyword">&gt;</span>(</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;                        memb2.avg_inv_sds-&gt;clone()));</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;                memb1.gammas = HostParamsSharedPtr(<span class="keyword">static_cast&lt;</span>HostParameters&lt;Scalar&gt;*<span class="keyword">&gt;</span>(</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;                        memb2.gammas-&gt;clone()));</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;                memb1.betas = HostParamsSharedPtr(<span class="keyword">static_cast&lt;</span>HostParameters&lt;Scalar&gt;*<span class="keyword">&gt;</span>(</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;                        memb2.betas-&gt;clone()));</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;            }</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;            memb1.avgs_init = memb2.avgs_init;</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;            memb1.inv_in_sd_cache = memb2.inv_in_sd_cache;</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;            memb1.std_in_mat_cache = memb2.std_in_mat_cache;</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;        }</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;    }</div><div class="line"><a name="l00135"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a7e23442f814d994e2989724901001202">  135</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_batch_norm_layer.html#a7e23442f814d994e2989724901001202">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a8d219fcba0da06256568e4fa61a6ade7">BatchNormLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;    }</div><div class="line"><a name="l00138"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#ab40438ea8902e5bbba29ff6d23b4f187">  138</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_batch_norm_layer.html#ab40438ea8902e5bbba29ff6d23b4f187">clone_with_shared_params</a>() {</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a8d219fcba0da06256568e4fa61a6ade7">BatchNormLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;    }</div><div class="line"><a name="l00141"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#ad64fb5495e73699d97714883a77056e8">  141</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer.html#ad64fb5495e73699d97714883a77056e8">get_params_owner</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;        <span class="keywordflow">return</span> owner;</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;    }</div><div class="line"><a name="l00144"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#aebba427879529275913f3f560ec42c5b">  144</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classcattle_1_1_dimensions.html">Base::Dims</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer.html#aebba427879529275913f3f560ec42c5b">get_input_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    }</div><div class="line"><a name="l00147"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a85b0b9559f66fe833daffa9936cfee94">  147</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classcattle_1_1_dimensions.html">Base::Dims</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer.html#a85b0b9559f66fe833daffa9936cfee94">get_output_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;    }</div><div class="line"><a name="l00150"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a617e18072bd65f87b90072d9d1288d95">  150</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a617e18072bd65f87b90072d9d1288d95">is_input_layer</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;    }</div><div class="line"><a name="l00153"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a66300725f60f30bd773d47f2dea19f46">  153</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a66300725f60f30bd773d47f2dea19f46">set_input_layer</a>(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;    }</div><div class="line"><a name="l00156"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a97015b85d3e5536b61d093296bad432d">  156</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;const Parameters&lt;Scalar&gt;*&gt; <a class="code" href="classcattle_1_1_batch_norm_layer.html#a97015b85d3e5536b61d093296bad432d">get_params</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;        std::vector&lt;const Parameters&lt;Scalar&gt;*&gt; params_vec;</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;        populate_params_vector&lt;const Parameters&lt;Scalar&gt;*&gt;(params_vec);</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;        <span class="keywordflow">return</span> params_vec;</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;    }</div><div class="line"><a name="l00161"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#ac30864573717c53a6e6f7b29b69c3136">  161</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;Parameters&lt;Scalar&gt;*&gt; <a class="code" href="classcattle_1_1_batch_norm_layer.html#ac30864573717c53a6e6f7b29b69c3136">get_params</a>() {</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;        std::vector&lt;Parameters&lt;Scalar&gt;*&gt; params_vec;</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;        populate_params_vector&lt;Parameters&lt;Scalar&gt;*&gt;(params_vec);</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;        <span class="keywordflow">return</span> params_vec;</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;    }</div><div class="line"><a name="l00166"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#ae82d6c00d3f84d865324c51bcb5ab90c">  166</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#ae82d6c00d3f84d865324c51bcb5ab90c">empty_cache</a>() {</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; memb_vec.size(); ++i)</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;            memb_vec[i].std_in_mat_cache = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>();</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;    }</div><div class="line"><a name="l00170"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a220d347e28e8456fbaa42e8b37ff565d">  170</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_batch_norm_layer.html#a220d347e28e8456fbaa42e8b37ff565d">pass_forward</a>(<span class="keyword">typename</span> Base::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;        extents[0] = rows;</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;        <span class="keyword">typename</span> Base::Data out;</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;        <span class="keywordflow">if</span> (channels == 1) {</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;            <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> in_mat(in.data(), rows, in.size() / rows);</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;            <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out_mat = _pass_forward(in_mat, 0, training);</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;            out = <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(out_mat.data(), extents);</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;            out = <span class="keyword">typename</span> Base::Data(in.dimensions());</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;            <span class="keywordflow">for</span> (std::size_t i = 0; i &lt; channels; ++i) {</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;                offsets[Rank] = i;</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;                <span class="keyword">typename</span> Base::Data in_slice = in.slice(offsets, extents);</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;                <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> in_slice_mat(in_slice.data(), rows, in_slice.size() / rows);</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;                <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out_slice_mat = _pass_forward(in_slice_mat, i, training);</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;                out.slice(offsets, extents) = <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(out_slice_mat.data(), extents);</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;            }</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;        }</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;    }</div><div class="line"><a name="l00192"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer.html#a1cc2a6f67e5d6b8e7f7996a9267b7401">  192</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_batch_norm_layer.html#a1cc2a6f67e5d6b8e7f7996a9267b7401">pass_back</a>(<span class="keyword">typename</span> Base::Data out_grad) {</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; extents[0] == out_grad.dimension(0));</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;        std::size_t rows = out_grad.dimension(0);</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;        <span class="keyword">typename</span> Base::Data prev_out_grad;</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;        <span class="keywordflow">if</span> (channels == 1) {</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;            <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> out_grad_mat(out_grad.data(), rows, out_grad.size() / rows);</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;            <span class="keywordflow">if</span> (input_layer) {</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;                _pass_back(out_grad_mat, 0);</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;                <span class="keywordflow">return</span> <span class="keyword">typename</span> Base::Data();</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;            } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;                <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> prev_out_grad_mat = _pass_back(out_grad_mat, 0);</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;                prev_out_grad = <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(prev_out_grad_mat.data(), extents);</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;            }</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;            prev_out_grad = input_layer ? <span class="keyword">typename</span> Base::Data() : <span class="keyword">typename</span> Base::Data(out_grad.dimensions());</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;            <span class="keywordflow">for</span> (std::size_t i = 0; i &lt; channels; ++i) {</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;                offsets[Rank] = i;</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;                <span class="keyword">typename</span> Base::Data out_grad_slice = out_grad.slice(offsets, extents);</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;                <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> out_grad_slice_mat(out_grad_slice.data(), rows, out_grad_slice.size() / rows);</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;                <span class="keywordflow">if</span> (input_layer) {</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;                    _pass_back(out_grad_slice_mat, i);</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;                    <span class="keywordflow">continue</span>;</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;                } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;                    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> prev_out_grad_slice_mat = _pass_back(out_grad_slice_mat, i);</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;                    prev_out_grad.slice(offsets, extents) =</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;                            <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(prev_out_grad_slice_mat.data(), extents);</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;                }</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;            }</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;        }</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;        <span class="keywordflow">return</span> prev_out_grad;</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;    }</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;    <span class="keyword">inline</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> _pass_forward(<a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a>&amp; in, std::size_t i, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out_mat;</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;        ChannelSpecificMembers&amp; memb = memb_vec[i];</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;            Scalar mean = in.mean();</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;            <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> norm_in_mat = in.array() - mean;</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;            memb.inv_in_sd_cache = 1 / sqrt(norm_in_mat.array().square().mean() + epsilon);</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;            memb.std_in_mat_cache = norm_in_mat * memb.inv_in_sd_cache;</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;            out_mat = memb.std_in_mat_cache;</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;            <span class="keywordflow">if</span> (memb.avgs_init) {</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;                memb.avg_means-&gt;set_values((1 - norm_avg_decay) * memb.avg_means-&gt;get_values().array() +</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;                        norm_avg_decay * mean);</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;                memb.avg_inv_sds-&gt;set_values((1 - norm_avg_decay) * memb.avg_inv_sds-&gt;get_values().array() +</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;                        norm_avg_decay * memb.inv_in_sd_cache);</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;            } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;                memb.avg_means-&gt;set_values(Matrix&lt;Scalar&gt;::Constant(1, 1, mean));</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;                memb.avg_inv_sds-&gt;set_values(Matrix&lt;Scalar&gt;::Constant(1, 1, memb.inv_in_sd_cache));</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;                memb.avgs_init = <span class="keyword">true</span>;</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;            }</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;            assert(memb.avgs_init);</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;            out_mat = (in.array() - memb.avg_means-&gt;get_values()(0,0)) * memb.avg_inv_sds-&gt;get_values()(0,0);</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;        }</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;        <span class="keywordflow">return</span> (out_mat * memb.gammas-&gt;get_values()(0,0)).array() + memb.betas-&gt;get_values()(0,0);</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;    }</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;    <span class="keyword">inline</span> Matrix&lt;Scalar&gt; _pass_back(MatrixMap&lt;Scalar&gt;&amp; out_grad, std::size_t i) {</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;        ChannelSpecificMembers&amp; memb = memb_vec[i];</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;        memb.gammas-&gt;accumulate_grad(Matrix&lt;Scalar&gt;::Constant(1, 1,</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;                out_grad.cwiseProduct(memb.std_in_mat_cache).sum()));</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;        memb.betas-&gt;accumulate_grad(Matrix&lt;Scalar&gt;::Constant(1, 1, out_grad.sum()));</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;        <span class="keywordflow">if</span> (input_layer)</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;            <span class="keywordflow">return</span> Matrix&lt;Scalar&gt;();</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;        std::size_t locations = out_grad.size();</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;        Matrix&lt;Scalar&gt; std_in_grad_mat = out_grad * memb.gammas-&gt;get_values()(0,0);</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;        <span class="keywordflow">return</span> (((locations * std_in_grad_mat).array() - std_in_grad_mat.sum()).matrix() -</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;                memb.std_in_mat_cache * memb.std_in_mat_cache.cwiseProduct(std_in_grad_mat).sum()) *</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;                (((Scalar) 1 / locations) * memb.inv_in_sd_cache);</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;    }</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> _ParamsPtr&gt;</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> populate_params_vector(std::vector&lt;_ParamsPtr&gt;&amp; params_vec)<span class="keyword"> const </span>{</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;        <span class="keywordflow">for</span> (std::size_t i = 0; i &lt; channels; ++i) {</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;            <span class="keyword">const</span> ChannelSpecificMembers&amp; memb = memb_vec[i];</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;            params_vec.push_back(memb.avg_means.get());</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;            params_vec.push_back(memb.avg_inv_sds.get());</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;            params_vec.push_back(memb.gammas.get());</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;            params_vec.push_back(memb.betas.get());</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;        }</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;    }</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;    <span class="keyword">const</span> Self&amp; owner;</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;    <span class="keyword">const</span> <span class="keyword">typename</span> Base::Dims dims;</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;    <span class="keyword">const</span> Scalar norm_avg_decay, epsilon;</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;    <span class="keyword">const</span> std::size_t channels;</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;    RankwiseArray offsets, extents;</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;    <span class="keyword">struct </span>ChannelSpecificMembers {</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;        <span class="comment">// Dynamic batch normalization parameters.</span></div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;        HostParamsSharedPtr avg_means, avg_inv_sds;</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;        <span class="keywordtype">bool</span> avgs_init;</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;        <span class="comment">// The optimizable parameters.</span></div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;        HostParamsSharedPtr gammas, betas;</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;        <span class="comment">// Staged computation cache.</span></div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;        Scalar inv_in_sd_cache;</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;        Matrix&lt;Scalar&gt; std_in_mat_cache;</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;    };</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;    std::vector&lt;ChannelSpecificMembers&gt; memb_vec;</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;};</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar, std::<span class="keywordtype">size_t</span> Rank&gt;</div><div class="line"><a name="l00298"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html">  298</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1_batch_norm_layer.html">BatchNormLayer</a>&lt;Scalar,Rank,false&gt; : <span class="keyword">public</span> <a class="code" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt; {</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_layer.html">Layer&lt;Scalar,Rank&gt;</a> <a class="code" href="classcattle_1_1_layer.html">Base</a>;</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html">BatchNormLayer&lt;Scalar,Rank,false&gt;</a> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html">Self</a>;</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;    <span class="keyword">typedef</span> std::shared_ptr&lt;HostParameters&lt;Scalar&gt;&gt; HostParamsSharedPtr;</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00334"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a6ae09223dbd4d038abab1e99fb6fb281">  334</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a6ae09223dbd4d038abab1e99fb6fb281">BatchNormLayer</a>(<span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classcattle_1_1_dimensions.html">Base::Dims</a>&amp; dims, Scalar norm_avg_decay = .1,</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;            Scalar epsilon = <a class="code" href="classcattle_1_1_numeric_utils.html">NumericUtils&lt;Scalar&gt;::EPSILON2</a>, <a class="code" href="namespacecattle.html#a8ea9ee634a3a9e87dbc4635d9f14320a">ParamRegSharedPtr&lt;Scalar&gt;</a> gamma_reg = <span class="keyword">nullptr</span>,</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;            Scalar gamma_clip = 0, Scalar gamma_max_l1_norm = 0, Scalar gamma_max_l2_norm = 0,</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;            Scalar gamma_grad_clip = 0, Scalar gamma_grad_max_l1_norm = 0, Scalar gamma_grad_max_l2_norm = 0,</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;            <a class="code" href="namespacecattle.html#a8ea9ee634a3a9e87dbc4635d9f14320a">ParamRegSharedPtr&lt;Scalar&gt;</a> beta_reg = <span class="keyword">nullptr</span>, Scalar beta_clip = 0, Scalar beta_max_l1_norm = 0,</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;            Scalar beta_max_l2_norm = 0, Scalar beta_grad_clip = 0, Scalar beta_grad_max_l1_norm = 0,</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;            Scalar beta_grad_max_l2_norm = 0) :</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;                owner(*this),</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;                dims(dims),</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;                norm_avg_decay(norm_avg_decay),</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;                epsilon(epsilon),</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;                avg_means(std::make_shared&lt;HostParameters&lt;Scalar&gt;&gt;(1, dims.get_volume(), false)),</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;                avg_inv_sds(std::make_shared&lt;HostParameters&lt;Scalar&gt;&gt;(1, dims.get_volume(), false)),</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;                avgs_init(false),</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;                gammas(std::make_shared&lt;HostParameters&lt;Scalar&gt;&gt;(1, dims.get_volume(), true,</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;                        std::make_shared&lt;<a class="code" href="classcattle_1_1_one_parameter_initialization.html">OneParameterInitialization</a>&lt;Scalar&gt;&gt;(), gamma_reg, gamma_clip,</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;                        gamma_max_l1_norm, gamma_max_l2_norm, gamma_grad_clip, gamma_grad_max_l1_norm,</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;                        gamma_grad_max_l2_norm)),</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;                betas(std::make_shared&lt;HostParameters&lt;Scalar&gt;&gt;(1, dims.get_volume(), true,</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;                        std::make_shared&lt;<a class="code" href="classcattle_1_1_zero_parameter_initialization.html">ZeroParameterInitialization</a>&lt;Scalar&gt;&gt;(), beta_reg, beta_clip,</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;                        beta_max_l1_norm, beta_max_l2_norm, beta_grad_clip, beta_grad_max_l1_norm,</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;                        beta_grad_max_l2_norm)),</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;                input_layer(false) {</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;        assert(norm_avg_decay &gt;= 0 &amp;&amp; norm_avg_decay &lt;= 1 &amp;&amp;</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;                <span class="stringliteral">&quot;norm avg decay must not be less than 0 or greater than 1&quot;</span>);</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;        assert(epsilon &gt; 0 &amp;&amp; <span class="stringliteral">&quot;epsilon must be greater than 0&quot;</span>);</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;    }</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a8d219fcba0da06256568e4fa61a6ade7">BatchNormLayer</a>(<span class="keyword">const</span> Self&amp; layer, <span class="keywordtype">bool</span> share_params = <span class="keyword">false</span>) :</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;            owner(share_params ? layer.owner : *this),</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;            dims(layer.dims),</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;            norm_avg_decay(layer.norm_avg_decay),</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;            epsilon(layer.epsilon),</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;            input_layer(layer.input_layer),</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;            avg_means(share_params ? layer.avg_means :</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;                    HostParamsSharedPtr(static_cast&lt;HostParameters&lt;Scalar&gt;*&gt;(layer.avg_means-&gt;<a class="code" href="classcattle_1_1_batch_norm_layer.html#a7e23442f814d994e2989724901001202">clone</a>()))),</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;            avg_inv_sds(share_params ? layer.avg_inv_sds :</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;                    HostParamsSharedPtr(static_cast&lt;HostParameters&lt;Scalar&gt;*&gt;(layer.avg_inv_sds-&gt;<a class="code" href="classcattle_1_1_batch_norm_layer.html#a7e23442f814d994e2989724901001202">clone</a>()))),</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;            avgs_init(layer.avgs_init),</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;            gammas(share_params ? layer.gammas :</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;                    HostParamsSharedPtr(static_cast&lt;HostParameters&lt;Scalar&gt;*&gt;(layer.gammas-&gt;<a class="code" href="classcattle_1_1_batch_norm_layer.html#a7e23442f814d994e2989724901001202">clone</a>()))),</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;            betas(share_params ? layer.betas :</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;                    HostParamsSharedPtr(static_cast&lt;HostParameters&lt;Scalar&gt;*&gt;(layer.betas-&gt;<a class="code" href="classcattle_1_1_batch_norm_layer.html#a7e23442f814d994e2989724901001202">clone</a>()))),</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;            inv_in_sd_cache(layer.inv_in_sd_cache),</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;            std_in_mat_cache(layer.std_in_mat_cache) { }</div><div class="line"><a name="l00378"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a18bd4016f07bfc33c27bb518066ff67b">  378</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a18bd4016f07bfc33c27bb518066ff67b">clone</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a8d219fcba0da06256568e4fa61a6ade7">BatchNormLayer</a>(*<span class="keyword">this</span>);</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;    }</div><div class="line"><a name="l00381"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ab952d37eca54ad52ec43c632ea6a7856">  381</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>* <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ab952d37eca54ad52ec43c632ea6a7856">clone_with_shared_params</a>() {</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">new</span> <a class="code" href="classcattle_1_1_batch_norm_layer.html#a8d219fcba0da06256568e4fa61a6ade7">BatchNormLayer</a>(*<span class="keyword">this</span>, <span class="keyword">true</span>);</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;    }</div><div class="line"><a name="l00384"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae91b49e8b4eaf586faf27c2147b3e684">  384</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <a class="code" href="classcattle_1_1_layer.html">Base</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae91b49e8b4eaf586faf27c2147b3e684">get_params_owner</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;        <span class="keywordflow">return</span> owner;</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;    }</div><div class="line"><a name="l00387"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a8625b962405d6a92b4b5522b937fa51f">  387</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classcattle_1_1_dimensions.html">Base::Dims</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a8625b962405d6a92b4b5522b937fa51f">get_input_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;    }</div><div class="line"><a name="l00390"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#aaee7992a15e8016e497ed85e150b1608">  390</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classcattle_1_1_dimensions.html">Base::Dims</a>&amp; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#aaee7992a15e8016e497ed85e150b1608">get_output_dims</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;        <span class="keywordflow">return</span> dims;</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;    }</div><div class="line"><a name="l00393"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7f46a6d30c7004193fef2b4b75835f28">  393</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7f46a6d30c7004193fef2b4b75835f28">is_input_layer</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;        <span class="keywordflow">return</span> input_layer;</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;    }</div><div class="line"><a name="l00396"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a6aebaf7cd158c35983c27f691c80a5bd">  396</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a6aebaf7cd158c35983c27f691c80a5bd">set_input_layer</a>(<span class="keywordtype">bool</span> input_layer) {</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;        this-&gt;input_layer = input_layer;</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;    }</div><div class="line"><a name="l00399"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#af1b61deed2a5de2a8f9805b197af3d31">  399</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;Parameters&lt;Scalar&gt;*&gt; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#af1b61deed2a5de2a8f9805b197af3d31">get_params</a>() {</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;        <span class="keywordflow">return</span> std::vector&lt;Parameters&lt;Scalar&gt;*&gt;({ avg_means.get(), avg_inv_sds.get(),</div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;                gammas.get(), betas.get() });</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;    }</div><div class="line"><a name="l00403"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a387a4e3752c6c09c7492ec02b1ea28bd">  403</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;const Parameters&lt;Scalar&gt;*&gt; <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a387a4e3752c6c09c7492ec02b1ea28bd">get_params</a>()<span class="keyword"> const  </span>{</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;        <span class="keywordflow">return</span> std::vector&lt;const Parameters&lt;Scalar&gt;*&gt;({ avg_means.get(), avg_inv_sds.get(),</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;                gammas.get(), betas.get() });</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;    }</div><div class="line"><a name="l00407"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7b62f3a8bab743a0714ec3d1c7e87506">  407</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7b62f3a8bab743a0714ec3d1c7e87506">empty_cache</a>() {</div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;        inv_in_sd_cache = <a class="code" href="namespacecattle.html#a23ebf4fefd4f6b9dc0cd34afb1ce1b65">RowVector&lt;Scalar&gt;</a>();</div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;        std_in_mat_cache = <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>();</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;    }</div><div class="line"><a name="l00411"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae01fe5aa00615cab21ac81babf2756b2">  411</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae01fe5aa00615cab21ac81babf2756b2">pass_forward</a>(<span class="keyword">typename</span> Base::Data in, <span class="keywordtype">bool</span> training) {</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(in.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;        assert(in.dimension(0) &gt; 0);</div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;        std::size_t rows = in.dimension(0);</div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;        <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> in_mat(in.data(), rows, in.size() / rows);</div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;        <span class="keywordflow">if</span> (training) {</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;            <a class="code" href="namespacecattle.html#a23ebf4fefd4f6b9dc0cd34afb1ce1b65">RowVector&lt;Scalar&gt;</a> mean_vec = in_mat.colwise().mean();</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;            <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> norm_in_mat = in_mat.rowwise() - mean_vec;</div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;            inv_in_sd_cache = (norm_in_mat.array().square().colwise().mean() + epsilon).sqrt().inverse();</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;            std_in_mat_cache = norm_in_mat * inv_in_sd_cache.asDiagonal();</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;            in_mat = std_in_mat_cache;</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;            <span class="comment">// Maintain a moving average of means and variances for testing.</span></div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;            <span class="keywordflow">if</span> (avgs_init) {</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;                avg_means-&gt;set_values((1 - norm_avg_decay) * avg_means-&gt;get_values() + norm_avg_decay * mean_vec);</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;                avg_inv_sds-&gt;set_values((1 - norm_avg_decay) * avg_inv_sds-&gt;get_values() +</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;                        norm_avg_decay * inv_in_sd_cache);</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;            } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;                avg_means-&gt;set_values(mean_vec);</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;                avg_inv_sds-&gt;set_values(inv_in_sd_cache);</div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;                avgs_init = <span class="keyword">true</span>;</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;            }</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;            <span class="comment">// For testing, use the moving averages.</span></div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;            assert(avgs_init);</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;            in_mat = (in_mat.rowwise() - avg_means-&gt;get_values().row(0)) * avg_inv_sds-&gt;get_values().asDiagonal();</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;        }</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> out_mat = (in_mat * gammas-&gt;get_values().asDiagonal()).rowwise() +</div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;                betas-&gt;get_values().row(0);</div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(out_mat.data(), in.dimensions());</div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;    }</div><div class="line"><a name="l00441"></a><span class="lineno"><a class="line" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ad1b665c616770249569c831b9bef076c">  441</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">typename</span> Base::Data <a class="code" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ad1b665c616770249569c831b9bef076c">pass_back</a>(<span class="keyword">typename</span> Base::Data out_grad) {</div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;        assert((<a class="code" href="classcattle_1_1_dimensions.html">Dimensions&lt;std::size_t,Base::DATA_RANK&gt;</a>(out_grad.dimensions()).<span class="keyword">template</span> demote&lt;&gt;()) == dims);</div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;        assert(out_grad.dimension(0) &gt; 0 &amp;&amp; std_in_mat_cache.rows() == out_grad.dimension(0));</div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;        std::size_t rows = out_grad.dimension(0);</div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;        <a class="code" href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">MatrixMap&lt;Scalar&gt;</a> out_grad_mat(out_grad.data(), rows, out_grad.size() / rows);</div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;        gammas-&gt;accumulate_grad(out_grad_mat.cwiseProduct(std_in_mat_cache).colwise().sum());</div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;        betas-&gt;accumulate_grad(out_grad_mat.colwise().sum());</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;        <span class="keywordflow">if</span> (input_layer)</div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;            <span class="keywordflow">return</span> <span class="keyword">typename</span> Base::Data();</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> std_in_grad_mat = out_grad_mat * gammas-&gt;get_values().asDiagonal();</div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;        <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> prev_out_grad_mat = (((rows * std_in_grad_mat).rowwise() -</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;                std_in_grad_mat.colwise().sum()) - std_in_mat_cache *</div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;                (std_in_mat_cache.cwiseProduct(std_in_grad_mat).colwise().sum().asDiagonal())) *</div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;                (((Scalar) 1 / rows) * inv_in_sd_cache).asDiagonal();</div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">TensorMap&lt;Scalar,Base::DATA_RANK&gt;</a>(prev_out_grad_mat.data(), out_grad.dimensions());</div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;    }</div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;    <span class="keyword">const</span> Self&amp; owner;</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;    <span class="keyword">const</span> <span class="keyword">typename</span> Base::Dims dims;</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;    <span class="keyword">const</span> Scalar norm_avg_decay, epsilon;</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;    <span class="keywordtype">bool</span> input_layer;</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;    <span class="comment">// Dynamic batch normalization parameters.</span></div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;    HostParamsSharedPtr avg_means, avg_inv_sds;</div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;    <span class="keywordtype">bool</span> avgs_init;</div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;    <span class="comment">// Betas and gammas</span></div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;    HostParamsSharedPtr gammas, betas;</div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;    <span class="comment">// Staged computation caches.</span></div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;    <a class="code" href="namespacecattle.html#a23ebf4fefd4f6b9dc0cd34afb1ce1b65">RowVector&lt;Scalar&gt;</a> inv_in_sd_cache;</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;    <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a> std_in_mat_cache;</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;};</div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;} <span class="comment">/* namespace cattle */</span></div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;<span class="preprocessor">#endif </span><span class="comment">/* C_ATTL3_LAYER_BATCHNORMLAYER_H_ */</span><span class="preprocessor"></span></div><div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a6aebaf7cd158c35983c27f691c80a5bd"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a6aebaf7cd158c35983c27f691c80a5bd">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::set_input_layer</a></div><div class="ttdeci">void set_input_layer(bool input_layer)</div><div class="ttdoc">Sets this instance&amp;#39;s input layer status to the given value. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:396</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_ad64fb5495e73699d97714883a77056e8"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#ad64fb5495e73699d97714883a77056e8">cattle::BatchNormLayer::get_params_owner</a></div><div class="ttdeci">const Base &amp; get_params_owner() const</div><div class="ttdoc">It returns a reference to the layer owning the parameters used. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:141</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a8d219fcba0da06256568e4fa61a6ade7"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a8d219fcba0da06256568e4fa61a6ade7">cattle::BatchNormLayer::BatchNormLayer</a></div><div class="ttdeci">BatchNormLayer(const typename Base::Dims &amp;dims, Scalar norm_avg_decay=.1, Scalar epsilon=NumericUtils&lt; Scalar &gt;::EPSILON2, ParamRegSharedPtr&lt; Scalar &gt; gamma_reg=nullptr, Scalar gamma_clip=0, Scalar gamma_max_l1_norm=0, Scalar gamma_max_l2_norm=0, Scalar gamma_grad_clip=0, Scalar gamma_grad_max_l1_norm=0, Scalar gamma_grad_max_l2_norm=0, ParamRegSharedPtr&lt; Scalar &gt; beta_reg=nullptr, Scalar beta_clip=0, Scalar beta_max_l1_norm=0, Scalar beta_max_l2_norm=0, Scalar beta_grad_clip=0, Scalar beta_grad_max_l1_norm=0, Scalar beta_grad_max_l2_norm=0)</div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:66</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a7e23442f814d994e2989724901001202"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a7e23442f814d994e2989724901001202">cattle::BatchNormLayer::clone</a></div><div class="ttdeci">Base * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:135</div></div>
<div class="ttc" id="namespacecattle_html_a23ebf4fefd4f6b9dc0cd34afb1ce1b65"><div class="ttname"><a href="namespacecattle.html#a23ebf4fefd4f6b9dc0cd34afb1ce1b65">cattle::RowVector</a></div><div class="ttdeci">Eigen::Matrix&lt; Scalar, 1, Eigen::Dynamic, Eigen::RowMajor, 1, Eigen::Dynamic &gt; RowVector</div><div class="ttdoc">An alias for a single row matrix of an arbitrary scalar type. </div><div class="ttdef"><b>Definition:</b> EigenProxy.hpp:31</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a7b62f3a8bab743a0714ec3d1c7e87506"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7b62f3a8bab743a0714ec3d1c7e87506">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:407</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a6ae09223dbd4d038abab1e99fb6fb281"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a6ae09223dbd4d038abab1e99fb6fb281">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::BatchNormLayer</a></div><div class="ttdeci">BatchNormLayer(const typename Base::Dims &amp;dims, Scalar norm_avg_decay=.1, Scalar epsilon=NumericUtils&lt; Scalar &gt;::EPSILON2, ParamRegSharedPtr&lt; Scalar &gt; gamma_reg=nullptr, Scalar gamma_clip=0, Scalar gamma_max_l1_norm=0, Scalar gamma_max_l2_norm=0, Scalar gamma_grad_clip=0, Scalar gamma_grad_max_l1_norm=0, Scalar gamma_grad_max_l2_norm=0, ParamRegSharedPtr&lt; Scalar &gt; beta_reg=nullptr, Scalar beta_clip=0, Scalar beta_max_l1_norm=0, Scalar beta_max_l2_norm=0, Scalar beta_grad_clip=0, Scalar beta_grad_max_l1_norm=0, Scalar beta_grad_max_l2_norm=0)</div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:334</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a7f46a6d30c7004193fef2b4b75835f28"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7f46a6d30c7004193fef2b4b75835f28">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::is_input_layer</a></div><div class="ttdeci">bool is_input_layer() const</div><div class="ttdoc">A constant method that returns whether this layer functions as an input layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:393</div></div>
<div class="ttc" id="namespacecattle_html_a1d78623a47279d516750a44dbad6090b"><div class="ttname"><a href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">cattle::Matrix</a></div><div class="ttdeci">Eigen::Matrix&lt; Scalar, Eigen::Dynamic, Eigen::Dynamic, Eigen::ColMajor, Eigen::Dynamic, Eigen::Dynamic &gt; Matrix</div><div class="ttdoc">An alias for a dynamically sized matrix of an arbitrary scalar type. </div><div class="ttdef"><b>Definition:</b> EigenProxy.hpp:44</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_aebba427879529275913f3f560ec42c5b"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#aebba427879529275913f3f560ec42c5b">cattle::BatchNormLayer::get_input_dims</a></div><div class="ttdeci">const Base::Dims &amp; get_input_dims() const</div><div class="ttdoc">A simple constant getter method for the input dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:144</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_ab40438ea8902e5bbba29ff6d23b4f187"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#ab40438ea8902e5bbba29ff6d23b4f187">cattle::BatchNormLayer::clone_with_shared_params</a></div><div class="ttdeci">Base * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:138</div></div>
<div class="ttc" id="namespacecattle_html"><div class="ttname"><a href="namespacecattle.html">cattle</a></div><div class="ttdoc">The namespace containing all classes and typedefs of the C-ATTL3 library. </div><div class="ttdef"><b>Definition:</b> PPMCodec.hpp:20</div></div>
<div class="ttc" id="classcattle_1_1_one_parameter_initialization_html"><div class="ttname"><a href="classcattle_1_1_one_parameter_initialization.html">cattle::OneParameterInitialization</a></div><div class="ttdoc">A class template for a weight initialization that sets all values to 1. </div><div class="ttdef"><b>Definition:</b> OneParameterInitialization.hpp:19</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a85b0b9559f66fe833daffa9936cfee94"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a85b0b9559f66fe833daffa9936cfee94">cattle::BatchNormLayer::get_output_dims</a></div><div class="ttdeci">const Base::Dims &amp; get_output_dims() const</div><div class="ttdoc">A simple constant getter method for the output dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:147</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a18bd4016f07bfc33c27bb518066ff67b"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a18bd4016f07bfc33c27bb518066ff67b">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::clone</a></div><div class="ttdeci">Base * clone() const</div><div class="ttdoc">It returns a clone of the layer instance. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:378</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a></div><div class="ttdoc">A class template for a per-activation batch normalization layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:298</div></div>
<div class="ttc" id="classcattle_1_1_dimensions_html"><div class="ttname"><a href="classcattle_1_1_dimensions.html">cattle::Dimensions&lt; std::size_t, Rank &gt;</a></div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a97015b85d3e5536b61d093296bad432d"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a97015b85d3e5536b61d093296bad432d">cattle::BatchNormLayer::get_params</a></div><div class="ttdeci">std::vector&lt; const Parameters&lt; Scalar &gt; * &gt; get_params() const</div><div class="ttdoc">It returns a vector of constant non-owning pointers to the parameters of the layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:156</div></div>
<div class="ttc" id="namespacecattle_html_a8ea9ee634a3a9e87dbc4635d9f14320a"><div class="ttname"><a href="namespacecattle.html#a8ea9ee634a3a9e87dbc4635d9f14320a">cattle::ParamRegSharedPtr</a></div><div class="ttdeci">std::shared_ptr&lt; ParameterRegularization&lt; Scalar &gt; &gt; ParamRegSharedPtr</div><div class="ttdoc">An alias for a shared pointer to a regularization penalty of an arbitrary scalar type. </div><div class="ttdef"><b>Definition:</b> HostParameters.hpp:34</div></div>
<div class="ttc" id="classcattle_1_1_layer_html"><div class="ttname"><a href="classcattle_1_1_layer.html">cattle::Layer</a></div><div class="ttdoc">An abstract class template representing layers in a neural network. </div><div class="ttdef"><b>Definition:</b> Layer.hpp:31</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a66300725f60f30bd773d47f2dea19f46"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a66300725f60f30bd773d47f2dea19f46">cattle::BatchNormLayer::set_input_layer</a></div><div class="ttdeci">void set_input_layer(bool input_layer)</div><div class="ttdoc">Sets this instance&amp;#39;s input layer status to the given value. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:153</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_af1b61deed2a5de2a8f9805b197af3d31"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#af1b61deed2a5de2a8f9805b197af3d31">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_params</a></div><div class="ttdeci">std::vector&lt; Parameters&lt; Scalar &gt; * &gt; get_params()</div><div class="ttdoc">It returns a vector of non-owning pointers to the parameters of the layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:399</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_ab952d37eca54ad52ec43c632ea6a7856"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ab952d37eca54ad52ec43c632ea6a7856">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::clone_with_shared_params</a></div><div class="ttdeci">Base * clone_with_shared_params()</div><div class="ttdoc">It returns a clone of the layer instance using a reference to the original&amp;#39;s parameters. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:381</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a387a4e3752c6c09c7492ec02b1ea28bd"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a387a4e3752c6c09c7492ec02b1ea28bd">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_params</a></div><div class="ttdeci">std::vector&lt; const Parameters&lt; Scalar &gt; * &gt; get_params() const</div><div class="ttdoc">It returns a vector of constant non-owning pointers to the parameters of the layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:403</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_ae82d6c00d3f84d865324c51bcb5ab90c"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#ae82d6c00d3f84d865324c51bcb5ab90c">cattle::BatchNormLayer::empty_cache</a></div><div class="ttdeci">void empty_cache()</div><div class="ttdoc">It empties the layer&amp;#39;s caches such as those required for the derivation of the function represented b...</div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:166</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_ad1b665c616770249569c831b9bef076c"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ad1b665c616770249569c831b9bef076c">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::pass_back</a></div><div class="ttdeci">Base::Data pass_back(typename Base::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:441</div></div>
<div class="ttc" id="namespacecattle_html_a7dfcb4d57e2c5da3170ebd8d13fd0431"><div class="ttname"><a href="namespacecattle.html#a7dfcb4d57e2c5da3170ebd8d13fd0431">cattle::TensorMap</a></div><div class="ttdeci">Eigen::TensorMap&lt; Tensor&lt; Scalar, Rank &gt; &gt; TensorMap</div><div class="ttdoc">An for a class that can be used to map raw pointer data to a tensor of arbitrary rank and scalar type...</div><div class="ttdef"><b>Definition:</b> EigenProxy.hpp:64</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_ae91b49e8b4eaf586faf27c2147b3e684"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae91b49e8b4eaf586faf27c2147b3e684">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_params_owner</a></div><div class="ttdeci">const Base &amp; get_params_owner() const</div><div class="ttdoc">It returns a reference to the layer owning the parameters used. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:384</div></div>
<div class="ttc" id="classcattle_1_1_zero_parameter_initialization_html"><div class="ttname"><a href="classcattle_1_1_zero_parameter_initialization.html">cattle::ZeroParameterInitialization</a></div><div class="ttdoc">A class template for a weight initialization that sets all values to 0. </div><div class="ttdef"><b>Definition:</b> ZeroParameterInitialization.hpp:19</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_ae01fe5aa00615cab21ac81babf2756b2"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae01fe5aa00615cab21ac81babf2756b2">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::pass_forward</a></div><div class="ttdeci">Base::Data pass_forward(typename Base::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:411</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html">cattle::BatchNormLayer</a></div><div class="ttdoc">A class template for a per-channel batch normalization layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:29</div></div>
<div class="ttc" id="classcattle_1_1_numeric_utils_html"><div class="ttname"><a href="classcattle_1_1_numeric_utils.html">cattle::NumericUtils</a></div><div class="ttdoc">A utility class template containing static methods and variables to help with numerical issues...</div><div class="ttdef"><b>Definition:</b> NumericUtils.hpp:22</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a1cc2a6f67e5d6b8e7f7996a9267b7401"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a1cc2a6f67e5d6b8e7f7996a9267b7401">cattle::BatchNormLayer::pass_back</a></div><div class="ttdeci">Base::Data pass_back(typename Base::Data out_grad)</div><div class="ttdoc">It back-propagates the derivative of the error function w.r.t. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:192</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_a8625b962405d6a92b4b5522b937fa51f"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a8625b962405d6a92b4b5522b937fa51f">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_input_dims</a></div><div class="ttdeci">const Base::Dims &amp; get_input_dims() const</div><div class="ttdoc">A simple constant getter method for the input dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:387</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_ac30864573717c53a6e6f7b29b69c3136"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#ac30864573717c53a6e6f7b29b69c3136">cattle::BatchNormLayer::get_params</a></div><div class="ttdeci">std::vector&lt; Parameters&lt; Scalar &gt; * &gt; get_params()</div><div class="ttdoc">It returns a vector of non-owning pointers to the parameters of the layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:161</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a220d347e28e8456fbaa42e8b37ff565d"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a220d347e28e8456fbaa42e8b37ff565d">cattle::BatchNormLayer::pass_forward</a></div><div class="ttdeci">Base::Data pass_forward(typename Base::Data in, bool training)</div><div class="ttdoc">It has the function represented by the layer applied to the input tensor. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:170</div></div>
<div class="ttc" id="namespacecattle_html_afe8803bdb57fb149be7d7b7916f30ca9"><div class="ttname"><a href="namespacecattle.html#afe8803bdb57fb149be7d7b7916f30ca9">cattle::MatrixMap</a></div><div class="ttdeci">Eigen::Map&lt; Matrix&lt; Scalar &gt; &gt; MatrixMap</div><div class="ttdoc">An alias for a class that can be used to map raw pointer data to a dynamically sized Matrix of an arb...</div><div class="ttdef"><b>Definition:</b> EigenProxy.hpp:51</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_html_a617e18072bd65f87b90072d9d1288d95"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer.html#a617e18072bd65f87b90072d9d1288d95">cattle::BatchNormLayer::is_input_layer</a></div><div class="ttdeci">bool is_input_layer() const</div><div class="ttdoc">A constant method that returns whether this layer functions as an input layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:150</div></div>
<div class="ttc" id="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4_html_aaee7992a15e8016e497ed85e150b1608"><div class="ttname"><a href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#aaee7992a15e8016e497ed85e150b1608">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;::get_output_dims</a></div><div class="ttdeci">const Base::Dims &amp; get_output_dims() const</div><div class="ttdoc">A simple constant getter method for the output dimensionality of the layer. </div><div class="ttdef"><b>Definition:</b> BatchNormLayer.hpp:390</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
