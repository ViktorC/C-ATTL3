<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: cattle::gpu::CuDNNTensor&lt; Scalar &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecattle.html">cattle</a></li><li class="navelem"><b>gpu</b></li><li class="navelem"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">cattle::gpu::CuDNNTensor&lt; Scalar &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>A template class for representing row-major cuDNN device tensors of different data types.  
 <a href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_cu_d_n_n_tensor_8hpp_source.html">CuDNNTensor.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for cattle::gpu::CuDNNTensor&lt; Scalar &gt;:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.png" usemap="#cattle::gpu::CuDNNTensor_3C_20Scalar_20_3E_map" alt=""/>
  <map id="cattle::gpu::CuDNNTensor_3C_20Scalar_20_3E_map" name="cattle::gpu::CuDNNTensor_3C_20Scalar_20_3E_map">
<area href="classcattle_1_1gpu_1_1_c_u_d_a_array.html" title="A template class for CUDA device arrays of different data types. " alt="cattle::gpu::CUDAArray&lt; Scalar &gt;" shape="rect" coords="0,0,218,24"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a65a43e2a1db06f62805887b0fe15a274"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a65a43e2a1db06f62805887b0fe15a274">CuDNNTensor</a> (Scalar *<a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>)</td></tr>
<tr class="separator:a65a43e2a1db06f62805887b0fe15a274"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6b7b616ec8965672b82f8186066bc29"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ac6b7b616ec8965672b82f8186066bc29">CuDNNTensor</a> (std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>)</td></tr>
<tr class="separator:ac6b7b616ec8965672b82f8186066bc29"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a99057790847ce509fbbb377ea8c07aad"><td class="memItemLeft" align="right" valign="top">std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a> () const</td></tr>
<tr class="separator:a99057790847ce509fbbb377ea8c07aad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61355129924153169b4f5be6177e4cc3"><td class="memItemLeft" align="right" valign="top">std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a> () const</td></tr>
<tr class="separator:a61355129924153169b4f5be6177e4cc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad48aa03288eb330549d7038813183456"><td class="memItemLeft" align="right" valign="top">std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a> () const</td></tr>
<tr class="separator:ad48aa03288eb330549d7038813183456"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a159a7f5ab933a8a4794cacf894cb3691"><td class="memItemLeft" align="right" valign="top">std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a> () const</td></tr>
<tr class="separator:a159a7f5ab933a8a4794cacf894cb3691"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad877d89c5fba27e4676659d0fc515faa"><td class="memItemLeft" align="right" valign="top">const cudnnTensorDescriptor_t &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a> () const</td></tr>
<tr class="separator:ad877d89c5fba27e4676659d0fc515faa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace265c09fcf365ac3900013ff0c971fe"><td class="memItemLeft" align="right" valign="top">const cudnnFilterDescriptor_t &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ace265c09fcf365ac3900013ff0c971fe">filter_desc</a> () const</td></tr>
<tr class="separator:ace265c09fcf365ac3900013ff0c971fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48fd267290bfb7b49e39a6d1e1b844ab"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a48fd267290bfb7b49e39a6d1e1b844ab">set_values</a> (Scalar value)</td></tr>
<tr class="separator:a48fd267290bfb7b49e39a6d1e1b844ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a879177caac8ca874b91a3ccee66af2b3"><td class="memItemLeft" align="right" valign="top">Scalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a879177caac8ca874b91a3ccee66af2b3">reduce</a> (cudnnReduceTensorOp_t op_type) const</td></tr>
<tr class="memdesc:a879177caac8ca874b91a3ccee66af2b3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs a reduction along all ranks of the tensor.  <a href="#a879177caac8ca874b91a3ccee66af2b3">More...</a><br /></td></tr>
<tr class="separator:a879177caac8ca874b91a3ccee66af2b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a794d079d4446a5a55beed6ac65ab4e72"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a794d079d4446a5a55beed6ac65ab4e72">reduce</a> (cudnnReduceTensorOp_t op_type, const std::array&lt; bool, 4 &gt; &amp;ranks) const</td></tr>
<tr class="memdesc:a794d079d4446a5a55beed6ac65ab4e72"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs a reduction along the specified ranks of the tensor.  <a href="#a794d079d4446a5a55beed6ac65ab4e72">More...</a><br /></td></tr>
<tr class="separator:a794d079d4446a5a55beed6ac65ab4e72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9094c2bf0bf56e5ca174a8ee9c13d0ee"><td class="memItemLeft" align="right" valign="top">Scalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a9094c2bf0bf56e5ca174a8ee9c13d0ee">sum</a> () const</td></tr>
<tr class="separator:a9094c2bf0bf56e5ca174a8ee9c13d0ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea14b2fc6d9f4df9c8e03f5177966899"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aea14b2fc6d9f4df9c8e03f5177966899">sum</a> (const std::array&lt; bool, 4 &gt; &amp;ranks) const</td></tr>
<tr class="separator:aea14b2fc6d9f4df9c8e03f5177966899"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a14fd93aae07810d6e5889015caa7186c"><td class="memItemLeft" align="right" valign="top">Scalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a14fd93aae07810d6e5889015caa7186c">avg</a> () const</td></tr>
<tr class="separator:a14fd93aae07810d6e5889015caa7186c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d8eb060deed9d0fe65ab385d559e4e6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a8d8eb060deed9d0fe65ab385d559e4e6">avg</a> (const std::array&lt; bool, 4 &gt; &amp;ranks) const</td></tr>
<tr class="separator:a8d8eb060deed9d0fe65ab385d559e4e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6b9a062dd41eb9cefaaccc003f1d44d"><td class="memItemLeft" align="right" valign="top">Scalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ac6b9a062dd41eb9cefaaccc003f1d44d">min</a> () const</td></tr>
<tr class="separator:ac6b9a062dd41eb9cefaaccc003f1d44d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab45c4cf77bc7a4aaabda0ea8a0d57282"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ab45c4cf77bc7a4aaabda0ea8a0d57282">min</a> (const std::array&lt; bool, 4 &gt; &amp;ranks) const</td></tr>
<tr class="separator:ab45c4cf77bc7a4aaabda0ea8a0d57282"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2755921f191344ac81f632d6557ef1f"><td class="memItemLeft" align="right" valign="top">Scalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ae2755921f191344ac81f632d6557ef1f">max</a> () const</td></tr>
<tr class="separator:ae2755921f191344ac81f632d6557ef1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a99a2d7f69a75e98703dbf66b48a53205"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99a2d7f69a75e98703dbf66b48a53205">max</a> (const std::array&lt; bool, 4 &gt; &amp;ranks) const</td></tr>
<tr class="separator:a99a2d7f69a75e98703dbf66b48a53205"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79a8c68688400c2eead390233cb28abe"><td class="memItemLeft" align="right" valign="top">Scalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a79a8c68688400c2eead390233cb28abe">abs_max</a> () const</td></tr>
<tr class="separator:a79a8c68688400c2eead390233cb28abe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f3906d0cfbfeb10fd7aeed16fe73182"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a4f3906d0cfbfeb10fd7aeed16fe73182">abs_max</a> (const std::array&lt; bool, 4 &gt; &amp;ranks) const</td></tr>
<tr class="separator:a4f3906d0cfbfeb10fd7aeed16fe73182"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80de652665a9fd62cb1e6a26cb3bf40c"><td class="memItemLeft" align="right" valign="top">Scalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a80de652665a9fd62cb1e6a26cb3bf40c">l1_norm</a> () const</td></tr>
<tr class="separator:a80de652665a9fd62cb1e6a26cb3bf40c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82878aacda8c60cd8cb4a17eb6d60ccf"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a82878aacda8c60cd8cb4a17eb6d60ccf">l1_norm</a> (const std::array&lt; bool, 4 &gt; &amp;ranks) const</td></tr>
<tr class="separator:a82878aacda8c60cd8cb4a17eb6d60ccf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac7d2e6127db547aae890c305405bb28"><td class="memItemLeft" align="right" valign="top">Scalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aac7d2e6127db547aae890c305405bb28">l2_norm</a> () const</td></tr>
<tr class="separator:aac7d2e6127db547aae890c305405bb28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a111736834abf5c68e42ea19bfa3ba651"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a111736834abf5c68e42ea19bfa3ba651">l2_norm</a> (const std::array&lt; bool, 4 &gt; &amp;ranks) const</td></tr>
<tr class="separator:a111736834abf5c68e42ea19bfa3ba651"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f8177e7ea5deb5771c564b56f4fac7f"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a5f8177e7ea5deb5771c564b56f4fac7f">to_string</a> () const</td></tr>
<tr class="separator:a5f8177e7ea5deb5771c564b56f4fac7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">cattle::gpu::CUDAArray&lt; Scalar &gt;</a></td></tr>
<tr class="memitem:a9c8b083433ece6cdbcb48a4af77cdd18 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a9c8b083433ece6cdbcb48a4af77cdd18">CUDAArray</a> (Scalar *<a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">size</a>)</td></tr>
<tr class="separator:a9c8b083433ece6cdbcb48a4af77cdd18 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e697aa1a2e02fedbd79fb97a810b018 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a7e697aa1a2e02fedbd79fb97a810b018">CUDAArray</a> (std::size_t <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">size</a>)</td></tr>
<tr class="separator:a7e697aa1a2e02fedbd79fb97a810b018 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d242f9908e1a4448a4585e220ef7ca1 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memItemLeft" align="right" valign="top">std::size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">size</a> () const</td></tr>
<tr class="separator:a5d242f9908e1a4448a4585e220ef7ca1 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3bd7455c00b1cb1cf3d31a849429e4d9 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memItemLeft" align="right" valign="top">const Scalar *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a> () const</td></tr>
<tr class="separator:a3bd7455c00b1cb1cf3d31a849429e4d9 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b8ace0183f8b7a7f99ce906d55d7d16 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memItemLeft" align="right" valign="top">Scalar *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5b8ace0183f8b7a7f99ce906d55d7d16">data</a> ()</td></tr>
<tr class="separator:a5b8ace0183f8b7a7f99ce906d55d7d16 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab931d02fc70e4c845fc9227c3c943c96 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#ab931d02fc70e4c845fc9227c3c943c96">wrapper</a> () const</td></tr>
<tr class="separator:ab931d02fc70e4c845fc9227c3c943c96 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a386d142c81ce70f35b43bc0802a89ad3 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a386d142c81ce70f35b43bc0802a89ad3">set_values</a> (int value)</td></tr>
<tr class="separator:a386d142c81ce70f35b43bc0802a89ad3 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53a0b01db3d84497c5c7c47a8582a22d inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a53a0b01db3d84497c5c7c47a8582a22d">copy_from_host</a> (const Scalar *host_array)</td></tr>
<tr class="memdesc:a53a0b01db3d84497c5c7c47a8582a22d inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="mdescLeft">&#160;</td><td class="mdescRight">It populates the entire device array with data from the host memory.  <a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a53a0b01db3d84497c5c7c47a8582a22d">More...</a><br /></td></tr>
<tr class="separator:a53a0b01db3d84497c5c7c47a8582a22d inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3aeb7d6d0bb4583880a3b187a3c5945 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#ab3aeb7d6d0bb4583880a3b187a3c5945">copy_to_host</a> (Scalar *host_array) const</td></tr>
<tr class="memdesc:ab3aeb7d6d0bb4583880a3b187a3c5945 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="mdescLeft">&#160;</td><td class="mdescRight">It copies the entire device array to the host memory.  <a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#ab3aeb7d6d0bb4583880a3b187a3c5945">More...</a><br /></td></tr>
<tr class="separator:ab3aeb7d6d0bb4583880a3b187a3c5945 inherit pub_methods_classcattle_1_1gpu_1_1_c_u_d_a_array"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:afed1d051b60b5bec470cb343a39b140b"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#afed1d051b60b5bec470cb343a39b140b">create_tensor_descriptor</a> (cudnnTensorDescriptor_t &amp;<a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>)</td></tr>
<tr class="separator:afed1d051b60b5bec470cb343a39b140b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae03ac08e0d7c75a1151bf6ba0aeb173"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aae03ac08e0d7c75a1151bf6ba0aeb173">destroy_tensor_descriptor</a> (const cudnnTensorDescriptor_t &amp;<a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad877d89c5fba27e4676659d0fc515faa">desc</a>)</td></tr>
<tr class="separator:aae03ac08e0d7c75a1151bf6ba0aeb173"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f655c4ac5713c8a79c2f45ffac06ced"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2f655c4ac5713c8a79c2f45ffac06ced">create_filter_descriptor</a> (cudnnFilterDescriptor_t &amp;<a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ace265c09fcf365ac3900013ff0c971fe">filter_desc</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a99057790847ce509fbbb377ea8c07aad">samples</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a61355129924153169b4f5be6177e4cc3">height</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ad48aa03288eb330549d7038813183456">width</a>, std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a159a7f5ab933a8a4794cacf894cb3691">channels</a>)</td></tr>
<tr class="separator:a2f655c4ac5713c8a79c2f45ffac06ced"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a54952cb1443c033f047f8dd7a0338c"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2a54952cb1443c033f047f8dd7a0338c">destroy_filter_descriptor</a> (const cudnnFilterDescriptor_t &amp;<a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#ace265c09fcf365ac3900013ff0c971fe">filter_desc</a>)</td></tr>
<tr class="separator:a2a54952cb1443c033f047f8dd7a0338c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acecbeef40e8d5703047aba4ebdfb17c8"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#acecbeef40e8d5703047aba4ebdfb17c8">scale</a> (Scalar alpha, <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;a)</td></tr>
<tr class="memdesc:acecbeef40e8d5703047aba4ebdfb17c8"><td class="mdescLeft">&#160;</td><td class="mdescRight">It scales the specified tensor by a certain factor.  <a href="#acecbeef40e8d5703047aba4ebdfb17c8">More...</a><br /></td></tr>
<tr class="separator:acecbeef40e8d5703047aba4ebdfb17c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea0e1ef1751ae11624c57bd199cef12b"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#aea0e1ef1751ae11624c57bd199cef12b">add</a> (Scalar alpha, const <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;a, Scalar beta, <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;b)</td></tr>
<tr class="memdesc:aea0e1ef1751ae11624c57bd199cef12b"><td class="mdescLeft">&#160;</td><td class="mdescRight">It adds tensor a to tensor b.  <a href="#aea0e1ef1751ae11624c57bd199cef12b">More...</a><br /></td></tr>
<tr class="separator:aea0e1ef1751ae11624c57bd199cef12b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5e3f42920bf068b750d71356a41cf1b"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#af5e3f42920bf068b750d71356a41cf1b">op</a> (const <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;a, Scalar alpha, const <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;b, Scalar beta, cudnnOpTensorOp_t op_type, Scalar gamma, <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;c)</td></tr>
<tr class="memdesc:af5e3f42920bf068b750d71356a41cf1b"><td class="mdescLeft">&#160;</td><td class="mdescRight">It performs the specified operation on tensors a and b and saves the result in c.  <a href="#af5e3f42920bf068b750d71356a41cf1b">More...</a><br /></td></tr>
<tr class="separator:af5e3f42920bf068b750d71356a41cf1b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d054df2a19f7623dfbda10bfcf639ae"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html#a2d054df2a19f7623dfbda10bfcf639ae">reduce_op</a> (Scalar alpha, const <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;a, cudnnReduceTensorOp_t op_type, Scalar beta, <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;b)</td></tr>
<tr class="memdesc:a2d054df2a19f7623dfbda10bfcf639ae"><td class="mdescLeft">&#160;</td><td class="mdescRight">It performs the specified reduction operation on tensor a and adds it to tensor b.  <a href="#a2d054df2a19f7623dfbda10bfcf639ae">More...</a><br /></td></tr>
<tr class="separator:a2d054df2a19f7623dfbda10bfcf639ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Scalar&gt;<br />
class cattle::gpu::CuDNNTensor&lt; Scalar &gt;</h3>

<p>A template class for representing row-major cuDNN device tensors of different data types. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a65a43e2a1db06f62805887b0fe15a274"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a65a43e2a1db06f62805887b0fe15a274">&#9670;&nbsp;</a></span>CuDNNTensor() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::<a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a> </td>
          <td>(</td>
          <td class="paramtype">Scalar *&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>samples</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>channels</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>The device array to wrap in a <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html" title="A template class for representing row-major cuDNN device tensors of different data types...">CuDNNTensor</a>. The ownership of the pointer is not transfered to the tensor. </td></tr>
    <tr><td class="paramname">samples</td><td>The batch size. </td></tr>
    <tr><td class="paramname">height</td><td>The height. </td></tr>
    <tr><td class="paramname">width</td><td>The width. </td></tr>
    <tr><td class="paramname">channels</td><td>The number of channels. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ac6b7b616ec8965672b82f8186066bc29"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac6b7b616ec8965672b82f8186066bc29">&#9670;&nbsp;</a></span>CuDNNTensor() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::<a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">CuDNNTensor</a> </td>
          <td>(</td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>samples</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>channels</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">samples</td><td>The batch size. </td></tr>
    <tr><td class="paramname">height</td><td>The height. </td></tr>
    <tr><td class="paramname">width</td><td>The width. </td></tr>
    <tr><td class="paramname">channels</td><td>The number of channels. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a79a8c68688400c2eead390233cb28abe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a79a8c68688400c2eead390233cb28abe">&#9670;&nbsp;</a></span>abs_max() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Scalar <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::abs_max </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>The absolute maximum of all elements of the tensor. </dd></dl>

</div>
</div>
<a id="a4f3906d0cfbfeb10fd7aeed16fe73182"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f3906d0cfbfeb10fd7aeed16fe73182">&#9670;&nbsp;</a></span>abs_max() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::abs_max </td>
          <td>(</td>
          <td class="paramtype">const std::array&lt; bool, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>ranks</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ranks</td><td>A size 4 boolean array denoting which ranks are to be reduced. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The reduced tensor. </dd></dl>

</div>
</div>
<a id="aea0e1ef1751ae11624c57bd199cef12b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aea0e1ef1751ae11624c57bd199cef12b">&#9670;&nbsp;</a></span>add()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::add </td>
          <td>(</td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;&#160;</td>
          <td class="paramname"><em>b</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It adds tensor a to tensor b. </p>
<p>\(B = \alpha * A + \beta * B\)</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">alpha</td><td>The scaling factor of the tensor to add to the other one. </td></tr>
    <tr><td class="paramname">a</td><td>The tensor to add to the other tensor. </td></tr>
    <tr><td class="paramname">beta</td><td>The scaling factor of the target tensor. </td></tr>
    <tr><td class="paramname">b</td><td>The target tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a14fd93aae07810d6e5889015caa7186c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a14fd93aae07810d6e5889015caa7186c">&#9670;&nbsp;</a></span>avg() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Scalar <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::avg </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>The mean of all elements of the tensor. </dd></dl>

</div>
</div>
<a id="a8d8eb060deed9d0fe65ab385d559e4e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d8eb060deed9d0fe65ab385d559e4e6">&#9670;&nbsp;</a></span>avg() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::avg </td>
          <td>(</td>
          <td class="paramtype">const std::array&lt; bool, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>ranks</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ranks</td><td>A size 4 boolean array denoting which ranks are to be reduced. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The reduced tensor. </dd></dl>

</div>
</div>
<a id="a159a7f5ab933a8a4794cacf894cb3691"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a159a7f5ab933a8a4794cacf894cb3691">&#9670;&nbsp;</a></span>channels()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::channels </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>The number of channels of the tensor. </dd></dl>

</div>
</div>
<a id="a2f655c4ac5713c8a79c2f45ffac06ced"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2f655c4ac5713c8a79c2f45ffac06ced">&#9670;&nbsp;</a></span>create_filter_descriptor()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::create_filter_descriptor </td>
          <td>(</td>
          <td class="paramtype">cudnnFilterDescriptor_t &amp;&#160;</td>
          <td class="paramname"><em>filter_desc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>samples</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>channels</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">filter_desc</td><td>A reference to the filter descriptor object. </td></tr>
    <tr><td class="paramname">samples</td><td>The batch size. </td></tr>
    <tr><td class="paramname">height</td><td>The height. </td></tr>
    <tr><td class="paramname">width</td><td>The width. </td></tr>
    <tr><td class="paramname">channels</td><td>The number of channels. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="afed1d051b60b5bec470cb343a39b140b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afed1d051b60b5bec470cb343a39b140b">&#9670;&nbsp;</a></span>create_tensor_descriptor()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::create_tensor_descriptor </td>
          <td>(</td>
          <td class="paramtype">cudnnTensorDescriptor_t &amp;&#160;</td>
          <td class="paramname"><em>desc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>samples</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>channels</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">desc</td><td>A reference to the tensor descri ptor object. </td></tr>
    <tr><td class="paramname">samples</td><td>The batch size. </td></tr>
    <tr><td class="paramname">height</td><td>The height. </td></tr>
    <tr><td class="paramname">width</td><td>The width. </td></tr>
    <tr><td class="paramname">channels</td><td>The number of channels. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ad877d89c5fba27e4676659d0fc515faa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad877d89c5fba27e4676659d0fc515faa">&#9670;&nbsp;</a></span>desc()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const cudnnTensorDescriptor_t&amp; <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::desc </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>A constant reference to the tensor descriptor. </dd></dl>

</div>
</div>
<a id="a2a54952cb1443c033f047f8dd7a0338c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2a54952cb1443c033f047f8dd7a0338c">&#9670;&nbsp;</a></span>destroy_filter_descriptor()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::destroy_filter_descriptor </td>
          <td>(</td>
          <td class="paramtype">const cudnnFilterDescriptor_t &amp;&#160;</td>
          <td class="paramname"><em>filter_desc</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">filter_desc</td><td>A constant reference to the filter descriptor object. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aae03ac08e0d7c75a1151bf6ba0aeb173"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae03ac08e0d7c75a1151bf6ba0aeb173">&#9670;&nbsp;</a></span>destroy_tensor_descriptor()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::destroy_tensor_descriptor </td>
          <td>(</td>
          <td class="paramtype">const cudnnTensorDescriptor_t &amp;&#160;</td>
          <td class="paramname"><em>desc</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">desc</td><td>A constant reference to the tensor descriptor object. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ace265c09fcf365ac3900013ff0c971fe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace265c09fcf365ac3900013ff0c971fe">&#9670;&nbsp;</a></span>filter_desc()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const cudnnFilterDescriptor_t&amp; <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::filter_desc </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>A constant reference to the filter descriptor. </dd></dl>

</div>
</div>
<a id="a61355129924153169b4f5be6177e4cc3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a61355129924153169b4f5be6177e4cc3">&#9670;&nbsp;</a></span>height()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::height </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>The height of the tensor. </dd></dl>

</div>
</div>
<a id="a80de652665a9fd62cb1e6a26cb3bf40c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80de652665a9fd62cb1e6a26cb3bf40c">&#9670;&nbsp;</a></span>l1_norm() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Scalar <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::l1_norm </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>The L1 norm of the tensor. </dd></dl>

</div>
</div>
<a id="a82878aacda8c60cd8cb4a17eb6d60ccf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a82878aacda8c60cd8cb4a17eb6d60ccf">&#9670;&nbsp;</a></span>l1_norm() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::l1_norm </td>
          <td>(</td>
          <td class="paramtype">const std::array&lt; bool, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>ranks</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ranks</td><td>A size 4 boolean array denoting which ranks are to be reduced. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The reduced tensor. </dd></dl>

</div>
</div>
<a id="aac7d2e6127db547aae890c305405bb28"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac7d2e6127db547aae890c305405bb28">&#9670;&nbsp;</a></span>l2_norm() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Scalar <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::l2_norm </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>The L2 norm of the tensor. </dd></dl>

</div>
</div>
<a id="a111736834abf5c68e42ea19bfa3ba651"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a111736834abf5c68e42ea19bfa3ba651">&#9670;&nbsp;</a></span>l2_norm() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::l2_norm </td>
          <td>(</td>
          <td class="paramtype">const std::array&lt; bool, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>ranks</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ranks</td><td>A size 4 boolean array denoting which ranks are to be reduced. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The reduced tensor. </dd></dl>

</div>
</div>
<a id="ae2755921f191344ac81f632d6557ef1f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae2755921f191344ac81f632d6557ef1f">&#9670;&nbsp;</a></span>max() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Scalar <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::max </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>The maximum of all elements of the tensor. </dd></dl>

</div>
</div>
<a id="a99a2d7f69a75e98703dbf66b48a53205"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a99a2d7f69a75e98703dbf66b48a53205">&#9670;&nbsp;</a></span>max() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::max </td>
          <td>(</td>
          <td class="paramtype">const std::array&lt; bool, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>ranks</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ranks</td><td>A size 4 boolean array denoting which ranks are to be reduced. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The reduced tensor. </dd></dl>

</div>
</div>
<a id="ac6b9a062dd41eb9cefaaccc003f1d44d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac6b9a062dd41eb9cefaaccc003f1d44d">&#9670;&nbsp;</a></span>min() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Scalar <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::min </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>The minimum of all elements of the tensor. </dd></dl>

</div>
</div>
<a id="ab45c4cf77bc7a4aaabda0ea8a0d57282"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab45c4cf77bc7a4aaabda0ea8a0d57282">&#9670;&nbsp;</a></span>min() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::min </td>
          <td>(</td>
          <td class="paramtype">const std::array&lt; bool, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>ranks</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ranks</td><td>A size 4 boolean array denoting which ranks are to be reduced. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The reduced tensor. </dd></dl>

</div>
</div>
<a id="af5e3f42920bf068b750d71356a41cf1b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5e3f42920bf068b750d71356a41cf1b">&#9670;&nbsp;</a></span>op()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::op </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;&#160;</td>
          <td class="paramname"><em>b</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnOpTensorOp_t&#160;</td>
          <td class="paramname"><em>op_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;&#160;</td>
          <td class="paramname"><em>c</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It performs the specified operation on tensors a and b and saves the result in c. </p>
<p>\(C = op(\alpha * A, \beta * B) + \gamma * C\)</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">a</td><td>The first operand. </td></tr>
    <tr><td class="paramname">alpha</td><td>The scaling factor of the first operand. </td></tr>
    <tr><td class="paramname">b</td><td>The second operand. </td></tr>
    <tr><td class="paramname">beta</td><td>The scaling factor of the second operand. </td></tr>
    <tr><td class="paramname">op_type</td><td>The operation type. </td></tr>
    <tr><td class="paramname">gamma</td><td>The scaling factor of the result tensor. </td></tr>
    <tr><td class="paramname">c</td><td>The result tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a879177caac8ca874b91a3ccee66af2b3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a879177caac8ca874b91a3ccee66af2b3">&#9670;&nbsp;</a></span>reduce() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Scalar <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::reduce </td>
          <td>(</td>
          <td class="paramtype">cudnnReduceTensorOp_t&#160;</td>
          <td class="paramname"><em>op_type</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs a reduction along all ranks of the tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">op_type</td><td>The reduction operation type. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The result of the reduction. </dd></dl>

</div>
</div>
<a id="a794d079d4446a5a55beed6ac65ab4e72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a794d079d4446a5a55beed6ac65ab4e72">&#9670;&nbsp;</a></span>reduce() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::reduce </td>
          <td>(</td>
          <td class="paramtype">cudnnReduceTensorOp_t&#160;</td>
          <td class="paramname"><em>op_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; bool, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>ranks</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Performs a reduction along the specified ranks of the tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">op_type</td><td>The reduction operation type. </td></tr>
    <tr><td class="paramname">ranks</td><td>A size 4 boolean array denoting which ranks are to be reduced. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The result of the reduction. </dd></dl>

</div>
</div>
<a id="a2d054df2a19f7623dfbda10bfcf639ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d054df2a19f7623dfbda10bfcf639ae">&#9670;&nbsp;</a></span>reduce_op()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::reduce_op </td>
          <td>(</td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudnnReduceTensorOp_t&#160;</td>
          <td class="paramname"><em>op_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;&#160;</td>
          <td class="paramname"><em>b</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It performs the specified reduction operation on tensor a and adds it to tensor b. </p>
<p>\(B = \alpha * reduce_op(A) + \beta * B\)</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">alpha</td><td>The factor by which the result of the reduction is to be scaled. </td></tr>
    <tr><td class="paramname">a</td><td>The tensor to reduce. </td></tr>
    <tr><td class="paramname">op_type</td><td>The reduction operation type. </td></tr>
    <tr><td class="paramname">beta</td><td>The scaling factor of the target tensor. </td></tr>
    <tr><td class="paramname">b</td><td>The target tensor. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a99057790847ce509fbbb377ea8c07aad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a99057790847ce509fbbb377ea8c07aad">&#9670;&nbsp;</a></span>samples()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::samples </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>The batch size of the tensor. </dd></dl>

</div>
</div>
<a id="acecbeef40e8d5703047aba4ebdfb17c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acecbeef40e8d5703047aba4ebdfb17c8">&#9670;&nbsp;</a></span>scale()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::scale </td>
          <td>(</td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It scales the specified tensor by a certain factor. </p>
<p>\(A = \alpha * B\)</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">alpha</td><td>The factor by which the tensor is to be scaled. </td></tr>
    <tr><td class="paramname">a</td><td>The tensor to scale. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a48fd267290bfb7b49e39a6d1e1b844ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a48fd267290bfb7b49e39a6d1e1b844ab">&#9670;&nbsp;</a></span>set_values()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::set_values </td>
          <td>(</td>
          <td class="paramtype">Scalar&#160;</td>
          <td class="paramname"><em>value</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">value</td><td>The value to which all elemetnts of the tensor are to be set. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a9094c2bf0bf56e5ca174a8ee9c13d0ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9094c2bf0bf56e5ca174a8ee9c13d0ee">&#9670;&nbsp;</a></span>sum() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Scalar <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::sum </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>The sum of all elements of the tensor. </dd></dl>

</div>
</div>
<a id="aea14b2fc6d9f4df9c8e03f5177966899"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aea14b2fc6d9f4df9c8e03f5177966899">&#9670;&nbsp;</a></span>sum() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Self</a> <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::sum </td>
          <td>(</td>
          <td class="paramtype">const std::array&lt; bool, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>ranks</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ranks</td><td>A size 4 boolean array denoting which ranks are to be reduced. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The reduced tensor. </dd></dl>

</div>
</div>
<a id="a5f8177e7ea5deb5771c564b56f4fac7f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5f8177e7ea5deb5771c564b56f4fac7f">&#9670;&nbsp;</a></span>to_string()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::to_string </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>A string representation of the tensor. </dd></dl>

</div>
</div>
<a id="ad48aa03288eb330549d7038813183456"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad48aa03288eb330549d7038813183456">&#9670;&nbsp;</a></span>width()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::size_t <a class="el" href="classcattle_1_1gpu_1_1_cu_d_n_n_tensor.html">cattle::gpu::CuDNNTensor</a>&lt; Scalar &gt;::width </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>The width of the tensor. </dd></dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/viktorcsomor/git/C-ATTL3/C-ATTL3/core/gpu/cudnn/<a class="el" href="_cu_d_n_n_tensor_8hpp_source.html">CuDNNTensor.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
