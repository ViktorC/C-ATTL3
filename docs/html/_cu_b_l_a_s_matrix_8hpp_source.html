<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: /Users/viktorcsomor/git/C-ATTL3/C-ATTL3/core/gpu/cublas/CuBLASMatrix.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_b8183163ce8e0490cf11c57c211e66be.html">C-ATTL3</a></li><li class="navelem"><a class="el" href="dir_d7824ce09980932099a987dd9d70823b.html">core</a></li><li class="navelem"><a class="el" href="dir_15b5e1e2b6051de2786d263ad618ae2e.html">gpu</a></li><li class="navelem"><a class="el" href="dir_3f7c3a56064c859eee8739f508695d1b.html">cublas</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">CuBLASMatrix.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/*</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"> * CuBLASMatrix.hpp</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> *  Created on: 12 Aug 2018</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> *      Author: Viktor Csomor</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#ifndef C_ATTL3_CORE_GPU_CUBLAS_CUBLASMATRIX_HPP_</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#define C_ATTL3_CORE_GPU_CUBLAS_CUBLASMATRIX_HPP_</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &lt;cassert&gt;</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &lt;cublas_v2.h&gt;</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &lt;type_traits&gt;</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &quot;core/EigenProxy.hpp&quot;</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &quot;core/gpu/cuda/CUDAArray.hpp&quot;</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &quot;CuBLASHandle.hpp&quot;</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacecattle.html">cattle</a> {</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="keyword">namespace </span>gpu {</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="keyword">namespace </span>{</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="keyword">using</span> AsumRoutine = cublasStatus_t (*)(cublasHandle_t, int, <span class="keyword">const</span> Scalar*, int, Scalar*);</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt; __inline__ AsumRoutine&lt;Scalar&gt; asum_routine() { <span class="keywordflow">return</span> &amp;cublasDasum; }</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="keyword">template</span>&lt;&gt; __inline__ AsumRoutine&lt;float&gt; asum_routine() { <span class="keywordflow">return</span> &amp;cublasSasum; }</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="keyword">using</span> Nrm2Routine = cublasStatus_t (*)(cublasHandle_t, int, <span class="keyword">const</span> Scalar*, int, Scalar*);</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt; __inline__ Nrm2Routine&lt;Scalar&gt; nrm2_routine() { <span class="keywordflow">return</span> &amp;cublasDnrm2; }</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="keyword">template</span>&lt;&gt; __inline__ Nrm2Routine&lt;float&gt; nrm2_routine() { <span class="keywordflow">return</span> &amp;cublasSnrm2; }</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="keyword">using</span> ScalRoutine = cublasStatus_t (*)(cublasHandle_t, int, <span class="keyword">const</span> Scalar*, Scalar*, int);</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt; __inline__ ScalRoutine&lt;Scalar&gt; scal_routine() { <span class="keywordflow">return</span> &amp;cublasDscal; }</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="keyword">template</span>&lt;&gt; __inline__ ScalRoutine&lt;float&gt; scal_routine() { <span class="keywordflow">return</span> &amp;cublasSscal; }</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="keyword">using</span> AxpyRoutine = cublasStatus_t (*)(cublasHandle_t, int, <span class="keyword">const</span> Scalar*, <span class="keyword">const</span> Scalar*, int, Scalar*, int);</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt; __inline__ AxpyRoutine&lt;Scalar&gt; axpy_routine() { <span class="keywordflow">return</span> &amp;cublasDaxpy; }</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="keyword">template</span>&lt;&gt; __inline__ AxpyRoutine&lt;float&gt; axpy_routine() { <span class="keywordflow">return</span> &amp;cublasSaxpy; }</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="keyword">using</span> GemmRoutine = cublasStatus_t (*)(cublasHandle_t, cublasOperation_t, cublasOperation_t, int, int, int,</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;        <span class="keyword">const</span> Scalar*, <span class="keyword">const</span> Scalar*, int, <span class="keyword">const</span> Scalar*, int, <span class="keyword">const</span> Scalar*, Scalar*, int);</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt; __inline__ GemmRoutine&lt;Scalar&gt; gemm_routine() { <span class="keywordflow">return</span> &amp;cublasDgemm; }</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="keyword">template</span>&lt;&gt; __inline__ GemmRoutine&lt;float&gt; gemm_routine() { <span class="keywordflow">return</span> &amp;cublasSgemm; }</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;}</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar&gt;</div><div class="line"><a name="l00056"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">   56</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix</a> : <span class="keyword">public</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray</a>&lt;Scalar&gt; {</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;    static_assert(std::is_floating_point&lt;Scalar&gt;::value, <span class="stringliteral">&quot;non floating-point scalar type&quot;</span>);</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">CUDAArray&lt;Scalar&gt;</a> <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Base</a>;</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix&lt;Scalar&gt;</a> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">Self</a>;</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00067"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#aa6673052417a6cc911df0d3113950ace">   67</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#aa6673052417a6cc911df0d3113950ace">CuBLASMatrix</a>(Scalar* <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>) :</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Base</a>(<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>, <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a> * <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>),</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;            _rows(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>),</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;            _cols(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>) { }</div><div class="line"><a name="l00075"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a7c9c0a836edc1bce17807198418325e4">   75</a></span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a7c9c0a836edc1bce17807198418325e4">CuBLASMatrix</a>(std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>, std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>) :</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">Base</a>(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a> * <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>),</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;            _rows(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>),</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;            _cols(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>) { }</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix</a>() :</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix</a>(0u, 0u) { }</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;    <span class="keyword">inline</span> CuBLASMatrix(<span class="keyword">const</span> <a class="code" href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">Matrix&lt;Scalar&gt;</a>&amp; matrix) :</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;            CuBLASMatrix(matrix.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>(), matrix.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>()) {</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>() &gt; 0)</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a53a0b01db3d84497c5c7c47a8582a22d">Base::copy_from_host</a>(matrix.data());</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;    }</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    <span class="keyword">inline</span> CuBLASMatrix(<span class="keyword">const</span> Self&amp; matrix) :</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;            Base(matrix),</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;            _rows(matrix._rows),</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;            _cols(matrix._cols) { }</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;    <span class="keyword">inline</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#aa6673052417a6cc911df0d3113950ace">CuBLASMatrix</a>(Self&amp;&amp; matrix) :</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;            <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#aa6673052417a6cc911df0d3113950ace">CuBLASMatrix</a>() {</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;        swap(*<span class="keyword">this</span>, matrix);</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;    }</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    <span class="keyword">virtual</span> ~<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#aa6673052417a6cc911df0d3113950ace">CuBLASMatrix</a>() = <span class="keywordflow">default</span>;</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;    <span class="keyword">inline</span> Self&amp; operator=(Self matrix) {</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;        swap(*<span class="keyword">this</span>, matrix);</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;    }</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;    <span class="keyword">inline</span> <span class="keyword">operator</span> Matrix&lt;Scalar&gt;() <span class="keyword">const</span> {</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>() == 0)</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;            <span class="keywordflow">return</span> Matrix&lt;Scalar&gt;();</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;        Matrix&lt;Scalar&gt; out(_rows, _cols);</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#ab3aeb7d6d0bb4583880a3b187a3c5945">Base::copy_to_host</a>(out.data());</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;        <span class="keywordflow">return</span> out;</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;    }</div><div class="line"><a name="l00109"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">  109</a></span>&#160;    <span class="keyword">inline</span> std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;        <span class="keywordflow">return</span> _rows;</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;    }</div><div class="line"><a name="l00115"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">  115</a></span>&#160;    <span class="keyword">inline</span> std::size_t <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;        <span class="keywordflow">return</span> _cols;</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;    }</div><div class="line"><a name="l00121"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a2c40e296009c91534680a9f819e86ac8">  121</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a2c40e296009c91534680a9f819e86ac8">l1_norm</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;        Scalar res;</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a24d2dc425c2dc819ba4207aea72c5396">asum</a>(<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>(), 1, *<span class="keyword">this</span>, &amp;res);</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;        <span class="keywordflow">return</span> res;</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;    }</div><div class="line"><a name="l00129"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#ab78bd90eeb6c0bd5cb94699423357e92">  129</a></span>&#160;    <span class="keyword">inline</span> Scalar <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#ab78bd90eeb6c0bd5cb94699423357e92">l2_norm</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;        Scalar res;</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a43c2a87d43b3bed5ae656a8252c6afbb">nrm2</a>(<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>(), 1, *<span class="keyword">this</span>, &amp;res);</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;        <span class="keywordflow">return</span> res;</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;    }</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;    <span class="keyword">inline</span> Self&amp; operator+=(<span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a20977bd5feb5b34923442926254c6fc2">axpy</a>(<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>(), 1, rhs, 1, 1, *<span class="keyword">this</span>);</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;    }</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;    <span class="keyword">inline</span> Self&amp; operator-=(<span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a20977bd5feb5b34923442926254c6fc2">axpy</a>(<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>(), 1, rhs, -1, 1, *<span class="keyword">this</span>);</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;    }</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;    <span class="keyword">inline</span> Self&amp; operator*=(<span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#ab3a42999b9e1502f76076c2253e8fd29">gemm</a>(*<span class="keyword">this</span>, <span class="keyword">false</span>, rhs, <span class="keyword">false</span>, 1, 1, *<span class="keyword">this</span>);</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;    }</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    <span class="keyword">inline</span> Self operator*=(Scalar rhs) {</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;        <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a5c3bbed871a3388e2d42cf09947fe206">scal</a>(<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">Base::size</a>(), rhs, 1, *<span class="keyword">this</span>);</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span>;</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;    }</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;    <span class="keyword">inline</span> Self operator*=(Scalar rhs) {</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;        <span class="keywordflow">return</span> *<span class="keyword">this</span> * (1 / rhs);</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;    }</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator+(Self lhs, <span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;        <span class="keywordflow">return</span> lhs += rhs;</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;    }</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator-(Self lhs, <span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;        <span class="keywordflow">return</span> lhs -= rhs;</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    }</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator*(Self lhs, <span class="keyword">const</span> Self&amp; rhs) {</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;        <span class="keywordflow">return</span> lhs *= rhs;</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;    }</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator*(Self lhs, Scalar rhs) {</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;        <span class="keywordflow">return</span> lhs *= rhs;</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;    }</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> Self operator/(Self lhs, Scalar rhs) {</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;        <span class="keywordflow">return</span> lhs /= rhs;</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;    }</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;    <span class="keyword">inline</span> <span class="keyword">friend</span> <span class="keywordtype">void</span> swap(Self&amp; matrix1, Self&amp; matrix2) {</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;        <span class="keyword">using</span> std::swap;</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;        swap(static_cast&lt;Base&amp;&gt;(matrix1), static_cast&lt;Base&amp;&gt;(matrix2));</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;        swap(matrix1._rows, matrix2._rows);</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;        swap(matrix1._cols, matrix2._cols);</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;    }</div><div class="line"><a name="l00184"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a24d2dc425c2dc819ba4207aea72c5396">  184</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a24d2dc425c2dc819ba4207aea72c5396">asum</a>(<span class="keywordtype">int</span> n, <span class="keywordtype">int</span> inc_a, <span class="keyword">const</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix&lt;Scalar&gt;</a>&amp; a, <span class="comment">/* out */</span> Scalar&amp; result) {</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;        AsumRoutine&lt;Scalar&gt; <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a24d2dc425c2dc819ba4207aea72c5396">asum</a> = asum_routine&lt;Scalar&gt;();</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;        cublasAssert(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a24d2dc425c2dc819ba4207aea72c5396">asum</a>(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_handle.html#ae900df184b6eca943bf4e5ce2ab56006">CuBLASHandle::get_instance</a>(), n, a.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), inc_a, &amp;result));</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;    }</div><div class="line"><a name="l00198"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a43c2a87d43b3bed5ae656a8252c6afbb">  198</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a43c2a87d43b3bed5ae656a8252c6afbb">nrm2</a>(<span class="keywordtype">int</span> n, <span class="keywordtype">int</span> inc_a, <span class="keyword">const</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix&lt;Scalar&gt;</a>&amp; a, <span class="comment">/* out */</span> Scalar&amp; result) {</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;        Nrm2Routine&lt;Scalar&gt; <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a43c2a87d43b3bed5ae656a8252c6afbb">nrm2</a> = nrm2_routine&lt;Scalar&gt;();</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;        cublasAssert(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a43c2a87d43b3bed5ae656a8252c6afbb">nrm2</a>(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_handle.html#ae900df184b6eca943bf4e5ce2ab56006">CuBLASHandle::get_instance</a>(), n, a.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), inc_a, &amp;result));</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;    }</div><div class="line"><a name="l00212"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a5c3bbed871a3388e2d42cf09947fe206">  212</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a5c3bbed871a3388e2d42cf09947fe206">scal</a>(<span class="keywordtype">int</span> n, Scalar alpha, <span class="keywordtype">int</span> inc_a, <span class="comment">/* in/out */</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix&lt;Scalar&gt;</a>&amp; a) {</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;        ScalRoutine&lt;Scalar&gt; <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a5c3bbed871a3388e2d42cf09947fe206">scal</a> = scal_routine&lt;Scalar&gt;();</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;        cublasAssert(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a5c3bbed871a3388e2d42cf09947fe206">scal</a>(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_handle.html#ae900df184b6eca943bf4e5ce2ab56006">CuBLASHandle::get_instance</a>(), n, &amp;alpha, a.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), inc_a));</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;    }</div><div class="line"><a name="l00228"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a20977bd5feb5b34923442926254c6fc2">  228</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a20977bd5feb5b34923442926254c6fc2">axpy</a>(<span class="keywordtype">int</span> n, <span class="keywordtype">int</span> inc_a, <span class="keyword">const</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix&lt;Scalar&gt;</a>&amp; a, Scalar alpha,</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;            <span class="keywordtype">int</span> inc_b, <span class="comment">/* in/out */</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix&lt;Scalar&gt;</a>&amp; b) {</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;        assert(a.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>() == b.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>() &amp;&amp; a.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>() == b.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>());</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;        AxpyRoutine&lt;Scalar&gt; <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a20977bd5feb5b34923442926254c6fc2">axpy</a> = axpy_routine&lt;Scalar&gt;();</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;        cublasAssert(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a20977bd5feb5b34923442926254c6fc2">axpy</a>(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_handle.html#ae900df184b6eca943bf4e5ce2ab56006">CuBLASHandle::get_instance</a>(), n, &amp;alpha, a.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), inc_a, b.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), inc_b));</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;    }</div><div class="line"><a name="l00248"></a><span class="lineno"><a class="line" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#ab3a42999b9e1502f76076c2253e8fd29">  248</a></span>&#160;    <span class="keyword">inline</span> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#ab3a42999b9e1502f76076c2253e8fd29">gemm</a>(<span class="keyword">const</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix&lt;Scalar&gt;</a>&amp; a, <span class="keywordtype">bool</span> transpose_a, <span class="keyword">const</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix&lt;Scalar&gt;</a>&amp; b,</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;            <span class="keywordtype">bool</span> transpose_b, Scalar alpha, Scalar beta, <span class="comment">/* out */</span> <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">CuBLASMatrix&lt;Scalar&gt;</a>&amp; c) {</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;        std::size_t a_rows, a_cols, b_rows, b_cols;</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;        <span class="keywordflow">if</span> (transpose_a) {</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;            a_rows = a.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>();</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;            a_cols = a.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>();</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;            a_rows = a.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>();</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;            a_cols = a.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>();</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;        }</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;        <span class="keywordflow">if</span> (transpose_b) {</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;            b_rows = b.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>();</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;            b_cols = b.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>();</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;            b_rows = b.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>();</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;            b_cols = b.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>();</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;        }</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;        assert(a_cols == b_rows);</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;        assert(c.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>() == a_rows() &amp;&amp; c.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cols</a>() == b_cols);</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;        cublasOperation_t a_op = transpose_a ? CUBLAS_OP_T : CUBLAS_OP_N;</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;        cublasOperation_t b_op = transpose_b ? CUBLAS_OP_T : CUBLAS_OP_N;</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;        <span class="comment">// Resolve the GEMM precision based on the scalar type.</span></div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;        GemmRoutine&lt;Scalar&gt; <a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#ab3a42999b9e1502f76076c2253e8fd29">gemm</a> = gemm_routine&lt;Scalar&gt;();</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;        <span class="comment">// Perform the matrix multiplication.</span></div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;        cublasAssert(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#ab3a42999b9e1502f76076c2253e8fd29">gemm</a>(<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_handle.html#ae900df184b6eca943bf4e5ce2ab56006">CuBLASHandle::get_instance</a>(), a_op, b_op, a_rows, b_cols, a_cols, &amp;alpha,</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;                a.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), a.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>(), b.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), b.<a class="code" href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">rows</a>(), &amp;beta, c.<a class="code" href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">data</a>(), a_rows));</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;    }</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;    std::size_t _rows, _cols;</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;};</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;} <span class="comment">/* namespace gpu */</span></div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;} <span class="comment">/* namespace cattle */</span></div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;<span class="preprocessor">#endif </span><span class="comment">/* C_ATTL3_CORE_GPU_CUBLAS_CUBLASMATRIX_HPP_ */</span><span class="preprocessor"></span></div><div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html_a20977bd5feb5b34923442926254c6fc2"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a20977bd5feb5b34923442926254c6fc2">cattle::gpu::CuBLASMatrix::axpy</a></div><div class="ttdeci">static void axpy(int n, int inc_a, const CuBLASMatrix&lt; Scalar &gt; &amp;a, Scalar alpha, int inc_b, CuBLASMatrix&lt; Scalar &gt; &amp;b)</div><div class="ttdoc">It adds a scaled matrix to another matrix. </div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:228</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html_a8e8bc68525218f84bc9bda488e82f7cf"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a8e8bc68525218f84bc9bda488e82f7cf">cattle::gpu::CuBLASMatrix::rows</a></div><div class="ttdeci">std::size_t rows() const</div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:109</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html">cattle::gpu::CuBLASMatrix</a></div><div class="ttdoc">A template class for column-major cuBLAS device matrices of different data types. ...</div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:56</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html_addb1729f23ff613be11802f1cf6ac83c"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#addb1729f23ff613be11802f1cf6ac83c">cattle::gpu::CuBLASMatrix::cols</a></div><div class="ttdeci">std::size_t cols() const</div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:115</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html_aa6673052417a6cc911df0d3113950ace"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#aa6673052417a6cc911df0d3113950ace">cattle::gpu::CuBLASMatrix::CuBLASMatrix</a></div><div class="ttdeci">CuBLASMatrix(Scalar *data, std::size_t rows, std::size_t cols)</div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:67</div></div>
<div class="ttc" id="namespacecattle_html_a1d78623a47279d516750a44dbad6090b"><div class="ttname"><a href="namespacecattle.html#a1d78623a47279d516750a44dbad6090b">cattle::Matrix</a></div><div class="ttdeci">Eigen::Matrix&lt; Scalar, Eigen::Dynamic, Eigen::Dynamic, Eigen::ColMajor, Eigen::Dynamic, Eigen::Dynamic &gt; Matrix</div><div class="ttdoc">An alias for a dynamically sized matrix of an arbitrary scalar type. </div><div class="ttdef"><b>Definition:</b> EigenProxy.hpp:44</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html_a24d2dc425c2dc819ba4207aea72c5396"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a24d2dc425c2dc819ba4207aea72c5396">cattle::gpu::CuBLASMatrix::asum</a></div><div class="ttdeci">static void asum(int n, int inc_a, const CuBLASMatrix&lt; Scalar &gt; &amp;a, Scalar &amp;result)</div><div class="ttdoc">It computes the sum of the absolute values of the matrix&amp;#39;s coefficients. </div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:184</div></div>
<div class="ttc" id="namespacecattle_html"><div class="ttname"><a href="namespacecattle.html">cattle</a></div><div class="ttdoc">The namespace containing all classes and typedefs of the C-ATTL3 library. </div><div class="ttdef"><b>Definition:</b> PPMCodec.hpp:20</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html_a43c2a87d43b3bed5ae656a8252c6afbb"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a43c2a87d43b3bed5ae656a8252c6afbb">cattle::gpu::CuBLASMatrix::nrm2</a></div><div class="ttdeci">static void nrm2(int n, int inc_a, const CuBLASMatrix&lt; Scalar &gt; &amp;a, Scalar &amp;result)</div><div class="ttdoc">It computes the Euclidian norm of the matrix&amp;#39;s coefficients. </div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:198</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_handle_html_ae900df184b6eca943bf4e5ce2ab56006"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_handle.html#ae900df184b6eca943bf4e5ce2ab56006">cattle::gpu::CuBLASHandle::get_instance</a></div><div class="ttdeci">static const CuBLASHandle &amp; get_instance()</div><div class="ttdef"><b>Definition:</b> CuBLASHandle.hpp:34</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html_ab3a42999b9e1502f76076c2253e8fd29"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#ab3a42999b9e1502f76076c2253e8fd29">cattle::gpu::CuBLASMatrix::gemm</a></div><div class="ttdeci">static void gemm(const CuBLASMatrix&lt; Scalar &gt; &amp;a, bool transpose_a, const CuBLASMatrix&lt; Scalar &gt; &amp;b, bool transpose_b, Scalar alpha, Scalar beta, CuBLASMatrix&lt; Scalar &gt; &amp;c)</div><div class="ttdoc">It computes the product of the matrix multiplication. </div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:248</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_c_u_d_a_array_html_a3bd7455c00b1cb1cf3d31a849429e4d9"><div class="ttname"><a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a3bd7455c00b1cb1cf3d31a849429e4d9">cattle::gpu::CUDAArray::data</a></div><div class="ttdeci">const Scalar * data() const</div><div class="ttdef"><b>Definition:</b> CUDAArray.hpp:78</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html_a5c3bbed871a3388e2d42cf09947fe206"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a5c3bbed871a3388e2d42cf09947fe206">cattle::gpu::CuBLASMatrix::scal</a></div><div class="ttdeci">static void scal(int n, Scalar alpha, int inc_a, CuBLASMatrix&lt; Scalar &gt; &amp;a)</div><div class="ttdoc">It scales the matrix by the specified factor. </div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:212</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html_a7c9c0a836edc1bce17807198418325e4"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a7c9c0a836edc1bce17807198418325e4">cattle::gpu::CuBLASMatrix::CuBLASMatrix</a></div><div class="ttdeci">CuBLASMatrix(std::size_t rows, std::size_t cols)</div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:75</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_c_u_d_a_array_html_a5d242f9908e1a4448a4585e220ef7ca1"><div class="ttname"><a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a5d242f9908e1a4448a4585e220ef7ca1">cattle::gpu::CUDAArray::size</a></div><div class="ttdeci">std::size_t size() const</div><div class="ttdef"><b>Definition:</b> CUDAArray.hpp:71</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_c_u_d_a_array_html_ab3aeb7d6d0bb4583880a3b187a3c5945"><div class="ttname"><a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#ab3aeb7d6d0bb4583880a3b187a3c5945">cattle::gpu::CUDAArray::copy_to_host</a></div><div class="ttdeci">void copy_to_host(Scalar *host_array) const</div><div class="ttdoc">It copies the entire device array to the host memory. </div><div class="ttdef"><b>Definition:</b> CUDAArray.hpp:116</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html_ab78bd90eeb6c0bd5cb94699423357e92"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#ab78bd90eeb6c0bd5cb94699423357e92">cattle::gpu::CuBLASMatrix::l2_norm</a></div><div class="ttdeci">Scalar l2_norm() const</div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:129</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_c_u_d_a_array_html"><div class="ttname"><a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html">cattle::gpu::CUDAArray</a></div><div class="ttdoc">A template class for CUDA device arrays of different data types. </div><div class="ttdef"><b>Definition:</b> CUDAArray.hpp:24</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix_html_a2c40e296009c91534680a9f819e86ac8"><div class="ttname"><a href="classcattle_1_1gpu_1_1_cu_b_l_a_s_matrix.html#a2c40e296009c91534680a9f819e86ac8">cattle::gpu::CuBLASMatrix::l1_norm</a></div><div class="ttdeci">Scalar l1_norm() const</div><div class="ttdef"><b>Definition:</b> CuBLASMatrix.hpp:121</div></div>
<div class="ttc" id="classcattle_1_1gpu_1_1_c_u_d_a_array_html_a53a0b01db3d84497c5c7c47a8582a22d"><div class="ttname"><a href="classcattle_1_1gpu_1_1_c_u_d_a_array.html#a53a0b01db3d84497c5c7c47a8582a22d">cattle::gpu::CUDAArray::copy_from_host</a></div><div class="ttdeci">void copy_from_host(const Scalar *host_array)</div><div class="ttdoc">It populates the entire device array with data from the host memory. </div><div class="ttdef"><b>Definition:</b> CUDAArray.hpp:106</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
