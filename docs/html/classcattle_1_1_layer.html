<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>C-ATTL3: cattle::Layer&lt; Scalar, Rank &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">C-ATTL3
   &#160;<span id="projectnumber">0.5</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecattle.html">cattle</a></li><li class="navelem"><a class="el" href="classcattle_1_1_layer.html">Layer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classcattle_1_1_layer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">cattle::Layer&lt; Scalar, Rank &gt; Class Template Reference<span class="mlabels"><span class="mlabel">abstract</span></span></div>  </div>
</div><!--header-->
<div class="contents">

<p>An abstract class template representing layers in a neural network.  
 <a href="classcattle_1_1_layer.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_layer_8hpp_source.html">Layer.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for cattle::Layer&lt; Scalar, Rank &gt;:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classcattle_1_1_layer.png" usemap="#cattle::Layer_3C_20Scalar_2C_20Rank_20_3E_map" alt=""/>
  <map id="cattle::Layer_3C_20Scalar_2C_20Rank_20_3E_map" name="cattle::Layer_3C_20Scalar_2C_20Rank_20_3E_map">
<area href="classcattle_1_1_activation_layer.html" title="An abstract class template that represents an activation function layer. " alt="cattle::ActivationLayer&lt; Scalar, Rank &gt;" shape="rect" coords="331,56,652,80"/>
<area href="classcattle_1_1_batch_norm_layer.html" title="A class template for a per-channel batch normalization layer. " alt="cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;" shape="rect" coords="331,112,652,136"/>
<area href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html" title="A class template for a per-activation batch normalization layer. " alt="cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;" shape="rect" coords="331,168,652,192"/>
<area href="classcattle_1_1_broadcast_layer.html" title="A class template representing a broadcasting layer that repeats the contents of its input tensors alo..." alt="cattle::BroadcastLayer&lt; Scalar, Rank &gt;" shape="rect" coords="331,224,652,248"/>
<area href="classcattle_1_1_dropout_layer.html" title="A class template representing a drop-out layer. " alt="cattle::DropoutLayer&lt; Scalar, Rank &gt;" shape="rect" coords="331,280,652,304"/>
<area href="classcattle_1_1_kernel_layer.html" title="An abstract class template that represents a kernel-based linear transformation function layer..." alt="cattle::KernelLayer&lt; Scalar, Rank &gt;" shape="rect" coords="331,336,652,360"/>
<area href="classcattle_1_1_pool_layer.html" title="An abstract base class template representing a pooling layer. " alt="cattle::PoolLayer&lt; Scalar, Rank &gt;" shape="rect" coords="331,392,652,416"/>
<area href="classcattle_1_1_reshape_layer.html" title="A class template representing a reshaping layer that outputs a reshaped copy of the input tensor with..." alt="cattle::ReshapeLayer&lt; Scalar, Rank &gt;" shape="rect" coords="331,448,652,472"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a46db46c62f3d46c6bbef5a482d7fcb00"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classcattle_1_1_layer.html">Layer</a>&lt; Scalar, Rank &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a46db46c62f3d46c6bbef5a482d7fcb00">clone</a> () const =0</td></tr>
<tr class="memdesc:a46db46c62f3d46c6bbef5a482d7fcb00"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a clone of the layer instance.  <a href="#a46db46c62f3d46c6bbef5a482d7fcb00">More...</a><br /></td></tr>
<tr class="separator:a46db46c62f3d46c6bbef5a482d7fcb00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a074a197df04250449a059d97a4e6e120"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classcattle_1_1_layer.html">Layer</a>&lt; Scalar, Rank &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a074a197df04250449a059d97a4e6e120">clone_with_shared_params</a> ()=0</td></tr>
<tr class="memdesc:a074a197df04250449a059d97a4e6e120"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a clone of the layer instance using a reference to the original's parameters.  <a href="#a074a197df04250449a059d97a4e6e120">More...</a><br /></td></tr>
<tr class="separator:a074a197df04250449a059d97a4e6e120"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a683f9b67748863329938da07e86ecd8c"><td class="memItemLeft" align="right" valign="top">virtual const <a class="el" href="classcattle_1_1_layer.html">Layer</a>&lt; Scalar, Rank &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a683f9b67748863329938da07e86ecd8c">get_params_owner</a> () const =0</td></tr>
<tr class="memdesc:a683f9b67748863329938da07e86ecd8c"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a reference to the layer owning the parameters used.  <a href="#a683f9b67748863329938da07e86ecd8c">More...</a><br /></td></tr>
<tr class="separator:a683f9b67748863329938da07e86ecd8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a450d75b5f9e084552819ad8fdcf2ad59"><td class="memItemLeft" align="right" valign="top">virtual const <a class="el" href="classcattle_1_1_dimensions.html">Dims</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a450d75b5f9e084552819ad8fdcf2ad59">get_input_dims</a> () const =0</td></tr>
<tr class="memdesc:a450d75b5f9e084552819ad8fdcf2ad59"><td class="mdescLeft">&#160;</td><td class="mdescRight">A simple constant getter method for the input dimensionality of the layer.  <a href="#a450d75b5f9e084552819ad8fdcf2ad59">More...</a><br /></td></tr>
<tr class="separator:a450d75b5f9e084552819ad8fdcf2ad59"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af29a87e0166c1dedc60af30ee392d099"><td class="memItemLeft" align="right" valign="top">virtual const <a class="el" href="classcattle_1_1_dimensions.html">Dims</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#af29a87e0166c1dedc60af30ee392d099">get_output_dims</a> () const =0</td></tr>
<tr class="memdesc:af29a87e0166c1dedc60af30ee392d099"><td class="mdescLeft">&#160;</td><td class="mdescRight">A simple constant getter method for the output dimensionality of the layer.  <a href="#af29a87e0166c1dedc60af30ee392d099">More...</a><br /></td></tr>
<tr class="separator:af29a87e0166c1dedc60af30ee392d099"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af208065ae34cbebcdc932c84383ea159"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#af208065ae34cbebcdc932c84383ea159">is_input_layer</a> () const =0</td></tr>
<tr class="memdesc:af208065ae34cbebcdc932c84383ea159"><td class="mdescLeft">&#160;</td><td class="mdescRight">A constant method that returns whether this layer functions as an input layer.  <a href="#af208065ae34cbebcdc932c84383ea159">More...</a><br /></td></tr>
<tr class="separator:af208065ae34cbebcdc932c84383ea159"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9557e077d940b2ff0c280e9a78c4b52e"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a9557e077d940b2ff0c280e9a78c4b52e">set_input_layer</a> (bool input_layer)=0</td></tr>
<tr class="memdesc:a9557e077d940b2ff0c280e9a78c4b52e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets this instance's input layer status to the given value.  <a href="#a9557e077d940b2ff0c280e9a78c4b52e">More...</a><br /></td></tr>
<tr class="separator:a9557e077d940b2ff0c280e9a78c4b52e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3d00e9fb6079e4b4990b3a14625a93d"><td class="memItemLeft" align="right" valign="top"><a id="ae3d00e9fb6079e4b4990b3a14625a93d"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#ae3d00e9fb6079e4b4990b3a14625a93d">empty_cache</a> ()=0</td></tr>
<tr class="memdesc:ae3d00e9fb6079e4b4990b3a14625a93d"><td class="mdescLeft">&#160;</td><td class="mdescRight">It empties the layer's caches such as those required for the derivation of the function represented by the layer. <br /></td></tr>
<tr class="separator:ae3d00e9fb6079e4b4990b3a14625a93d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ec2fb727209b884263e29759fdf3b39"><td class="memItemLeft" align="right" valign="top">virtual std::vector&lt; const Parameters&lt; Scalar &gt; * &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a0ec2fb727209b884263e29759fdf3b39">get_params</a> () const =0</td></tr>
<tr class="memdesc:a0ec2fb727209b884263e29759fdf3b39"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a vector of constant non-owning pointers to the parameters of the layer.  <a href="#a0ec2fb727209b884263e29759fdf3b39">More...</a><br /></td></tr>
<tr class="separator:a0ec2fb727209b884263e29759fdf3b39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2ec670602524164665de1d0e6eb0b19"><td class="memItemLeft" align="right" valign="top">virtual std::vector&lt; Parameters&lt; Scalar &gt; * &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#ad2ec670602524164665de1d0e6eb0b19">get_params</a> ()=0</td></tr>
<tr class="memdesc:ad2ec670602524164665de1d0e6eb0b19"><td class="mdescLeft">&#160;</td><td class="mdescRight">It returns a vector of non-owning pointers to the parameters of the layer.  <a href="#ad2ec670602524164665de1d0e6eb0b19">More...</a><br /></td></tr>
<tr class="separator:ad2ec670602524164665de1d0e6eb0b19"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c1ea7b25d9f882364b7f2288f02d8da"><td class="memItemLeft" align="right" valign="top">virtual Data&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a6c1ea7b25d9f882364b7f2288f02d8da">pass_forward</a> (Data in, bool training)=0</td></tr>
<tr class="memdesc:a6c1ea7b25d9f882364b7f2288f02d8da"><td class="mdescLeft">&#160;</td><td class="mdescRight">It has the function represented by the layer applied to the input tensor.  <a href="#a6c1ea7b25d9f882364b7f2288f02d8da">More...</a><br /></td></tr>
<tr class="separator:a6c1ea7b25d9f882364b7f2288f02d8da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7cb51862ef9b87632b5abb8e3ab36dd9"><td class="memItemLeft" align="right" valign="top">virtual Data&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a7cb51862ef9b87632b5abb8e3ab36dd9">pass_back</a> (Data out_grad)=0</td></tr>
<tr class="memdesc:a7cb51862ef9b87632b5abb8e3ab36dd9"><td class="mdescLeft">&#160;</td><td class="mdescRight">It back-propagates the derivative of the error function w.r.t.  <a href="#a7cb51862ef9b87632b5abb8e3ab36dd9">More...</a><br /></td></tr>
<tr class="separator:a7cb51862ef9b87632b5abb8e3ab36dd9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac92d606818b5a240d0ce898e35afe63d"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#ac92d606818b5a240d0ce898e35afe63d">is_shared_params_clone</a> () const</td></tr>
<tr class="memdesc:ac92d606818b5a240d0ce898e35afe63d"><td class="mdescLeft">&#160;</td><td class="mdescRight">It determines whether the layer instance is a clone using the shared parameters of another instance.  <a href="#ac92d606818b5a240d0ce898e35afe63d">More...</a><br /></td></tr>
<tr class="separator:ac92d606818b5a240d0ce898e35afe63d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ba02f76506a7f8a72f44be78693209e"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcattle_1_1_layer.html#a3ba02f76506a7f8a72f44be78693209e">is_parametric</a> () const</td></tr>
<tr class="memdesc:a3ba02f76506a7f8a72f44be78693209e"><td class="mdescLeft">&#160;</td><td class="mdescRight">A method that returns whether the layer has parameters.  <a href="#a3ba02f76506a7f8a72f44be78693209e">More...</a><br /></td></tr>
<tr class="separator:a3ba02f76506a7f8a72f44be78693209e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Scalar, std::size_t Rank&gt;<br />
class cattle::Layer&lt; Scalar, Rank &gt;</h3>

<p>An abstract class template representing layers in a neural network. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a46db46c62f3d46c6bbef5a482d7fcb00"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46db46c62f3d46c6bbef5a482d7fcb00">&#9670;&nbsp;</a></span>clone()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt;* <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::clone </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a clone of the layer instance. </p>
<dl class="section return"><dt>Returns</dt><dd>A pointer to a copy of the instance. The instance does not take ownership of the returned pointer (i.e. the caller is responsible for deleting it). </dd></dl>

<p>Implemented in <a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a6080ccef67824a4886b42982186e51aa">cattle::TransConvKernelLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aeaa3fa2d91460475a2e9b970deed5ad2">cattle::ConvKernelLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_012_01_4.html#abe0d88774063296b87ea011c748d81bd">cattle::TransConvKernelLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a5bc6b37c61ab96080ff9615915871212">cattle::ConvKernelLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a18bd4016f07bfc33c27bb518066ff67b">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a>, <a class="el" href="classcattle_1_1_trans_conv_kernel_layer.html#aa8089b96406134523796279412629621">cattle::TransConvKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer.html#a205e894a1bd2a0c8c0a210813c232c21">cattle::ConvKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#a3190763e39f851cf28606dc1b7906f4a">cattle::MaxPoolLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#acee10ea9184f727d8734038b2f390bee">cattle::MeanPoolLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#abf3096d94719bacc657cca0fcad1afb4">cattle::MaxPoolLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer.html#a7e23442f814d994e2989724901001202">cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;</a>, <a class="el" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#a624e7117839125b1c67c1178e381064c">cattle::MeanPoolLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_max_pool_layer.html#a26a24d870ec2b776bc5c229ba01448a7">cattle::MaxPoolLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_dense_kernel_layer.html#ac70aa473ee0b2cd7c18a4575dcadaa0e">cattle::DenseKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_p_re_l_u_activation_layer.html#a103003f64ce9820804834f15d169d6c2">cattle::PReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_mean_pool_layer.html#a78fe029b0af419a4a04fd0526e444445">cattle::MeanPoolLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_p_swish_activation_layer.html#a8908ccf599442daa45682028d79a0871">cattle::PSwishActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_e_l_u_activation_layer.html#aebf72f5b5761fefad869154293156a94">cattle::ELUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#a714166bb7f6525b6abb592bc3f4d6c7d">cattle::LeakyReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_dropout_layer.html#a0206c8917c45b9ac3f4388fa29ab9a26">cattle::DropoutLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softmax_activation_layer.html#a056fd8ef5905c2649e61713c8a4f9f03">cattle::SoftmaxActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_broadcast_layer.html#a44310d6481f10b0ff302979a51b38a1e">cattle::BroadcastLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_reshape_layer.html#ac07e30bf427e0fdf40265ac8ae66cdc3">cattle::ReshapeLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_re_l_u_activation_layer.html#a349bc5ef7264152b47740d52b8b4bf14">cattle::ReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_binary_step_activation_layer.html#a79f59f919c1223cc78750d6d20b72003">cattle::BinaryStepActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_swish_activation_layer.html#a49cfed288be20f14532ec5df4b4b46c2">cattle::SwishActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_scaled_activation_layer.html#a5560ddd8c97a5c8feb8752ccce16d167">cattle::ScaledActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softplus_activation_layer.html#a859e74b009e8b11b735d9f50f133ead9">cattle::SoftplusActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_identity_activation_layer.html#af53b6179ca817e02269113a944f2f08f">cattle::IdentityActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softsign_activation_layer.html#ac2aae3d09d1188e22e60594a14128ee8">cattle::SoftsignActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_sigmoid_activation_layer.html#a4b9fa7dc1973c543265dcbc49e065fa8">cattle::SigmoidActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_tanh_activation_layer.html#a7b573429965fb07969b8affd0503bbb9">cattle::TanhActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_activation_layer.html#acfbb6290f425e0f5d94dbc14d9aabfae">cattle::ActivationLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_pool_layer.html#a40d43922450a2d28e36057256905403e">cattle::PoolLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a074a197df04250449a059d97a4e6e120"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a074a197df04250449a059d97a4e6e120">&#9670;&nbsp;</a></span>clone_with_shared_params()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt;* <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::clone_with_shared_params </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a clone of the layer instance using a reference to the original's parameters. </p>
<p>Non-parametric layers do not need to support parameter sharing and thus are just expected to return a normal clone.</p>
<dl class="section return"><dt>Returns</dt><dd>A clone of the original layer instance sharing the same parameters with the original. </dd></dl>

<p>Implemented in <a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a90e9d65ea84f1c74a74147c71976b318">cattle::TransConvKernelLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a9dcaad150e53f16071543ad8d19079a1">cattle::ConvKernelLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a71a831029bfb45bb75f634ed6f542abc">cattle::TransConvKernelLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#aae11392cc9350c8ac87a0fe0db278a19">cattle::ConvKernelLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ab952d37eca54ad52ec43c632ea6a7856">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a>, <a class="el" href="classcattle_1_1_trans_conv_kernel_layer.html#aa5d15742b7c7c9474fd86445bfa2a4f7">cattle::TransConvKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer.html#a12ec3c5520108283dabf16f90dc9c850">cattle::ConvKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer.html#ab40438ea8902e5bbba29ff6d23b4f187">cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;</a>, <a class="el" href="classcattle_1_1_dense_kernel_layer.html#a849b12085e90cba66e75f6011f0274a9">cattle::DenseKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_p_re_l_u_activation_layer.html#a01e678cea84bc7f952303bc5747e7c3f">cattle::PReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_p_swish_activation_layer.html#a0d6f194ac78749343dbf7eb0e378cc55">cattle::PSwishActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_dropout_layer.html#a14cbbb352c679482e3fe4ce2b970f06a">cattle::DropoutLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_broadcast_layer.html#a9996f83ed27ef7abcb9df3f8f64fc14e">cattle::BroadcastLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_reshape_layer.html#a1ffb24e855f633d0f5e8cc14e108d9fc">cattle::ReshapeLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_activation_layer.html#a2ff3acc579905c6a26c219caaa018993">cattle::ActivationLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_pool_layer.html#a2197c18cdbc8c8e80bc059d8f36a4d5c">cattle::PoolLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a450d75b5f9e084552819ad8fdcf2ad59"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a450d75b5f9e084552819ad8fdcf2ad59">&#9670;&nbsp;</a></span>get_input_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual const <a class="el" href="classcattle_1_1_dimensions.html">Dims</a>&amp; <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::get_input_dims </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>A simple constant getter method for the input dimensionality of the layer. </p>
<dl class="section return"><dt>Returns</dt><dd>A constant reference to the member variable denoting the dimensions of the tensors accepted by the layer as its input (except for the first rank which denotes the variable sample size). </dd></dl>

<p>Implemented in <a class="el" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a8625b962405d6a92b4b5522b937fa51f">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer.html#aebba427879529275913f3f560ec42c5b">cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;</a>, <a class="el" href="classcattle_1_1_dropout_layer.html#af1fd380c06276301044ec6e8111398e1">cattle::DropoutLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_broadcast_layer.html#a678518b45b6c818f1afd1a281cc32070">cattle::BroadcastLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_reshape_layer.html#a56e5cbef834186c11391dd816944f0b4">cattle::ReshapeLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_activation_layer.html#a45399b5559d61e070a3c8202e8f609b1">cattle::ActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_kernel_layer.html#adeda7a9df35daf9f0b75b4241f280591">cattle::KernelLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_pool_layer.html#aa39d93f2aeb8c2adf888d1dbe6bacc4d">cattle::PoolLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="af29a87e0166c1dedc60af30ee392d099"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af29a87e0166c1dedc60af30ee392d099">&#9670;&nbsp;</a></span>get_output_dims()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual const <a class="el" href="classcattle_1_1_dimensions.html">Dims</a>&amp; <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::get_output_dims </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>A simple constant getter method for the output dimensionality of the layer. </p>
<dl class="section return"><dt>Returns</dt><dd>A constant reference to the member variable denoting the dimensions of the tensors output by the layer along all ranks except the first one. </dd></dl>

<p>Implemented in <a class="el" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#aaee7992a15e8016e497ed85e150b1608">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer.html#a85b0b9559f66fe833daffa9936cfee94">cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;</a>, <a class="el" href="classcattle_1_1_dropout_layer.html#a5fdf29e307592b198536aca8d50a81cc">cattle::DropoutLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_broadcast_layer.html#ab7d2bc18c7a32270aff1a68f1ee04f6b">cattle::BroadcastLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_reshape_layer.html#a38b34d57fd7f8053656ea54e9d7eb91b">cattle::ReshapeLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_activation_layer.html#a4c849c9e130f87f059c4267e1ed3102c">cattle::ActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_kernel_layer.html#af1dd40a0c82ece82e605140cb3e4b3c1">cattle::KernelLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_pool_layer.html#ac9f512d4b0a4df20ad1ff86da65e1917">cattle::PoolLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a0ec2fb727209b884263e29759fdf3b39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0ec2fb727209b884263e29759fdf3b39">&#9670;&nbsp;</a></span>get_params() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual std::vector&lt;const Parameters&lt;Scalar&gt;*&gt; <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::get_params </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a vector of constant non-owning pointers to the parameters of the layer. </p>
<dl class="section return"><dt>Returns</dt><dd>A vector of constant pointers to the parameters of the layer. </dd></dl>

<p>Implemented in <a class="el" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a387a4e3752c6c09c7492ec02b1ea28bd">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer.html#a97015b85d3e5536b61d093296bad432d">cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;</a>, <a class="el" href="classcattle_1_1_dropout_layer.html#ae25a9edd15a2ecaab73300cbfb0759dc">cattle::DropoutLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_broadcast_layer.html#abd74301eb230fe2d919bbc57073a8e59">cattle::BroadcastLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_reshape_layer.html#a5f713dcec456922dd9e4616af9a825c3">cattle::ReshapeLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_activation_layer.html#a54dbf69a84dc172d326d7e959d42ec2a">cattle::ActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_kernel_layer.html#a43964c527f383c2b94555b662bd5ee23">cattle::KernelLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_pool_layer.html#a4a57d29cefeac14d42fcf5049921df91">cattle::PoolLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="ad2ec670602524164665de1d0e6eb0b19"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad2ec670602524164665de1d0e6eb0b19">&#9670;&nbsp;</a></span>get_params() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual std::vector&lt;Parameters&lt;Scalar&gt;*&gt; <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::get_params </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a vector of non-owning pointers to the parameters of the layer. </p>
<dl class="section return"><dt>Returns</dt><dd>A vector of pointers to the parameters of the layer. </dd></dl>

<p>Implemented in <a class="el" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#af1b61deed2a5de2a8f9805b197af3d31">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer.html#ac30864573717c53a6e6f7b29b69c3136">cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;</a>, <a class="el" href="classcattle_1_1_dropout_layer.html#a232f450a14225cd09e5c84d5c9040b3f">cattle::DropoutLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_broadcast_layer.html#a291c38b11f97c002a5023cb62c9ee53b">cattle::BroadcastLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_reshape_layer.html#ade468ae978001f582f5f8c1cc15c1eed">cattle::ReshapeLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_activation_layer.html#a847eb6b1764810d926f0a3a93b19b590">cattle::ActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_kernel_layer.html#a13f89d64108eb11ba7de73a5fa037636">cattle::KernelLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_pool_layer.html#a81206a1f6b08fdd52d9d3719bdf18be2">cattle::PoolLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a683f9b67748863329938da07e86ecd8c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a683f9b67748863329938da07e86ecd8c">&#9670;&nbsp;</a></span>get_params_owner()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual const <a class="el" href="classcattle_1_1_layer.html">Layer</a>&lt;Scalar,Rank&gt;&amp; <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::get_params_owner </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It returns a reference to the layer owning the parameters used. </p>
<p>If this owner goes out of scope (in case this one is a clone with shared parameters), the behaviour of the clone is undefined.</p>
<dl class="section return"><dt>Returns</dt><dd>A reference to the layer owning the parameters. If this layer is not using shared parameters, it returns a reference to itself. </dd></dl>

<p>Implemented in <a class="el" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae91b49e8b4eaf586faf27c2147b3e684">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer.html#ad64fb5495e73699d97714883a77056e8">cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;</a>, <a class="el" href="classcattle_1_1_dropout_layer.html#a8fb4d7ea9030d99c74a04902bea3d477">cattle::DropoutLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_broadcast_layer.html#a02660b1012003ef67a1f98730de09489">cattle::BroadcastLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_reshape_layer.html#ac348f24763e65ede1ae53f024b000c18">cattle::ReshapeLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_activation_layer.html#a261c832c58e43392cdede3257e666dec">cattle::ActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_kernel_layer.html#a08d25e205022e91c9d13db75fe1babe1">cattle::KernelLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_pool_layer.html#a5920113d2477183eb7f64a5e92fa2ab6">cattle::PoolLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="af208065ae34cbebcdc932c84383ea159"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af208065ae34cbebcdc932c84383ea159">&#9670;&nbsp;</a></span>is_input_layer()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::is_input_layer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>A constant method that returns whether this layer functions as an input layer. </p>
<p>An input layer does not need to propagate the gradients all the way during the backward pass as it is assumed that no other layer needs them derive the gradient on its parameters. It is therefore possible for an input layer to simply return a null tensor as the output of its backward pass.</p>
<dl class="section return"><dt>Returns</dt><dd>Whether this layer is the input layer of the neural network that contains it. </dd></dl>

<p>Implemented in <a class="el" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a7f46a6d30c7004193fef2b4b75835f28">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer.html#a617e18072bd65f87b90072d9d1288d95">cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;</a>, <a class="el" href="classcattle_1_1_dropout_layer.html#a601eec2c307fd047dd390e2e4347cc58">cattle::DropoutLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_broadcast_layer.html#ab3321ebfcbeeaf3c97a8a3ed4c3d48fc">cattle::BroadcastLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_reshape_layer.html#af25577fd157dbd6a8ddd05d3abdf65ed">cattle::ReshapeLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_activation_layer.html#a3733446d064f63f86f8a48bd30c0dbcb">cattle::ActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_kernel_layer.html#a93f48e39e3e9af884acc8ddd518c45e4">cattle::KernelLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_pool_layer.html#a1f08f1fb9ee99afb1a899a38ff12adbf">cattle::PoolLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a3ba02f76506a7f8a72f44be78693209e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3ba02f76506a7f8a72f44be78693209e">&#9670;&nbsp;</a></span>is_parametric()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::is_parametric </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>A method that returns whether the layer has parameters. </p>
<dl class="section return"><dt>Returns</dt><dd>Whether the layer uses parameters. </dd></dl>

</div>
</div>
<a id="ac92d606818b5a240d0ce898e35afe63d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac92d606818b5a240d0ce898e35afe63d">&#9670;&nbsp;</a></span>is_shared_params_clone()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::is_shared_params_clone </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It determines whether the layer instance is a clone using the shared parameters of another instance. </p>
<dl class="section return"><dt>Returns</dt><dd>Whether the layer instance is a shared-parameter clone. </dd></dl>

</div>
</div>
<a id="a7cb51862ef9b87632b5abb8e3ab36dd9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7cb51862ef9b87632b5abb8e3ab36dd9">&#9670;&nbsp;</a></span>pass_back()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual Data <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::pass_back </td>
          <td>(</td>
          <td class="paramtype">Data&#160;</td>
          <td class="paramname"><em>out_grad</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It back-propagates the derivative of the error function w.r.t. </p>
<p>the output of the layer updating the gradient of its learnable parameters along the way if there are any.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out_grad</td><td>The derivative of the loss function w.r.t. the output of the layer </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The derivative of the loss function w.r.t. the output of the previous layer or a null tensor if the layer is an input layer. </dd></dl>

<p>Implemented in <a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aedee9c48d1aae1c3294d3a597283d011">cattle::TransConvKernelLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a93619900866409b99543510a099855b3">cattle::ConvKernelLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ad1b665c616770249569c831b9bef076c">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a>, <a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_012_01_4.html#ac1642b1ab224abe74e9076d83637d7e4">cattle::TransConvKernelLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a2379f9e643bf7e47a33f4e0a5e7bc2c1">cattle::ConvKernelLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_trans_conv_kernel_layer.html#ab054dd53afc8785e549a1f9bd1718d30">cattle::TransConvKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer.html#af1423e99f6cbf2fe5ea5780aa46945a2">cattle::ConvKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#a4766dca992a2b2255a3bb8800dc00dc2">cattle::MaxPoolLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer.html#a1cc2a6f67e5d6b8e7f7996a9267b7401">cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;</a>, <a class="el" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#a420dc3d7bbed6bfa1c706bc927ca7b25">cattle::MaxPoolLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#ae48c09c01819911fb2ed189b0203beb1">cattle::MeanPoolLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#a8f3dcbc5d06b5c461c7df214c2263e54">cattle::MeanPoolLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_max_pool_layer.html#a50a2546e78f1e39a9fef5fcc4dbc10ca">cattle::MaxPoolLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_dense_kernel_layer.html#a38cac34fd04b0cde05f4f803d5aac5c1">cattle::DenseKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_p_re_l_u_activation_layer.html#a03db64ab6a9f91966257269af1662373">cattle::PReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_dropout_layer.html#a7d71b25a0789d9b8b852f9fdfd86f183">cattle::DropoutLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_p_swish_activation_layer.html#a1d5a8b953b4d2533e4d8e2baf2b24860">cattle::PSwishActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_mean_pool_layer.html#aea2085455b95f06f2046085af0275a67">cattle::MeanPoolLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_broadcast_layer.html#a1f24f60a80843b341131b87270f02ec5">cattle::BroadcastLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_reshape_layer.html#a9ce0f661d35ef7efa79885e76dec673a">cattle::ReshapeLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_e_l_u_activation_layer.html#a712f1ee68d924b13db82dce302ba2b20">cattle::ELUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softmax_activation_layer.html#a8ccc8f03783ec2791aabf328ebcc855e">cattle::SoftmaxActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#aea6e407de7b9a8c3dd366e6f89823bc4">cattle::LeakyReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_swish_activation_layer.html#a5434963c7955b090aed37844ab47441b">cattle::SwishActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_re_l_u_activation_layer.html#a3f50854f7aaf891eccf373b8f70cb3d7">cattle::ReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_binary_step_activation_layer.html#a934bfb1068ace14920a2ccc0277668e2">cattle::BinaryStepActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softplus_activation_layer.html#a93b157a4de8aad27a722f9acb5e6aaff">cattle::SoftplusActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softsign_activation_layer.html#a10ece7c1af4ebfdfaf03f2c64b05c2b5">cattle::SoftsignActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_scaled_activation_layer.html#ab734027e0de3a17a15e4cb3f0fac4da2">cattle::ScaledActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_sigmoid_activation_layer.html#a1b3bf686340f3b716d11425fc93431d4">cattle::SigmoidActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_tanh_activation_layer.html#ab22a9baac0d6e0285f837b8c8c8f2e07">cattle::TanhActivationLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_identity_activation_layer.html#ab6e4a91524b3a535c74b7804e8c0097f">cattle::IdentityActivationLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a6c1ea7b25d9f882364b7f2288f02d8da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c1ea7b25d9f882364b7f2288f02d8da">&#9670;&nbsp;</a></span>pass_forward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual Data <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::pass_forward </td>
          <td>(</td>
          <td class="paramtype">Data&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>training</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>It has the function represented by the layer applied to the input tensor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>A tensor representing a batch of observations. The observations are of the rank specified by the layer's template parameter and the input tensors rank is one greater. </td></tr>
    <tr><td class="paramname">training</td><td>Whether the input is to be processed in training or inference mode. If the forward pass is performed in inference mode, the backward pass is not guaranteed to work. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output of the function represented by the layer applied to the input tensor. </dd></dl>

<p>Implemented in <a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_011_01_4.html#a03735bb0f5601752db5c420a6bece3ff">cattle::TransConvKernelLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_011_01_4.html#aaf1ed54777882941a705fdd94595fc5c">cattle::ConvKernelLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_trans_conv_kernel_layer_3_01_scalar_00_012_01_4.html#a7f980247497974536d6531431b22db59">cattle::TransConvKernelLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#ae01fe5aa00615cab21ac81babf2756b2">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer_3_01_scalar_00_012_01_4.html#ac391887510fae8472b7ea92b7f4d6114">cattle::ConvKernelLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_trans_conv_kernel_layer.html#af218557f56d84df306fb763bbfa50af0">cattle::TransConvKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_conv_kernel_layer.html#abb6ecb02b8f801f151e345a2735efd2a">cattle::ConvKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_011_01_4.html#ae8f4e95932e2d890d7d475198522e0bd">cattle::MaxPoolLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer.html#a220d347e28e8456fbaa42e8b37ff565d">cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;</a>, <a class="el" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_011_01_4.html#a8bddebf1d3fcfdafbdd1c4e93b3294dd">cattle::MeanPoolLayer&lt; Scalar, 1 &gt;</a>, <a class="el" href="classcattle_1_1_max_pool_layer_3_01_scalar_00_012_01_4.html#a230df133932f7c470be5d6c796c3ca87">cattle::MaxPoolLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_mean_pool_layer_3_01_scalar_00_012_01_4.html#adf15353dcff3915634b18f3bbd533c6c">cattle::MeanPoolLayer&lt; Scalar, 2 &gt;</a>, <a class="el" href="classcattle_1_1_max_pool_layer.html#a735124db085951aad791d44b24485610">cattle::MaxPoolLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_dense_kernel_layer.html#a89706a4d8b43b46dd3df65f2c0340969">cattle::DenseKernelLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_p_re_l_u_activation_layer.html#a2c4c775a8f711ecce2636d71b4d31c77">cattle::PReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_p_swish_activation_layer.html#a55177f124396da9ed5d9a6356cd676f5">cattle::PSwishActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_dropout_layer.html#a0c833b2176304d5f975e7f66ac203d15">cattle::DropoutLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_mean_pool_layer.html#a6a011291cc3fc7a494a462f499ea3a8f">cattle::MeanPoolLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_broadcast_layer.html#a47b9545f9324f4a039e7cd94a0f590d3">cattle::BroadcastLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_reshape_layer.html#ad90d03809c1a76aee78463a25c7724a3">cattle::ReshapeLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_e_l_u_activation_layer.html#a67800526be3ccda15d3b5c6f8c2d4f2e">cattle::ELUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_leaky_re_l_u_activation_layer.html#aa9ac55adebb9725a86db28ed148d22f0">cattle::LeakyReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softmax_activation_layer.html#a627e9ccac859cacac5e7ade52be93142">cattle::SoftmaxActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_re_l_u_activation_layer.html#ae53d86eece7966ace131af941bb6e095">cattle::ReLUActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_swish_activation_layer.html#ad2d918f28cb80019cde160152d85650e">cattle::SwishActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_binary_step_activation_layer.html#ac4ea89bab72ee953cb38dcd31b89041e">cattle::BinaryStepActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softplus_activation_layer.html#a4cff59f6b0eab448d9ca41ba99261c31">cattle::SoftplusActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_softsign_activation_layer.html#ac1c1cf2b0fdcd49fd896c12147995ca1">cattle::SoftsignActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_scaled_activation_layer.html#a42aa507a420c05fb92231beb2771384e">cattle::ScaledActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_sigmoid_activation_layer.html#aa5501e54efa3a5ec8bc7e1dc7025d102">cattle::SigmoidActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_tanh_activation_layer.html#a8376f4a0a7162753dafa16f5c10bb220">cattle::TanhActivationLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_identity_activation_layer.html#aa66b095d8084fecdddaaeade76728bb6">cattle::IdentityActivationLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<a id="a9557e077d940b2ff0c280e9a78c4b52e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9557e077d940b2ff0c280e9a78c4b52e">&#9670;&nbsp;</a></span>set_input_layer()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Scalar, std::size_t Rank&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classcattle_1_1_layer.html">cattle::Layer</a>&lt; Scalar, Rank &gt;::set_input_layer </td>
          <td>(</td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>input_layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Sets this instance's input layer status to the given value. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_layer</td><td>Whether this layer is to be an input layer or not. </td></tr>
  </table>
  </dd>
</dl>

<p>Implemented in <a class="el" href="classcattle_1_1_batch_norm_layer_3_01_scalar_00_01_rank_00_01false_01_4.html#a6aebaf7cd158c35983c27f691c80a5bd">cattle::BatchNormLayer&lt; Scalar, Rank, false &gt;</a>, <a class="el" href="classcattle_1_1_batch_norm_layer.html#a66300725f60f30bd773d47f2dea19f46">cattle::BatchNormLayer&lt; Scalar, Rank, PerLastRank &gt;</a>, <a class="el" href="classcattle_1_1_dropout_layer.html#ae1d090be4a0c212daaf625f5acbd9f22">cattle::DropoutLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_broadcast_layer.html#ac454d37d09cc063531c2e750f45cf511">cattle::BroadcastLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_reshape_layer.html#a57c06bd60a7784adde787012e2b78178">cattle::ReshapeLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_activation_layer.html#a34972577a520dc5e4d34d40c448f127b">cattle::ActivationLayer&lt; Scalar, Rank &gt;</a>, <a class="el" href="classcattle_1_1_kernel_layer.html#a2cfd231e456e1f828dc3638b3a5eb0c7">cattle::KernelLayer&lt; Scalar, Rank &gt;</a>, and <a class="el" href="classcattle_1_1_pool_layer.html#a584687e28d220062f36ec67d0cf90054">cattle::PoolLayer&lt; Scalar, Rank &gt;</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>C:/Users/Viktor/git/C-ATTL3/C-ATTL3/core/<a class="el" href="_layer_8hpp_source.html">Layer.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
